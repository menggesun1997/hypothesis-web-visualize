[
  {
    "paperId": "pub.1185893146",
    "doi": "10.1002/2211-5463.70003",
    "title": "Beyond digital twins: the role of foundation models in enhancing the interpretability of multiomics modalities in precision medicine",
    "year": 2025,
    "citationCount": 1,
    "fieldCitationRatio": NaN,
    "abstract": "Medical digital twins (MDTs) are virtual representations of patients that simulate the biological, physiological, and clinical processes of individuals to enable personalized medicine. With the increasing complexity of omics data, particularly multiomics, there is a growing need for advanced computational frameworks to interpret these data effectively. Foundation models (FMs), large-scale machine learning models pretrained on diverse data types, have recently emerged as powerful tools for improving data interpretability and decision-making in precision medicine. This review discusses the integration of FMs into MDT systems, particularly their role in enhancing the interpretability of multiomics data. We examine current challenges, recent advancements, and future opportunities in leveraging FMs for multiomics analysis in MDTs, with a focus on their application in precision medicine.",
    "reference_ids": [
      "pub.1139612475",
      "pub.1170800734",
      "pub.1154603556",
      "pub.1135602046",
      "pub.1141246169",
      "pub.1170734252",
      "pub.1154925256",
      "pub.1148565704",
      "pub.1139502929",
      "pub.1150075926",
      "pub.1149785769",
      "pub.1140066078",
      "pub.1155107690",
      "pub.1144359242",
      "pub.1073310782",
      "pub.1123797102",
      "pub.1048467366",
      "pub.1160604018",
      "pub.1135341938",
      "pub.1160645506",
      "pub.1168695323",
      "pub.1140547342",
      "pub.1143520556",
      "pub.1150266304",
      "pub.1140673190",
      "pub.1157402878",
      "pub.1157184122",
      "pub.1149920738",
      "pub.1172075977",
      "pub.1130929567",
      "pub.1166418780",
      "pub.1125622025",
      "pub.1133174567",
      "pub.1133177140",
      "pub.1154557609",
      "pub.1161672315",
      "pub.1170247597",
      "pub.1120516167",
      "pub.1165103854",
      "pub.1169823524",
      "pub.1141942664",
      "pub.1144466022",
      "pub.1160684974",
      "pub.1164046301",
      "pub.1099136894",
      "pub.1150078820",
      "pub.1160827625",
      "pub.1171626158",
      "pub.1144520708",
      "pub.1099151330",
      "pub.1184689199",
      "pub.1059414285",
      "pub.1163991365",
      "pub.1140296749",
      "pub.1169027555",
      "pub.1160666885",
      "pub.1171599555",
      "pub.1156513821",
      "pub.1132358894",
      "pub.1168984708",
      "pub.1145167333",
      "pub.1170001554",
      "pub.1163044790",
      "pub.1150234226",
      "pub.1138202955",
      "pub.1155857207",
      "pub.1173618196",
      "pub.1120882528",
      "pub.1173663320",
      "pub.1151222914",
      "pub.1138840297",
      "pub.1149465382",
      "pub.1175902526",
      "pub.1172532425",
      "pub.1163198905",
      "pub.1156416113",
      "pub.1119417047",
      "pub.1155193455",
      "pub.1151616046",
      "pub.1145023578",
      "pub.1170999170",
      "pub.1165802589",
      "pub.1173387757",
      "pub.1160011251",
      "pub.1135112882",
      "pub.1160542559",
      "pub.1167605502",
      "pub.1169869471",
      "pub.1160635088",
      "pub.1138840042",
      "pub.1140542709",
      "pub.1038436955",
      "pub.1152760769",
      "pub.1165266957",
      "pub.1167703866",
      "pub.1134089846",
      "pub.1171066308",
      "pub.1170063038",
      "pub.1117372596",
      "pub.1141522418",
      "pub.1112590730",
      "pub.1162713541",
      "pub.1154573607",
      "pub.1154236140",
      "pub.1155095969",
      "pub.1139691916",
      "pub.1131794605",
      "pub.1133174582",
      "pub.1163911973",
      "pub.1122233512",
      "pub.1149338327",
      "pub.1138614283",
      "pub.1111334730",
      "pub.1148764672"
    ],
    "concepts_scores": [
      {
        "concept": "precision medicine",
        "relevance": 0.513
      },
      {
        "concept": "omics data",
        "relevance": 0.472
      },
      {
        "concept": "multiomics data",
        "relevance": 0.467
      },
      {
        "concept": "multiomics analysis",
        "relevance": 0.463
      },
      {
        "concept": "medical digital twins",
        "relevance": 0.459
      },
      {
        "concept": "diverse data types",
        "relevance": 0.458
      },
      {
        "concept": "personalized medicine",
        "relevance": 0.433
      },
      {
        "concept": "large-scale machine learning models",
        "relevance": 0.431
      },
      {
        "concept": "multiomics",
        "relevance": 0.416
      },
      {
        "concept": "advanced computational framework",
        "relevance": 0.404
      },
      {
        "concept": "machine learning models",
        "relevance": 0.395
      },
      {
        "concept": "digital twin",
        "relevance": 0.391
      },
      {
        "concept": "representation of patients",
        "relevance": 0.378
      },
      {
        "concept": "learning models",
        "relevance": 0.368
      },
      {
        "concept": "data types",
        "relevance": 0.367
      },
      {
        "concept": "virtual representation",
        "relevance": 0.363
      },
      {
        "concept": "improving data interpretation",
        "relevance": 0.362
      },
      {
        "concept": "computational framework",
        "relevance": 0.352
      },
      {
        "concept": "increasing complexity",
        "relevance": 0.338
      },
      {
        "concept": "medicine",
        "relevance": 0.329
      },
      {
        "concept": "foundation model",
        "relevance": 0.327
      },
      {
        "concept": "patients",
        "relevance": 0.321
      },
      {
        "concept": "modalities",
        "relevance": 0.303
      },
      {
        "concept": "clinical processes",
        "relevance": 0.296
      },
      {
        "concept": "precision",
        "relevance": 0.289
      },
      {
        "concept": "data interpretation",
        "relevance": 0.284
      },
      {
        "concept": "decision-making",
        "relevance": 0.282
      },
      {
        "concept": "type",
        "relevance": 0.278
      },
      {
        "concept": "review",
        "relevance": 0.274
      },
      {
        "concept": "data",
        "relevance": 0.26
      },
      {
        "concept": "individuals",
        "relevance": 0.258
      },
      {
        "concept": "model",
        "relevance": 0.253
      },
      {
        "concept": "twin",
        "relevance": 0.252
      },
      {
        "concept": "framework",
        "relevance": 0.252
      },
      {
        "concept": "process of individuation",
        "relevance": 0.247
      },
      {
        "concept": "analysis",
        "relevance": 0.24
      },
      {
        "concept": "interpretation",
        "relevance": 0.231
      },
      {
        "concept": "system",
        "relevance": 0.228
      },
      {
        "concept": "advances",
        "relevance": 0.225
      },
      {
        "concept": "integration",
        "relevance": 0.219
      },
      {
        "concept": "challenges",
        "relevance": 0.215
      },
      {
        "concept": "foundations",
        "relevance": 0.198
      },
      {
        "concept": "opportunities",
        "relevance": 0.184
      }
    ]
  },
  {
    "paperId": "pub.1181316862",
    "doi": "10.3389/frai.2024.1460364",
    "title": "Large language models for whole-learner support: opportunities and challenges",
    "year": 2024,
    "citationCount": 6,
    "fieldCitationRatio": NaN,
    "abstract": "In recent years, large language models (LLMs) have seen rapid advancement and adoption, and are increasingly being used in educational contexts. In this perspective article, we explore the open challenge of leveraging LLMs to create personalized learning environments that support the \"whole learner\" by modeling and adapting to both cognitive and non-cognitive characteristics. We identify three key challenges toward this vision: (1) improving the interpretability of LLMs' representations of whole learners, (2) implementing adaptive technologies that can leverage such representations to provide tailored pedagogical support, and (3) authoring and evaluating LLM-based educational agents. For interpretability, we discuss approaches for explaining LLM behaviors in terms of their internal representations of learners; for adaptation, we examine how LLMs can be used to provide context-aware feedback and scaffold non-cognitive skills through natural language interactions; and for authoring, we highlight the opportunities and challenges involved in using natural language instructions to specify behaviors of educational agents. Addressing these challenges will enable personalized AI tutors that can enhance learning by accounting for each student's unique background, abilities, motivations, and socioemotional needs.",
    "reference_ids": [
      "pub.1160236758",
      "pub.1148691214",
      "pub.1118944844",
      "pub.1157409883",
      "pub.1163044197",
      "pub.1119139261",
      "pub.1007877204",
      "pub.1127904281",
      "pub.1161706903",
      "pub.1125460778",
      "pub.1139350525",
      "pub.1147478078",
      "pub.1168623357",
      "pub.1019724917",
      "pub.1156524438",
      "pub.1119424518",
      "pub.1166623280",
      "pub.1167360779",
      "pub.1158657407",
      "pub.1157124644",
      "pub.1168590416",
      "pub.1172695247",
      "pub.1092715308",
      "pub.1137540950",
      "pub.1168590380",
      "pub.1160757501",
      "pub.1172299402",
      "pub.1170393471",
      "pub.1137378140",
      "pub.1131768885",
      "pub.1169657295",
      "pub.1152315820",
      "pub.1128698813",
      "pub.1162260418",
      "pub.1128995025",
      "pub.1168964548",
      "pub.1148391035",
      "pub.1151357062",
      "pub.1119368332",
      "pub.1163033266",
      "pub.1166679840",
      "pub.1166873601",
      "pub.1023485861",
      "pub.1127521026",
      "pub.1136404423",
      "pub.1157666249",
      "pub.1119428074",
      "pub.1155883103",
      "pub.1092690269",
      "pub.1159783896",
      "pub.1155381802",
      "pub.1111260834",
      "pub.1099108309"
    ],
    "concepts_scores": [
      {
        "concept": "educational agents",
        "relevance": 0.732
      },
      {
        "concept": "personal learning environments",
        "relevance": 0.681
      },
      {
        "concept": "non-cognitive characteristics",
        "relevance": 0.672
      },
      {
        "concept": "non-cognitive skills",
        "relevance": 0.671
      },
      {
        "concept": "educational context",
        "relevance": 0.633
      },
      {
        "concept": "learning environment",
        "relevance": 0.631
      },
      {
        "concept": "pedagogical support",
        "relevance": 0.631
      },
      {
        "concept": "AI tutor",
        "relevance": 0.629
      },
      {
        "concept": "language instruction",
        "relevance": 0.628
      },
      {
        "concept": "language model",
        "relevance": 0.624
      },
      {
        "concept": "enhance learning",
        "relevance": 0.623
      },
      {
        "concept": "socioemotional needs",
        "relevance": 0.62
      },
      {
        "concept": "language interaction",
        "relevance": 0.6
      },
      {
        "concept": "learners",
        "relevance": 0.599
      },
      {
        "concept": "natural language instructions",
        "relevance": 0.589
      },
      {
        "concept": "natural language interaction",
        "relevance": 0.587
      },
      {
        "concept": "unique background",
        "relevance": 0.587
      },
      {
        "concept": "context-aware feedback",
        "relevance": 0.572
      },
      {
        "concept": "adaptive technology",
        "relevance": 0.559
      },
      {
        "concept": "language",
        "relevance": 0.513
      },
      {
        "concept": "opportunities",
        "relevance": 0.504
      },
      {
        "concept": "internal representation",
        "relevance": 0.497
      },
      {
        "concept": "tutors",
        "relevance": 0.494
      },
      {
        "concept": "students",
        "relevance": 0.49
      },
      {
        "concept": "instruction",
        "relevance": 0.484
      },
      {
        "concept": "learning",
        "relevance": 0.481
      },
      {
        "concept": "skills",
        "relevance": 0.474
      },
      {
        "concept": "motivation",
        "relevance": 0.461
      },
      {
        "concept": "LLM",
        "relevance": 0.442
      },
      {
        "concept": "Rapid advancement",
        "relevance": 0.441
      },
      {
        "concept": "authors",
        "relevance": 0.433
      },
      {
        "concept": "context",
        "relevance": 0.417
      },
      {
        "concept": "needs",
        "relevance": 0.416
      },
      {
        "concept": "feedback",
        "relevance": 0.411
      },
      {
        "concept": "ability",
        "relevance": 0.398
      },
      {
        "concept": "article",
        "relevance": 0.394
      },
      {
        "concept": "support",
        "relevance": 0.382
      },
      {
        "concept": "challenges",
        "relevance": 0.38
      },
      {
        "concept": "background",
        "relevance": 0.378
      },
      {
        "concept": "representation",
        "relevance": 0.375
      },
      {
        "concept": "vision",
        "relevance": 0.362
      },
      {
        "concept": "technology",
        "relevance": 0.361
      },
      {
        "concept": "environment",
        "relevance": 0.357
      },
      {
        "concept": "adoption",
        "relevance": 0.349
      },
      {
        "concept": "interpretation",
        "relevance": 0.348
      },
      {
        "concept": "model",
        "relevance": 0.339
      },
      {
        "concept": "approach",
        "relevance": 0.338
      },
      {
        "concept": "scaffolds",
        "relevance": 0.313
      },
      {
        "concept": "years",
        "relevance": 0.311
      },
      {
        "concept": "adaptation",
        "relevance": 0.311
      },
      {
        "concept": "behavior",
        "relevance": 0.297
      },
      {
        "concept": "advances",
        "relevance": 0.288
      },
      {
        "concept": "interaction",
        "relevance": 0.278
      },
      {
        "concept": "agents",
        "relevance": 0.244
      },
      {
        "concept": "characteristics",
        "relevance": 0.243
      }
    ]
  },
  {
    "paperId": "pub.1185063598",
    "doi": "10.3389/frai.2025.1477246",
    "title": "Analysis of argument structure constructions in the large language model BERT",
    "year": 2025,
    "citationCount": 5,
    "fieldCitationRatio": NaN,
    "abstract": "Understanding how language and linguistic constructions are processed in the brain is a fundamental question in cognitive computational neuroscience. In this study, we investigate the processing and representation of Argument Structure Constructions (ASCs) in the BERT language model, extending previous analyses conducted with Long Short-Term Memory (LSTM) networks. We utilized a custom GPT-4 generated dataset comprising 2000 sentences, evenly distributed among four ASC types: transitive, ditransitive, caused-motion, and resultative constructions. BERT was assessed using the various token embeddings across its 12 layers. Our analyses involved visualizing the embeddings with Multidimensional Scaling (MDS) and t-Distributed Stochastic Neighbor Embedding (t-SNE), and calculating the Generalized Discrimination Value (GDV) to quantify the degree of clustering. We also trained feedforward classifiers (probes) to predict construction categories from these embeddings. Results reveal that CLS token embeddings cluster best according to ASC types in layers 2, 3, and 4, with diminished clustering in intermediate layers and a slight increase in the final layers. Token embeddings for DET and SUBJ showed consistent intermediate-level clustering across layers, while VERB embeddings demonstrated a systematic increase in clustering from layer 1 to 12. OBJ embeddings exhibited minimal clustering initially, which increased substantially, peaking in layer 10. Probe accuracies indicated that initial embeddings contained no specific construction information, as seen in low clustering and chance-level accuracies in layer 1. From layer 2 onward, probe accuracies surpassed 90 percent, highlighting latent construction category information not evident from GDV clustering alone. Additionally, Fisher Discriminant Ratio (FDR) analysis of attention weights revealed that OBJ tokens had the highest FDR scores, indicating they play a crucial role in differentiating ASCs, followed by VERB and DET tokens. SUBJ, CLS, and SEP tokens did not show significant FDR scores. Our study underscores the complex, layered processing of linguistic constructions in BERT, revealing both similarities and differences compared to recurrent models like LSTMs. Future research will compare these computational findings with neuroimaging data during continuous speech perception to better understand the neural correlates of ASC processing. This research demonstrates the potential of both recurrent and transformer-based neural language models to mirror linguistic processing in the human brain, offering valuable insights into the computational and neural mechanisms underlying language understanding.",
    "reference_ids": [
      "pub.1018964677",
      "pub.1121025044",
      "pub.1136963456",
      "pub.1008411626",
      "pub.1113303335",
      "pub.1041424734",
      "pub.1136337349",
      "pub.1143777714",
      "pub.1163042322",
      "pub.1111963452",
      "pub.1150865996",
      "pub.1163043515",
      "pub.1113327075",
      "pub.1130863323",
      "pub.1118441415",
      "pub.1154955846",
      "pub.1136924088",
      "pub.1164574991",
      "pub.1174540913",
      "pub.1061398159",
      "pub.1163045657",
      "pub.1100484362",
      "pub.1163991029",
      "pub.1163043646",
      "pub.1016513253",
      "pub.1134455541",
      "pub.1168919128",
      "pub.1169920601",
      "pub.1101774663",
      "pub.1112124139",
      "pub.1152643147",
      "pub.1175187753",
      "pub.1119353072",
      "pub.1123085085",
      "pub.1139187623",
      "pub.1155178717",
      "pub.1182811574",
      "pub.1119371501",
      "pub.1166071406",
      "pub.1142528212",
      "pub.1038140272",
      "pub.1087156990",
      "pub.1153865028",
      "pub.1120961786",
      "pub.1164905011",
      "pub.1004309834",
      "pub.1158187517",
      "pub.1018592673",
      "pub.1090806672",
      "pub.1119813541",
      "pub.1121024948",
      "pub.1173776264",
      "pub.1122290462",
      "pub.1123086186",
      "pub.1182811701",
      "pub.1061398162",
      "pub.1061398464",
      "pub.1130014351",
      "pub.1020406516",
      "pub.1141625582",
      "pub.1132475377",
      "pub.1147382082",
      "pub.1162656499",
      "pub.1121025776",
      "pub.1148390987",
      "pub.1049993707",
      "pub.1101853038",
      "pub.1166872087"
    ],
    "concepts_scores": [
      {
        "concept": "argument structure constructions",
        "relevance": 0.775
      },
      {
        "concept": "long short-term memory",
        "relevance": 0.718
      },
      {
        "concept": "t-distributed stochastic neighbor embedding",
        "relevance": 0.668
      },
      {
        "concept": "continuous speech perception",
        "relevance": 0.638
      },
      {
        "concept": "chance-level accuracy",
        "relevance": 0.629
      },
      {
        "concept": "linguistic constructions",
        "relevance": 0.625
      },
      {
        "concept": "probe accuracy",
        "relevance": 0.6
      },
      {
        "concept": "BERT language model",
        "relevance": 0.587
      },
      {
        "concept": "neural correlates",
        "relevance": 0.587
      },
      {
        "concept": "language model BERT",
        "relevance": 0.584
      },
      {
        "concept": "linguistic processing",
        "relevance": 0.581
      },
      {
        "concept": "short-term memory",
        "relevance": 0.579
      },
      {
        "concept": "neural mechanisms",
        "relevance": 0.579
      },
      {
        "concept": "neuroimaging data",
        "relevance": 0.573
      },
      {
        "concept": "structure construction",
        "relevance": 0.568
      },
      {
        "concept": "speech perception",
        "relevance": 0.565
      },
      {
        "concept": "stochastic neighbor embedding",
        "relevance": 0.56
      },
      {
        "concept": "caused-motion",
        "relevance": 0.549
      },
      {
        "concept": "layer 2",
        "relevance": 0.549
      },
      {
        "concept": "attention weights",
        "relevance": 0.543
      },
      {
        "concept": "model BERT",
        "relevance": 0.542
      },
      {
        "concept": "human brain",
        "relevance": 0.542
      },
      {
        "concept": "language model",
        "relevance": 0.541
      },
      {
        "concept": "resultative constructions",
        "relevance": 0.541
      },
      {
        "concept": "language understanding",
        "relevance": 0.538
      },
      {
        "concept": "computational neuroscience",
        "relevance": 0.528
      },
      {
        "concept": "BERT",
        "relevance": 0.526
      },
      {
        "concept": "Multidimensional Scaling (MDS",
        "relevance": 0.526
      },
      {
        "concept": "neighbor embedding",
        "relevance": 0.526
      },
      {
        "concept": "verbs",
        "relevance": 0.516
      },
      {
        "concept": "initial embedding",
        "relevance": 0.515
      },
      {
        "concept": "recurrent model",
        "relevance": 0.51
      },
      {
        "concept": "language",
        "relevance": 0.509
      },
      {
        "concept": "embedding",
        "relevance": 0.507
      },
      {
        "concept": "tokens",
        "relevance": 0.502
      },
      {
        "concept": "brain",
        "relevance": 0.489
      },
      {
        "concept": "construct categories",
        "relevance": 0.489
      },
      {
        "concept": "OBJ",
        "relevance": 0.472
      },
      {
        "concept": "layer 1",
        "relevance": 0.464
      },
      {
        "concept": "low cluster",
        "relevance": 0.452
      },
      {
        "concept": "accuracy",
        "relevance": 0.447
      },
      {
        "concept": "scores",
        "relevance": 0.447
      },
      {
        "concept": "Subje",
        "relevance": 0.44
      },
      {
        "concept": "neuroscience",
        "relevance": 0.437
      },
      {
        "concept": "memory",
        "relevance": 0.431
      },
      {
        "concept": "sentences",
        "relevance": 0.429
      },
      {
        "concept": "construction information",
        "relevance": 0.424
      },
      {
        "concept": "classifier",
        "relevance": 0.422
      },
      {
        "concept": "discriminative value",
        "relevance": 0.417
      },
      {
        "concept": "information",
        "relevance": 0.412
      },
      {
        "concept": "clusters",
        "relevance": 0.41
      },
      {
        "concept": "construction",
        "relevance": 0.407
      },
      {
        "concept": "dataset",
        "relevance": 0.402
      },
      {
        "concept": "network",
        "relevance": 0.397
      },
      {
        "concept": "research",
        "relevance": 0.38
      },
      {
        "concept": "perception",
        "relevance": 0.379
      },
      {
        "concept": "layer processes",
        "relevance": 0.377
      },
      {
        "concept": "representation",
        "relevance": 0.376
      },
      {
        "concept": "findings",
        "relevance": 0.367
      },
      {
        "concept": "intermediate layer",
        "relevance": 0.363
      },
      {
        "concept": "model",
        "relevance": 0.358
      },
      {
        "concept": "customers",
        "relevance": 0.358
      },
      {
        "concept": "study",
        "relevance": 0.347
      },
      {
        "concept": "generalization",
        "relevance": 0.345
      },
      {
        "concept": "MDS",
        "relevance": 0.341
      },
      {
        "concept": "process",
        "relevance": 0.339
      },
      {
        "concept": "differences",
        "relevance": 0.337
      },
      {
        "concept": "categories",
        "relevance": 0.335
      },
      {
        "concept": "understanding",
        "relevance": 0.334
      },
      {
        "concept": "systematic increase",
        "relevance": 0.326
      },
      {
        "concept": "similarity",
        "relevance": 0.322
      },
      {
        "concept": "layer",
        "relevance": 0.304
      },
      {
        "concept": "degree of clustering",
        "relevance": 0.304
      },
      {
        "concept": "DET",
        "relevance": 0.301
      },
      {
        "concept": "complex",
        "relevance": 0.295
      },
      {
        "concept": "analysis",
        "relevance": 0.293
      },
      {
        "concept": "increase",
        "relevance": 0.287
      },
      {
        "concept": "data",
        "relevance": 0.281
      },
      {
        "concept": "longer",
        "relevance": 0.28
      },
      {
        "concept": "results",
        "relevance": 0.271
      },
      {
        "concept": "mechanism",
        "relevance": 0.265
      },
      {
        "concept": "CLS",
        "relevance": 0.264
      },
      {
        "concept": "computational findings",
        "relevance": 0.259
      },
      {
        "concept": "probe",
        "relevance": 0.246
      },
      {
        "concept": "type",
        "relevance": 0.242
      },
      {
        "concept": "diminished clustering",
        "relevance": 0.239
      },
      {
        "concept": "degree",
        "relevance": 0.238
      },
      {
        "concept": "weight",
        "relevance": 0.238
      },
      {
        "concept": "Fisher",
        "relevance": 0.235
      },
      {
        "concept": "potential",
        "relevance": 0.22
      },
      {
        "concept": "values",
        "relevance": 0.204
      }
    ]
  },
  {
    "paperId": "pub.1164479057",
    "doi": "10.1002/alz.13479",
    "title": "Artificial intelligence for neurodegenerative experimental models",
    "year": 2023,
    "citationCount": 14,
    "fieldCitationRatio": 9.24,
    "abstract": "INTRODUCTION: Experimental models are essential tools in neurodegenerative disease research. However, the translation of insights and drugs discovered in model systems has proven immensely challenging, marred by high failure rates in human clinical trials.\nMETHODS: Here we review the application of artificial intelligence (AI) and machine learning (ML) in experimental medicine for dementia research.\nRESULTS: Considering the specific challenges of reproducibility and translation between other species or model systems and human biology in preclinical dementia research, we highlight best practices and resources that can be leveraged to quantify and evaluate translatability. We then evaluate how AI and ML approaches could be applied to enhance both cross-model reproducibility and translation to human biology, while sustaining biological interpretability.\nDISCUSSION: AI and ML approaches in experimental medicine remain in their infancy. However, they have great potential to strengthen preclinical research and translation if based upon adequate, robust, and reproducible experimental data.\nHIGHLIGHTS: There are increasing applications of AI in experimental medicine. We identified issues in reproducibility, cross-species translation, and data curation in the field. Our review highlights data resources and AI approaches as solutions. Multi-omics analysis with AI offers exciting future possibilities in drug discovery.",
    "reference_ids": [
      "pub.1110062860",
      "pub.1016278802",
      "pub.1025396152",
      "pub.1120396052",
      "pub.1131393553",
      "pub.1127885244",
      "pub.1140739853",
      "pub.1127243370",
      "pub.1129128665",
      "pub.1153906722",
      "pub.1028819119",
      "pub.1112165414",
      "pub.1090283160",
      "pub.1163420986",
      "pub.1127888027",
      "pub.1107690600",
      "pub.1147207427",
      "pub.1125989712",
      "pub.1123669031",
      "pub.1142723112",
      "pub.1017872565",
      "pub.1141447737",
      "pub.1160708745",
      "pub.1141942664",
      "pub.1153238659",
      "pub.1004886537",
      "pub.1008042428",
      "pub.1016832912",
      "pub.1129778966",
      "pub.1033034247",
      "pub.1151374661",
      "pub.1121621301",
      "pub.1137437416",
      "pub.1025668439",
      "pub.1007586453",
      "pub.1098913318",
      "pub.1023958838",
      "pub.1037292812",
      "pub.1037983101",
      "pub.1015211346",
      "pub.1006627894",
      "pub.1034301724",
      "pub.1131699366",
      "pub.1112925802",
      "pub.1156479774",
      "pub.1104455471",
      "pub.1017077595",
      "pub.1106253846",
      "pub.1099929632",
      "pub.1037605009",
      "pub.1119945749",
      "pub.1048043231",
      "pub.1024866807",
      "pub.1163325667",
      "pub.1157787044",
      "pub.1019388008",
      "pub.1012487019",
      "pub.1123540715",
      "pub.1009096342",
      "pub.1005102238",
      "pub.1113356001",
      "pub.1141602431",
      "pub.1133283923",
      "pub.1151853781",
      "pub.1013757649",
      "pub.1023604005",
      "pub.1092081310",
      "pub.1012665776",
      "pub.1132551428",
      "pub.1104021081",
      "pub.1164933700",
      "pub.1113266982",
      "pub.1105772941",
      "pub.1122785808",
      "pub.1091690179",
      "pub.1032444369",
      "pub.1019269773",
      "pub.1117620916",
      "pub.1131649481",
      "pub.1001029142",
      "pub.1092997716",
      "pub.1130135299",
      "pub.1131933523",
      "pub.1011294634",
      "pub.1110105670",
      "pub.1127575486",
      "pub.1158245976",
      "pub.1064612086",
      "pub.1139146358",
      "pub.1110646891",
      "pub.1131925132",
      "pub.1078885497",
      "pub.1134960870",
      "pub.1023229955",
      "pub.1105020566",
      "pub.1085462276",
      "pub.1092219370",
      "pub.1004297784",
      "pub.1084186622",
      "pub.1137262319",
      "pub.1132250251",
      "pub.1006813673",
      "pub.1018195580",
      "pub.1122486669",
      "pub.1120126389",
      "pub.1029403456",
      "pub.1084807405",
      "pub.1041325874",
      "pub.1041197603",
      "pub.1090951158",
      "pub.1152531635",
      "pub.1147616318",
      "pub.1160635088",
      "pub.1120186638",
      "pub.1012542794",
      "pub.1117801802",
      "pub.1148391030",
      "pub.1128479749",
      "pub.1002849969",
      "pub.1125617415",
      "pub.1008133998",
      "pub.1133233678",
      "pub.1013732820",
      "pub.1163751428",
      "pub.1129503475",
      "pub.1113893271",
      "pub.1157589351",
      "pub.1005603549",
      "pub.1136574263",
      "pub.1129432263",
      "pub.1150792682",
      "pub.1158502219",
      "pub.1046869300",
      "pub.1107363293",
      "pub.1020724657",
      "pub.1151322635",
      "pub.1014842622",
      "pub.1141545497",
      "pub.1006666875",
      "pub.1022573122",
      "pub.1099922902",
      "pub.1157582144",
      "pub.1162791134",
      "pub.1132714762",
      "pub.1168777384",
      "pub.1139691916",
      "pub.1108474719",
      "pub.1023592308",
      "pub.1084433686",
      "pub.1156267132",
      "pub.1033632930",
      "pub.1165970553",
      "pub.1077825514",
      "pub.1133177140",
      "pub.1144469644",
      "pub.1004078305",
      "pub.1035163834",
      "pub.1086028191",
      "pub.1122147463",
      "pub.1137489746",
      "pub.1136845881",
      "pub.1106088135",
      "pub.1050421915",
      "pub.1157671562",
      "pub.1033186800",
      "pub.1100467404",
      "pub.1028215370",
      "pub.1123013911",
      "pub.1154444334",
      "pub.1106289667",
      "pub.1039107870",
      "pub.1109958317",
      "pub.1132714763",
      "pub.1110042705",
      "pub.1110928007",
      "pub.1143679425",
      "pub.1140577083",
      "pub.1000064838",
      "pub.1010983637",
      "pub.1015206105",
      "pub.1111318774",
      "pub.1038344748",
      "pub.1035909997",
      "pub.1105714173",
      "pub.1121586171",
      "pub.1117944742",
      "pub.1023424116",
      "pub.1053571426",
      "pub.1138150067",
      "pub.1105333615",
      "pub.1123061593",
      "pub.1107128190",
      "pub.1138685725",
      "pub.1025877023",
      "pub.1140001253",
      "pub.1163220049",
      "pub.1112364128",
      "pub.1018997799",
      "pub.1133082139",
      "pub.1123462168",
      "pub.1158549027",
      "pub.1121618765",
      "pub.1131996794",
      "pub.1116672220",
      "pub.1126910157",
      "pub.1151332162",
      "pub.1112676463",
      "pub.1101143158",
      "pub.1157691732",
      "pub.1030269407",
      "pub.1137703351",
      "pub.1069189131",
      "pub.1048902509",
      "pub.1121980795"
    ],
    "concepts_scores": [
      {
        "concept": "application of artificial intelligence",
        "relevance": 0.6
      },
      {
        "concept": "machine learning",
        "relevance": 0.515
      },
      {
        "concept": "artificial intelligence",
        "relevance": 0.513
      },
      {
        "concept": "ML approaches",
        "relevance": 0.496
      },
      {
        "concept": "human biology",
        "relevance": 0.477
      },
      {
        "concept": "multi-omics analysis",
        "relevance": 0.474
      },
      {
        "concept": "application of AI",
        "relevance": 0.472
      },
      {
        "concept": "AI approaches",
        "relevance": 0.446
      },
      {
        "concept": "data curation",
        "relevance": 0.442
      },
      {
        "concept": "multi-omics",
        "relevance": 0.442
      },
      {
        "concept": "neurodegenerative disease research",
        "relevance": 0.441
      },
      {
        "concept": "model system",
        "relevance": 0.44
      },
      {
        "concept": "biological interpretation",
        "relevance": 0.435
      },
      {
        "concept": "experimental model",
        "relevance": 0.406
      },
      {
        "concept": "neurodegenerative experimental models",
        "relevance": 0.402
      },
      {
        "concept": "human clinical trials",
        "relevance": 0.399
      },
      {
        "concept": "cross-species translation",
        "relevance": 0.396
      },
      {
        "concept": "data resources",
        "relevance": 0.396
      },
      {
        "concept": "intelligence",
        "relevance": 0.387
      },
      {
        "concept": "disease research",
        "relevance": 0.385
      },
      {
        "concept": "experimental medicine",
        "relevance": 0.38
      },
      {
        "concept": "drug discovery",
        "relevance": 0.378
      },
      {
        "concept": "clinical trials",
        "relevance": 0.371
      },
      {
        "concept": "biology",
        "relevance": 0.371
      },
      {
        "concept": "identified issues",
        "relevance": 0.369
      },
      {
        "concept": "preclinical research",
        "relevance": 0.365
      },
      {
        "concept": "translation",
        "relevance": 0.36
      },
      {
        "concept": "evaluate translation",
        "relevance": 0.341
      },
      {
        "concept": "species",
        "relevance": 0.336
      },
      {
        "concept": "failure rate",
        "relevance": 0.327
      },
      {
        "concept": "machine",
        "relevance": 0.327
      },
      {
        "concept": "resources",
        "relevance": 0.324
      },
      {
        "concept": "drug",
        "relevance": 0.322
      },
      {
        "concept": "learning",
        "relevance": 0.32
      },
      {
        "concept": "system",
        "relevance": 0.314
      },
      {
        "concept": "model",
        "relevance": 0.307
      },
      {
        "concept": "research",
        "relevance": 0.299
      },
      {
        "concept": "reproducibility",
        "relevance": 0.299
      },
      {
        "concept": "increasing application",
        "relevance": 0.299
      },
      {
        "concept": "curation",
        "relevance": 0.296
      },
      {
        "concept": "medicine",
        "relevance": 0.293
      },
      {
        "concept": "dementia research",
        "relevance": 0.292
      },
      {
        "concept": "discovery",
        "relevance": 0.29
      },
      {
        "concept": "data",
        "relevance": 0.288
      },
      {
        "concept": "experimental data",
        "relevance": 0.284
      },
      {
        "concept": "applications",
        "relevance": 0.281
      },
      {
        "concept": "trials",
        "relevance": 0.274
      },
      {
        "concept": "issues",
        "relevance": 0.268
      },
      {
        "concept": "infancy",
        "relevance": 0.266
      },
      {
        "concept": "challenges",
        "relevance": 0.255
      },
      {
        "concept": "solution",
        "relevance": 0.255
      },
      {
        "concept": "failure",
        "relevance": 0.25
      },
      {
        "concept": "review",
        "relevance": 0.248
      },
      {
        "concept": "insights",
        "relevance": 0.234
      },
      {
        "concept": "analysis",
        "relevance": 0.227
      },
      {
        "concept": "approach",
        "relevance": 0.22
      },
      {
        "concept": "potential",
        "relevance": 0.22
      },
      {
        "concept": "rate",
        "relevance": 0.218
      },
      {
        "concept": "possibilities",
        "relevance": 0.217
      },
      {
        "concept": "interpretation",
        "relevance": 0.215
      },
      {
        "concept": "field",
        "relevance": 0.214
      },
      {
        "concept": "dementia",
        "relevance": 0.213
      },
      {
        "concept": "practice",
        "relevance": 0.192
      }
    ]
  },
  {
    "paperId": "pub.1170211509",
    "doi": "10.1088/1361-6560/ad387d",
    "title": "Advancing medical imaging with language models: featuring a spotlight on ChatGPT",
    "year": 2024,
    "citationCount": 31,
    "fieldCitationRatio": NaN,
    "abstract": "This review paper aims to serve as a comprehensive guide and instructional resource for researchers seeking to effectively implement language models in medical imaging research. First, we presented the fundamental principles and evolution of language models, dedicating particular attention to large language models. We then reviewed the current literature on how language models are being used to improve medical imaging, emphasizing a range of applications such as image captioning, report generation, report classification, findings extraction, visual question response systems, interpretable diagnosis and so on. Notably, the capabilities of ChatGPT were spotlighted for researchers to explore its further applications. Furthermore, we covered the advantageous impacts of accurate and efficient language models in medical imaging analysis, such as the enhancement of clinical workflow efficiency, reduction of diagnostic errors, and assistance of clinicians in providing timely and accurate diagnoses. Overall, our goal is to have better integration of language models with medical imaging, thereby inspiring new ideas and innovations. It is our aspiration that this review can serve as a useful resource for researchers in this field, stimulating continued investigative and innovative pursuits of the application of language models in medical imaging.",
    "reference_ids": [
      "pub.1135528973",
      "pub.1162835902",
      "pub.1158836329",
      "pub.1153631876",
      "pub.1157362983",
      "pub.1122290393",
      "pub.1166130148",
      "pub.1175773771",
      "pub.1160172437",
      "pub.1164705743",
      "pub.1151033044",
      "pub.1165876932",
      "pub.1155196311",
      "pub.1138337559",
      "pub.1110399669",
      "pub.1149214644",
      "pub.1160332642",
      "pub.1169868057",
      "pub.1166193492",
      "pub.1148390520",
      "pub.1163452669",
      "pub.1150187654",
      "pub.1146436225",
      "pub.1163453847",
      "pub.1133175894",
      "pub.1164575541",
      "pub.1012802956",
      "pub.1166405420",
      "pub.1129479873",
      "pub.1128582016",
      "pub.1164452784",
      "pub.1164939438",
      "pub.1159737511",
      "pub.1157273035",
      "pub.1095839635",
      "pub.1061178979",
      "pub.1165125771",
      "pub.1031388101",
      "pub.1144682962",
      "pub.1162720855",
      "pub.1114995901",
      "pub.1160505148",
      "pub.1100767582",
      "pub.1131464992",
      "pub.1151033040",
      "pub.1158635650",
      "pub.1145901384",
      "pub.1159867915",
      "pub.1164113528",
      "pub.1169767395",
      "pub.1155254261",
      "pub.1139828544",
      "pub.1146815576",
      "pub.1157053699",
      "pub.1158133161",
      "pub.1151033100",
      "pub.1038140272",
      "pub.1140106935",
      "pub.1160506723",
      "pub.1164576157",
      "pub.1166268573",
      "pub.1139861295",
      "pub.1163636742",
      "pub.1166189430",
      "pub.1151130044",
      "pub.1112536714",
      "pub.1134139819",
      "pub.1165647708",
      "pub.1160000503",
      "pub.1163678978",
      "pub.1170726180",
      "pub.1129757334",
      "pub.1139947810",
      "pub.1131343503",
      "pub.1156359853",
      "pub.1150163629"
    ],
    "concepts_scores": [
      {
        "concept": "language model",
        "relevance": 0.564
      },
      {
        "concept": "medical images",
        "relevance": 0.542
      },
      {
        "concept": "application of language models",
        "relevance": 0.49
      },
      {
        "concept": "efficient language model",
        "relevance": 0.487
      },
      {
        "concept": "medical image analysis",
        "relevance": 0.486
      },
      {
        "concept": "medical imaging research",
        "relevance": 0.475
      },
      {
        "concept": "image captions",
        "relevance": 0.457
      },
      {
        "concept": "improve medical imaging",
        "relevance": 0.448
      },
      {
        "concept": "report classification",
        "relevance": 0.433
      },
      {
        "concept": "report generation",
        "relevance": 0.432
      },
      {
        "concept": "assistance of clinicians",
        "relevance": 0.426
      },
      {
        "concept": "clinical workflow efficiency",
        "relevance": 0.42
      },
      {
        "concept": "ChatGPT",
        "relevance": 0.411
      },
      {
        "concept": "interpretable diagnosis",
        "relevance": 0.403
      },
      {
        "concept": "reduction of diagnostic errors",
        "relevance": 0.4
      },
      {
        "concept": "question–response system",
        "relevance": 0.396
      },
      {
        "concept": "innovative pursuits",
        "relevance": 0.387
      },
      {
        "concept": "workflow efficiency",
        "relevance": 0.386
      },
      {
        "concept": "advanced medical imaging",
        "relevance": 0.369
      },
      {
        "concept": "findings extraction",
        "relevance": 0.369
      },
      {
        "concept": "images",
        "relevance": 0.364
      },
      {
        "concept": "image analysis",
        "relevance": 0.361
      },
      {
        "concept": "language",
        "relevance": 0.358
      },
      {
        "concept": "imaging research",
        "relevance": 0.354
      },
      {
        "concept": "captions",
        "relevance": 0.346
      },
      {
        "concept": "diagnostic errors",
        "relevance": 0.331
      },
      {
        "concept": "response system",
        "relevance": 0.329
      },
      {
        "concept": "applications",
        "relevance": 0.322
      },
      {
        "concept": "resources",
        "relevance": 0.32
      },
      {
        "concept": "instructional resources",
        "relevance": 0.319
      },
      {
        "concept": "classification",
        "relevance": 0.319
      },
      {
        "concept": "model",
        "relevance": 0.306
      },
      {
        "concept": "capability",
        "relevance": 0.297
      },
      {
        "concept": "review paper",
        "relevance": 0.296
      },
      {
        "concept": "research",
        "relevance": 0.296
      },
      {
        "concept": "error",
        "relevance": 0.294
      },
      {
        "concept": "comprehensive guide",
        "relevance": 0.274
      },
      {
        "concept": "system",
        "relevance": 0.268
      },
      {
        "concept": "diagnosis",
        "relevance": 0.268
      },
      {
        "concept": "clinicians",
        "relevance": 0.268
      },
      {
        "concept": "goal",
        "relevance": 0.263
      },
      {
        "concept": "review",
        "relevance": 0.261
      },
      {
        "concept": "integration",
        "relevance": 0.258
      },
      {
        "concept": "efficiency",
        "relevance": 0.257
      },
      {
        "concept": "assistance",
        "relevance": 0.257
      },
      {
        "concept": "ideas",
        "relevance": 0.251
      },
      {
        "concept": "accurate diagnosis",
        "relevance": 0.25
      },
      {
        "concept": "innovation",
        "relevance": 0.249
      },
      {
        "concept": "pursuit",
        "relevance": 0.245
      },
      {
        "concept": "guide",
        "relevance": 0.234
      },
      {
        "concept": "extraction",
        "relevance": 0.231
      },
      {
        "concept": "generation",
        "relevance": 0.23
      },
      {
        "concept": "enhancement",
        "relevance": 0.223
      },
      {
        "concept": "reports",
        "relevance": 0.214
      },
      {
        "concept": "literature",
        "relevance": 0.208
      },
      {
        "concept": "evolution",
        "relevance": 0.204
      },
      {
        "concept": "impact",
        "relevance": 0.203
      },
      {
        "concept": "aspiration",
        "relevance": 0.203
      },
      {
        "concept": "reduction",
        "relevance": 0.199
      },
      {
        "concept": "paper",
        "relevance": 0.187
      },
      {
        "concept": "analysis",
        "relevance": 0.186
      }
    ]
  },
  {
    "paperId": "pub.1173429169",
    "doi": "10.1146/annurev-vision-112823-030616",
    "title": "The Quest for an Integrated Set of Neural Mechanisms Underlying Object Recognition in Primates",
    "year": 2024,
    "citationCount": 11,
    "fieldCitationRatio": NaN,
    "abstract": "Inferences made about objects via vision, such as rapid and accurate categorization, are core to primate cognition despite the algorithmic challenge posed by varying viewpoints and scenes. Until recently, the brain mechanisms that support these capabilities were deeply mysterious. However, over the past decade, this scientific mystery has been illuminated by the discovery and development of brain-inspired, image-computable, artificial neural network (ANN) systems that rival primates in these behavioral feats. Apart from fundamentally changing the landscape of artificial intelligence, modified versions of these ANN systems are the current leading scientific hypotheses of an integrated set of mechanisms in the primate ventral visual stream that support core object recognition. What separates brain-mapped versions of these systems from prior conceptual models is that they are sensory computable, mechanistic, anatomically referenced, and testable (SMART). In this article, we review and provide perspective on the brain mechanisms addressed by the current leading SMART models. We review their empirical brain and behavioral alignment successes and failures, discuss the next frontiers for an even more accurate mechanistic understanding, and outline the likely applications.",
    "reference_ids": [
      "pub.1080482714",
      "pub.1159990388",
      "pub.1074549978",
      "pub.1075081117",
      "pub.1014277013",
      "pub.1062586169",
      "pub.1049468503",
      "pub.1153783246",
      "pub.1113638467",
      "pub.1015195293",
      "pub.1037811822",
      "pub.1052504025",
      "pub.1090806672",
      "pub.1136653596",
      "pub.1003857944",
      "pub.1018357603",
      "pub.1020903388",
      "pub.1142398195",
      "pub.1018367015",
      "pub.1095836020",
      "pub.1045030418",
      "pub.1010848474",
      "pub.1131877131",
      "pub.1122203431",
      "pub.1149210524",
      "pub.1155810052",
      "pub.1032233097",
      "pub.1023480985",
      "pub.1128350212",
      "pub.1132861346",
      "pub.1129261072",
      "pub.1093497718",
      "pub.1125155917",
      "pub.1122147171",
      "pub.1149447333",
      "pub.1008345178",
      "pub.1001383059",
      "pub.1045269885",
      "pub.1106711788",
      "pub.1038118556",
      "pub.1035393709",
      "pub.1048430852",
      "pub.1151572813",
      "pub.1113878352",
      "pub.1018261102",
      "pub.1079716424",
      "pub.1128496600",
      "pub.1015723148",
      "pub.1164699331",
      "pub.1045519116",
      "pub.1001986745",
      "pub.1001952025",
      "pub.1074893733",
      "pub.1021339188",
      "pub.1002583964",
      "pub.1100824007",
      "pub.1122299922",
      "pub.1015677315",
      "pub.1036702724",
      "pub.1106970665",
      "pub.1103457801",
      "pub.1113874818",
      "pub.1083089633",
      "pub.1135618834",
      "pub.1015293875",
      "pub.1130761564",
      "pub.1128558549",
      "pub.1128343375",
      "pub.1129913795",
      "pub.1016635886",
      "pub.1012239887",
      "pub.1134504684",
      "pub.1144651712",
      "pub.1091759494",
      "pub.1106134814",
      "pub.1009767488",
      "pub.1148122727",
      "pub.1052496534",
      "pub.1052132745",
      "pub.1135415677",
      "pub.1113811374",
      "pub.1148706875",
      "pub.1132300793",
      "pub.1029407884",
      "pub.1002388132",
      "pub.1110806112",
      "pub.1154296822",
      "pub.1158199764",
      "pub.1141232359",
      "pub.1133090913",
      "pub.1105573040",
      "pub.1146319922",
      "pub.1128470445",
      "pub.1124646104",
      "pub.1010421612",
      "pub.1093359587",
      "pub.1152762493",
      "pub.1039208930",
      "pub.1026858180",
      "pub.1084098863",
      "pub.1137734093",
      "pub.1140736919",
      "pub.1024899264",
      "pub.1051009506",
      "pub.1082570465"
    ],
    "concepts_scores": [
      {
        "concept": "brain mechanisms",
        "relevance": 0.694
      },
      {
        "concept": "primate ventral visual stream",
        "relevance": 0.649
      },
      {
        "concept": "ventral visual stream",
        "relevance": 0.645
      },
      {
        "concept": "object recognition",
        "relevance": 0.644
      },
      {
        "concept": "core object recognition",
        "relevance": 0.641
      },
      {
        "concept": "primate cognition",
        "relevance": 0.597
      },
      {
        "concept": "neural mechanisms",
        "relevance": 0.594
      },
      {
        "concept": "visual stream",
        "relevance": 0.588
      },
      {
        "concept": "brain",
        "relevance": 0.527
      },
      {
        "concept": "integrated settings",
        "relevance": 0.477
      },
      {
        "concept": "primates",
        "relevance": 0.474
      },
      {
        "concept": "modified version",
        "relevance": 0.472
      },
      {
        "concept": "artificial neural network",
        "relevance": 0.47
      },
      {
        "concept": "cognition",
        "relevance": 0.461
      },
      {
        "concept": "accurate categorization",
        "relevance": 0.458
      },
      {
        "concept": "landscape of artificial intelligence",
        "relevance": 0.453
      },
      {
        "concept": "scientific hypotheses",
        "relevance": 0.438
      },
      {
        "concept": "artificial neural network system",
        "relevance": 0.414
      },
      {
        "concept": "version",
        "relevance": 0.412
      },
      {
        "concept": "Brain-inspired",
        "relevance": 0.411
      },
      {
        "concept": "categorization",
        "relevance": 0.41
      },
      {
        "concept": "neural network",
        "relevance": 0.404
      },
      {
        "concept": "artificial intelligence",
        "relevance": 0.398
      },
      {
        "concept": "intelligence",
        "relevance": 0.398
      },
      {
        "concept": "recognition",
        "relevance": 0.387
      },
      {
        "concept": "hypothesis",
        "relevance": 0.383
      },
      {
        "concept": "conceptual model",
        "relevance": 0.379
      },
      {
        "concept": "smart model",
        "relevance": 0.375
      },
      {
        "concept": "image-computable",
        "relevance": 0.372
      },
      {
        "concept": "feat",
        "relevance": 0.367
      },
      {
        "concept": "scientific mysteries",
        "relevance": 0.366
      },
      {
        "concept": "frontier",
        "relevance": 0.365
      },
      {
        "concept": "landscape",
        "relevance": 0.36
      },
      {
        "concept": "mystery",
        "relevance": 0.357
      },
      {
        "concept": "Smart",
        "relevance": 0.353
      },
      {
        "concept": "alignment success",
        "relevance": 0.344
      },
      {
        "concept": "quest",
        "relevance": 0.342
      },
      {
        "concept": "mechanism",
        "relevance": 0.336
      },
      {
        "concept": "behavioral feats",
        "relevance": 0.336
      },
      {
        "concept": "discovery",
        "relevance": 0.328
      },
      {
        "concept": "objective",
        "relevance": 0.321
      },
      {
        "concept": "inference",
        "relevance": 0.317
      },
      {
        "concept": "scene",
        "relevance": 0.313
      },
      {
        "concept": "perspective",
        "relevance": 0.31
      },
      {
        "concept": "understanding",
        "relevance": 0.307
      },
      {
        "concept": "network",
        "relevance": 0.301
      },
      {
        "concept": "vision",
        "relevance": 0.287
      },
      {
        "concept": "system",
        "relevance": 0.283
      },
      {
        "concept": "mechanistic understanding",
        "relevance": 0.28
      },
      {
        "concept": "capability",
        "relevance": 0.27
      },
      {
        "concept": "model",
        "relevance": 0.268
      },
      {
        "concept": "development",
        "relevance": 0.267
      },
      {
        "concept": "stream",
        "relevance": 0.264
      },
      {
        "concept": "viewpoint",
        "relevance": 0.259
      },
      {
        "concept": "next frontiers",
        "relevance": 0.259
      },
      {
        "concept": "integration",
        "relevance": 0.255
      },
      {
        "concept": "success",
        "relevance": 0.254
      },
      {
        "concept": "applications",
        "relevance": 0.253
      },
      {
        "concept": "core",
        "relevance": 0.251
      },
      {
        "concept": "failure",
        "relevance": 0.196
      }
    ]
  },
  {
    "paperId": "pub.1173571264",
    "doi": "10.1038/s41598-024-66576-y",
    "title": "Clinical efficacy of pre-trained large language models through the lens of aphasia",
    "year": 2024,
    "citationCount": 6,
    "fieldCitationRatio": NaN,
    "abstract": "The rapid development of large language models (LLMs) motivates us to explore how such state-of-the-art natural language processing systems can inform aphasia research. What kind of language indices can we derive from a pre-trained LLM? How do they differ from or relate to the existing language features in aphasia? To what extent can LLMs serve as an interpretable and effective diagnostic and measurement tool in a clinical context? To investigate these questions, we constructed predictive and correlational models, which utilize mean surprisals from LLMs as predictor variables. Using AphasiaBank archived data, we validated our models’ efficacy in aphasia diagnosis, measurement, and prediction. Our finding is that LLMs-surprisals can effectively detect the presence of aphasia and different natures of the disorder, LLMs in conjunction with the existing language indices improve models’ efficacy in subtyping aphasia, and LLMs-surprisals can capture common agrammatic deficits at both word and sentence level. Overall, LLMs have potential to advance automatic and precise aphasia prediction. A natural language processing pipeline can be greatly benefitted from integrating LLMs, enabling us to refine models of existing language disorders, such as aphasia.",
    "reference_ids": [
      "pub.1101077470",
      "pub.1128090968",
      "pub.1160790403",
      "pub.1143756185",
      "pub.1138840144",
      "pub.1054021615",
      "pub.1160093558",
      "pub.1135809542",
      "pub.1164682908",
      "pub.1167202784",
      "pub.1059458578",
      "pub.1117131937",
      "pub.1118169781",
      "pub.1117018662",
      "pub.1133174687",
      "pub.1148735882",
      "pub.1146948631",
      "pub.1162678819",
      "pub.1165335145",
      "pub.1169244023",
      "pub.1100477927",
      "pub.1163045737",
      "pub.1027296971",
      "pub.1164942935",
      "pub.1155157625",
      "pub.1157797966",
      "pub.1152874399",
      "pub.1127991064",
      "pub.1149938091",
      "pub.1002505827",
      "pub.1165710051",
      "pub.1148391290",
      "pub.1004323840",
      "pub.1006245699",
      "pub.1125940713",
      "pub.1068672630",
      "pub.1163281256",
      "pub.1146119153",
      "pub.1163041499",
      "pub.1169314117",
      "pub.1039702115",
      "pub.1163682577",
      "pub.1163044778",
      "pub.1084787359",
      "pub.1133175485",
      "pub.1148956311",
      "pub.1168627511",
      "pub.1100856193",
      "pub.1159935224",
      "pub.1105851989",
      "pub.1146321275",
      "pub.1163393637",
      "pub.1117660125",
      "pub.1163041477",
      "pub.1164843562",
      "pub.1035757625",
      "pub.1026060254",
      "pub.1156563993",
      "pub.1004610763",
      "pub.1141277347",
      "pub.1118169373",
      "pub.1156713671",
      "pub.1004358475",
      "pub.1169262449",
      "pub.1169618364",
      "pub.1160025526",
      "pub.1139147535",
      "pub.1049852644",
      "pub.1019919595",
      "pub.1138061862",
      "pub.1145153985",
      "pub.1144507098",
      "pub.1107487555"
    ],
    "concepts_scores": [
      {
        "concept": "Language Index",
        "relevance": 0.759
      },
      {
        "concept": "language model",
        "relevance": 0.699
      },
      {
        "concept": "presence of aphasia",
        "relevance": 0.699
      },
      {
        "concept": "natural language processing systems",
        "relevance": 0.667
      },
      {
        "concept": "agrammatic deficits",
        "relevance": 0.665
      },
      {
        "concept": "language processing system",
        "relevance": 0.661
      },
      {
        "concept": "aphasia research",
        "relevance": 0.661
      },
      {
        "concept": "language disorders",
        "relevance": 0.66
      },
      {
        "concept": "aphasia diagnosis",
        "relevance": 0.659
      },
      {
        "concept": "aphasia",
        "relevance": 0.643
      },
      {
        "concept": "language processing pipeline",
        "relevance": 0.62
      },
      {
        "concept": "sentence level",
        "relevance": 0.617
      },
      {
        "concept": "language features",
        "relevance": 0.61
      },
      {
        "concept": "language",
        "relevance": 0.604
      },
      {
        "concept": "natural language processing pipeline",
        "relevance": 0.589
      },
      {
        "concept": "disorders",
        "relevance": 0.559
      },
      {
        "concept": "predictor variables",
        "relevance": 0.548
      },
      {
        "concept": "clinical context",
        "relevance": 0.531
      },
      {
        "concept": "deficits",
        "relevance": 0.492
      },
      {
        "concept": "sentences",
        "relevance": 0.481
      },
      {
        "concept": "words",
        "relevance": 0.473
      },
      {
        "concept": "efficacy",
        "relevance": 0.458
      },
      {
        "concept": "measurement tools",
        "relevance": 0.456
      },
      {
        "concept": "clinical efficacy",
        "relevance": 0.44
      },
      {
        "concept": "state-of-the-art",
        "relevance": 0.438
      },
      {
        "concept": "LLM",
        "relevance": 0.437
      },
      {
        "concept": "processing system",
        "relevance": 0.431
      },
      {
        "concept": "predictors",
        "relevance": 0.422
      },
      {
        "concept": "context",
        "relevance": 0.411
      },
      {
        "concept": "findings",
        "relevance": 0.411
      },
      {
        "concept": "questions",
        "relevance": 0.402
      },
      {
        "concept": "measurements",
        "relevance": 0.392
      },
      {
        "concept": "lens",
        "relevance": 0.388
      },
      {
        "concept": "surprises",
        "relevance": 0.388
      },
      {
        "concept": "processing pipeline",
        "relevance": 0.386
      },
      {
        "concept": "research",
        "relevance": 0.367
      },
      {
        "concept": "variables",
        "relevance": 0.358
      },
      {
        "concept": "model efficacy",
        "relevance": 0.35
      },
      {
        "concept": "nature",
        "relevance": 0.344
      },
      {
        "concept": "prediction",
        "relevance": 0.33
      },
      {
        "concept": "diagnosis",
        "relevance": 0.326
      },
      {
        "concept": "model",
        "relevance": 0.316
      },
      {
        "concept": "correlation model",
        "relevance": 0.316
      },
      {
        "concept": "levels",
        "relevance": 0.316
      },
      {
        "concept": "features",
        "relevance": 0.305
      },
      {
        "concept": "improved model",
        "relevance": 0.304
      },
      {
        "concept": "index",
        "relevance": 0.301
      },
      {
        "concept": "refined models",
        "relevance": 0.296
      },
      {
        "concept": "development",
        "relevance": 0.291
      },
      {
        "concept": "conjunction",
        "relevance": 0.282
      },
      {
        "concept": "tools",
        "relevance": 0.281
      },
      {
        "concept": "data",
        "relevance": 0.27
      },
      {
        "concept": "pipeline",
        "relevance": 0.266
      },
      {
        "concept": "system",
        "relevance": 0.24
      },
      {
        "concept": "presence",
        "relevance": 0.203
      }
    ]
  },
  {
    "paperId": "pub.1162678819",
    "doi": "10.1002/hcs2.61",
    "title": "Large language models in health care: Development, applications, and challenges",
    "year": 2023,
    "citationCount": 179,
    "fieldCitationRatio": 141.03,
    "abstract": "Recently, the emergence of ChatGPT, an artificial intelligence chatbot developed by OpenAI, has attracted significant attention due to its exceptional language comprehension and content generation capabilities, highlighting the immense potential of large language models (LLMs). LLMs have become a burgeoning hotspot across many fields, including health care. Within health care, LLMs may be classified into LLMs for the biomedical domain and LLMs for the clinical domain based on the corpora used for pre-training. In the last 3 years, these domain-specific LLMs have demonstrated exceptional performance on multiple natural language processing tasks, surpassing the performance of general LLMs as well. This not only emphasizes the significance of developing dedicated LLMs for the specific domains, but also raises expectations for their applications in health care. We believe that LLMs may be used widely in preconsultation, diagnosis, and management, with appropriate development and supervision. Additionally, LLMs hold tremendous promise in assisting with medical education, medical writing and other related applications. Likewise, health care systems must recognize and address the challenges posed by LLMs.",
    "reference_ids": [
      "pub.1155183271",
      "pub.1107560049",
      "pub.1153982932",
      "pub.1015829888",
      "pub.1136656239",
      "pub.1155156739",
      "pub.1122290388",
      "pub.1124921542",
      "pub.1155066899",
      "pub.1037473231",
      "pub.1112926379",
      "pub.1092352256",
      "pub.1131933523",
      "pub.1168641193",
      "pub.1119353072",
      "pub.1134623724",
      "pub.1131543103",
      "pub.1155936177",
      "pub.1039633073",
      "pub.1150924332",
      "pub.1157704870",
      "pub.1157166150",
      "pub.1120882528",
      "pub.1133177133",
      "pub.1155270525",
      "pub.1131969987",
      "pub.1155066898",
      "pub.1110854318",
      "pub.1154881766",
      "pub.1155728628",
      "pub.1129260878",
      "pub.1141717110",
      "pub.1160635088",
      "pub.1085903717",
      "pub.1153999847",
      "pub.1134455297",
      "pub.1141942664",
      "pub.1127990889",
      "pub.1160103012",
      "pub.1166872692",
      "pub.1121996860",
      "pub.1126027253",
      "pub.1119407798",
      "pub.1154476459",
      "pub.1131298097",
      "pub.1133543352",
      "pub.1155156738",
      "pub.1157733451",
      "pub.1123132128",
      "pub.1155222253",
      "pub.1104137178"
    ],
    "concepts_scores": [
      {
        "concept": "health care",
        "relevance": 0.637
      },
      {
        "concept": "health care system",
        "relevance": 0.555
      },
      {
        "concept": "care system",
        "relevance": 0.514
      },
      {
        "concept": "language comprehension",
        "relevance": 0.511
      },
      {
        "concept": "language model",
        "relevance": 0.507
      },
      {
        "concept": "medical education",
        "relevance": 0.5
      },
      {
        "concept": "care",
        "relevance": 0.493
      },
      {
        "concept": "natural language processing tasks",
        "relevance": 0.49
      },
      {
        "concept": "health",
        "relevance": 0.485
      },
      {
        "concept": "language processing tasks",
        "relevance": 0.476
      },
      {
        "concept": "clinical domains",
        "relevance": 0.461
      },
      {
        "concept": "artificial intelligence chatbots",
        "relevance": 0.451
      },
      {
        "concept": "processing tasks",
        "relevance": 0.45
      },
      {
        "concept": "intelligent chatbot",
        "relevance": 0.438
      },
      {
        "concept": "biomedical domain",
        "relevance": 0.43
      },
      {
        "concept": "pre-training",
        "relevance": 0.429
      },
      {
        "concept": "preconsultation",
        "relevance": 0.412
      },
      {
        "concept": "language",
        "relevance": 0.409
      },
      {
        "concept": "comprehension",
        "relevance": 0.371
      },
      {
        "concept": "generation capability",
        "relevance": 0.366
      },
      {
        "concept": "education",
        "relevance": 0.357
      },
      {
        "concept": "task",
        "relevance": 0.353
      },
      {
        "concept": "OpenAI",
        "relevance": 0.348
      },
      {
        "concept": "ChatGPT",
        "relevance": 0.345
      },
      {
        "concept": "supervision",
        "relevance": 0.342
      },
      {
        "concept": "chatbot",
        "relevance": 0.34
      },
      {
        "concept": "performance",
        "relevance": 0.331
      },
      {
        "concept": "emergency",
        "relevance": 0.33
      },
      {
        "concept": "domain",
        "relevance": 0.33
      },
      {
        "concept": "applications",
        "relevance": 0.328
      },
      {
        "concept": "years",
        "relevance": 0.328
      },
      {
        "concept": "diagnosis",
        "relevance": 0.323
      },
      {
        "concept": "LLM",
        "relevance": 0.317
      },
      {
        "concept": "expectations",
        "relevance": 0.317
      },
      {
        "concept": "attention",
        "relevance": 0.307
      },
      {
        "concept": "management",
        "relevance": 0.296
      },
      {
        "concept": "corpus",
        "relevance": 0.295
      },
      {
        "concept": "capability",
        "relevance": 0.288
      },
      {
        "concept": "challenges",
        "relevance": 0.277
      },
      {
        "concept": "model",
        "relevance": 0.275
      },
      {
        "concept": "significance",
        "relevance": 0.263
      },
      {
        "concept": "development",
        "relevance": 0.26
      },
      {
        "concept": "system",
        "relevance": 0.26
      },
      {
        "concept": "medical writing",
        "relevance": 0.233
      },
      {
        "concept": "writing",
        "relevance": 0.227
      },
      {
        "concept": "field",
        "relevance": 0.206
      },
      {
        "concept": "potential",
        "relevance": 0.19
      },
      {
        "concept": "content",
        "relevance": 0.179
      }
    ]
  },
  {
    "paperId": "pub.1185608677",
    "doi": "10.3389/fninf.2025.1527582",
    "title": "Contrastive self-supervised learning for neurodegenerative disorder classification",
    "year": 2025,
    "citationCount": 1,
    "fieldCitationRatio": NaN,
    "abstract": "Introduction: Neurodegenerative diseases such as Alzheimer's disease (AD) or frontotemporal lobar degeneration (FTLD) involve specific loss of brain volume, detectable <i>in vivo</i> using T1-weighted MRI scans. Supervised machine learning approaches classifying neurodegenerative diseases require diagnostic-labels for each sample. However, it can be difficult to obtain expert labels for a large amount of data. Self-supervised learning (SSL) offers an alternative for training machine learning models without data-labels.\nMethods: We investigated if the SSL models can be applied to distinguish between different neurodegenerative disorders in an interpretable manner. Our method comprises a feature extractor and a downstream classification head. A deep convolutional neural network, trained with a contrastive loss, serves as the feature extractor that learns latent representations. The classification head is a single-layer perceptron that is trained to perform diagnostic group separation. We used <i>N</i> = 2,694 T1-weighted MRI scans from four data cohorts: two ADNI datasets, AIBL and FTLDNI, including cognitively normal controls (CN), cases with prodromal and clinical AD, as well as FTLD cases differentiated into its phenotypes.\nResults: Our results showed that the feature extractor trained in a self-supervised way provides generalizable and robust representations for the downstream classification. For AD vs. CN, our model achieves 82% balanced accuracy on the test subset and 80% on an independent holdout dataset. Similarly, the Behavioral variant of frontotemporal dementia (BV) vs. CN model attains an 88% balanced accuracy on the test subset. The average feature attribution heatmaps obtained by the Integrated Gradient method highlighted hallmark regions, i.e., temporal gray matter atrophy for AD, and insular atrophy for BV.\nConclusion: Our models perform comparably to state-of-the-art supervised deep learning approaches. This suggests that the SSL methodology can successfully make use of unannotated neuroimaging datasets as training data while remaining robust and interpretable.",
    "reference_ids": [
      "pub.1138337599",
      "pub.1150555623",
      "pub.1175842394",
      "pub.1045321436",
      "pub.1123786681",
      "pub.1135275656",
      "pub.1141302104",
      "pub.1142383815",
      "pub.1149621828",
      "pub.1181365058",
      "pub.1131951508",
      "pub.1153525251",
      "pub.1121715269",
      "pub.1131294289",
      "pub.1153876564",
      "pub.1134729937",
      "pub.1164969292",
      "pub.1157521684",
      "pub.1125158192",
      "pub.1141326749",
      "pub.1064349696",
      "pub.1127359547",
      "pub.1124797200",
      "pub.1158541789",
      "pub.1145901938",
      "pub.1143755414",
      "pub.1095837574",
      "pub.1095510970",
      "pub.1127249569",
      "pub.1141326790",
      "pub.1123987679",
      "pub.1149193766",
      "pub.1150997087",
      "pub.1140404196",
      "pub.1052274820",
      "pub.1171274813",
      "pub.1033293393",
      "pub.1155105027",
      "pub.1134893015",
      "pub.1151491672",
      "pub.1186105994",
      "pub.1146347249",
      "pub.1134178299",
      "pub.1024827031",
      "pub.1163061838",
      "pub.1142907653",
      "pub.1095181185",
      "pub.1093359587",
      "pub.1140741834",
      "pub.1156493740",
      "pub.1170471323",
      "pub.1126480817",
      "pub.1110720608",
      "pub.1123988721",
      "pub.1045486954",
      "pub.1136916487",
      "pub.1170135415",
      "pub.1166146103",
      "pub.1094758581",
      "pub.1032231527",
      "pub.1155160554",
      "pub.1160173990",
      "pub.1120935852",
      "pub.1151380774",
      "pub.1120002052",
      "pub.1095843442",
      "pub.1044720211",
      "pub.1147616318",
      "pub.1095689025"
    ],
    "concepts_scores": [
      {
        "concept": "self-supervised learning",
        "relevance": 0.807
      },
      {
        "concept": "behavioral variant of frontotemporal dementia",
        "relevance": 0.709
      },
      {
        "concept": "classification head",
        "relevance": 0.691
      },
      {
        "concept": "self-supervised learning methodology",
        "relevance": 0.667
      },
      {
        "concept": "contrastive self-supervised learning",
        "relevance": 0.666
      },
      {
        "concept": "self-supervised learning model",
        "relevance": 0.665
      },
      {
        "concept": "learning approach",
        "relevance": 0.659
      },
      {
        "concept": "deep convolutional neural network",
        "relevance": 0.657
      },
      {
        "concept": "T1-weighted MRI scans",
        "relevance": 0.648
      },
      {
        "concept": "self-supervised way",
        "relevance": 0.645
      },
      {
        "concept": "train machine learning models",
        "relevance": 0.642
      },
      {
        "concept": "convolutional neural network",
        "relevance": 0.64
      },
      {
        "concept": "single-layer perceptron",
        "relevance": 0.639
      },
      {
        "concept": "balanced accuracy",
        "relevance": 0.632
      },
      {
        "concept": "deep learning approach",
        "relevance": 0.63
      },
      {
        "concept": "supervised machine learning approach",
        "relevance": 0.629
      },
      {
        "concept": "Integrated Gradients method",
        "relevance": 0.628
      },
      {
        "concept": "cognitively normal controls",
        "relevance": 0.625
      },
      {
        "concept": "frontotemporal lobar degeneration",
        "relevance": 0.624
      },
      {
        "concept": "test subset",
        "relevance": 0.62
      },
      {
        "concept": "machine learning models",
        "relevance": 0.61
      },
      {
        "concept": "machine learning approach",
        "relevance": 0.606
      },
      {
        "concept": "latent representation",
        "relevance": 0.598
      },
      {
        "concept": "data labels",
        "relevance": 0.597
      },
      {
        "concept": "contrastive loss",
        "relevance": 0.595
      },
      {
        "concept": "downstream classification",
        "relevance": 0.593
      },
      {
        "concept": "expert labels",
        "relevance": 0.59
      },
      {
        "concept": "training data",
        "relevance": 0.589
      },
      {
        "concept": "neural network",
        "relevance": 0.584
      },
      {
        "concept": "ADNI dataset",
        "relevance": 0.58
      },
      {
        "concept": "variant of frontotemporal dementia",
        "relevance": 0.579
      },
      {
        "concept": "robust representation",
        "relevance": 0.577
      },
      {
        "concept": "Alzheimer's disease",
        "relevance": 0.569
      },
      {
        "concept": "loss of brain volume",
        "relevance": 0.568
      },
      {
        "concept": "learning models",
        "relevance": 0.568
      },
      {
        "concept": "gray matter atrophy",
        "relevance": 0.549
      },
      {
        "concept": "extractor",
        "relevance": 0.545
      },
      {
        "concept": "neuroimaging datasets",
        "relevance": 0.544
      },
      {
        "concept": "dataset",
        "relevance": 0.536
      },
      {
        "concept": "insular atrophy",
        "relevance": 0.526
      },
      {
        "concept": "MRI scans",
        "relevance": 0.522
      },
      {
        "concept": "behavioral variant",
        "relevance": 0.518
      },
      {
        "concept": "disorder classification",
        "relevance": 0.516
      },
      {
        "concept": "holdout dataset",
        "relevance": 0.515
      },
      {
        "concept": "brain volume",
        "relevance": 0.512
      },
      {
        "concept": "classification",
        "relevance": 0.509
      },
      {
        "concept": "gradient method",
        "relevance": 0.492
      },
      {
        "concept": "frontotemporal dementia",
        "relevance": 0.489
      },
      {
        "concept": "learning",
        "relevance": 0.481
      },
      {
        "concept": "clinical AD",
        "relevance": 0.481
      },
      {
        "concept": "representation",
        "relevance": 0.477
      },
      {
        "concept": "data cohort",
        "relevance": 0.472
      },
      {
        "concept": "accuracy",
        "relevance": 0.466
      },
      {
        "concept": "perceptron",
        "relevance": 0.459
      },
      {
        "concept": "frontotemporal lobar degeneration cases",
        "relevance": 0.457
      },
      {
        "concept": "normal controls",
        "relevance": 0.456
      },
      {
        "concept": "neurodegenerative diseases",
        "relevance": 0.453
      },
      {
        "concept": "training",
        "relevance": 0.445
      },
      {
        "concept": "network",
        "relevance": 0.434
      },
      {
        "concept": "heatmap",
        "relevance": 0.428
      },
      {
        "concept": "ADNI",
        "relevance": 0.426
      },
      {
        "concept": "neurodegenerative disorders",
        "relevance": 0.422
      },
      {
        "concept": "data",
        "relevance": 0.421
      },
      {
        "concept": "cognition",
        "relevance": 0.405
      },
      {
        "concept": "model",
        "relevance": 0.401
      },
      {
        "concept": "CN model",
        "relevance": 0.396
      },
      {
        "concept": "method",
        "relevance": 0.395
      },
      {
        "concept": "disorders",
        "relevance": 0.388
      },
      {
        "concept": "subsets",
        "relevance": 0.379
      },
      {
        "concept": "attributes",
        "relevance": 0.375
      },
      {
        "concept": "labeling",
        "relevance": 0.373
      },
      {
        "concept": "dementia",
        "relevance": 0.371
      },
      {
        "concept": "Alzheimer",
        "relevance": 0.363
      },
      {
        "concept": "data",
        "relevance": 0.356
      },
      {
        "concept": "AIBL",
        "relevance": 0.356
      },
      {
        "concept": "way",
        "relevance": 0.352
      },
      {
        "concept": "atrophy",
        "relevance": 0.351
      },
      {
        "concept": "group separation",
        "relevance": 0.343
      },
      {
        "concept": "integration",
        "relevance": 0.339
      },
      {
        "concept": "methodology",
        "relevance": 0.337
      },
      {
        "concept": "i.",
        "relevance": 0.318
      },
      {
        "concept": "phenotype",
        "relevance": 0.314
      },
      {
        "concept": "test",
        "relevance": 0.314
      },
      {
        "concept": "results",
        "relevance": 0.297
      },
      {
        "concept": "head",
        "relevance": 0.29
      },
      {
        "concept": "cases",
        "relevance": 0.284
      },
      {
        "concept": "disease",
        "relevance": 0.283
      },
      {
        "concept": "alternative",
        "relevance": 0.275
      },
      {
        "concept": "control",
        "relevance": 0.275
      },
      {
        "concept": "samples",
        "relevance": 0.269
      },
      {
        "concept": "loss",
        "relevance": 0.258
      },
      {
        "concept": "cohort",
        "relevance": 0.25
      },
      {
        "concept": "degeneration",
        "relevance": 0.235
      },
      {
        "concept": "approach",
        "relevance": 0.232
      },
      {
        "concept": "scanning",
        "relevance": 0.221
      },
      {
        "concept": "separation",
        "relevance": 0.201
      },
      {
        "concept": "volume",
        "relevance": 0.193
      }
    ]
  },
  {
    "paperId": "pub.1184066574",
    "doi": "10.1038/s41598-024-84530-w",
    "title": "Brain-model neural similarity reveals abstractive summarization performance",
    "year": 2025,
    "citationCount": 1,
    "fieldCitationRatio": NaN,
    "abstract": "Deep language models (DLMs) have exhibited remarkable language understanding and generation capabilities, prompting researchers to explore the similarities between their internal mechanisms and human language cognitive processing. This study investigated the representational similarity (RS) between the abstractive summarization (ABS) models and the human brain and its correlation to the performance of ABS tasks. Specifically, representational similarity analysis (RSA) was used to measure the similarity between the representational patterns (RPs) of the BART, PEGASUS, and T5 models’ hidden layers and the human brain’s language RPs under different spatiotemporal conditions. Layer-wise ablation manipulation, including attention ablation and noise addition was employed to examine the hidden layers’ effect on model performance. The results demonstrate that as the depth of hidden layers increases, the models’ text encoding becomes increasingly similar to the human brain’s language RPs. Manipulating deeper layers leads to more substantial decline in summarization performance compared to shallower layers, highlighting the crucial role of deeper layers in integrating essential information. Notably, the study confirms the hypothesis that the hidden layers exhibiting higher similarity to human brain activity play a more critical role in model performance, with their correlations reaching statistical significance even after controlling for perplexity. These findings deepen our understanding of the cognitive mechanisms underlying language representations in DLMs and their neural correlates, potentially providing insights for optimizing and improving language models by aligning them with the human brain’s language-processing mechanisms.",
    "reference_ids": [
      "pub.1146119153",
      "pub.1164828150",
      "pub.1056396464",
      "pub.1170104372",
      "pub.1151448807",
      "pub.1114059327",
      "pub.1155885045",
      "pub.1165161885",
      "pub.1168442072",
      "pub.1153796319",
      "pub.1145598382",
      "pub.1157338414",
      "pub.1142398195",
      "pub.1138365777",
      "pub.1133246266",
      "pub.1163045434",
      "pub.1174025895",
      "pub.1128559464",
      "pub.1149902404",
      "pub.1168149665",
      "pub.1138840568",
      "pub.1117658852",
      "pub.1156895083",
      "pub.1142910911",
      "pub.1171284231",
      "pub.1153866667",
      "pub.1144501413",
      "pub.1149382405",
      "pub.1163269196",
      "pub.1149966370",
      "pub.1121024948",
      "pub.1156543204",
      "pub.1142681044",
      "pub.1171600853",
      "pub.1062645873",
      "pub.1112000050",
      "pub.1168167241",
      "pub.1164073767",
      "pub.1133309952",
      "pub.1134455709",
      "pub.1164851478",
      "pub.1170273210",
      "pub.1182703573",
      "pub.1143468605",
      "pub.1006481445",
      "pub.1053193814",
      "pub.1006108758",
      "pub.1129757334",
      "pub.1139661088",
      "pub.1169268693",
      "pub.1155808762"
    ],
    "concepts_scores": [
      {
        "concept": "deep language models",
        "relevance": 0.668
      },
      {
        "concept": "representational similarity analysis",
        "relevance": 0.649
      },
      {
        "concept": "abstractive summarization",
        "relevance": 0.603
      },
      {
        "concept": "summarization performance",
        "relevance": 0.598
      },
      {
        "concept": "representational similarity",
        "relevance": 0.596
      },
      {
        "concept": "language model",
        "relevance": 0.594
      },
      {
        "concept": "hidden layer",
        "relevance": 0.587
      },
      {
        "concept": "representation patterns",
        "relevance": 0.573
      },
      {
        "concept": "improve language models",
        "relevance": 0.557
      },
      {
        "concept": "neural similarity",
        "relevance": 0.525
      },
      {
        "concept": "neural correlates",
        "relevance": 0.522
      },
      {
        "concept": "AB task",
        "relevance": 0.521
      },
      {
        "concept": "T5 model",
        "relevance": 0.519
      },
      {
        "concept": "human brain activity",
        "relevance": 0.519
      },
      {
        "concept": "cognitive mechanisms",
        "relevance": 0.516
      },
      {
        "concept": "noise addition",
        "relevance": 0.515
      },
      {
        "concept": "cognitive processes",
        "relevance": 0.514
      },
      {
        "concept": "brain activity",
        "relevance": 0.511
      },
      {
        "concept": "language understanding",
        "relevance": 0.51
      },
      {
        "concept": "hidden layer",
        "relevance": 0.507
      },
      {
        "concept": "language representation",
        "relevance": 0.507
      },
      {
        "concept": "model performance",
        "relevance": 0.489
      },
      {
        "concept": "human brain",
        "relevance": 0.482
      },
      {
        "concept": "summarization",
        "relevance": 0.465
      },
      {
        "concept": "model texts",
        "relevance": 0.461
      },
      {
        "concept": "similarity analysis",
        "relevance": 0.439
      },
      {
        "concept": "generation capability",
        "relevance": 0.428
      },
      {
        "concept": "performance",
        "relevance": 0.418
      },
      {
        "concept": "shallow layer",
        "relevance": 0.417
      },
      {
        "concept": "essential information",
        "relevance": 0.411
      },
      {
        "concept": "language",
        "relevance": 0.401
      },
      {
        "concept": "spatiotemporal conditions",
        "relevance": 0.399
      },
      {
        "concept": "text",
        "relevance": 0.389
      },
      {
        "concept": "similarity",
        "relevance": 0.38
      },
      {
        "concept": "brain",
        "relevance": 0.376
      },
      {
        "concept": "task",
        "relevance": 0.365
      },
      {
        "concept": "perplexity",
        "relevance": 0.365
      },
      {
        "concept": "representation",
        "relevance": 0.357
      },
      {
        "concept": "noise",
        "relevance": 0.356
      },
      {
        "concept": "model",
        "relevance": 0.348
      },
      {
        "concept": "capability",
        "relevance": 0.338
      },
      {
        "concept": "information",
        "relevance": 0.338
      },
      {
        "concept": "hypothesis",
        "relevance": 0.332
      },
      {
        "concept": "Pegasus",
        "relevance": 0.328
      },
      {
        "concept": "findings",
        "relevance": 0.326
      },
      {
        "concept": "correlation",
        "relevance": 0.325
      },
      {
        "concept": "attention",
        "relevance": 0.316
      },
      {
        "concept": "internal mechanism",
        "relevance": 0.315
      },
      {
        "concept": "deep layers",
        "relevance": 0.311
      },
      {
        "concept": "study",
        "relevance": 0.308
      },
      {
        "concept": "manipulation",
        "relevance": 0.306
      },
      {
        "concept": "statistical significance",
        "relevance": 0.299
      },
      {
        "concept": "research",
        "relevance": 0.292
      },
      {
        "concept": "layer",
        "relevance": 0.288
      },
      {
        "concept": "mechanism",
        "relevance": 0.286
      },
      {
        "concept": "understanding",
        "relevance": 0.266
      },
      {
        "concept": "effect",
        "relevance": 0.265
      },
      {
        "concept": "process",
        "relevance": 0.264
      },
      {
        "concept": "generation",
        "relevance": 0.261
      },
      {
        "concept": "patterns",
        "relevance": 0.261
      },
      {
        "concept": "results",
        "relevance": 0.257
      },
      {
        "concept": "Bart",
        "relevance": 0.246
      },
      {
        "concept": "activity",
        "relevance": 0.243
      },
      {
        "concept": "conditions",
        "relevance": 0.215
      },
      {
        "concept": "analysis",
        "relevance": 0.214
      },
      {
        "concept": "significance",
        "relevance": 0.213
      },
      {
        "concept": "depth",
        "relevance": 0.205
      },
      {
        "concept": "ablation",
        "relevance": 0.17
      },
      {
        "concept": "addition",
        "relevance": 0.159
      }
    ]
  }
]