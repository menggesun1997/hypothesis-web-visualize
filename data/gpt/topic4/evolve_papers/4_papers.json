{
  "papers": [
    {
      "paperId": "pub.1175845134",
      "doi": "10.1145/3695988",
      "title": "Large Language Models for Software Engineering: A Systematic Literature Review",
      "year": 2024,
      "citationCount": 347,
      "fieldCitationRatio": NaN,
      "abstract": " Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a Systematic Literature Review (SLR) on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. We selected and analyzed 395 research articles from January 2017 to January 2024 to answer four key Research Questions (RQs). In RQ1, we categorize different LLMs that have been employed in SE tasks, characterizing their distinctive features and uses. In RQ2, we analyze the methods used in data collection, pre-processing, and application, highlighting the role of well-curated datasets for successful LLM for SE implementation. RQ3 investigates the strategies employed to optimize and evaluate the performance of LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have shown success to date, illustrating their practical contributions to the field. From the answers to these RQs, we discuss the current state-of-the-art and trends, identifying gaps in existing research, and highlighting promising areas for future study. Our artifacts are publicly available at https://github.com/security-pride/LLM4SE_SLR . ",
      "reference_ids": [
        "pub.1166473981",
        "pub.1168593104",
        "pub.1166872344",
        "pub.1170644911",
        "pub.1144123804",
        "pub.1173879691",
        "pub.1168597016",
        "pub.1172853420",
        "pub.1149507903",
        "pub.1154991596",
        "pub.1143052462",
        "pub.1106260453",
        "pub.1047317951",
        "pub.1171469423",
        "pub.1166484591",
        "pub.1164032337",
        "pub.1149658130",
        "pub.1134913827",
        "pub.1164955444",
        "pub.1006514715",
        "pub.1154263376",
        "pub.1166487967",
        "pub.1149507869",
        "pub.1168872394",
        "pub.1012988085",
        "pub.1034891606",
        "pub.1154263442",
        "pub.1160660435",
        "pub.1158257850",
        "pub.1163042422",
        "pub.1166475799",
        "pub.1127745563",
        "pub.1139948543",
        "pub.1148904699",
        "pub.1157156690",
        "pub.1160648386",
        "pub.1160195005",
        "pub.1099113633",
        "pub.1160285050",
        "pub.1173879696",
        "pub.1113998605",
        "pub.1168599571",
        "pub.1151613990",
        "pub.1152468148",
        "pub.1148878427",
        "pub.1105723410",
        "pub.1165723102",
        "pub.1166485425",
        "pub.1143949474",
        "pub.1153581687",
        "pub.1095454257",
        "pub.1150464538",
        "pub.1168599583",
        "pub.1131375822",
        "pub.1148897984",
        "pub.1166873943",
        "pub.1170646359",
        "pub.1165648584",
        "pub.1164618708",
        "pub.1093207508",
        "pub.1152622061",
        "pub.1166880487",
        "pub.1168599446",
        "pub.1168019581",
        "pub.1152622150",
        "pub.1160322123",
        "pub.1163043859",
        "pub.1166535528",
        "pub.1171905879",
        "pub.1132276140",
        "pub.1155682176",
        "pub.1132276148",
        "pub.1162634800",
        "pub.1148899800",
        "pub.1138068604",
        "pub.1147783415",
        "pub.1168149665",
        "pub.1172814708",
        "pub.1137854795",
        "pub.1147783413",
        "pub.1167393978",
        "pub.1182672051",
        "pub.1186384380",
        "pub.1167607106",
        "pub.1153734012",
        "pub.1175215167",
        "pub.1168013651",
        "pub.1061421082",
        "pub.1167041781",
        "pub.1120604281",
        "pub.1160653681",
        "pub.1163043420",
        "pub.1165536538",
        "pub.1033221758",
        "pub.1169562619",
        "pub.1172304190",
        "pub.1148903657",
        "pub.1063170507",
        "pub.1156150198",
        "pub.1162972292",
        "pub.1166477986",
        "pub.1163045500",
        "pub.1149507909",
        "pub.1166873863",
        "pub.1146188698",
        "pub.1094101114",
        "pub.1149300959",
        "pub.1166445927",
        "pub.1160719483",
        "pub.1158592766",
        "pub.1106260451",
        "pub.1061788523",
        "pub.1166490212",
        "pub.1134915136",
        "pub.1133175050",
        "pub.1130838254",
        "pub.1148697564",
        "pub.1148900283",
        "pub.1143050596",
        "pub.1168593827",
        "pub.1104576545",
        "pub.1153795134",
        "pub.1148522939",
        "pub.1170647412",
        "pub.1154263433",
        "pub.1152622128",
        "pub.1148898608",
        "pub.1148903227",
        "pub.1152377816",
        "pub.1153795194",
        "pub.1148895107",
        "pub.1163029560",
        "pub.1148897844",
        "pub.1148307304",
        "pub.1152622074",
        "pub.1129757045",
        "pub.1173879734",
        "pub.1160717572",
        "pub.1108387031",
        "pub.1106260430",
        "pub.1017969092",
        "pub.1136269624",
        "pub.1095710474",
        "pub.1153332768",
        "pub.1182022794",
        "pub.1094013537",
        "pub.1149257011",
        "pub.1153500306",
        "pub.1148307305",
        "pub.1162804688",
        "pub.1142638056",
        "pub.1163042588",
        "pub.1014258985",
        "pub.1168594510",
        "pub.1157308242",
        "pub.1143948984",
        "pub.1168777835",
        "pub.1138840378",
        "pub.1168595386",
        "pub.1128391191",
        "pub.1061786980",
        "pub.1169657972",
        "pub.1146057267",
        "pub.1148391290",
        "pub.1156110108",
        "pub.1131375800",
        "pub.1166474857",
        "pub.1154960162",
        "pub.1166485727",
        "pub.1181477037",
        "pub.1153500004",
        "pub.1106260444",
        "pub.1183559020",
        "pub.1039836062",
        "pub.1100885301",
        "pub.1149658363",
        "pub.1166482484",
        "pub.1030955573",
        "pub.1163041829",
        "pub.1154351115",
        "pub.1166135283",
        "pub.1152331335",
        "pub.1107916117",
        "pub.1163045348",
        "pub.1165942007",
        "pub.1148581733",
        "pub.1148897523",
        "pub.1133174433",
        "pub.1009535781",
        "pub.1084527254",
        "pub.1183614415",
        "pub.1166873019",
        "pub.1166873684",
        "pub.1160719237",
        "pub.1148904539",
        "pub.1131225916",
        "pub.1163044218",
        "pub.1166491049",
        "pub.1168022892",
        "pub.1186383757",
        "pub.1093860235",
        "pub.1137865998",
        "pub.1093572493",
        "pub.1168600984",
        "pub.1166874040",
        "pub.1038557439",
        "pub.1148903402",
        "pub.1184929900",
        "pub.1148900537",
        "pub.1163764868",
        "pub.1154263528",
        "pub.1143941836",
        "pub.1168592076",
        "pub.1084227982",
        "pub.1017019936",
        "pub.1166873218"
      ],
      "concepts_scores": [
        {
          "concept": "software engineering",
          "relevance": 0.788
        },
        {
          "concept": "SE tasks",
          "relevance": 0.768
        },
        {
          "concept": "language model",
          "relevance": 0.724
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.679
        },
        {
          "concept": "systematic literature review",
          "relevance": 0.674
        },
        {
          "concept": "pre-processing",
          "relevance": 0.602
        },
        {
          "concept": "well-curated datasets",
          "relevance": 0.59
        },
        {
          "concept": "SE implementation",
          "relevance": 0.573
        },
        {
          "concept": "task",
          "relevance": 0.541
        },
        {
          "concept": "research questions",
          "relevance": 0.536
        },
        {
          "concept": "software",
          "relevance": 0.526
        },
        {
          "concept": "literature review",
          "relevance": 0.486
        },
        {
          "concept": "research articles",
          "relevance": 0.477
        },
        {
          "concept": "language",
          "relevance": 0.473
        },
        {
          "concept": "dataset",
          "relevance": 0.464
        },
        {
          "concept": "LLM",
          "relevance": 0.453
        },
        {
          "concept": "applications",
          "relevance": 0.446
        },
        {
          "concept": "data",
          "relevance": 0.444
        },
        {
          "concept": "RQ3",
          "relevance": 0.434
        },
        {
          "concept": "engineering",
          "relevance": 0.43
        },
        {
          "concept": "RQ1",
          "relevance": 0.422
        },
        {
          "concept": "implementation",
          "relevance": 0.422
        },
        {
          "concept": "RQ4",
          "relevance": 0.419
        },
        {
          "concept": "artifacts",
          "relevance": 0.414
        },
        {
          "concept": "performance",
          "relevance": 0.409
        },
        {
          "concept": "research",
          "relevance": 0.403
        },
        {
          "concept": "model",
          "relevance": 0.393
        },
        {
          "concept": "features",
          "relevance": 0.393
        },
        {
          "concept": "data collection",
          "relevance": 0.39
        },
        {
          "concept": "domain",
          "relevance": 0.387
        },
        {
          "concept": "answers",
          "relevance": 0.382
        },
        {
          "concept": "collection",
          "relevance": 0.363
        },
        {
          "concept": "method",
          "relevance": 0.359
        },
        {
          "concept": "gap",
          "relevance": 0.328
        },
        {
          "concept": "publications",
          "relevance": 0.322
        },
        {
          "concept": "process",
          "relevance": 0.322
        },
        {
          "concept": "success",
          "relevance": 0.313
        },
        {
          "concept": "field",
          "relevance": 0.294
        },
        {
          "concept": "limitations",
          "relevance": 0.292
        },
        {
          "concept": "contribution",
          "relevance": 0.29
        },
        {
          "concept": "early stages",
          "relevance": 0.289
        },
        {
          "concept": "understanding",
          "relevance": 0.287
        },
        {
          "concept": "comprehensive understanding",
          "relevance": 0.275
        },
        {
          "concept": "article",
          "relevance": 0.272
        },
        {
          "concept": "questions",
          "relevance": 0.26
        },
        {
          "concept": "trends",
          "relevance": 0.256
        },
        {
          "concept": "stage",
          "relevance": 0.24
        },
        {
          "concept": "review",
          "relevance": 0.224
        },
        {
          "concept": "effect",
          "relevance": 0.204
        },
        {
          "concept": "study",
          "relevance": 0.186
        },
        {
          "concept": "outcomes",
          "relevance": 0.144
        }
      ]
    },
    {
      "paperId": "pub.1172304190",
      "doi": "10.1007/978-3-031-55642-5_4",
      "title": "ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design",
      "year": 2024,
      "citationCount": 207,
      "fieldCitationRatio": 0.0,
      "abstract": "This chapter presents design techniques for software engineering, in the form of prompt patterns, to solve common problems that arise when using large language models (LLMs) to automate common software engineering activities, such as ensuring code is decoupled from third-party libraries and creating API specifications from lists of requirements. This chapter provides two contributions to research on using LLMs for software engineering. First, it provides a catalog of patterns for software engineering that classifies patterns according to the types of problems they solve. Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, code quality, deployment, and testing.",
      "reference_ids": [
        "pub.1155096588",
        "pub.1149798057",
        "pub.1002400887",
        "pub.1150577958",
        "pub.1128474475",
        "pub.1111334540",
        "pub.1169640331",
        "pub.1151003027",
        "pub.1157891790",
        "pub.1162804688",
        "pub.1158466310",
        "pub.1061387764",
        "pub.1164301924"
      ],
      "concepts_scores": [
        {
          "concept": "software engineering",
          "relevance": 0.79
        },
        {
          "concept": "requirements elicitation",
          "relevance": 0.751
        },
        {
          "concept": "code quality",
          "relevance": 0.749
        },
        {
          "concept": "catalog of patterns",
          "relevance": 0.704
        },
        {
          "concept": "improve requirements elicitation",
          "relevance": 0.704
        },
        {
          "concept": "software engineering activities",
          "relevance": 0.702
        },
        {
          "concept": "third-party libraries",
          "relevance": 0.702
        },
        {
          "concept": "improving code quality",
          "relevance": 0.701
        },
        {
          "concept": "language model",
          "relevance": 0.642
        },
        {
          "concept": "software design",
          "relevance": 0.636
        },
        {
          "concept": "API specification",
          "relevance": 0.622
        },
        {
          "concept": "software",
          "relevance": 0.581
        },
        {
          "concept": "engineering activities",
          "relevance": 0.576
        },
        {
          "concept": "code",
          "relevance": 0.538
        },
        {
          "concept": "design techniques",
          "relevance": 0.52
        },
        {
          "concept": "refactoring",
          "relevance": 0.509
        },
        {
          "concept": "ChatGPT",
          "relevance": 0.505
        },
        {
          "concept": "requirements",
          "relevance": 0.483
        },
        {
          "concept": "elicitation",
          "relevance": 0.48
        },
        {
          "concept": "deployment",
          "relevance": 0.476
        },
        {
          "concept": "API",
          "relevance": 0.466
        },
        {
          "concept": "engineering",
          "relevance": 0.464
        },
        {
          "concept": "library",
          "relevance": 0.448
        },
        {
          "concept": "prototype",
          "relevance": 0.439
        },
        {
          "concept": "LLM",
          "relevance": 0.431
        },
        {
          "concept": "design",
          "relevance": 0.427
        },
        {
          "concept": "language",
          "relevance": 0.419
        },
        {
          "concept": "quality",
          "relevance": 0.416
        },
        {
          "concept": "catalog",
          "relevance": 0.416
        },
        {
          "concept": "technique",
          "relevance": 0.375
        },
        {
          "concept": "patterns",
          "relevance": 0.357
        },
        {
          "concept": "model",
          "relevance": 0.349
        },
        {
          "concept": "improvement",
          "relevance": 0.336
        },
        {
          "concept": "specificity",
          "relevance": 0.324
        },
        {
          "concept": "contribution",
          "relevance": 0.298
        },
        {
          "concept": "test",
          "relevance": 0.262
        },
        {
          "concept": "problem",
          "relevance": 0.175
        },
        {
          "concept": "activity",
          "relevance": 0.172
        }
      ]
    },
    {
      "paperId": "pub.1128474475",
      "doi": "10.1145/3386252",
      "title": "Generalizing from a Few Examples",
      "year": 2020,
      "citationCount": 2526,
      "fieldCitationRatio": 707.41,
      "abstract": " Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this article, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimizer is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the FSL problem setups, techniques, applications, and theories, are also proposed to provide insights for future research. 1 ",
      "reference_ids": [
        "pub.1088751839",
        "pub.1027055246",
        "pub.1050466409",
        "pub.1091357656",
        "pub.1061743121",
        "pub.1088800339",
        "pub.1038140272",
        "pub.1061661916",
        "pub.1084536967",
        "pub.1008597102",
        "pub.1103799846",
        "pub.1110904900",
        "pub.1110923419",
        "pub.1051365551",
        "pub.1041355599",
        "pub.1015677315",
        "pub.1084152728"
      ],
      "concepts_scores": [
        {
          "concept": "few-shot learning",
          "relevance": 0.832
        },
        {
          "concept": "hypothesis space",
          "relevance": 0.697
        },
        {
          "concept": "few-shot learning methods",
          "relevance": 0.684
        },
        {
          "concept": "machine learning problems",
          "relevance": 0.661
        },
        {
          "concept": "data-intensive applications",
          "relevance": 0.656
        },
        {
          "concept": "empirical risk minimization",
          "relevance": 0.655
        },
        {
          "concept": "supervised information",
          "relevance": 0.617
        },
        {
          "concept": "learning problems",
          "relevance": 0.598
        },
        {
          "concept": "machine learning",
          "relevance": 0.593
        },
        {
          "concept": "risk minimization",
          "relevance": 0.574
        },
        {
          "concept": "problem setup",
          "relevance": 0.568
        },
        {
          "concept": "learning",
          "relevance": 0.494
        },
        {
          "concept": "core issues",
          "relevance": 0.465
        },
        {
          "concept": "algorithm",
          "relevance": 0.455
        },
        {
          "concept": "machine",
          "relevance": 0.436
        },
        {
          "concept": "applications",
          "relevance": 0.435
        },
        {
          "concept": "task",
          "relevance": 0.434
        },
        {
          "concept": "knowledge",
          "relevance": 0.433
        },
        {
          "concept": "issues",
          "relevance": 0.414
        },
        {
          "concept": "space",
          "relevance": 0.407
        },
        {
          "concept": "information",
          "relevance": 0.401
        },
        {
          "concept": "search",
          "relevance": 0.39
        },
        {
          "concept": "taxonomy",
          "relevance": 0.388
        },
        {
          "concept": "data",
          "relevance": 0.366
        },
        {
          "concept": "setup",
          "relevance": 0.358
        },
        {
          "concept": "technique",
          "relevance": 0.356
        },
        {
          "concept": "method",
          "relevance": 0.35
        },
        {
          "concept": "minimization",
          "relevance": 0.348
        },
        {
          "concept": "definition",
          "relevance": 0.339
        },
        {
          "concept": "experiments",
          "relevance": 0.332
        },
        {
          "concept": "model",
          "relevance": 0.331
        },
        {
          "concept": "research",
          "relevance": 0.323
        },
        {
          "concept": "categories",
          "relevance": 0.306
        },
        {
          "concept": "pros",
          "relevance": 0.298
        },
        {
          "concept": "perspective",
          "relevance": 0.297
        },
        {
          "concept": "Con",
          "relevance": 0.295
        },
        {
          "concept": "direction",
          "relevance": 0.295
        },
        {
          "concept": "core",
          "relevance": 0.291
        },
        {
          "concept": "supervision experiences",
          "relevance": 0.285
        },
        {
          "concept": "theory",
          "relevance": 0.265
        },
        {
          "concept": "size",
          "relevance": 0.258
        },
        {
          "concept": "survey",
          "relevance": 0.238
        },
        {
          "concept": "hypothesis",
          "relevance": 0.209
        },
        {
          "concept": "problem",
          "relevance": 0.193
        },
        {
          "concept": "samples",
          "relevance": 0.189
        }
      ]
    },
    {
      "paperId": "pub.1038140272",
      "doi": "10.1162/neco.1997.9.8.1735",
      "title": "Long Short-Term Memory",
      "year": 1997,
      "citationCount": 76145,
      "fieldCitationRatio": NaN,
      "abstract": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.",
      "reference_ids": [
        "pub.1040448456",
        "pub.1062950862",
        "pub.1010400358",
        "pub.1061218816",
        "pub.1028253248",
        "pub.1061218416",
        "pub.1026846030",
        "pub.1061218649",
        "pub.1036797001",
        "pub.1062899544",
        "pub.1061218426",
        "pub.1025746693",
        "pub.1060795871",
        "pub.1039169504",
        "pub.1019444189",
        "pub.1019562274",
        "pub.1086305447",
        "pub.1052711422",
        "pub.1046141720",
        "pub.1003959523"
      ],
      "concepts_scores": [
        {
          "concept": "long short-term memory",
          "relevance": 0.852
        },
        {
          "concept": "constant error flow",
          "relevance": 0.794
        },
        {
          "concept": "real-time recurrent learning",
          "relevance": 0.693
        },
        {
          "concept": "recurrent cascade correlation",
          "relevance": 0.686
        },
        {
          "concept": "error flow",
          "relevance": 0.669
        },
        {
          "concept": "constant error carousels",
          "relevance": 0.651
        },
        {
          "concept": "gradient-based methods",
          "relevance": 0.638
        },
        {
          "concept": "short-term memory",
          "relevance": 0.634
        },
        {
          "concept": "recurrent backpropagation",
          "relevance": 0.633
        },
        {
          "concept": "Cascade Correlation",
          "relevance": 0.626
        },
        {
          "concept": "recurrent learning",
          "relevance": 0.625
        },
        {
          "concept": "pattern representation",
          "relevance": 0.621
        },
        {
          "concept": "computational complexity",
          "relevance": 0.62
        },
        {
          "concept": "Elman net",
          "relevance": 0.615
        },
        {
          "concept": "network algorithm",
          "relevance": 0.612
        },
        {
          "concept": "gate unit",
          "relevance": 0.61
        },
        {
          "concept": "back propagation",
          "relevance": 0.61
        },
        {
          "concept": "artificial data",
          "relevance": 0.591
        },
        {
          "concept": "minimal time lag",
          "relevance": 0.542
        },
        {
          "concept": "backpropagation",
          "relevance": 0.487
        },
        {
          "concept": "Elman",
          "relevance": 0.472
        },
        {
          "concept": "chunks",
          "relevance": 0.469
        },
        {
          "concept": "algorithm",
          "relevance": 0.467
        },
        {
          "concept": "task",
          "relevance": 0.445
        },
        {
          "concept": "learning",
          "relevance": 0.438
        },
        {
          "concept": "representation",
          "relevance": 0.435
        },
        {
          "concept": "nets",
          "relevance": 0.415
        },
        {
          "concept": "information",
          "relevance": 0.411
        },
        {
          "concept": "memory",
          "relevance": 0.394
        },
        {
          "concept": "extended time interval",
          "relevance": 0.364
        },
        {
          "concept": "carousel",
          "relevance": 0.361
        },
        {
          "concept": "space",
          "relevance": 0.361
        },
        {
          "concept": "method",
          "relevance": 0.36
        },
        {
          "concept": "experiments",
          "relevance": 0.341
        },
        {
          "concept": "complex",
          "relevance": 0.34
        },
        {
          "concept": "propagation",
          "relevance": 0.329
        },
        {
          "concept": "time interval",
          "relevance": 0.328
        },
        {
          "concept": "data",
          "relevance": 0.325
        },
        {
          "concept": "time",
          "relevance": 0.31
        },
        {
          "concept": "gradient",
          "relevance": 0.291
        },
        {
          "concept": "time lag",
          "relevance": 0.287
        },
        {
          "concept": "comparison",
          "relevance": 0.28
        },
        {
          "concept": "weight",
          "relevance": 0.275
        },
        {
          "concept": "flow",
          "relevance": 0.27
        },
        {
          "concept": "analysis",
          "relevance": 0.258
        },
        {
          "concept": "backflow",
          "relevance": 0.244
        },
        {
          "concept": "units",
          "relevance": 0.241
        },
        {
          "concept": "interval",
          "relevance": 0.216
        },
        {
          "concept": "correlation",
          "relevance": 0.215
        },
        {
          "concept": "lag",
          "relevance": 0.213
        },
        {
          "concept": "problem",
          "relevance": 0.198
        },
        {
          "concept": "harm",
          "relevance": 0.17
        },
        {
          "concept": "excess",
          "relevance": 0.156
        }
      ]
    },
    {
      "paperId": "pub.1061661916",
      "doi": "10.1109/tkde.2008.239",
      "title": "Learning from Imbalanced Data",
      "year": 2009,
      "citationCount": 7418,
      "fieldCitationRatio": 1677.46,
      "abstract": "With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, and finance, it becomes critical to advance the fundamental understanding of knowledge discovery and analysis from raw data to support decision-making processes. Although existing knowledge discovery and data engineering techniques have shown great success in many real-world applications, the problem of learning from imbalanced data (the imbalanced learning problem) is a relatively new challenge that has attracted growing attention from both academia and industry. The imbalanced learning problem is concerned with the performance of learning algorithms in the presence of underrepresented data and severe class distribution skews. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. In this paper, we provide a comprehensive review of the development of research in learning from imbalanced data. Our focus is to provide a critical review of the nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance under the imbalanced learning scenario. Furthermore, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potential important research directions for learning from imbalanced data.",
      "reference_ids": [
        "pub.1046546824",
        "pub.1045398430",
        "pub.1098661684",
        "pub.1094451585",
        "pub.1022715535",
        "pub.1008579028",
        "pub.1061661058",
        "pub.1061661763",
        "pub.1021956833",
        "pub.1077006722",
        "pub.1093531524",
        "pub.1052391244",
        "pub.1034176297",
        "pub.1023806993",
        "pub.1093566489",
        "pub.1022351828",
        "pub.1093182361",
        "pub.1012896250",
        "pub.1000822708",
        "pub.1061717103",
        "pub.1061156933",
        "pub.1005002170",
        "pub.1095444225",
        "pub.1017426846",
        "pub.1009769041",
        "pub.1034986465",
        "pub.1095738751",
        "pub.1105579281",
        "pub.1061661489",
        "pub.1094836214",
        "pub.1038617092",
        "pub.1013701558",
        "pub.1095091450",
        "pub.1036100567",
        "pub.1013255251",
        "pub.1007047227",
        "pub.1105579550",
        "pub.1094083247",
        "pub.1011094196",
        "pub.1019422208",
        "pub.1107703598",
        "pub.1061661695",
        "pub.1094917713",
        "pub.1016314455",
        "pub.1040465799",
        "pub.1037852366",
        "pub.1094480931",
        "pub.1006040100",
        "pub.1022023208",
        "pub.1061717412",
        "pub.1027764922",
        "pub.1095166946",
        "pub.1010464079",
        "pub.1003442924",
        "pub.1027312764",
        "pub.1094526849",
        "pub.1036355972",
        "pub.1009182784",
        "pub.1011629758",
        "pub.1005877303",
        "pub.1001290304",
        "pub.1008288303",
        "pub.1094557491",
        "pub.1095207594",
        "pub.1062950888",
        "pub.1094259222",
        "pub.1018015582",
        "pub.1094491390",
        "pub.1028143634",
        "pub.1061717112",
        "pub.1034710737",
        "pub.1012245555",
        "pub.1050012563",
        "pub.1044229856",
        "pub.1019404879",
        "pub.1023479322",
        "pub.1014940366",
        "pub.1025850532",
        "pub.1040433546",
        "pub.1061661558",
        "pub.1024280650",
        "pub.1061186312",
        "pub.1094926134",
        "pub.1041320371",
        "pub.1061219235",
        "pub.1094503952",
        "pub.1015517659",
        "pub.1004338842",
        "pub.1041567410",
        "pub.1009268211"
      ],
      "concepts_scores": [
        {
          "concept": "imbalanced data",
          "relevance": 0.767
        },
        {
          "concept": "knowledge discovery",
          "relevance": 0.728
        },
        {
          "concept": "performance of learning algorithms",
          "relevance": 0.706
        },
        {
          "concept": "imbalanced data sets",
          "relevance": 0.686
        },
        {
          "concept": "imbalanced learning problem",
          "relevance": 0.684
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.684
        },
        {
          "concept": "data engineering techniques",
          "relevance": 0.68
        },
        {
          "concept": "severe class distribution",
          "relevance": 0.672
        },
        {
          "concept": "raw data",
          "relevance": 0.656
        },
        {
          "concept": "transform vast amounts",
          "relevance": 0.638
        },
        {
          "concept": "imbalanced data",
          "relevance": 0.636
        },
        {
          "concept": "knowledge representation",
          "relevance": 0.634
        },
        {
          "concept": "evaluate learning performance",
          "relevance": 0.629
        },
        {
          "concept": "learning algorithms",
          "relevance": 0.624
        },
        {
          "concept": "learning problems",
          "relevance": 0.618
        },
        {
          "concept": "learning scenarios",
          "relevance": 0.612
        },
        {
          "concept": "state-of-the-art technologies",
          "relevance": 0.605
        },
        {
          "concept": "network system",
          "relevance": 0.603
        },
        {
          "concept": "class distribution",
          "relevance": 0.6
        },
        {
          "concept": "assessment metrics",
          "relevance": 0.598
        },
        {
          "concept": "learning performance",
          "relevance": 0.588
        },
        {
          "concept": "vast amounts",
          "relevance": 0.583
        },
        {
          "concept": "data sets",
          "relevance": 0.577
        },
        {
          "concept": "research directions",
          "relevance": 0.553
        },
        {
          "concept": "algorithm",
          "relevance": 0.544
        },
        {
          "concept": "engineering techniques",
          "relevance": 0.537
        },
        {
          "concept": "data availability",
          "relevance": 0.532
        },
        {
          "concept": "continuous expansion",
          "relevance": 0.51
        },
        {
          "concept": "complex characteristics",
          "relevance": 0.51
        },
        {
          "concept": "decision-making process",
          "relevance": 0.495
        },
        {
          "concept": "Internet",
          "relevance": 0.477
        },
        {
          "concept": "performance",
          "relevance": 0.476
        },
        {
          "concept": "stimulate future research",
          "relevance": 0.472
        },
        {
          "concept": "imbalancing",
          "relevance": 0.47
        },
        {
          "concept": "security",
          "relevance": 0.47
        },
        {
          "concept": "metrics",
          "relevance": 0.453
        },
        {
          "concept": "development of research",
          "relevance": 0.448
        },
        {
          "concept": "data",
          "relevance": 0.447
        },
        {
          "concept": "learning",
          "relevance": 0.441
        },
        {
          "concept": "representation",
          "relevance": 0.437
        },
        {
          "concept": "knowledge",
          "relevance": 0.436
        },
        {
          "concept": "future research",
          "relevance": 0.429
        },
        {
          "concept": "scenarios",
          "relevance": 0.428
        },
        {
          "concept": "information",
          "relevance": 0.414
        },
        {
          "concept": "academia",
          "relevance": 0.412
        },
        {
          "concept": "technology",
          "relevance": 0.409
        },
        {
          "concept": "data",
          "relevance": 0.408
        },
        {
          "concept": "applications",
          "relevance": 0.388
        },
        {
          "concept": "research",
          "relevance": 0.386
        },
        {
          "concept": "comprehensive review",
          "relevance": 0.375
        },
        {
          "concept": "system",
          "relevance": 0.374
        },
        {
          "concept": "tools",
          "relevance": 0.374
        },
        {
          "concept": "sets",
          "relevance": 0.373
        },
        {
          "concept": "discovery",
          "relevance": 0.372
        },
        {
          "concept": "technique",
          "relevance": 0.368
        },
        {
          "concept": "challenges",
          "relevance": 0.352
        },
        {
          "concept": "complex",
          "relevance": 0.342
        },
        {
          "concept": "surveillance",
          "relevance": 0.34
        },
        {
          "concept": "availability",
          "relevance": 0.326
        },
        {
          "concept": "principles",
          "relevance": 0.325
        },
        {
          "concept": "process",
          "relevance": 0.324
        },
        {
          "concept": "industry",
          "relevance": 0.324
        },
        {
          "concept": "success",
          "relevance": 0.315
        },
        {
          "concept": "direction",
          "relevance": 0.305
        },
        {
          "concept": "opportunities",
          "relevance": 0.301
        },
        {
          "concept": "development",
          "relevance": 0.281
        },
        {
          "concept": "nature",
          "relevance": 0.266
        },
        {
          "concept": "distribution",
          "relevance": 0.262
        },
        {
          "concept": "amount",
          "relevance": 0.26
        },
        {
          "concept": "analysis",
          "relevance": 0.259
        },
        {
          "concept": "finance",
          "relevance": 0.237
        },
        {
          "concept": "assessment",
          "relevance": 0.23
        },
        {
          "concept": "problem",
          "relevance": 0.228
        },
        {
          "concept": "review",
          "relevance": 0.226
        },
        {
          "concept": "presence",
          "relevance": 0.155
        }
      ]
    },
    {
      "paperId": "pub.1061387764",
      "doi": "10.1109/mc.2006.58",
      "title": "Guest Editor's Introduction: Model-Driven Engineering",
      "year": 2006,
      "citationCount": 1696,
      "fieldCitationRatio": 380.78,
      "abstract": "Model-driven engineering technologies offer a promising approach to address the inability of third-generation languages to alleviate the complexity of platforms and express domain concepts effectively.",
      "reference_ids": [
        "pub.1053280737"
      ],
      "concepts_scores": [
        {
          "concept": "model-driven engineering technologies",
          "relevance": 0.649
        },
        {
          "concept": "express domain concepts",
          "relevance": 0.634
        },
        {
          "concept": "third-generation languages",
          "relevance": 0.628
        },
        {
          "concept": "domain concepts",
          "relevance": 0.573
        },
        {
          "concept": "complexity of platforms",
          "relevance": 0.547
        },
        {
          "concept": "engineering technology",
          "relevance": 0.399
        },
        {
          "concept": "platform",
          "relevance": 0.397
        },
        {
          "concept": "language",
          "relevance": 0.378
        },
        {
          "concept": "technology",
          "relevance": 0.376
        },
        {
          "concept": "concept",
          "relevance": 0.331
        },
        {
          "concept": "complex",
          "relevance": 0.315
        },
        {
          "concept": "inability",
          "relevance": 0.208
        }
      ]
    },
    {
      "paperId": "pub.1170644911",
      "doi": "10.1145/3597503.3639183",
      "title": "Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization)",
      "year": 2024,
      "citationCount": 67,
      "fieldCitationRatio": 0.0,
      "abstract": "Large Language Models (LLM) are a new class of computation engines, \"programmed\" via prompt engineering. Researchers are still learning how to best \"program\" these LLMs to help developers. We start with the intuition that developers tend to consciously and unconsciously collect semantics facts, from the code, while working. Mostly these are shallow, simple facts arising from a quick read. For a function, such facts might include parameter and local variable names, return expressions, simple pre- and post-conditions, and basic control and data flow, etc. One might assume that the powerful multi-layer architecture of transformer-style LLMs makes them implicitly capable of doing this simple level of \"code analysis\" and extracting such information, while processing code: but are they, really? If they aren't, could explicitly adding this information help? Our goal here is to investigate this question, using the code summarization task and evaluate whether automatically augmenting an LLM's prompt with semantic facts explicitly, actually helps. Prior work shows that LLM performance on code summarization benefits from embedding a few code & summary exemplars in the prompt, before the code to be summarized. While summarization performance has steadily progressed since the early days, there is still room for improvement: LLM performance on code summarization still lags its performance on natural-language tasks like translation and text summarization. We find that adding semantic facts to the code in the prompt actually does help! This approach improves performance in several different settings suggested by prior work, including for three different Large Language Models. In most cases, we see improvements, as measured by a range of commonly-used metrics; for the PHP language in the challenging CodeSearchNet dataset, this augmentation actually yields performance surpassing 30 BLEU1. In addition, we have also found that including semantic facts yields a substantial enhancement in LLMs' line completion performance.",
      "reference_ids": [
        "pub.1160719363",
        "pub.1140503219",
        "pub.1105723410",
        "pub.1150489574",
        "pub.1099117498",
        "pub.1095330507",
        "pub.1152082732",
        "pub.1143949474",
        "pub.1050954861",
        "pub.1158600650",
        "pub.1120610676",
        "pub.1160714163",
        "pub.1138840378",
        "pub.1028431957",
        "pub.1068001284",
        "pub.1034297058",
        "pub.1154263506",
        "pub.1160713483",
        "pub.1121664431",
        "pub.1148900466",
        "pub.1095453495",
        "pub.1041967254",
        "pub.1148904699",
        "pub.1095290363",
        "pub.1165778378",
        "pub.1133175050",
        "pub.1129757051",
        "pub.1105386422",
        "pub.1148581733",
        "pub.1092219302",
        "pub.1131375800",
        "pub.1036806696",
        "pub.1099113633"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.737
        },
        {
          "concept": "code summarization tasks",
          "relevance": 0.697
        },
        {
          "concept": "local variable names",
          "relevance": 0.684
        },
        {
          "concept": "code summarization",
          "relevance": 0.647
        },
        {
          "concept": "text summarization",
          "relevance": 0.645
        },
        {
          "concept": "summarization task",
          "relevance": 0.644
        },
        {
          "concept": "semantic augmentation",
          "relevance": 0.643
        },
        {
          "concept": "summarization performance",
          "relevance": 0.64
        },
        {
          "concept": "PHP language",
          "relevance": 0.625
        },
        {
          "concept": "data flow",
          "relevance": 0.622
        },
        {
          "concept": "variable names",
          "relevance": 0.619
        },
        {
          "concept": "semantic facts",
          "relevance": 0.608
        },
        {
          "concept": "summarization",
          "relevance": 0.606
        },
        {
          "concept": "computer engineering",
          "relevance": 0.601
        },
        {
          "concept": "processing code",
          "relevance": 0.582
        },
        {
          "concept": "code",
          "relevance": 0.575
        },
        {
          "concept": "post-conditioning",
          "relevance": 0.57
        },
        {
          "concept": "improved performance",
          "relevance": 0.564
        },
        {
          "concept": "completion performance",
          "relevance": 0.553
        },
        {
          "concept": "task",
          "relevance": 0.524
        },
        {
          "concept": "performance",
          "relevance": 0.519
        },
        {
          "concept": "language",
          "relevance": 0.505
        },
        {
          "concept": "semantics",
          "relevance": 0.489
        },
        {
          "concept": "information",
          "relevance": 0.485
        },
        {
          "concept": "PHP",
          "relevance": 0.475
        },
        {
          "concept": "dataset",
          "relevance": 0.472
        },
        {
          "concept": "architecture",
          "relevance": 0.469
        },
        {
          "concept": "computer",
          "relevance": 0.465
        },
        {
          "concept": "LLM",
          "relevance": 0.461
        },
        {
          "concept": "metrics",
          "relevance": 0.458
        },
        {
          "concept": "engineering",
          "relevance": 0.438
        },
        {
          "concept": "facts",
          "relevance": 0.435
        },
        {
          "concept": "augmentation",
          "relevance": 0.433
        },
        {
          "concept": "early days",
          "relevance": 0.422
        },
        {
          "concept": "text",
          "relevance": 0.417
        },
        {
          "concept": "prompts",
          "relevance": 0.408
        },
        {
          "concept": "intuition",
          "relevance": 0.406
        },
        {
          "concept": "model",
          "relevance": 0.4
        },
        {
          "concept": "improvement",
          "relevance": 0.386
        },
        {
          "concept": "exemplars",
          "relevance": 0.377
        },
        {
          "concept": "translation",
          "relevance": 0.372
        },
        {
          "concept": "goal",
          "relevance": 0.371
        },
        {
          "concept": "names",
          "relevance": 0.368
        },
        {
          "concept": "informal help",
          "relevance": 0.359
        },
        {
          "concept": "research",
          "relevance": 0.337
        },
        {
          "concept": "data",
          "relevance": 0.33
        },
        {
          "concept": "development",
          "relevance": 0.329
        },
        {
          "concept": "questions",
          "relevance": 0.329
        },
        {
          "concept": "process",
          "relevance": 0.328
        },
        {
          "concept": "benefits",
          "relevance": 0.312
        },
        {
          "concept": "help",
          "relevance": 0.305
        },
        {
          "concept": "function",
          "relevance": 0.303
        },
        {
          "concept": "parameters",
          "relevance": 0.302
        },
        {
          "concept": "cases",
          "relevance": 0.263
        },
        {
          "concept": "control",
          "relevance": 0.261
        },
        {
          "concept": "return",
          "relevance": 0.224
        },
        {
          "concept": "pre-",
          "relevance": 0.216
        },
        {
          "concept": "flow",
          "relevance": 0.213
        },
        {
          "concept": "levels",
          "relevance": 0.211
        },
        {
          "concept": "expression",
          "relevance": 0.195
        },
        {
          "concept": "days",
          "relevance": 0.164
        }
      ]
    },
    {
      "paperId": "pub.1105723410",
      "doi": "10.1145/3196321.3196334",
      "title": "Deep code comment generation",
      "year": 2018,
      "citationCount": 555,
      "fieldCitationRatio": 140.66,
      "abstract": "During software maintenance, code comments help developers comprehend programs and reduce additional time spent on reading and navigating source code. Unfortunately, these comments are often mismatched, missing or outdated in the software projects. Developers have to infer the functionality from the source code. This paper proposes a new approach named DeepCom to automatically generate code comments for Java methods. The generated comments aim to help developers understand the functionality of Java methods. DeepCom applies Natural Language Processing (NLP) techniques to learn from a large code corpus and generates comments from learned features. We use a deep neural network that analyzes structural information of Java methods for better comments generation. We conduct experiments on a large-scale Java corpus built from 9,714 open source projects from GitHub. We evaluate the experimental results on a machine translation metric. Experimental results demonstrate that our method DeepCom outperforms the state-of-the-art by a substantial margin.",
      "reference_ids": [
        "pub.1095330507",
        "pub.1041967254",
        "pub.1028725918",
        "pub.1050954861",
        "pub.1014258985",
        "pub.1083938409",
        "pub.1023897083",
        "pub.1095290363",
        "pub.1043550973",
        "pub.1038140272",
        "pub.1093737273",
        "pub.1050616695",
        "pub.1038173339",
        "pub.1063165244",
        "pub.1099239594",
        "pub.1094226903",
        "pub.1003137333",
        "pub.1091293947",
        "pub.1095442644",
        "pub.1110957706",
        "pub.1093374943",
        "pub.1027773223",
        "pub.1025674564",
        "pub.1050682620"
      ],
      "concepts_scores": [
        {
          "concept": "natural language processing",
          "relevance": 0.8
        },
        {
          "concept": "Java methods",
          "relevance": 0.785
        },
        {
          "concept": "code comments",
          "relevance": 0.747
        },
        {
          "concept": "deep neural networks",
          "relevance": 0.697
        },
        {
          "concept": "machine translation metrics",
          "relevance": 0.696
        },
        {
          "concept": "experimental results",
          "relevance": 0.665
        },
        {
          "concept": "software maintenance",
          "relevance": 0.652
        },
        {
          "concept": "comment generation",
          "relevance": 0.652
        },
        {
          "concept": "software projects",
          "relevance": 0.65
        },
        {
          "concept": "code corpus",
          "relevance": 0.65
        },
        {
          "concept": "Java corpus",
          "relevance": 0.647
        },
        {
          "concept": "learned features",
          "relevance": 0.643
        },
        {
          "concept": "source code",
          "relevance": 0.639
        },
        {
          "concept": "neural network",
          "relevance": 0.632
        },
        {
          "concept": "reduce additional time",
          "relevance": 0.628
        },
        {
          "concept": "language processing",
          "relevance": 0.628
        },
        {
          "concept": "translation metrics",
          "relevance": 0.594
        },
        {
          "concept": "substantial margin",
          "relevance": 0.582
        },
        {
          "concept": "code",
          "relevance": 0.579
        },
        {
          "concept": "software",
          "relevance": 0.54
        },
        {
          "concept": "structural information",
          "relevance": 0.533
        },
        {
          "concept": "corpus",
          "relevance": 0.501
        },
        {
          "concept": "GitHub",
          "relevance": 0.484
        },
        {
          "concept": "Java",
          "relevance": 0.473
        },
        {
          "concept": "network",
          "relevance": 0.47
        },
        {
          "concept": "metrics",
          "relevance": 0.462
        },
        {
          "concept": "machine",
          "relevance": 0.46
        },
        {
          "concept": "method",
          "relevance": 0.457
        },
        {
          "concept": "comments",
          "relevance": 0.413
        },
        {
          "concept": "features",
          "relevance": 0.404
        },
        {
          "concept": "additional time",
          "relevance": 0.399
        },
        {
          "concept": "technique",
          "relevance": 0.375
        },
        {
          "concept": "results",
          "relevance": 0.372
        },
        {
          "concept": "project",
          "relevance": 0.362
        },
        {
          "concept": "program",
          "relevance": 0.361
        },
        {
          "concept": "function",
          "relevance": 0.354
        },
        {
          "concept": "experiments",
          "relevance": 0.35
        },
        {
          "concept": "development",
          "relevance": 0.332
        },
        {
          "concept": "process",
          "relevance": 0.331
        },
        {
          "concept": "generation",
          "relevance": 0.327
        },
        {
          "concept": "time",
          "relevance": 0.318
        },
        {
          "concept": "maintenance",
          "relevance": 0.306
        },
        {
          "concept": "source",
          "relevance": 0.299
        },
        {
          "concept": "nature",
          "relevance": 0.272
        },
        {
          "concept": "margin",
          "relevance": 0.228
        }
      ]
    },
    {
      "paperId": "pub.1099239594",
      "doi": "10.3115/1073083.1073135",
      "title": "BLEU: a method for automatic evaluation of machine translation",
      "year": 2001,
      "citationCount": 11516,
      "fieldCitationRatio": 3629.45,
      "abstract": "Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.",
      "reference_ids": NaN,
      "concepts_scores": [
        {
          "concept": "evaluation of machine translation",
          "relevance": 0.757
        },
        {
          "concept": "human evaluation",
          "relevance": 0.713
        },
        {
          "concept": "machine translation",
          "relevance": 0.682
        },
        {
          "concept": "automatic evaluation of machine translation",
          "relevance": 0.667
        },
        {
          "concept": "human evaluation of machine translation",
          "relevance": 0.649
        },
        {
          "concept": "machine translation evaluation",
          "relevance": 0.641
        },
        {
          "concept": "language-independent",
          "relevance": 0.582
        },
        {
          "concept": "automatic evaluation",
          "relevance": 0.571
        },
        {
          "concept": "human judges",
          "relevance": 0.568
        },
        {
          "concept": "translation evaluation",
          "relevance": 0.555
        },
        {
          "concept": "human labor",
          "relevance": 0.505
        },
        {
          "concept": "translation",
          "relevance": 0.474
        },
        {
          "concept": "evaluation",
          "relevance": 0.418
        },
        {
          "concept": "method",
          "relevance": 0.41
        },
        {
          "concept": "understudies",
          "relevance": 0.407
        },
        {
          "concept": "cost",
          "relevance": 0.349
        },
        {
          "concept": "judges",
          "relevance": 0.333
        },
        {
          "concept": "frequent evaluation",
          "relevance": 0.307
        },
        {
          "concept": "labor",
          "relevance": 0.302
        },
        {
          "concept": "months",
          "relevance": 0.249
        },
        {
          "concept": "marginal cost",
          "relevance": 0.227
        }
      ]
    },
    {
      "paperId": "pub.1158600650",
      "doi": "10.1016/j.inffus.2023.101861",
      "title": "ChatGPT: Jack of all trades, master of none",
      "year": 2023,
      "citationCount": 446,
      "fieldCitationRatio": 288.18,
      "abstract": "OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. The first contact with the chatbot reveals its ability to provide detailed and precise answers in various areas. Several publications on ChatGPT evaluation test its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT’s capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness, and stance detection. In contrast, the other tasks require more objective reasoning like word sense disambiguation, linguistic acceptability, and question answering. We also evaluated GPT-4 model on five selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process and analyzed more than 49k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quality of the ChatGPT model was about 25% for zero-shot and few-shot evaluation. For GPT-4 model, a loss for semantic tasks is significantly lower than for ChatGPT. We showed that the more difficult the task (lower SOTA performance), the higher the ChatGPT loss. It especially refers to pragmatic NLP problems like emotion recognition. We also tested the ability to personalize ChatGPT responses for selected subjective tasks via Random Contextual Few-Shot Personalization, and we obtained significantly better user-based predictions. Additional qualitative analysis revealed a ChatGPT bias, most likely due to the rules imposed on human trainers by OpenAI. Our results provide the basis for a fundamental discussion of whether the high quality of recent predictive NLP models can indicate a tool’s usefulness to society and how the learning and validation procedures for such systems should be established.",
      "reference_ids": [
        "pub.1154837874",
        "pub.1129756966",
        "pub.1148390517",
        "pub.1154044041",
        "pub.1099096265",
        "pub.1154100542",
        "pub.1150771152",
        "pub.1146504828",
        "pub.1139947510",
        "pub.1155230818",
        "pub.1154976771",
        "pub.1133175062",
        "pub.1157891790",
        "pub.1099204121",
        "pub.1153986892",
        "pub.1164024752",
        "pub.1129756791",
        "pub.1131485422",
        "pub.1154007278",
        "pub.1164705743",
        "pub.1166034433",
        "pub.1139947839",
        "pub.1122291225",
        "pub.1154504925",
        "pub.1138840539",
        "pub.1117659708",
        "pub.1150380949",
        "pub.1121398611",
        "pub.1163044310",
        "pub.1157617446",
        "pub.1086031134",
        "pub.1117660148",
        "pub.1147686404",
        "pub.1122642995",
        "pub.1133174481",
        "pub.1155008211",
        "pub.1144948934",
        "pub.1151003027",
        "pub.1155230755",
        "pub.1096026248",
        "pub.1145372509",
        "pub.1138574606",
        "pub.1111822112",
        "pub.1139948903",
        "pub.1087958697",
        "pub.1154069231",
        "pub.1139947326",
        "pub.1012313573",
        "pub.1124484286",
        "pub.1095827341",
        "pub.1143948839",
        "pub.1152036583",
        "pub.1158361897"
      ],
      "concepts_scores": [
        {
          "concept": "state-of-the-art",
          "relevance": 0.785
        },
        {
          "concept": "natural language processing",
          "relevance": 0.778
        },
        {
          "concept": "NLP tasks",
          "relevance": 0.73
        },
        {
          "concept": "emotion recognition",
          "relevance": 0.71
        },
        {
          "concept": "Generative Pre-trained Transformer",
          "relevance": 0.692
        },
        {
          "concept": "word sense disambiguation",
          "relevance": 0.68
        },
        {
          "concept": "pre-trained transformers",
          "relevance": 0.673
        },
        {
          "concept": "human-model interaction",
          "relevance": 0.633
        },
        {
          "concept": "Zero-Shot",
          "relevance": 0.632
        },
        {
          "concept": "sense disambiguation",
          "relevance": 0.631
        },
        {
          "concept": "stance detection",
          "relevance": 0.629
        },
        {
          "concept": "sentiment analysis",
          "relevance": 0.623
        },
        {
          "concept": "ChatGPT",
          "relevance": 0.614
        },
        {
          "concept": "NLP models",
          "relevance": 0.613
        },
        {
          "concept": "human trainer",
          "relevance": 0.612
        },
        {
          "concept": "language processing",
          "relevance": 0.61
        },
        {
          "concept": "OpenAI",
          "relevance": 0.574
        },
        {
          "concept": "linguistic acceptability",
          "relevance": 0.566
        },
        {
          "concept": "task",
          "relevance": 0.554
        },
        {
          "concept": "NLP problem",
          "relevance": 0.55
        },
        {
          "concept": "non-automated",
          "relevance": 0.534
        },
        {
          "concept": "recognition",
          "relevance": 0.494
        },
        {
          "concept": "subject's task",
          "relevance": 0.492
        },
        {
          "concept": "objective reasoning",
          "relevance": 0.491
        },
        {
          "concept": "disambiguation",
          "relevance": 0.486
        },
        {
          "concept": "chatbot",
          "relevance": 0.484
        },
        {
          "concept": "capability",
          "relevance": 0.476
        },
        {
          "concept": "semantic tasks",
          "relevance": 0.464
        },
        {
          "concept": "validation procedure",
          "relevance": 0.45
        },
        {
          "concept": "sentiment",
          "relevance": 0.445
        },
        {
          "concept": "evaluation",
          "relevance": 0.437
        },
        {
          "concept": "learning",
          "relevance": 0.437
        },
        {
          "concept": "model",
          "relevance": 0.419
        },
        {
          "concept": "randomization",
          "relevance": 0.412
        },
        {
          "concept": "emotions",
          "relevance": 0.411
        },
        {
          "concept": "qualitative analysis",
          "relevance": 0.41
        },
        {
          "concept": "rules",
          "relevance": 0.41
        },
        {
          "concept": "quality",
          "relevance": 0.404
        },
        {
          "concept": "detection",
          "relevance": 0.392
        },
        {
          "concept": "ChAT",
          "relevance": 0.385
        },
        {
          "concept": "answers",
          "relevance": 0.381
        },
        {
          "concept": "words",
          "relevance": 0.38
        },
        {
          "concept": "process",
          "relevance": 0.372
        },
        {
          "concept": "transformation",
          "relevance": 0.371
        },
        {
          "concept": "system",
          "relevance": 0.371
        },
        {
          "concept": "results",
          "relevance": 0.361
        },
        {
          "concept": "reasons",
          "relevance": 0.349
        },
        {
          "concept": "stance",
          "relevance": 0.348
        },
        {
          "concept": "subsets",
          "relevance": 0.344
        },
        {
          "concept": "society",
          "relevance": 0.332
        },
        {
          "concept": "validity",
          "relevance": 0.33
        },
        {
          "concept": "publications",
          "relevance": 0.321
        },
        {
          "concept": "discussion",
          "relevance": 0.313
        },
        {
          "concept": "acceptance",
          "relevance": 0.309
        },
        {
          "concept": "trainers",
          "relevance": 0.303
        },
        {
          "concept": "analysis",
          "relevance": 0.298
        },
        {
          "concept": "persons",
          "relevance": 0.294
        },
        {
          "concept": "loss",
          "relevance": 0.285
        },
        {
          "concept": "comparison",
          "relevance": 0.279
        },
        {
          "concept": "average loss",
          "relevance": 0.277
        },
        {
          "concept": "humans",
          "relevance": 0.276
        },
        {
          "concept": "area",
          "relevance": 0.259
        },
        {
          "concept": "procedure",
          "relevance": 0.253
        },
        {
          "concept": "interaction",
          "relevance": 0.251
        },
        {
          "concept": "response",
          "relevance": 0.246
        },
        {
          "concept": "trade",
          "relevance": 0.24
        },
        {
          "concept": "bias",
          "relevance": 0.237
        },
        {
          "concept": "study",
          "relevance": 0.209
        },
        {
          "concept": "effect",
          "relevance": 0.203
        },
        {
          "concept": "contact",
          "relevance": 0.2
        },
        {
          "concept": "problem",
          "relevance": 0.179
        }
      ]
    },
    {
      "paperId": "pub.1164705743",
      "doi": "10.1007/s00330-023-10213-1",
      "title": "ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports",
      "year": 2023,
      "citationCount": 405,
      "fieldCitationRatio": 322.62,
      "abstract": "ObjectivesTo assess the quality of simplified radiology reports generated with the large language model (LLM) ChatGPT and to discuss challenges and chances of ChatGPT-like LLMs for medical text simplification.MethodsIn this exploratory case study, a radiologist created three fictitious radiology reports which we simplified by prompting ChatGPT with “Explain this medical report to a child using simple language.” In a questionnaire, we tasked 15 radiologists to rate the quality of the simplified radiology reports with respect to their factual correctness, completeness, and potential harm for patients. We used Likert scale analysis and inductive free-text categorization to assess the quality of the simplified reports.ResultsMost radiologists agreed that the simplified reports were factually correct, complete, and not potentially harmful to the patient. Nevertheless, instances of incorrect statements, missed relevant medical information, and potentially harmful passages were reported.ConclusionWhile we see a need for further adaption to the medical field, the initial insights of this study indicate a tremendous potential in using LLMs like ChatGPT to improve patient-centered care in radiology and other medical domains.Clinical relevance statementPatients have started to use ChatGPT to simplify and explain their medical reports, which is expected to affect patient-doctor interaction. This phenomenon raises several opportunities and challenges for clinical routine.Key Points• Patients have started to use ChatGPT to simplify their medical reports, but their quality was unknown.• In a questionnaire, most participating radiologists overall asserted good quality to radiology reports simplified with ChatGPT. However, they also highlighted a notable presence of errors, potentially leading patients to draw harmful conclusions.• Large language models such as ChatGPT have vast potential to enhance patient-centered care in radiology and other medical domains. To realize this potential while minimizing harm, they need supervision by medical experts and adaption to the medical field.Graphical Abstract",
      "reference_ids": [
        "pub.1138305898",
        "pub.1120882528",
        "pub.1108734890",
        "pub.1150392229",
        "pub.1139947961",
        "pub.1117660211",
        "pub.1149740848",
        "pub.1160635088",
        "pub.1067340875",
        "pub.1039586136",
        "pub.1129756915",
        "pub.1111271153",
        "pub.1107513488",
        "pub.1163991170",
        "pub.1099120510",
        "pub.1136054193",
        "pub.1110953740",
        "pub.1148390672",
        "pub.1124484286",
        "pub.1141942664",
        "pub.1143672116",
        "pub.1099870475",
        "pub.1135710434"
      ],
      "concepts_scores": [
        {
          "concept": "patient-centered care",
          "relevance": 0.707
        },
        {
          "concept": "language model",
          "relevance": 0.694
        },
        {
          "concept": "medical domain",
          "relevance": 0.69
        },
        {
          "concept": "improve patient-centered care",
          "relevance": 0.627
        },
        {
          "concept": "exploratory case study",
          "relevance": 0.623
        },
        {
          "concept": "medical reports",
          "relevance": 0.606
        },
        {
          "concept": "radiology reports",
          "relevance": 0.604
        },
        {
          "concept": "medical field",
          "relevance": 0.6
        },
        {
          "concept": "presence of errors",
          "relevance": 0.597
        },
        {
          "concept": "ChatGPT",
          "relevance": 0.59
        },
        {
          "concept": "text simplification",
          "relevance": 0.59
        },
        {
          "concept": "patient-doctor interaction",
          "relevance": 0.587
        },
        {
          "concept": "relevant medical information",
          "relevance": 0.583
        },
        {
          "concept": "medical experts",
          "relevance": 0.562
        },
        {
          "concept": "medical information",
          "relevance": 0.537
        },
        {
          "concept": "case study",
          "relevance": 0.524
        },
        {
          "concept": "care",
          "relevance": 0.496
        },
        {
          "concept": "questionnaire",
          "relevance": 0.479
        },
        {
          "concept": "language",
          "relevance": 0.476
        },
        {
          "concept": "radiology",
          "relevance": 0.443
        },
        {
          "concept": "Likert scale analysis",
          "relevance": 0.438
        },
        {
          "concept": "patients",
          "relevance": 0.437
        },
        {
          "concept": "domain",
          "relevance": 0.43
        },
        {
          "concept": "quality",
          "relevance": 0.429
        },
        {
          "concept": "LLM",
          "relevance": 0.423
        },
        {
          "concept": "clinical routine",
          "relevance": 0.421
        },
        {
          "concept": "ResultsMost",
          "relevance": 0.418
        },
        {
          "concept": "radiologists",
          "relevance": 0.409
        },
        {
          "concept": "ConclusionWhile",
          "relevance": 0.404
        },
        {
          "concept": "reports",
          "relevance": 0.403
        },
        {
          "concept": "harm",
          "relevance": 0.402
        },
        {
          "concept": "categorization",
          "relevance": 0.396
        },
        {
          "concept": "Likert",
          "relevance": 0.395
        },
        {
          "concept": "information",
          "relevance": 0.394
        },
        {
          "concept": "error",
          "relevance": 0.39
        },
        {
          "concept": "experts",
          "relevance": 0.39
        },
        {
          "concept": "challenges",
          "relevance": 0.388
        },
        {
          "concept": "model",
          "relevance": 0.377
        },
        {
          "concept": "children",
          "relevance": 0.377
        },
        {
          "concept": "medicine",
          "relevance": 0.376
        },
        {
          "concept": "study",
          "relevance": 0.376
        },
        {
          "concept": "incorrect statements",
          "relevance": 0.374
        },
        {
          "concept": "supervision",
          "relevance": 0.368
        },
        {
          "concept": "simplification",
          "relevance": 0.352
        },
        {
          "concept": "completion",
          "relevance": 0.348
        },
        {
          "concept": "adaptation",
          "relevance": 0.346
        },
        {
          "concept": "routine",
          "relevance": 0.345
        },
        {
          "concept": "correction",
          "relevance": 0.328
        },
        {
          "concept": "field",
          "relevance": 0.326
        },
        {
          "concept": "opportunities",
          "relevance": 0.322
        },
        {
          "concept": "statements",
          "relevance": 0.32
        },
        {
          "concept": "chance",
          "relevance": 0.309
        },
        {
          "concept": "conclusions",
          "relevance": 0.303
        },
        {
          "concept": "scaling analysis",
          "relevance": 0.279
        },
        {
          "concept": "analysis",
          "relevance": 0.273
        },
        {
          "concept": "potential",
          "relevance": 0.253
        },
        {
          "concept": "presence",
          "relevance": 0.245
        },
        {
          "concept": "interaction",
          "relevance": 0.241
        },
        {
          "concept": "passage",
          "relevance": 0.228
        },
        {
          "concept": "phenomenon",
          "relevance": 0.203
        }
      ]
    },
    {
      "paperId": "pub.1157891790",
      "doi": "10.21203/rs.3.rs-2895792/v1",
      "title": "A Categorical Archive of ChatGPT Failures",
      "year": 2023,
      "citationCount": 272,
      "fieldCitationRatio": 542.42,
      "abstract": "Large language models have been demonstrated to be valuable in different fields. ChatGPT, developed by OpenAI, has been trained using massive amounts of data and simulates human conversation by comprehending context and generating appropriate responses. It has garnered significant attention due to its ability to effectively answer a broad range of human inquiries, with fluent and comprehensive answers surpassing prior public chatbots in both security and usefulness. However, a comprehensive analysis of ChatGPT’s failures is lacking, which is the focus of this study. Eleven categories of failures, including reasoning, factual errors, math, coding, and bias, are presented and discussed. The risks, limitations, and societal implications of ChatGPT are also highlighted. The goal of this study is to assist researchers and developers in enhancing future language models and chatbots. Please refer to here for the list of questions.",
      "reference_ids": NaN,
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.655
        },
        {
          "concept": "human conversation",
          "relevance": 0.549
        },
        {
          "concept": "massive amounts",
          "relevance": 0.541
        },
        {
          "concept": "ChatGPT",
          "relevance": 0.516
        },
        {
          "concept": "chatbot",
          "relevance": 0.508
        },
        {
          "concept": "categories of failure",
          "relevance": 0.464
        },
        {
          "concept": "OpenAI",
          "relevance": 0.449
        },
        {
          "concept": "security",
          "relevance": 0.423
        },
        {
          "concept": "comprehensive answer",
          "relevance": 0.413
        },
        {
          "concept": "code",
          "relevance": 0.409
        },
        {
          "concept": "categorization",
          "relevance": 0.374
        },
        {
          "concept": "language",
          "relevance": 0.37
        },
        {
          "concept": "error",
          "relevance": 0.368
        },
        {
          "concept": "societal implications",
          "relevance": 0.362
        },
        {
          "concept": "model",
          "relevance": 0.356
        },
        {
          "concept": "factual errors",
          "relevance": 0.348
        },
        {
          "concept": "answers",
          "relevance": 0.346
        },
        {
          "concept": "comprehensive analysis",
          "relevance": 0.346
        },
        {
          "concept": "human inquiry",
          "relevance": 0.335
        },
        {
          "concept": "goal",
          "relevance": 0.33
        },
        {
          "concept": "reasons",
          "relevance": 0.316
        },
        {
          "concept": "research",
          "relevance": 0.3
        },
        {
          "concept": "inquiry",
          "relevance": 0.296
        },
        {
          "concept": "data",
          "relevance": 0.294
        },
        {
          "concept": "attention",
          "relevance": 0.294
        },
        {
          "concept": "math",
          "relevance": 0.285
        },
        {
          "concept": "categories",
          "relevance": 0.284
        },
        {
          "concept": "implications",
          "relevance": 0.275
        },
        {
          "concept": "questions",
          "relevance": 0.274
        },
        {
          "concept": "field",
          "relevance": 0.266
        },
        {
          "concept": "limitations",
          "relevance": 0.265
        },
        {
          "concept": "failure",
          "relevance": 0.262
        },
        {
          "concept": "development",
          "relevance": 0.253
        },
        {
          "concept": "amount",
          "relevance": 0.234
        },
        {
          "concept": "study",
          "relevance": 0.232
        },
        {
          "concept": "use",
          "relevance": 0.23
        },
        {
          "concept": "response",
          "relevance": 0.213
        },
        {
          "concept": "conversion",
          "relevance": 0.205
        },
        {
          "concept": "risk",
          "relevance": 0.198
        }
      ]
    }
  ],
  "evolution_links": [
    {
      "source": "pub.1175845134",
      "target": "pub.1172304190",
      "source_title": "Large Language Models for Software Engineering: A Systematic Literature Review",
      "target_title": "ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design"
    },
    {
      "source": "pub.1172304190",
      "target": "pub.1128474475",
      "source_title": "ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design",
      "target_title": "Generalizing from a Few Examples"
    },
    {
      "source": "pub.1128474475",
      "target": "pub.1038140272",
      "source_title": "Generalizing from a Few Examples",
      "target_title": "Long Short-Term Memory"
    },
    {
      "source": "pub.1128474475",
      "target": "pub.1061661916",
      "source_title": "Generalizing from a Few Examples",
      "target_title": "Learning from Imbalanced Data"
    },
    {
      "source": "pub.1172304190",
      "target": "pub.1061387764",
      "source_title": "ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design",
      "target_title": "Guest Editor's Introduction: Model-Driven Engineering"
    },
    {
      "source": "pub.1175845134",
      "target": "pub.1170644911",
      "source_title": "Large Language Models for Software Engineering: A Systematic Literature Review",
      "target_title": "Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization)"
    },
    {
      "source": "pub.1170644911",
      "target": "pub.1105723410",
      "source_title": "Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization)",
      "target_title": "Deep code comment generation"
    },
    {
      "source": "pub.1105723410",
      "target": "pub.1038140272",
      "source_title": "Deep code comment generation",
      "target_title": "Long Short-Term Memory"
    },
    {
      "source": "pub.1105723410",
      "target": "pub.1099239594",
      "source_title": "Deep code comment generation",
      "target_title": "BLEU: a method for automatic evaluation of machine translation"
    },
    {
      "source": "pub.1170644911",
      "target": "pub.1158600650",
      "source_title": "Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization)",
      "target_title": "ChatGPT: Jack of all trades, master of none"
    },
    {
      "source": "pub.1158600650",
      "target": "pub.1164705743",
      "source_title": "ChatGPT: Jack of all trades, master of none",
      "target_title": "ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports"
    },
    {
      "source": "pub.1158600650",
      "target": "pub.1157891790",
      "source_title": "ChatGPT: Jack of all trades, master of none",
      "target_title": "A Categorical Archive of ChatGPT Failures"
    }
  ]
}