{
  "papers": [
    {
      "paperId": "pub.1160759555",
      "doi": "10.1038/s41591-023-02448-8",
      "title": "Large language models in medicine",
      "year": 2023,
      "citationCount": 1908,
      "fieldCitationRatio": NaN,
      "abstract": "Large language models (LLMs) can respond to free-text queries without being specifically trained in the task in question, causing excitement and concern about their use in healthcare settings. ChatGPT is a generative artificial intelligence (AI) chatbot produced through sophisticated fine-tuning of an LLM, and other tools are emerging through similar developmental processes. Here we outline how LLM applications such as ChatGPT are developed, and we discuss how they are being leveraged in clinical settings. We consider the strengths and limitations of LLMs and their potential to improve the efficiency and effectiveness of clinical, educational and research work in medicine. LLM chatbots have already been deployed in a range of biomedical contexts, with impressive but mixed results. This review acts as a primer for interested clinicians, who will determine if and how LLM technology is used in healthcare for the benefit of patients and practitioners.",
      "reference_ids": [
        "pub.1146560091",
        "pub.1155230109",
        "pub.1147717653",
        "pub.1157581229",
        "pub.1158116221",
        "pub.1122001516",
        "pub.1149606025",
        "pub.1154888867",
        "pub.1156188546",
        "pub.1153982932",
        "pub.1155156739",
        "pub.1079391238",
        "pub.1154789385",
        "pub.1155270533",
        "pub.1156180076",
        "pub.1149462641",
        "pub.1148187428",
        "pub.1110890640",
        "pub.1155526539",
        "pub.1156284911",
        "pub.1147955703",
        "pub.1155642680",
        "pub.1155222253",
        "pub.1152602671",
        "pub.1124048120",
        "pub.1155156738",
        "pub.1141942664",
        "pub.1147032854",
        "pub.1135710434",
        "pub.1131074864",
        "pub.1155477331",
        "pub.1146478063",
        "pub.1133616237",
        "pub.1155035437",
        "pub.1158159997",
        "pub.1155846816",
        "pub.1124301819",
        "pub.1154632837",
        "pub.1155759241",
        "pub.1133176915",
        "pub.1151601774",
        "pub.1136978383",
        "pub.1154969490",
        "pub.1154872323",
        "pub.1144813060",
        "pub.1152843639",
        "pub.1153999847",
        "pub.1156478958",
        "pub.1121159568",
        "pub.1154888930",
        "pub.1153523036",
        "pub.1156602823",
        "pub.1156955584",
        "pub.1146094553",
        "pub.1156097806",
        "pub.1152860639",
        "pub.1119417047",
        "pub.1138942250",
        "pub.1155270525",
        "pub.1119411109",
        "pub.1157166150",
        "pub.1155183271",
        "pub.1157585608",
        "pub.1120882528",
        "pub.1153201607",
        "pub.1139691916",
        "pub.1153518825",
        "pub.1151477970",
        "pub.1093180809",
        "pub.1123669031",
        "pub.1155156740",
        "pub.1155711413",
        "pub.1154795038",
        "pub.1125372827",
        "pub.1153777178",
        "pub.1144859682",
        "pub.1155477103",
        "pub.1156041912",
        "pub.1155808762",
        "pub.1153897575",
        "pub.1111607515",
        "pub.1152145461",
        "pub.1150069360",
        "pub.1157184122",
        "pub.1140466886",
        "pub.1146120781",
        "pub.1012818229",
        "pub.1155096796",
        "pub.1147113881",
        "pub.1155684205",
        "pub.1151726319",
        "pub.1158149056",
        "pub.1154432832"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.584
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.567
        },
        {
          "concept": "free-text queries",
          "relevance": 0.547
        },
        {
          "concept": "generative artificial intelligence",
          "relevance": 0.508
        },
        {
          "concept": "healthcare settings",
          "relevance": 0.462
        },
        {
          "concept": "ChatGPT",
          "relevance": 0.46
        },
        {
          "concept": "benefit of patients",
          "relevance": 0.455
        },
        {
          "concept": "chatbot",
          "relevance": 0.453
        },
        {
          "concept": "research work",
          "relevance": 0.427
        },
        {
          "concept": "clinical setting",
          "relevance": 0.416
        },
        {
          "concept": "healthcare",
          "relevance": 0.414
        },
        {
          "concept": "query",
          "relevance": 0.396
        },
        {
          "concept": "language",
          "relevance": 0.382
        },
        {
          "concept": "biomedical context",
          "relevance": 0.378
        },
        {
          "concept": "intelligence",
          "relevance": 0.37
        },
        {
          "concept": "LLM",
          "relevance": 0.365
        },
        {
          "concept": "medicine",
          "relevance": 0.364
        },
        {
          "concept": "task",
          "relevance": 0.359
        },
        {
          "concept": "sets",
          "relevance": 0.346
        },
        {
          "concept": "clinicians",
          "relevance": 0.337
        },
        {
          "concept": "practitioners",
          "relevance": 0.33
        },
        {
          "concept": "technology",
          "relevance": 0.328
        },
        {
          "concept": "model",
          "relevance": 0.317
        },
        {
          "concept": "applications",
          "relevance": 0.311
        },
        {
          "concept": "tools",
          "relevance": 0.3
        },
        {
          "concept": "patients",
          "relevance": 0.295
        },
        {
          "concept": "efficiency",
          "relevance": 0.287
        },
        {
          "concept": "review",
          "relevance": 0.283
        },
        {
          "concept": "benefits",
          "relevance": 0.278
        },
        {
          "concept": "questions",
          "relevance": 0.275
        },
        {
          "concept": "context",
          "relevance": 0.272
        },
        {
          "concept": "developmental processes",
          "relevance": 0.271
        },
        {
          "concept": "research",
          "relevance": 0.267
        },
        {
          "concept": "process",
          "relevance": 0.26
        },
        {
          "concept": "results",
          "relevance": 0.252
        },
        {
          "concept": "work",
          "relevance": 0.248
        },
        {
          "concept": "limitations",
          "relevance": 0.236
        },
        {
          "concept": "strength",
          "relevance": 0.235
        },
        {
          "concept": "effect",
          "relevance": 0.209
        },
        {
          "concept": "primers",
          "relevance": 0.198
        },
        {
          "concept": "potential",
          "relevance": 0.176
        },
        {
          "concept": "excitation",
          "relevance": 0.165
        }
      ]
    },
    {
      "paperId": "pub.1157585608",
      "doi": "10.1001/jamainternmed.2023.1838",
      "title": "Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum",
      "year": 2023,
      "citationCount": 1520,
      "fieldCitationRatio": 1197.53,
      "abstract": "Importance: The rapid expansion of virtual health care has caused a surge in patient messages concomitant with more work and burnout among health care professionals. Artificial intelligence (AI) assistants could potentially aid in creating answers to patient questions by drafting responses that could be reviewed by clinicians.\nObjective: To evaluate the ability of an AI chatbot assistant (ChatGPT), released in November 2022, to provide quality and empathetic responses to patient questions.\nDesign, Setting, and Participants: In this cross-sectional study, a public and nonidentifiable database of questions from a public social media forum (Reddit's r/AskDocs) was used to randomly draw 195 exchanges from October 2022 where a verified physician responded to a public question. Chatbot responses were generated by entering the original question into a fresh session (without prior questions having been asked in the session) on December 22 and 23, 2022. The original question along with anonymized and randomly ordered physician and chatbot responses were evaluated in triplicate by a team of licensed health care professionals. Evaluators chose \"which response was better\" and judged both \"the quality of information provided\" (very poor, poor, acceptable, good, or very good) and \"the empathy or bedside manner provided\" (not empathetic, slightly empathetic, moderately empathetic, empathetic, and very empathetic). Mean outcomes were ordered on a 1 to 5 scale and compared between chatbot and physicians.\nResults: Of the 195 questions and responses, evaluators preferred chatbot responses to physician responses in 78.6% (95% CI, 75.0%-81.8%) of the 585 evaluations. Mean (IQR) physician responses were significantly shorter than chatbot responses (52 [17-62] words vs 211 [168-245] words; t = 25.4; P < .001). Chatbot responses were rated of significantly higher quality than physician responses (t = 13.3; P < .001). The proportion of responses rated as good or very good quality (≥ 4), for instance, was higher for chatbot than physicians (chatbot: 78.5%, 95% CI, 72.3%-84.1%; physicians: 22.1%, 95% CI, 16.4%-28.2%;). This amounted to 3.6 times higher prevalence of good or very good quality responses for the chatbot. Chatbot responses were also rated significantly more empathetic than physician responses (t = 18.9; P < .001). The proportion of responses rated empathetic or very empathetic (≥4) was higher for chatbot than for physicians (physicians: 4.6%, 95% CI, 2.1%-7.7%; chatbot: 45.1%, 95% CI, 38.5%-51.8%; physicians: 4.6%, 95% CI, 2.1%-7.7%). This amounted to 9.8 times higher prevalence of empathetic or very empathetic responses for the chatbot.\nConclusions: In this cross-sectional study, a chatbot generated quality and empathetic responses to patient questions posed in an online forum. Further exploration of this technology is warranted in clinical settings, such as using chatbot to draft responses that physicians could then edit. Randomized trials could assess further if using AI assistants might improve responses, lower clinician burnout, and improve patient outcomes.",
      "reference_ids": [
        "pub.1152010517",
        "pub.1129605381",
        "pub.1135021344",
        "pub.1053500544",
        "pub.1129721600",
        "pub.1150998871",
        "pub.1160635088",
        "pub.1124371749",
        "pub.1117681667",
        "pub.1067592346",
        "pub.1150572291",
        "pub.1062469256",
        "pub.1135021091",
        "pub.1151885972",
        "pub.1143216524",
        "pub.1036430084",
        "pub.1154286648",
        "pub.1105573386",
        "pub.1092052784"
      ],
      "concepts_scores": [
        {
          "concept": "response to patient questions",
          "relevance": 0.723
        },
        {
          "concept": "health care professionals",
          "relevance": 0.698
        },
        {
          "concept": "physician responses",
          "relevance": 0.684
        },
        {
          "concept": "patient questions",
          "relevance": 0.678
        },
        {
          "concept": "cross-sectional study",
          "relevance": 0.675
        },
        {
          "concept": "care professionals",
          "relevance": 0.647
        },
        {
          "concept": "licensed health care professionals",
          "relevance": 0.62
        },
        {
          "concept": "proportion of responses",
          "relevance": 0.62
        },
        {
          "concept": "virtual health care",
          "relevance": 0.6
        },
        {
          "concept": "highest prevalence",
          "relevance": 0.591
        },
        {
          "concept": "improve patient outcomes",
          "relevance": 0.57
        },
        {
          "concept": "clinician burnout",
          "relevance": 0.566
        },
        {
          "concept": "social media forums",
          "relevance": 0.556
        },
        {
          "concept": "health care",
          "relevance": 0.553
        },
        {
          "concept": "patient messages",
          "relevance": 0.551
        },
        {
          "concept": "bedside manner",
          "relevance": 0.549
        },
        {
          "concept": "significantly higher quality",
          "relevance": 0.53
        },
        {
          "concept": "chatbot responses",
          "relevance": 0.529
        },
        {
          "concept": "physicians",
          "relevance": 0.525
        },
        {
          "concept": "patient outcomes",
          "relevance": 0.524
        },
        {
          "concept": "original question",
          "relevance": 0.51
        },
        {
          "concept": "quality of information",
          "relevance": 0.506
        },
        {
          "concept": "clinical setting",
          "relevance": 0.498
        },
        {
          "concept": "media forums",
          "relevance": 0.49
        },
        {
          "concept": "randomized trials",
          "relevance": 0.488
        },
        {
          "concept": "mean outcome",
          "relevance": 0.486
        },
        {
          "concept": "burnout",
          "relevance": 0.485
        },
        {
          "concept": "professionals",
          "relevance": 0.484
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.482
        },
        {
          "concept": "prevalence",
          "relevance": 0.463
        },
        {
          "concept": "assistance",
          "relevance": 0.448
        },
        {
          "concept": "outcomes",
          "relevance": 0.44
        },
        {
          "concept": "online forums",
          "relevance": 0.435
        },
        {
          "concept": "high quality",
          "relevance": 0.434
        },
        {
          "concept": "empathetic responses",
          "relevance": 0.434
        },
        {
          "concept": "chatbot assistant",
          "relevance": 0.433
        },
        {
          "concept": "patients",
          "relevance": 0.429
        },
        {
          "concept": "quality",
          "relevance": 0.429
        },
        {
          "concept": "care",
          "relevance": 0.428
        },
        {
          "concept": "health",
          "relevance": 0.419
        },
        {
          "concept": "chatbot",
          "relevance": 0.416
        },
        {
          "concept": "AI assistance",
          "relevance": 0.413
        },
        {
          "concept": "questions",
          "relevance": 0.411
        },
        {
          "concept": "participants",
          "relevance": 0.405
        },
        {
          "concept": "clinicians",
          "relevance": 0.403
        },
        {
          "concept": "sessions",
          "relevance": 0.402
        },
        {
          "concept": "team",
          "relevance": 0.398
        },
        {
          "concept": "proportion",
          "relevance": 0.397
        },
        {
          "concept": "bedside",
          "relevance": 0.396
        },
        {
          "concept": "IQR",
          "relevance": 0.39
        },
        {
          "concept": "forum",
          "relevance": 0.384
        },
        {
          "concept": "evaluation",
          "relevance": 0.379
        },
        {
          "concept": "trials",
          "relevance": 0.364
        },
        {
          "concept": "improved response",
          "relevance": 0.362
        },
        {
          "concept": "draft responses",
          "relevance": 0.359
        },
        {
          "concept": "study",
          "relevance": 0.357
        },
        {
          "concept": "empathy",
          "relevance": 0.352
        },
        {
          "concept": "sets",
          "relevance": 0.349
        },
        {
          "concept": "ChatGPT",
          "relevance": 0.337
        },
        {
          "concept": "publications",
          "relevance": 0.336
        },
        {
          "concept": "intelligence",
          "relevance": 0.314
        },
        {
          "concept": "public questions",
          "relevance": 0.314
        },
        {
          "concept": "messages",
          "relevance": 0.313
        },
        {
          "concept": "response",
          "relevance": 0.308
        },
        {
          "concept": "Artificial",
          "relevance": 0.306
        },
        {
          "concept": "answers",
          "relevance": 0.297
        },
        {
          "concept": "information",
          "relevance": 0.295
        },
        {
          "concept": "work",
          "relevance": 0.291
        },
        {
          "concept": "ability",
          "relevance": 0.289
        },
        {
          "concept": "technology",
          "relevance": 0.279
        },
        {
          "concept": "design",
          "relevance": 0.266
        },
        {
          "concept": "exploration",
          "relevance": 0.245
        },
        {
          "concept": "quality responses",
          "relevance": 0.236
        },
        {
          "concept": "manner",
          "relevance": 0.217
        },
        {
          "concept": "surge",
          "relevance": 0.205
        },
        {
          "concept": "triplicate",
          "relevance": 0.188
        },
        {
          "concept": "exchange",
          "relevance": 0.174
        },
        {
          "concept": "expansion",
          "relevance": 0.147
        }
      ]
    },
    {
      "paperId": "pub.1062469256",
      "doi": "10.1126/science.1248506",
      "title": "The Parable of Google Flu: Traps in Big Data Analysis",
      "year": 2014,
      "citationCount": 2085,
      "fieldCitationRatio": 430.12,
      "abstract": "Large errors in flu prediction were largely avoidable, which offers lessons for the use of big data.\n In February 2013, Google Flu Trends (GFT) made headlines but not for a reason that Google executives or the creators of the flu tracking system would have hoped. Nature reported that GFT was predicting more than double the proportion of doctor visits for influenza-like illness (ILI) than the Centers for Disease Control and Prevention (CDC), which bases its estimates on surveillance reports from laboratories across the United States (  1  ,  2  ). This happened despite the fact that GFT was built to predict CDC reports. Given that GFT is often held up as an exemplary use of big data (  3  ,  4  ), what lessons can we draw from this error? ",
      "reference_ids": [
        "pub.1021424991",
        "pub.1027636693",
        "pub.1034187193",
        "pub.1019071008",
        "pub.1062459206",
        "pub.1047234899",
        "pub.1016070094",
        "pub.1049734322",
        "pub.1062460014",
        "pub.1038398193",
        "pub.1062462906",
        "pub.1015168619",
        "pub.1093781194",
        "pub.1078635588",
        "pub.1023676943",
        "pub.1053339208",
        "pub.1044456787",
        "pub.1020852786",
        "pub.1054919615",
        "pub.1053829925",
        "pub.1018176286",
        "pub.1072711034",
        "pub.1049162460",
        "pub.1005625058",
        "pub.1043897101",
        "pub.1005138990",
        "pub.1048342245",
        "pub.1041387047"
      ],
      "concepts_scores": [
        {
          "concept": "Centers for Disease Control and Prevention",
          "relevance": 0.649
        },
        {
          "concept": "influenza-like illness",
          "relevance": 0.586
        },
        {
          "concept": "Google Flu Trends",
          "relevance": 0.545
        },
        {
          "concept": "Disease Control and Prevention",
          "relevance": 0.526
        },
        {
          "concept": "Control and Prevention",
          "relevance": 0.513
        },
        {
          "concept": "doctor visits",
          "relevance": 0.485
        },
        {
          "concept": "Centers for Disease Control and Prevention report",
          "relevance": 0.459
        },
        {
          "concept": "surveillance reports",
          "relevance": 0.458
        },
        {
          "concept": "big data",
          "relevance": 0.427
        },
        {
          "concept": "data analysis",
          "relevance": 0.41
        },
        {
          "concept": "United States",
          "relevance": 0.404
        },
        {
          "concept": "big data analysis",
          "relevance": 0.392
        },
        {
          "concept": "Flu Trends",
          "relevance": 0.381
        },
        {
          "concept": "Google executives",
          "relevance": 0.381
        },
        {
          "concept": "flu",
          "relevance": 0.377
        },
        {
          "concept": "flu prediction",
          "relevance": 0.374
        },
        {
          "concept": "Google",
          "relevance": 0.372
        },
        {
          "concept": "visits",
          "relevance": 0.364
        },
        {
          "concept": "illness",
          "relevance": 0.362
        },
        {
          "concept": "reports",
          "relevance": 0.356
        },
        {
          "concept": "prevention",
          "relevance": 0.349
        },
        {
          "concept": "tracking system",
          "relevance": 0.341
        },
        {
          "concept": "lessons",
          "relevance": 0.34
        },
        {
          "concept": "surveillance",
          "relevance": 0.325
        },
        {
          "concept": "creators",
          "relevance": 0.31
        },
        {
          "concept": "data",
          "relevance": 0.307
        },
        {
          "concept": "center",
          "relevance": 0.304
        },
        {
          "concept": "parable",
          "relevance": 0.303
        },
        {
          "concept": "proportion",
          "relevance": 0.302
        },
        {
          "concept": "headlines",
          "relevance": 0.301
        },
        {
          "concept": "units",
          "relevance": 0.286
        },
        {
          "concept": "error",
          "relevance": 0.285
        },
        {
          "concept": "execution",
          "relevance": 0.276
        },
        {
          "concept": "laboratory",
          "relevance": 0.272
        },
        {
          "concept": "trends",
          "relevance": 0.27
        },
        {
          "concept": "Big",
          "relevance": 0.265
        },
        {
          "concept": "analysis",
          "relevance": 0.241
        },
        {
          "concept": "state",
          "relevance": 0.226
        },
        {
          "concept": "system",
          "relevance": 0.225
        },
        {
          "concept": "traps",
          "relevance": 0.219
        },
        {
          "concept": "nature",
          "relevance": 0.217
        },
        {
          "concept": "estimation",
          "relevance": 0.217
        },
        {
          "concept": "prediction",
          "relevance": 0.212
        }
      ]
    },
    {
      "paperId": "pub.1023676943",
      "doi": "10.1080/1369118x.2012.678878",
      "title": "CRITICAL QUESTIONS FOR BIG DATA",
      "year": 2012,
      "citationCount": 4358,
      "fieldCitationRatio": 1456.08,
      "abstract": "The era of Big Data has begun. Computer scientists, physicists, economists, mathematicians, political scientists, bio-informaticists, sociologists, and other scholars are clamoring for access to the massive quantities of information produced by and about people, things, and their interactions. Diverse groups argue about the potential benefits and costs of analyzing genetic sequences, social media interactions, health records, phone logs, government records, and other digital traces left by people. Significant questions emerge. Will large-scale search data help us create better tools, services, and public goods? Or will it usher in a new wave of privacy incursions and invasive marketing? Will data analytics help us understand online communities and political movements? Or will it be used to track protesters and suppress speech? Will it transform how we study human communication and culture, or narrow the palette of research options and alter what ‘research’ means? Given the rise of Big Data as a socio-technical phenomenon, we argue that it is necessary to critically interrogate its assumptions and biases. In this article, we offer six provocations to spark conversations about the issues of Big Data: a cultural, technological, and scholarly phenomenon that rests on the interplay of technology, analysis, and mythology that provokes extensive utopian and dystopian rhetoric.",
      "reference_ids": [
        "pub.1071560778",
        "pub.1100652636",
        "pub.1135927054",
        "pub.1025075085",
        "pub.1007637098",
        "pub.1099569925",
        "pub.1103045818",
        "pub.1011807941",
        "pub.1033536743",
        "pub.1031666473",
        "pub.1108447074",
        "pub.1053253394",
        "pub.1062464504",
        "pub.1007820830",
        "pub.1073454824",
        "pub.1062459206",
        "pub.1021552157",
        "pub.1167050602",
        "pub.1058544967",
        "pub.1108944239",
        "pub.1051392531",
        "pub.1087524588",
        "pub.1058791410",
        "pub.1070200866",
        "pub.1030435739"
      ],
      "concepts_scores": [
        {
          "concept": "Big Data",
          "relevance": 0.725
        },
        {
          "concept": "study human communication",
          "relevance": 0.702
        },
        {
          "concept": "social media interaction",
          "relevance": 0.694
        },
        {
          "concept": "issues of Big Data",
          "relevance": 0.684
        },
        {
          "concept": "massive quantities of information",
          "relevance": 0.66
        },
        {
          "concept": "era of Big Data",
          "relevance": 0.65
        },
        {
          "concept": "scholarly phenomenon",
          "relevance": 0.649
        },
        {
          "concept": "human communication",
          "relevance": 0.644
        },
        {
          "concept": "media interaction",
          "relevance": 0.643
        },
        {
          "concept": "invasive marketing",
          "relevance": 0.636
        },
        {
          "concept": "suppress speech",
          "relevance": 0.632
        },
        {
          "concept": "spark conversations",
          "relevance": 0.628
        },
        {
          "concept": "online communities",
          "relevance": 0.62
        },
        {
          "concept": "political movements",
          "relevance": 0.619
        },
        {
          "concept": "privacy incursions",
          "relevance": 0.613
        },
        {
          "concept": "socio-technical phenomenon",
          "relevance": 0.613
        },
        {
          "concept": "digital traces",
          "relevance": 0.608
        },
        {
          "concept": "quantity of information",
          "relevance": 0.587
        },
        {
          "concept": "computer scientists",
          "relevance": 0.576
        },
        {
          "concept": "phone logs",
          "relevance": 0.572
        },
        {
          "concept": "political scientists",
          "relevance": 0.554
        },
        {
          "concept": "health records",
          "relevance": 0.546
        },
        {
          "concept": "government records",
          "relevance": 0.545
        },
        {
          "concept": "massive quantities",
          "relevance": 0.534
        },
        {
          "concept": "significant questions",
          "relevance": 0.527
        },
        {
          "concept": "data",
          "relevance": 0.525
        },
        {
          "concept": "mythology",
          "relevance": 0.506
        },
        {
          "concept": "rhetoric",
          "relevance": 0.505
        },
        {
          "concept": "speech",
          "relevance": 0.504
        },
        {
          "concept": "protest",
          "relevance": 0.495
        },
        {
          "concept": "Big",
          "relevance": 0.484
        },
        {
          "concept": "scholars",
          "relevance": 0.479
        },
        {
          "concept": "people",
          "relevance": 0.479
        },
        {
          "concept": "sociologists",
          "relevance": 0.477
        },
        {
          "concept": "era",
          "relevance": 0.448
        },
        {
          "concept": "culture",
          "relevance": 0.448
        },
        {
          "concept": "communication",
          "relevance": 0.444
        },
        {
          "concept": "computer",
          "relevance": 0.437
        },
        {
          "concept": "phone",
          "relevance": 0.437
        },
        {
          "concept": "phenomenon",
          "relevance": 0.436
        },
        {
          "concept": "research options",
          "relevance": 0.434
        },
        {
          "concept": "research",
          "relevance": 0.429
        },
        {
          "concept": "palette",
          "relevance": 0.425
        },
        {
          "concept": "questions",
          "relevance": 0.422
        },
        {
          "concept": "public goods",
          "relevance": 0.418
        },
        {
          "concept": "diverse group",
          "relevance": 0.412
        },
        {
          "concept": "scientists",
          "relevance": 0.408
        },
        {
          "concept": "incursion",
          "relevance": 0.407
        },
        {
          "concept": "provocation",
          "relevance": 0.4
        },
        {
          "concept": "information",
          "relevance": 0.393
        },
        {
          "concept": "services",
          "relevance": 0.391
        },
        {
          "concept": "technology",
          "relevance": 0.388
        },
        {
          "concept": "community",
          "relevance": 0.384
        },
        {
          "concept": "issues",
          "relevance": 0.377
        },
        {
          "concept": "potential benefits",
          "relevance": 0.373
        },
        {
          "concept": "conversion",
          "relevance": 0.365
        },
        {
          "concept": "movement",
          "relevance": 0.364
        },
        {
          "concept": "goods",
          "relevance": 0.357
        },
        {
          "concept": "cost",
          "relevance": 0.355
        },
        {
          "concept": "tools",
          "relevance": 0.355
        },
        {
          "concept": "government",
          "relevance": 0.354
        },
        {
          "concept": "assumptions",
          "relevance": 0.345
        },
        {
          "concept": "log",
          "relevance": 0.342
        },
        {
          "concept": "mathematicians",
          "relevance": 0.332
        },
        {
          "concept": "records",
          "relevance": 0.332
        },
        {
          "concept": "market",
          "relevance": 0.331
        },
        {
          "concept": "interaction",
          "relevance": 0.319
        },
        {
          "concept": "economists",
          "relevance": 0.314
        },
        {
          "concept": "trace",
          "relevance": 0.308
        },
        {
          "concept": "benefits",
          "relevance": 0.293
        },
        {
          "concept": "analysis",
          "relevance": 0.287
        },
        {
          "concept": "health",
          "relevance": 0.274
        },
        {
          "concept": "group",
          "relevance": 0.262
        },
        {
          "concept": "sequence",
          "relevance": 0.262
        },
        {
          "concept": "physicists",
          "relevance": 0.257
        },
        {
          "concept": "bias",
          "relevance": 0.255
        },
        {
          "concept": "wave",
          "relevance": 0.194
        },
        {
          "concept": "options",
          "relevance": 0.188
        },
        {
          "concept": "genetic sequences",
          "relevance": 0.176
        }
      ]
    },
    {
      "paperId": "pub.1044456787",
      "doi": "10.1093/pan/mpr057",
      "title": "Evaluating Online Labor Markets for Experimental Research: Amazon.com's Mechanical Turk",
      "year": 2012,
      "citationCount": 3282,
      "fieldCitationRatio": 1186.89,
      "abstract": "\n                    We examine the trade-offs associated with using\n                    Amazon.com\n                    's Mechanical Turk (MTurk) interface for subject recruitment. We first describe MTurk and its promise as a vehicle for performing low-cost and easy-to-field experiments. We then assess the internal and external validity of experiments performed using MTurk, employing a framework that can be used to evaluate other subject pools. We first investigate the characteristics of samples drawn from the MTurk population. We show that respondents recruited in this manner are often more representative of the U.S. population than in-person convenience samples—the modal sample in published experimental political science—but less representative than subjects in Internet-based panels or national probability samples. Finally, we replicate important published experimental work using MTurk samples.\n                  ",
      "reference_ids": [
        "pub.1042647885",
        "pub.1001388454",
        "pub.1018654382",
        "pub.1028805986",
        "pub.1053127305",
        "pub.1054802257",
        "pub.1062646798",
        "pub.1027706734",
        "pub.1011231963",
        "pub.1099150814",
        "pub.1093557144",
        "pub.1053573448",
        "pub.1059969043",
        "pub.1038844959",
        "pub.1058579769",
        "pub.1027965171",
        "pub.1033820502",
        "pub.1154176417",
        "pub.1035269715",
        "pub.1102270469",
        "pub.1014721149",
        "pub.1042000046",
        "pub.1000473239",
        "pub.1000135922",
        "pub.1045685410",
        "pub.1041142737",
        "pub.1043859722",
        "pub.1009340257",
        "pub.1004194125"
      ],
      "concepts_scores": [
        {
          "concept": "online labor markets",
          "relevance": 0.557
        },
        {
          "concept": "Mechanical Turk",
          "relevance": 0.496
        },
        {
          "concept": "labor market",
          "relevance": 0.482
        },
        {
          "concept": "MTurk sample",
          "relevance": 0.466
        },
        {
          "concept": "MTurk",
          "relevance": 0.457
        },
        {
          "concept": "subject pool",
          "relevance": 0.44
        },
        {
          "concept": "internet-based panel",
          "relevance": 0.434
        },
        {
          "concept": "national probability sample",
          "relevance": 0.423
        },
        {
          "concept": "probability sample",
          "relevance": 0.418
        },
        {
          "concept": "trade-offs",
          "relevance": 0.413
        },
        {
          "concept": "market",
          "relevance": 0.411
        },
        {
          "concept": "vehicle",
          "relevance": 0.374
        },
        {
          "concept": "respondents",
          "relevance": 0.36
        },
        {
          "concept": "U.S.",
          "relevance": 0.36
        },
        {
          "concept": "convenience",
          "relevance": 0.354
        },
        {
          "concept": "Turks",
          "relevance": 0.349
        },
        {
          "concept": "research",
          "relevance": 0.336
        },
        {
          "concept": "framework",
          "relevance": 0.332
        },
        {
          "concept": "panel",
          "relevance": 0.328
        },
        {
          "concept": "work",
          "relevance": 0.315
        },
        {
          "concept": "U.S. population",
          "relevance": 0.304
        },
        {
          "concept": "samples",
          "relevance": 0.289
        },
        {
          "concept": "low cost",
          "relevance": 0.27
        },
        {
          "concept": "MTurk population",
          "relevance": 0.259
        },
        {
          "concept": "in-person",
          "relevance": 0.258
        },
        {
          "concept": "experiments",
          "relevance": 0.253
        },
        {
          "concept": "published experimental work",
          "relevance": 0.252
        },
        {
          "concept": "characteristics of samples",
          "relevance": 0.25
        },
        {
          "concept": "characteristics",
          "relevance": 0.25
        },
        {
          "concept": "experimental research",
          "relevance": 0.249
        },
        {
          "concept": "recruitment",
          "relevance": 0.241
        },
        {
          "concept": "experimental work",
          "relevance": 0.238
        },
        {
          "concept": "subject recruitment",
          "relevance": 0.228
        },
        {
          "concept": "population",
          "relevance": 0.217
        },
        {
          "concept": "pool",
          "relevance": 0.213
        },
        {
          "concept": "experimentation",
          "relevance": 0.202
        },
        {
          "concept": "subjects",
          "relevance": 0.185
        },
        {
          "concept": "mechanism",
          "relevance": 0.16
        }
      ]
    },
    {
      "paperId": "pub.1160635088",
      "doi": "10.1038/s41586-023-06291-2",
      "title": "Large language models encode clinical knowledge",
      "year": 2023,
      "citationCount": 1807,
      "fieldCitationRatio": 1143.54,
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities, but the bar for clinical applications is high. Attempts to assess the clinical knowledge of models typically rely on automated evaluations based on limited benchmarks. Here, to address these limitations, we present MultiMedQA, a benchmark combining six existing medical question answering datasets spanning professional medicine, research and consumer queries and a new dataset of medical questions searched online, HealthSearchQA. We propose a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. In addition, we evaluate Pathways Language Model1 (PaLM, a 540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM2 on MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA3, MedMCQA4, PubMedQA5 and Measuring Massive Multitask Language Understanding (MMLU) clinical topics6), including 67.6% accuracy on MedQA (US Medical Licensing Exam-style questions), surpassing the prior state of the art by more than 17%. However, human evaluation reveals key gaps. To resolve this, we introduce instruction prompt tuning, a parameter-efficient approach for aligning LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians. We show that comprehension, knowledge recall and reasoning improve with model scale and instruction prompt tuning, suggesting the potential utility of LLMs in medicine. Our human evaluations reveal limitations of today’s models, reinforcing the importance of both evaluation frameworks and method development in creating safe, helpful LLMs for clinical applications.",
      "reference_ids": [
        "pub.1149439682",
        "pub.1149600393",
        "pub.1146909620",
        "pub.1152022267",
        "pub.1136509890",
        "pub.1148187428",
        "pub.1031369500",
        "pub.1152818808",
        "pub.1118803161",
        "pub.1146726542",
        "pub.1124308279",
        "pub.1145122135",
        "pub.1152983179",
        "pub.1147625763",
        "pub.1084253366",
        "pub.1131794605",
        "pub.1124301819",
        "pub.1137337965",
        "pub.1128562573",
        "pub.1169290908",
        "pub.1060343143",
        "pub.1134427256",
        "pub.1149547072",
        "pub.1148815213",
        "pub.1151765911",
        "pub.1100517312",
        "pub.1144859682",
        "pub.1163991073",
        "pub.1152020866",
        "pub.1148150423",
        "pub.1139648327",
        "pub.1119464119",
        "pub.1120882528",
        "pub.1144119443",
        "pub.1143749058",
        "pub.1148116107",
        "pub.1152637972",
        "pub.1011491073",
        "pub.1152818783",
        "pub.1148283402",
        "pub.1019551002",
        "pub.1121015527",
        "pub.1145333867",
        "pub.1096025530",
        "pub.1133174582",
        "pub.1141035588",
        "pub.1127688687",
        "pub.1137740499",
        "pub.1129565202",
        "pub.1146892344",
        "pub.1143948984",
        "pub.1151655603",
        "pub.1134323565",
        "pub.1146909638",
        "pub.1117658904",
        "pub.1122290388",
        "pub.1111334730",
        "pub.1142230135",
        "pub.1125798967",
        "pub.1006217895",
        "pub.1138572951",
        "pub.1140910420",
        "pub.1137821262",
        "pub.1139758893",
        "pub.1151003027",
        "pub.1140466886",
        "pub.1163045658",
        "pub.1148556704",
        "pub.1162970625",
        "pub.1143336252",
        "pub.1146094553",
        "pub.1119262691",
        "pub.1144537306",
        "pub.1139947391",
        "pub.1122290276",
        "pub.1143544709",
        "pub.1146478063",
        "pub.1142420217",
        "pub.1127261664",
        "pub.1163041639",
        "pub.1104506335",
        "pub.1130673697",
        "pub.1122290595",
        "pub.1099239594",
        "pub.1121658381",
        "pub.1148728946",
        "pub.1140052367",
        "pub.1149151305",
        "pub.1118818544",
        "pub.1151332162",
        "pub.1137024208",
        "pub.1145942961",
        "pub.1117925618",
        "pub.1148115417",
        "pub.1141942664"
      ],
      "concepts_scores": [
        {
          "concept": "prompt tuning",
          "relevance": 0.716
        },
        {
          "concept": "human evaluation",
          "relevance": 0.708
        },
        {
          "concept": "state-of-the-art accuracy",
          "relevance": 0.69
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.665
        },
        {
          "concept": "evaluation framework",
          "relevance": 0.634
        },
        {
          "concept": "answering dataset",
          "relevance": 0.618
        },
        {
          "concept": "language model",
          "relevance": 0.612
        },
        {
          "concept": "consumer queries",
          "relevance": 0.606
        },
        {
          "concept": "automated evaluation",
          "relevance": 0.573
        },
        {
          "concept": "impressive capability",
          "relevance": 0.555
        },
        {
          "concept": "dataset",
          "relevance": 0.553
        },
        {
          "concept": "knowledge of models",
          "relevance": 0.545
        },
        {
          "concept": "model answers",
          "relevance": 0.53
        },
        {
          "concept": "medical questions",
          "relevance": 0.496
        },
        {
          "concept": "MedQA",
          "relevance": 0.489
        },
        {
          "concept": "accuracy",
          "relevance": 0.481
        },
        {
          "concept": "query",
          "relevance": 0.48
        },
        {
          "concept": "clinical knowledge",
          "relevance": 0.466
        },
        {
          "concept": "framework",
          "relevance": 0.465
        },
        {
          "concept": "knowledge recall",
          "relevance": 0.465
        },
        {
          "concept": "language",
          "relevance": 0.463
        },
        {
          "concept": "benchmarks",
          "relevance": 0.444
        },
        {
          "concept": "LLM",
          "relevance": 0.439
        },
        {
          "concept": "applications",
          "relevance": 0.436
        },
        {
          "concept": "evaluation",
          "relevance": 0.436
        },
        {
          "concept": "tuning",
          "relevance": 0.436
        },
        {
          "concept": "model",
          "relevance": 0.414
        },
        {
          "concept": "recall",
          "relevance": 0.411
        },
        {
          "concept": "model scale",
          "relevance": 0.409
        },
        {
          "concept": "multiple axes",
          "relevance": 0.407
        },
        {
          "concept": "knowledge",
          "relevance": 0.404
        },
        {
          "concept": "capability",
          "relevance": 0.403
        },
        {
          "concept": "reasons",
          "relevance": 0.396
        },
        {
          "concept": "instruction",
          "relevance": 0.384
        },
        {
          "concept": "domain",
          "relevance": 0.379
        },
        {
          "concept": "answers",
          "relevance": 0.374
        },
        {
          "concept": "comprehension",
          "relevance": 0.369
        },
        {
          "concept": "exemplars",
          "relevance": 0.363
        },
        {
          "concept": "method",
          "relevance": 0.352
        },
        {
          "concept": "factuality",
          "relevance": 0.344
        },
        {
          "concept": "professional medicine",
          "relevance": 0.335
        },
        {
          "concept": "limitations",
          "relevance": 0.331
        },
        {
          "concept": "utilization",
          "relevance": 0.329
        },
        {
          "concept": "research",
          "relevance": 0.324
        },
        {
          "concept": "consumers",
          "relevance": 0.314
        },
        {
          "concept": "model1",
          "relevance": 0.305
        },
        {
          "concept": "strategies",
          "relevance": 0.305
        },
        {
          "concept": "variants",
          "relevance": 0.295
        },
        {
          "concept": "gap",
          "relevance": 0.277
        },
        {
          "concept": "questions",
          "relevance": 0.274
        },
        {
          "concept": "development",
          "relevance": 0.273
        },
        {
          "concept": "combination",
          "relevance": 0.268
        },
        {
          "concept": "method development",
          "relevance": 0.263
        },
        {
          "concept": "clinical application",
          "relevance": 0.25
        },
        {
          "concept": "harm",
          "relevance": 0.243
        },
        {
          "concept": "scale",
          "relevance": 0.232
        },
        {
          "concept": "potential utility",
          "relevance": 0.224
        },
        {
          "concept": "medicine",
          "relevance": 0.222
        },
        {
          "concept": "approach",
          "relevance": 0.189
        },
        {
          "concept": "clinicians",
          "relevance": 0.187
        },
        {
          "concept": "bar",
          "relevance": 0.174
        },
        {
          "concept": "axis",
          "relevance": 0.155
        }
      ]
    },
    {
      "paperId": "pub.1151332162",
      "doi": "10.1093/bib/bbac409",
      "title": "BioGPT: generative pre-trained transformer for biomedical text generation and mining",
      "year": 2022,
      "citationCount": 633,
      "fieldCitationRatio": 164.65,
      "abstract": "Pre-trained language models have attracted increasing attention in the biomedical domain, inspired by their great success in the general natural language domain. Among the two main branches of pre-trained language models in the general language domain, i.e. BERT (and its variants) and GPT (and its variants), the first one has been extensively studied in the biomedical domain, such as BioBERT and PubMedBERT. While they have achieved great success on a variety of discriminative downstream biomedical tasks, the lack of generation ability constrains their application scope. In this paper, we propose BioGPT, a domain-specific generative Transformer language model pre-trained on large-scale biomedical literature. We evaluate BioGPT on six biomedical natural language processing tasks and demonstrate that our model outperforms previous models on most tasks. Especially, we get 44.98%, 38.42% and 40.76% F1 score on BC5CDR, KD-DTI and DDI end-to-end relation extraction tasks, respectively, and 78.2% accuracy on PubMedQA, creating a new record. Our case study on text generation further demonstrates the advantage of BioGPT on biomedical literature to generate fluent descriptions for biomedical terms.",
      "reference_ids": [
        "pub.1039633073",
        "pub.1129119978",
        "pub.1121024723",
        "pub.1163041639",
        "pub.1133174796",
        "pub.1118169851",
        "pub.1138840042",
        "pub.1099113707",
        "pub.1125947346",
        "pub.1122290276",
        "pub.1045847617",
        "pub.1099113598",
        "pub.1133174687",
        "pub.1121025784",
        "pub.1141942664",
        "pub.1117659374",
        "pub.1151003027",
        "pub.1148391030",
        "pub.1117660148",
        "pub.1133177283",
        "pub.1129756704",
        "pub.1144245013",
        "pub.1134455314",
        "pub.1139947391",
        "pub.1120882528",
        "pub.1105386706",
        "pub.1019551002",
        "pub.1148391303",
        "pub.1151667611",
        "pub.1129120019",
        "pub.1129756783",
        "pub.1143948902",
        "pub.1133177065",
        "pub.1163042704",
        "pub.1129757334",
        "pub.1122290388",
        "pub.1032444382",
        "pub.1007810086"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.716
        },
        {
          "concept": "text generation",
          "relevance": 0.679
        },
        {
          "concept": "biomedical domain",
          "relevance": 0.67
        },
        {
          "concept": "natural language processing tasks",
          "relevance": 0.66
        },
        {
          "concept": "pre-trained language models",
          "relevance": 0.656
        },
        {
          "concept": "relation extraction task",
          "relevance": 0.645
        },
        {
          "concept": "language processing tasks",
          "relevance": 0.64
        },
        {
          "concept": "biomedical natural language processing tasks",
          "relevance": 0.638
        },
        {
          "concept": "transformer language models",
          "relevance": 0.637
        },
        {
          "concept": "pre-trained transformers",
          "relevance": 0.635
        },
        {
          "concept": "natural language domain",
          "relevance": 0.635
        },
        {
          "concept": "biomedical literature",
          "relevance": 0.629
        },
        {
          "concept": "fluent descriptions",
          "relevance": 0.599
        },
        {
          "concept": "extraction task",
          "relevance": 0.593
        },
        {
          "concept": "F1 score",
          "relevance": 0.584
        },
        {
          "concept": "processing tasks",
          "relevance": 0.574
        },
        {
          "concept": "biomedical tasks",
          "relevance": 0.558
        },
        {
          "concept": "biomedical terms",
          "relevance": 0.555
        },
        {
          "concept": "task",
          "relevance": 0.519
        },
        {
          "concept": "language domains",
          "relevance": 0.513
        },
        {
          "concept": "PubMedQA",
          "relevance": 0.471
        },
        {
          "concept": "BC5CDR",
          "relevance": 0.469
        },
        {
          "concept": "BERT",
          "relevance": 0.463
        },
        {
          "concept": "BioBERT",
          "relevance": 0.463
        },
        {
          "concept": "PubMedBERT",
          "relevance": 0.462
        },
        {
          "concept": "domain",
          "relevance": 0.451
        },
        {
          "concept": "case study",
          "relevance": 0.445
        },
        {
          "concept": "increasing attention",
          "relevance": 0.412
        },
        {
          "concept": "mining",
          "relevance": 0.404
        },
        {
          "concept": "accuracy",
          "relevance": 0.4
        },
        {
          "concept": "model",
          "relevance": 0.398
        },
        {
          "concept": "text",
          "relevance": 0.386
        },
        {
          "concept": "language",
          "relevance": 0.385
        },
        {
          "concept": "transformation",
          "relevance": 0.35
        },
        {
          "concept": "generation",
          "relevance": 0.347
        },
        {
          "concept": "success",
          "relevance": 0.341
        },
        {
          "concept": "description",
          "relevance": 0.317
        },
        {
          "concept": "i.",
          "relevance": 0.316
        },
        {
          "concept": "literature",
          "relevance": 0.309
        },
        {
          "concept": "attention",
          "relevance": 0.306
        },
        {
          "concept": "term",
          "relevance": 0.278
        },
        {
          "concept": "records",
          "relevance": 0.271
        },
        {
          "concept": "lack",
          "relevance": 0.257
        },
        {
          "concept": "branches",
          "relevance": 0.253
        },
        {
          "concept": "cases",
          "relevance": 0.243
        },
        {
          "concept": "GPT",
          "relevance": 0.23
        },
        {
          "concept": "study",
          "relevance": 0.212
        },
        {
          "concept": "scores",
          "relevance": 0.207
        },
        {
          "concept": "ddI",
          "relevance": 0.176
        }
      ]
    },
    {
      "paperId": "pub.1152983179",
      "doi": "10.1016/j.aiopen.2022.11.003",
      "title": "PTR: Prompt Tuning with Rules for Text Classification",
      "year": 2022,
      "citationCount": 302,
      "fieldCitationRatio": 119.17,
      "abstract": "Recently, prompt tuning has been widely applied to stimulate the rich knowledge in pre-trained language models (PLMs) to serve NLP tasks. Although prompt tuning has achieved promising results on some few-class classification tasks, such as sentiment classification and natural language inference, manually designing prompts is cumbersome. Meanwhile, generating prompts automatically is also difficult and time-consuming. Therefore, obtaining effective prompts for complex many-class classification tasks still remains a challenge. In this paper, we propose to encode the prior knowledge of a classification task into rules, then design sub-prompts according to the rules, and finally combine the sub-prompts to handle the task. We name this Prompt Tuning method with Rules “PTR”. Compared with existing prompt-based methods, PTR achieves a good trade-off between effectiveness and efficiency in building prompts. We conduct experiments on three many-class classification tasks, including relation classification, entity typing, and intent classification. The results show that PTR outperforms both vanilla and prompt tuning baselines, indicating the effectiveness of utilizing rules for prompt tuning. The source code of PTR is available at https://github.com/thunlp/PTR.",
      "reference_ids": [
        "pub.1150866022",
        "pub.1142776451",
        "pub.1100516689",
        "pub.1133177283",
        "pub.1147477782",
        "pub.1148391028",
        "pub.1121024871",
        "pub.1134455702",
        "pub.1012146698",
        "pub.1151003027",
        "pub.1122290126",
        "pub.1121024948",
        "pub.1129756711",
        "pub.1139947274",
        "pub.1096024932",
        "pub.1125558196",
        "pub.1122290267",
        "pub.1129756622",
        "pub.1041355599",
        "pub.1148391057",
        "pub.1129757730",
        "pub.1131074864",
        "pub.1143948874",
        "pub.1122290729",
        "pub.1133177060",
        "pub.1122290148",
        "pub.1148390501",
        "pub.1133174526",
        "pub.1117658890",
        "pub.1143948984",
        "pub.1122290022",
        "pub.1139947326",
        "pub.1133177171",
        "pub.1129756642",
        "pub.1133174687",
        "pub.1149741611",
        "pub.1139947391"
      ],
      "concepts_scores": [
        {
          "concept": "classification task",
          "relevance": 0.774
        },
        {
          "concept": "prompt tuning",
          "relevance": 0.728
        },
        {
          "concept": "prompt-based method",
          "relevance": 0.682
        },
        {
          "concept": "natural language inference",
          "relevance": 0.679
        },
        {
          "concept": "sentiment classification",
          "relevance": 0.631
        },
        {
          "concept": "text classification",
          "relevance": 0.629
        },
        {
          "concept": "NLP tasks",
          "relevance": 0.629
        },
        {
          "concept": "language inference",
          "relevance": 0.629
        },
        {
          "concept": "intent classification",
          "relevance": 0.628
        },
        {
          "concept": "entity types",
          "relevance": 0.623
        },
        {
          "concept": "language model",
          "relevance": 0.622
        },
        {
          "concept": "task",
          "relevance": 0.553
        },
        {
          "concept": "classification",
          "relevance": 0.547
        },
        {
          "concept": "time-consuming",
          "relevance": 0.531
        },
        {
          "concept": "rules",
          "relevance": 0.509
        },
        {
          "concept": "NLP",
          "relevance": 0.481
        },
        {
          "concept": "effective prompts",
          "relevance": 0.478
        },
        {
          "concept": "tuning",
          "relevance": 0.466
        },
        {
          "concept": "vanilla",
          "relevance": 0.451
        },
        {
          "concept": "code",
          "relevance": 0.45
        },
        {
          "concept": "sentiment",
          "relevance": 0.444
        },
        {
          "concept": "inference",
          "relevance": 0.421
        },
        {
          "concept": "method",
          "relevance": 0.414
        },
        {
          "concept": "knowledge",
          "relevance": 0.411
        },
        {
          "concept": "text",
          "relevance": 0.407
        },
        {
          "concept": "language",
          "relevance": 0.406
        },
        {
          "concept": "manually",
          "relevance": 0.398
        },
        {
          "concept": "PLM",
          "relevance": 0.392
        },
        {
          "concept": "prompts",
          "relevance": 0.379
        },
        {
          "concept": "entities",
          "relevance": 0.369
        },
        {
          "concept": "results",
          "relevance": 0.36
        },
        {
          "concept": "efficiency",
          "relevance": 0.354
        },
        {
          "concept": "experiments",
          "relevance": 0.339
        },
        {
          "concept": "model",
          "relevance": 0.338
        },
        {
          "concept": "intention",
          "relevance": 0.338
        },
        {
          "concept": "baseline",
          "relevance": 0.251
        },
        {
          "concept": "PTR",
          "relevance": 0.247
        },
        {
          "concept": "effect",
          "relevance": 0.235
        },
        {
          "concept": "type",
          "relevance": 0.213
        }
      ]
    },
    {
      "paperId": "pub.1156602823",
      "doi": "10.1056/nejmsr2214184",
      "title": "Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine",
      "year": 2023,
      "citationCount": 1204,
      "fieldCitationRatio": NaN,
      "abstract": "GPT-4, a General AI Chatbot for Medicine Chatbots are computer programs with which one can have a conversation. In this article, the authors describe how the GPT-4 chatbot, which has been given a g...",
      "reference_ids": [
        "pub.1155270525",
        "pub.1150999098",
        "pub.1134322180",
        "pub.1145086372",
        "pub.1136777420",
        "pub.1100133641"
      ],
      "concepts_scores": [
        {
          "concept": "AI chatbots",
          "relevance": 0.555
        },
        {
          "concept": "chatbot",
          "relevance": 0.472
        },
        {
          "concept": "computer program",
          "relevance": 0.417
        },
        {
          "concept": "computer",
          "relevance": 0.359
        },
        {
          "concept": "generalization",
          "relevance": 0.313
        },
        {
          "concept": "program",
          "relevance": 0.276
        },
        {
          "concept": "article",
          "relevance": 0.273
        },
        {
          "concept": "authors",
          "relevance": 0.264
        },
        {
          "concept": "benefits",
          "relevance": 0.241
        },
        {
          "concept": "medicine",
          "relevance": 0.238
        },
        {
          "concept": "limitations",
          "relevance": 0.23
        },
        {
          "concept": "risk",
          "relevance": 0.208
        },
        {
          "concept": "conversion",
          "relevance": 0.191
        }
      ]
    },
    {
      "paperId": "pub.1155270525",
      "doi": "10.1371/journal.pdig.0000198",
      "title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models",
      "year": 2023,
      "citationCount": 2693,
      "fieldCitationRatio": 2145.24,
      "abstract": "We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, clinical decision-making.",
      "reference_ids": [
        "pub.1121025018",
        "pub.1100900092",
        "pub.1130542575",
        "pub.1117041738",
        "pub.1117939920",
        "pub.1136656239",
        "pub.1092352256",
        "pub.1127685771",
        "pub.1121129078",
        "pub.1045049575",
        "pub.1151451023",
        "pub.1113525484",
        "pub.1126027253",
        "pub.1139648327",
        "pub.1116881202",
        "pub.1169290908",
        "pub.1112585067",
        "pub.1033178586",
        "pub.1078412683",
        "pub.1129260878",
        "pub.1147955703",
        "pub.1093497718"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.682
        },
        {
          "concept": "ChatGPT",
          "relevance": 0.546
        },
        {
          "concept": "United States Medical Licensing Exam",
          "relevance": 0.536
        },
        {
          "concept": "medical education",
          "relevance": 0.476
        },
        {
          "concept": "language",
          "relevance": 0.445
        },
        {
          "concept": "clinical decision-making",
          "relevance": 0.428
        },
        {
          "concept": "Medical Licensing Exam",
          "relevance": 0.427
        },
        {
          "concept": "performance",
          "relevance": 0.424
        },
        {
          "concept": "decision-making",
          "relevance": 0.412
        },
        {
          "concept": "level of concordance",
          "relevance": 0.405
        },
        {
          "concept": "licensing exam",
          "relevance": 0.394
        },
        {
          "concept": "specialized training",
          "relevance": 0.392
        },
        {
          "concept": "model",
          "relevance": 0.37
        },
        {
          "concept": "training",
          "relevance": 0.363
        },
        {
          "concept": "education",
          "relevance": 0.34
        },
        {
          "concept": "exam",
          "relevance": 0.339
        },
        {
          "concept": "reinforcement",
          "relevance": 0.324
        },
        {
          "concept": "threshold",
          "relevance": 0.296
        },
        {
          "concept": "results",
          "relevance": 0.28
        },
        {
          "concept": "concordance",
          "relevance": 0.263
        },
        {
          "concept": "units",
          "relevance": 0.247
        },
        {
          "concept": "levels",
          "relevance": 0.216
        },
        {
          "concept": "potential",
          "relevance": 0.196
        }
      ]
    },
    {
      "paperId": "pub.1093497718",
      "doi": "10.1109/cvpr.2016.308",
      "title": "Rethinking the Inception Architecture for Computer Vision",
      "year": 2016,
      "citationCount": 26343,
      "fieldCitationRatio": 5148.56,
      "abstract": "Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5% top-5 error and 17.3% top-1 error on the validation set and 3.6% top-5 error on the official test set.",
      "reference_ids": [
        "pub.1094727707",
        "pub.1095510970",
        "pub.1037471929",
        "pub.1061218465",
        "pub.1094291017",
        "pub.1095072940",
        "pub.1093828312",
        "pub.1022837810",
        "pub.1085642448",
        "pub.1093626237",
        "pub.1095738839",
        "pub.1094869203"
      ],
      "concepts_scores": [
        {
          "concept": "convolutional network",
          "relevance": 0.733
        },
        {
          "concept": "computational cost",
          "relevance": 0.697
        },
        {
          "concept": "top-1 error",
          "relevance": 0.691
        },
        {
          "concept": "computer vision solutions",
          "relevance": 0.688
        },
        {
          "concept": "Big Data scenarios",
          "relevance": 0.687
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.685
        },
        {
          "concept": "deep convolutional networks",
          "relevance": 0.683
        },
        {
          "concept": "increasing model size",
          "relevance": 0.663
        },
        {
          "concept": "low parameter count",
          "relevance": 0.661
        },
        {
          "concept": "computer vision",
          "relevance": 0.635
        },
        {
          "concept": "top-1",
          "relevance": 0.635
        },
        {
          "concept": "Inception architecture",
          "relevance": 0.631
        },
        {
          "concept": "vision solutions",
          "relevance": 0.629
        },
        {
          "concept": "factorized convolution",
          "relevance": 0.626
        },
        {
          "concept": "parameter count",
          "relevance": 0.623
        },
        {
          "concept": "model size",
          "relevance": 0.618
        },
        {
          "concept": "mobile vision",
          "relevance": 0.611
        },
        {
          "concept": "quality gains",
          "relevance": 0.61
        },
        {
          "concept": "multiply-add",
          "relevance": 0.595
        },
        {
          "concept": "computational efficiency",
          "relevance": 0.574
        },
        {
          "concept": "network",
          "relevance": 0.572
        },
        {
          "concept": "computer",
          "relevance": 0.534
        },
        {
          "concept": "task",
          "relevance": 0.52
        },
        {
          "concept": "error",
          "relevance": 0.508
        },
        {
          "concept": "ILSVRC",
          "relevance": 0.502
        },
        {
          "concept": "vision",
          "relevance": 0.49
        },
        {
          "concept": "validation set",
          "relevance": 0.486
        },
        {
          "concept": "convolution",
          "relevance": 0.481
        },
        {
          "concept": "architecture",
          "relevance": 0.465
        },
        {
          "concept": "benchmarks",
          "relevance": 0.457
        },
        {
          "concept": "classification",
          "relevance": 0.445
        },
        {
          "concept": "cost",
          "relevance": 0.434
        },
        {
          "concept": "scenarios",
          "relevance": 0.429
        },
        {
          "concept": "inference",
          "relevance": 0.427
        },
        {
          "concept": "regularization",
          "relevance": 0.421
        },
        {
          "concept": "evaluation",
          "relevance": 0.42
        },
        {
          "concept": "ensemble",
          "relevance": 0.401
        },
        {
          "concept": "official tests",
          "relevance": 0.387
        },
        {
          "concept": "sets",
          "relevance": 0.373
        },
        {
          "concept": "method",
          "relevance": 0.362
        },
        {
          "concept": "efficiency",
          "relevance": 0.359
        },
        {
          "concept": "solution",
          "relevance": 0.353
        },
        {
          "concept": "gain",
          "relevance": 0.347
        },
        {
          "concept": "model",
          "relevance": 0.343
        },
        {
          "concept": "validity",
          "relevance": 0.333
        },
        {
          "concept": "mainstream",
          "relevance": 0.308
        },
        {
          "concept": "core",
          "relevance": 0.302
        },
        {
          "concept": "parameters",
          "relevance": 0.299
        },
        {
          "concept": "inception",
          "relevance": 0.267
        },
        {
          "concept": "size",
          "relevance": 0.267
        },
        {
          "concept": "cases",
          "relevance": 0.261
        },
        {
          "concept": "test",
          "relevance": 0.257
        },
        {
          "concept": "state",
          "relevance": 0.226
        },
        {
          "concept": "count",
          "relevance": 0.204
        },
        {
          "concept": "factors",
          "relevance": 0.193
        }
      ]
    },
    {
      "paperId": "pub.1127685771",
      "doi": "10.1038/s41591-020-0842-3",
      "title": "A deep learning system for differential diagnosis of skin diseases",
      "year": 2020,
      "citationCount": 616,
      "fieldCitationRatio": 175.6,
      "abstract": "Skin conditions affect 1.9 billion people. Because of a shortage of dermatologists, most cases are seen instead by general practitioners with lower diagnostic accuracy. We present a deep learning system (DLS) to provide a differential diagnosis of skin conditions using 16,114 de-identified cases (photographs and clinical data) from a teledermatology practice serving 17 sites. The DLS distinguishes between 26 common skin conditions, representing 80% of cases seen in primary care, while also providing a secondary prediction covering 419 skin conditions. On 963 validation cases, where a rotating panel of three board-certified dermatologists defined the reference standard, the DLS was non-inferior to six other dermatologists and superior to six primary care physicians (PCPs) and six nurse practitioners (NPs) (top-1 accuracy: 0.66 DLS, 0.63 dermatologists, 0.44 PCPs and 0.40 NPs). These results highlight the potential of the DLS to assist general practitioners in diagnosing skin conditions.",
      "reference_ids": [
        "pub.1009634351",
        "pub.1077793311",
        "pub.1106835128",
        "pub.1112466976",
        "pub.1104293396",
        "pub.1052314382",
        "pub.1009767488",
        "pub.1120312910",
        "pub.1084948468",
        "pub.1091080781",
        "pub.1021839880",
        "pub.1019018231",
        "pub.1084246301",
        "pub.1100565524",
        "pub.1074344209",
        "pub.1045074199",
        "pub.1051728167",
        "pub.1003788636",
        "pub.1100484852",
        "pub.1121783884",
        "pub.1105579486",
        "pub.1039230587",
        "pub.1000798719",
        "pub.1105977295",
        "pub.1103818178",
        "pub.1034543347",
        "pub.1044058999",
        "pub.1054104140",
        "pub.1084005844",
        "pub.1021955972",
        "pub.1031248877",
        "pub.1126584795",
        "pub.1059744049",
        "pub.1003052029",
        "pub.1007815996",
        "pub.1032664445",
        "pub.1148955875",
        "pub.1043162503",
        "pub.1074217286",
        "pub.1113359490",
        "pub.1046704911",
        "pub.1117069073",
        "pub.1043265979",
        "pub.1110720271",
        "pub.1008508369",
        "pub.1079025257"
      ],
      "concepts_scores": [
        {
          "concept": "primary care physicians",
          "relevance": 0.645
        },
        {
          "concept": "nurse practitioners",
          "relevance": 0.604
        },
        {
          "concept": "general practitioners",
          "relevance": 0.598
        },
        {
          "concept": "skin conditions",
          "relevance": 0.579
        },
        {
          "concept": "differential diagnosis",
          "relevance": 0.571
        },
        {
          "concept": "differential diagnosis of skin diseases",
          "relevance": 0.547
        },
        {
          "concept": "shortage of dermatologists",
          "relevance": 0.546
        },
        {
          "concept": "primary care",
          "relevance": 0.522
        },
        {
          "concept": "board-certified dermatologists",
          "relevance": 0.521
        },
        {
          "concept": "care physicians",
          "relevance": 0.516
        },
        {
          "concept": "diagnosis of skin conditions",
          "relevance": 0.508
        },
        {
          "concept": "deep learning system",
          "relevance": 0.506
        },
        {
          "concept": "diagnosing skin conditions",
          "relevance": 0.503
        },
        {
          "concept": "diagnostic accuracy",
          "relevance": 0.489
        },
        {
          "concept": "non-inferiority",
          "relevance": 0.488
        },
        {
          "concept": "teledermatology practice",
          "relevance": 0.48
        },
        {
          "concept": "reference standard",
          "relevance": 0.471
        },
        {
          "concept": "skin diseases",
          "relevance": 0.464
        },
        {
          "concept": "diagnosis of skin diseases",
          "relevance": 0.458
        },
        {
          "concept": "dermatologists",
          "relevance": 0.453
        },
        {
          "concept": "practitioners",
          "relevance": 0.444
        },
        {
          "concept": "skin",
          "relevance": 0.432
        },
        {
          "concept": "learning system",
          "relevance": 0.427
        },
        {
          "concept": "nurses",
          "relevance": 0.408
        },
        {
          "concept": "care",
          "relevance": 0.396
        },
        {
          "concept": "teledermatology",
          "relevance": 0.39
        },
        {
          "concept": "physicians",
          "relevance": 0.389
        },
        {
          "concept": "cases",
          "relevance": 0.376
        },
        {
          "concept": "billion people",
          "relevance": 0.369
        },
        {
          "concept": "disease",
          "relevance": 0.364
        },
        {
          "concept": "secondary prediction",
          "relevance": 0.352
        },
        {
          "concept": "people",
          "relevance": 0.342
        },
        {
          "concept": "practice",
          "relevance": 0.336
        },
        {
          "concept": "rotating panel",
          "relevance": 0.334
        },
        {
          "concept": "shortage",
          "relevance": 0.323
        },
        {
          "concept": "validity",
          "relevance": 0.295
        },
        {
          "concept": "billion",
          "relevance": 0.275
        },
        {
          "concept": "validation cases",
          "relevance": 0.273
        },
        {
          "concept": "standards",
          "relevance": 0.267
        },
        {
          "concept": "sites",
          "relevance": 0.266
        },
        {
          "concept": "conditions",
          "relevance": 0.263
        },
        {
          "concept": "system",
          "relevance": 0.262
        },
        {
          "concept": "accuracy",
          "relevance": 0.258
        },
        {
          "concept": "panel",
          "relevance": 0.258
        },
        {
          "concept": "potential",
          "relevance": 0.252
        },
        {
          "concept": "reference",
          "relevance": 0.242
        },
        {
          "concept": "results",
          "relevance": 0.22
        },
        {
          "concept": "prediction",
          "relevance": 0.213
        }
      ]
    },
    {
      "paperId": "pub.1100133641",
      "doi": "10.1109/access.2017.2788044",
      "title": "Deep Learning Applications in Medical Image Analysis",
      "year": 2017,
      "citationCount": 1277,
      "fieldCitationRatio": 257.43,
      "abstract": "The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. This review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field. The advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features. We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration. We conclude by discussing research obstacles, emerging trends, and possible future directions.",
      "reference_ids": [
        "pub.1085642448",
        "pub.1061696713",
        "pub.1061696712",
        "pub.1061798360",
        "pub.1061696680",
        "pub.1028715170",
        "pub.1061696710",
        "pub.1009611012",
        "pub.1023638731",
        "pub.1015376043",
        "pub.1044365820",
        "pub.1061696692",
        "pub.1085753273",
        "pub.1095401413",
        "pub.1006555326",
        "pub.1094552856",
        "pub.1061744581",
        "pub.1008345178",
        "pub.1090383886",
        "pub.1061696721",
        "pub.1095735220",
        "pub.1008016534",
        "pub.1018633844",
        "pub.1010719422",
        "pub.1086144283",
        "pub.1093359587",
        "pub.1017257287",
        "pub.1061696572",
        "pub.1092089127",
        "pub.1085595827",
        "pub.1094291017",
        "pub.1039374598",
        "pub.1061696747",
        "pub.1046426641",
        "pub.1029133537",
        "pub.1095848734",
        "pub.1009551752",
        "pub.1091427714",
        "pub.1090579939",
        "pub.1061170381",
        "pub.1034209570",
        "pub.1061696734",
        "pub.1091589576",
        "pub.1030890551",
        "pub.1084908686",
        "pub.1037811822",
        "pub.1031059013",
        "pub.1095714739",
        "pub.1093838265",
        "pub.1023070025",
        "pub.1095641255",
        "pub.1084718850",
        "pub.1014968475",
        "pub.1091574901",
        "pub.1061696716",
        "pub.1027043520",
        "pub.1084918352",
        "pub.1006217895",
        "pub.1028121501",
        "pub.1013664571",
        "pub.1078913727",
        "pub.1009469917",
        "pub.1085742825",
        "pub.1084921376",
        "pub.1084228312",
        "pub.1018367015",
        "pub.1090662020",
        "pub.1095321586",
        "pub.1091930620",
        "pub.1061744373",
        "pub.1061696434",
        "pub.1009767488",
        "pub.1099192756",
        "pub.1086506677",
        "pub.1061696701",
        "pub.1100060688",
        "pub.1005938513",
        "pub.1034980694",
        "pub.1031091687",
        "pub.1061696607",
        "pub.1093656300",
        "pub.1017774818",
        "pub.1074217286",
        "pub.1004707137",
        "pub.1061696689",
        "pub.1002436929",
        "pub.1061696703"
      ],
      "concepts_scores": [
        {
          "concept": "medical image analysis",
          "relevance": 0.792
        },
        {
          "concept": "machine learning algorithms",
          "relevance": 0.772
        },
        {
          "concept": "learning algorithms",
          "relevance": 0.728
        },
        {
          "concept": "era of medical big data",
          "relevance": 0.721
        },
        {
          "concept": "application of medical image classification",
          "relevance": 0.721
        },
        {
          "concept": "success of machine learning algorithms",
          "relevance": 0.716
        },
        {
          "concept": "hand-crafting of features",
          "relevance": 0.714
        },
        {
          "concept": "medical image classification",
          "relevance": 0.692
        },
        {
          "concept": "image recognition tasks",
          "relevance": 0.691
        },
        {
          "concept": "convolutional neural network",
          "relevance": 0.684
        },
        {
          "concept": "deep learning applications",
          "relevance": 0.683
        },
        {
          "concept": "medical big data",
          "relevance": 0.679
        },
        {
          "concept": "image classification",
          "relevance": 0.635
        },
        {
          "concept": "hand-crafted",
          "relevance": 0.631
        },
        {
          "concept": "learning applications",
          "relevance": 0.624
        },
        {
          "concept": "neural network",
          "relevance": 0.624
        },
        {
          "concept": "machine learning",
          "relevance": 0.618
        },
        {
          "concept": "big data",
          "relevance": 0.617
        },
        {
          "concept": "recognition task",
          "relevance": 0.611
        },
        {
          "concept": "image analysis",
          "relevance": 0.587
        },
        {
          "concept": "research area",
          "relevance": 0.566
        },
        {
          "concept": "algorithm",
          "relevance": 0.548
        },
        {
          "concept": "hierarchical relationships",
          "relevance": 0.541
        },
        {
          "concept": "electronic medical records",
          "relevance": 0.529
        },
        {
          "concept": "machine",
          "relevance": 0.526
        },
        {
          "concept": "research obstacles",
          "relevance": 0.499
        },
        {
          "concept": "Deep",
          "relevance": 0.479
        },
        {
          "concept": "images",
          "relevance": 0.476
        },
        {
          "concept": "network",
          "relevance": 0.465
        },
        {
          "concept": "applications",
          "relevance": 0.452
        },
        {
          "concept": "task",
          "relevance": 0.451
        },
        {
          "concept": "classification",
          "relevance": 0.448
        },
        {
          "concept": "learning",
          "relevance": 0.444
        },
        {
          "concept": "obstacles",
          "relevance": 0.416
        },
        {
          "concept": "features",
          "relevance": 0.399
        },
        {
          "concept": "detection",
          "relevance": 0.399
        },
        {
          "concept": "segments",
          "relevance": 0.391
        },
        {
          "concept": "registration",
          "relevance": 0.39
        },
        {
          "concept": "research",
          "relevance": 0.389
        },
        {
          "concept": "increased use",
          "relevance": 0.382
        },
        {
          "concept": "data",
          "relevance": 0.381
        },
        {
          "concept": "clinical aspects",
          "relevance": 0.373
        },
        {
          "concept": "medical records",
          "relevance": 0.37
        },
        {
          "concept": "diagnostic imaging",
          "relevance": 0.368
        },
        {
          "concept": "localization",
          "relevance": 0.347
        },
        {
          "concept": "era",
          "relevance": 0.328
        },
        {
          "concept": "aspects",
          "relevance": 0.319
        },
        {
          "concept": "success",
          "relevance": 0.318
        },
        {
          "concept": "time",
          "relevance": 0.315
        },
        {
          "concept": "direction",
          "relevance": 0.308
        },
        {
          "concept": "analysis",
          "relevance": 0.302
        },
        {
          "concept": "field",
          "relevance": 0.298
        },
        {
          "concept": "records",
          "relevance": 0.291
        },
        {
          "concept": "medication",
          "relevance": 0.286
        },
        {
          "concept": "area",
          "relevance": 0.264
        },
        {
          "concept": "trends",
          "relevance": 0.259
        },
        {
          "concept": "use",
          "relevance": 0.258
        },
        {
          "concept": "review",
          "relevance": 0.253
        },
        {
          "concept": "years",
          "relevance": 0.248
        },
        {
          "concept": "relationship",
          "relevance": 0.226
        }
      ]
    },
    {
      "paperId": "pub.1093359587",
      "doi": "10.1109/cvpr.2016.90",
      "title": "Deep Residual Learning for Image Recognition",
      "year": 2016,
      "citationCount": 186455,
      "fieldCitationRatio": 36441.39,
      "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers-8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions11http://image-net.org/challenges/LSVRC/2015/ and http://mscoco.org/dataset/#detections-challenge2015., where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation. http://image-net.org/challenges/LSVRC/2015/ and http://mscoco.org/dataset/#detections-challenge2015.",
      "reference_ids": [
        "pub.1061744812",
        "pub.1008345178",
        "pub.1033229571",
        "pub.1037602011",
        "pub.1085642448",
        "pub.1061743975",
        "pub.1032233097",
        "pub.1093456265",
        "pub.1095559903",
        "pub.1014796149",
        "pub.1033986161",
        "pub.1061218416",
        "pub.1099341617",
        "pub.1098556598",
        "pub.1061745117",
        "pub.1061744117",
        "pub.1038140272",
        "pub.1098665985",
        "pub.1061156500",
        "pub.1045321436",
        "pub.1094727707",
        "pub.1030406568",
        "pub.1165598000",
        "pub.1095573598",
        "pub.1050111762",
        "pub.1093626237",
        "pub.1036869950",
        "pub.1094291017",
        "pub.1093828312"
      ],
      "concepts_scores": [
        {
          "concept": "residual nets",
          "relevance": 0.756
        },
        {
          "concept": "COCO object detection dataset",
          "relevance": 0.693
        },
        {
          "concept": "deep residual net",
          "relevance": 0.675
        },
        {
          "concept": "object detection datasets",
          "relevance": 0.673
        },
        {
          "concept": "residual learning framework",
          "relevance": 0.671
        },
        {
          "concept": "training of network",
          "relevance": 0.66
        },
        {
          "concept": "visual recognition tasks",
          "relevance": 0.659
        },
        {
          "concept": "learning residual functions",
          "relevance": 0.657
        },
        {
          "concept": "CIFAR-10",
          "relevance": 0.624
        },
        {
          "concept": "depth of representations",
          "relevance": 0.624
        },
        {
          "concept": "detection dataset",
          "relevance": 0.623
        },
        {
          "concept": "COCO detection",
          "relevance": 0.623
        },
        {
          "concept": "ImageNet dataset",
          "relevance": 0.622
        },
        {
          "concept": "deep representations",
          "relevance": 0.621
        },
        {
          "concept": "VGG-Net",
          "relevance": 0.619
        },
        {
          "concept": "classification task",
          "relevance": 0.619
        },
        {
          "concept": "residual network",
          "relevance": 0.614
        },
        {
          "concept": "learning framework",
          "relevance": 0.613
        },
        {
          "concept": "neural network",
          "relevance": 0.606
        },
        {
          "concept": "layer input",
          "relevance": 0.605
        },
        {
          "concept": "ImageNet",
          "relevance": 0.595
        },
        {
          "concept": "recognition task",
          "relevance": 0.593
        },
        {
          "concept": "ILSVRC",
          "relevance": 0.568
        },
        {
          "concept": "COCO",
          "relevance": 0.557
        },
        {
          "concept": "network",
          "relevance": 0.548
        },
        {
          "concept": "task",
          "relevance": 0.533
        },
        {
          "concept": "dataset",
          "relevance": 0.529
        },
        {
          "concept": "comprehensive empirical evidence",
          "relevance": 0.526
        },
        {
          "concept": "nets",
          "relevance": 0.506
        },
        {
          "concept": "representation",
          "relevance": 0.495
        },
        {
          "concept": "VGG",
          "relevance": 0.486
        },
        {
          "concept": "detection",
          "relevance": 0.448
        },
        {
          "concept": "classification",
          "relevance": 0.435
        },
        {
          "concept": "accuracy",
          "relevance": 0.418
        },
        {
          "concept": "input",
          "relevance": 0.408
        },
        {
          "concept": "framework",
          "relevance": 0.404
        },
        {
          "concept": "error",
          "relevance": 0.401
        },
        {
          "concept": "training",
          "relevance": 0.399
        },
        {
          "concept": "ensemble",
          "relevance": 0.392
        },
        {
          "concept": "segments",
          "relevance": 0.379
        },
        {
          "concept": "submission",
          "relevance": 0.378
        },
        {
          "concept": "residual function",
          "relevance": 0.365
        },
        {
          "concept": "function",
          "relevance": 0.339
        },
        {
          "concept": "layer",
          "relevance": 0.336
        },
        {
          "concept": "localization",
          "relevance": 0.336
        },
        {
          "concept": "complex",
          "relevance": 0.335
        },
        {
          "concept": "improvement",
          "relevance": 0.322
        },
        {
          "concept": "empirical evidence",
          "relevance": 0.321
        },
        {
          "concept": "depth",
          "relevance": 0.299
        },
        {
          "concept": "foundations",
          "relevance": 0.292
        },
        {
          "concept": "increasing depth",
          "relevance": 0.282
        },
        {
          "concept": "analysis",
          "relevance": 0.253
        },
        {
          "concept": "test",
          "relevance": 0.251
        },
        {
          "concept": "evidence",
          "relevance": 0.177
        }
      ]
    },
    {
      "paperId": "pub.1094291017",
      "doi": "10.1109/cvpr.2015.7298594",
      "title": "Going Deeper with Convolutions",
      "year": 2015,
      "citationCount": 41698,
      "fieldCitationRatio": 8196.56,
      "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the Im-ageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.",
      "reference_ids": [
        "pub.1061743347",
        "pub.1061179979",
        "pub.1062855239",
        "pub.1032233097",
        "pub.1094869203",
        "pub.1008345178",
        "pub.1025436137",
        "pub.1093519792",
        "pub.1095738839",
        "pub.1094727707",
        "pub.1062844374"
      ],
      "concepts_scores": [
        {
          "concept": "deep convolutional neural network architecture",
          "relevance": 0.646
        },
        {
          "concept": "convolutional neural network architecture",
          "relevance": 0.642
        },
        {
          "concept": "neural network architecture",
          "relevance": 0.625
        },
        {
          "concept": "context of classification",
          "relevance": 0.619
        },
        {
          "concept": "Recognition Challenge",
          "relevance": 0.582
        },
        {
          "concept": "deep networks",
          "relevance": 0.582
        },
        {
          "concept": "network architecture",
          "relevance": 0.576
        },
        {
          "concept": "computational resources",
          "relevance": 0.567
        },
        {
          "concept": "architectural decisions",
          "relevance": 0.564
        },
        {
          "concept": "Hebbian principle",
          "relevance": 0.551
        },
        {
          "concept": "multi-scale processes",
          "relevance": 0.519
        },
        {
          "concept": "network",
          "relevance": 0.514
        },
        {
          "concept": "architecture",
          "relevance": 0.492
        },
        {
          "concept": "classification",
          "relevance": 0.471
        },
        {
          "concept": "convolution",
          "relevance": 0.44
        },
        {
          "concept": "improve utilization",
          "relevance": 0.433
        },
        {
          "concept": "detection",
          "relevance": 0.42
        },
        {
          "concept": "quality",
          "relevance": 0.373
        },
        {
          "concept": "intuition",
          "relevance": 0.368
        },
        {
          "concept": "decision",
          "relevance": 0.362
        },
        {
          "concept": "resources",
          "relevance": 0.354
        },
        {
          "concept": "submission",
          "relevance": 0.354
        },
        {
          "concept": "design",
          "relevance": 0.331
        },
        {
          "concept": "challenges",
          "relevance": 0.323
        },
        {
          "concept": "context",
          "relevance": 0.311
        },
        {
          "concept": "utilization",
          "relevance": 0.31
        },
        {
          "concept": "principles",
          "relevance": 0.298
        },
        {
          "concept": "process",
          "relevance": 0.297
        },
        {
          "concept": "layer",
          "relevance": 0.259
        },
        {
          "concept": "inception",
          "relevance": 0.244
        },
        {
          "concept": "depth",
          "relevance": 0.23
        },
        {
          "concept": "width",
          "relevance": 0.199
        },
        {
          "concept": "constant",
          "relevance": 0.177
        }
      ]
    }
  ],
  "evolution_links": [
    {
      "source": "pub.1160759555",
      "target": "pub.1157585608",
      "source_title": "Large language models in medicine",
      "target_title": "Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum"
    },
    {
      "source": "pub.1157585608",
      "target": "pub.1062469256",
      "source_title": "Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum",
      "target_title": "The Parable of Google Flu: Traps in Big Data Analysis"
    },
    {
      "source": "pub.1062469256",
      "target": "pub.1023676943",
      "source_title": "The Parable of Google Flu: Traps in Big Data Analysis",
      "target_title": "CRITICAL QUESTIONS FOR BIG DATA"
    },
    {
      "source": "pub.1062469256",
      "target": "pub.1044456787",
      "source_title": "The Parable of Google Flu: Traps in Big Data Analysis",
      "target_title": "Evaluating Online Labor Markets for Experimental Research: Amazon.com's Mechanical Turk"
    },
    {
      "source": "pub.1157585608",
      "target": "pub.1160635088",
      "source_title": "Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum",
      "target_title": "Large language models encode clinical knowledge"
    },
    {
      "source": "pub.1160635088",
      "target": "pub.1151332162",
      "source_title": "Large language models encode clinical knowledge",
      "target_title": "BioGPT: generative pre-trained transformer for biomedical text generation and mining"
    },
    {
      "source": "pub.1160635088",
      "target": "pub.1152983179",
      "source_title": "Large language models encode clinical knowledge",
      "target_title": "PTR: Prompt Tuning with Rules for Text Classification"
    },
    {
      "source": "pub.1160759555",
      "target": "pub.1156602823",
      "source_title": "Large language models in medicine",
      "target_title": "Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine"
    },
    {
      "source": "pub.1156602823",
      "target": "pub.1155270525",
      "source_title": "Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine",
      "target_title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models"
    },
    {
      "source": "pub.1155270525",
      "target": "pub.1093497718",
      "source_title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models",
      "target_title": "Rethinking the Inception Architecture for Computer Vision"
    },
    {
      "source": "pub.1155270525",
      "target": "pub.1127685771",
      "source_title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models",
      "target_title": "A deep learning system for differential diagnosis of skin diseases"
    },
    {
      "source": "pub.1156602823",
      "target": "pub.1100133641",
      "source_title": "Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine",
      "target_title": "Deep Learning Applications in Medical Image Analysis"
    },
    {
      "source": "pub.1100133641",
      "target": "pub.1093359587",
      "source_title": "Deep Learning Applications in Medical Image Analysis",
      "target_title": "Deep Residual Learning for Image Recognition"
    },
    {
      "source": "pub.1100133641",
      "target": "pub.1094291017",
      "source_title": "Deep Learning Applications in Medical Image Analysis",
      "target_title": "Going Deeper with Convolutions"
    }
  ]
}