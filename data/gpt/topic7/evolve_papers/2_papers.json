{
  "papers": [
    {
      "paperId": "pub.1156949961",
      "doi": "10.1007/s11831-023-09899-9",
      "title": "On the Analyses of Medical Images Using Traditional Machine Learning Techniques and Convolutional Neural Networks",
      "year": 2023,
      "citationCount": 114,
      "fieldCitationRatio": NaN,
      "abstract": "Convolutional neural network (CNN) has shown dissuasive accomplishment on different areas especially Object Detection, Segmentation, Reconstruction (2D and 3D), Information Retrieval, Medical Image Registration, Multi-lingual translation, Local language Processing, Anomaly Detection on video and Speech Recognition. CNN is a special type of Neural Network, which has compelling and effective learning ability to learn features at several steps during augmentation of the data. Recently, different interesting and inspiring ideas of Deep Learning (DL) such as different activation functions, hyperparameter optimization, regularization, momentum and loss functions has improved the performance, operation and execution of CNN Different internal architecture innovation of CNN and different representational style of CNN has significantly improved the performance. This survey focuses on internal taxonomy of deep learning, different models of vonvolutional neural network, especially depth and width of models and in addition CNN components, applications and current challenges of deep learning.",
      "reference_ids": [
        "pub.1124405439",
        "pub.1145662339",
        "pub.1085304410",
        "pub.1144539534",
        "pub.1148542005",
        "pub.1013889575",
        "pub.1105796824",
        "pub.1083759736",
        "pub.1147508007",
        "pub.1106190327",
        "pub.1147151641",
        "pub.1090320046",
        "pub.1060722691",
        "pub.1150155554",
        "pub.1103109399",
        "pub.1150465165",
        "pub.1125073624",
        "pub.1107515978",
        "pub.1061696593",
        "pub.1124660964",
        "pub.1127573643",
        "pub.1146688645",
        "pub.1150129085",
        "pub.1146678151",
        "pub.1094291017",
        "pub.1149437679",
        "pub.1150554501",
        "pub.1116303763",
        "pub.1120714616",
        "pub.1141327124",
        "pub.1150455007",
        "pub.1148786697",
        "pub.1145697827",
        "pub.1148496992",
        "pub.1111753969",
        "pub.1017774818",
        "pub.1061229990",
        "pub.1117016225",
        "pub.1131162173",
        "pub.1150319597",
        "pub.1136471994",
        "pub.1126595878",
        "pub.1134295101",
        "pub.1149654704",
        "pub.1149193766",
        "pub.1032233097",
        "pub.1148947135",
        "pub.1127550672",
        "pub.1149159371",
        "pub.1099720434",
        "pub.1124302268",
        "pub.1105068107",
        "pub.1144742671",
        "pub.1149553642",
        "pub.1115023148",
        "pub.1149789244",
        "pub.1084921376",
        "pub.1149245170",
        "pub.1119945276",
        "pub.1084920702",
        "pub.1049944142",
        "pub.1121734292",
        "pub.1150587739",
        "pub.1047407288",
        "pub.1128227313",
        "pub.1095689476",
        "pub.1150190636",
        "pub.1147488864",
        "pub.1136229051",
        "pub.1091594880",
        "pub.1035981827",
        "pub.1134928685",
        "pub.1107486919",
        "pub.1121891470",
        "pub.1151381610",
        "pub.1149099739",
        "pub.1146552299",
        "pub.1149444249",
        "pub.1145148949",
        "pub.1044372848",
        "pub.1148265131",
        "pub.1095839391",
        "pub.1146863133",
        "pub.1149364865",
        "pub.1145833395",
        "pub.1150304431",
        "pub.1092926945",
        "pub.1094669438",
        "pub.1150429674",
        "pub.1120758013",
        "pub.1148113470",
        "pub.1061170457",
        "pub.1148775101",
        "pub.1124031325",
        "pub.1112851689",
        "pub.1147187390",
        "pub.1149273495",
        "pub.1144261621",
        "pub.1092665654",
        "pub.1148443194",
        "pub.1149487307",
        "pub.1122863171",
        "pub.1039662878",
        "pub.1140125274",
        "pub.1144545570",
        "pub.1149474692",
        "pub.1148955162",
        "pub.1146519833",
        "pub.1034884807",
        "pub.1113055877",
        "pub.1093339580",
        "pub.1084896161",
        "pub.1148040567",
        "pub.1060799329",
        "pub.1132270157",
        "pub.1147900043",
        "pub.1013664571",
        "pub.1149575870",
        "pub.1047572202",
        "pub.1009767488",
        "pub.1149412792",
        "pub.1010020120",
        "pub.1084228312",
        "pub.1146319893",
        "pub.1150549932",
        "pub.1091226316",
        "pub.1121477259",
        "pub.1150190360",
        "pub.1150300029",
        "pub.1134427256",
        "pub.1129785776",
        "pub.1149321493",
        "pub.1095301349",
        "pub.1131205747",
        "pub.1093921969",
        "pub.1090957760",
        "pub.1144402199",
        "pub.1096897141",
        "pub.1106026187",
        "pub.1132860572",
        "pub.1142136828",
        "pub.1144001639",
        "pub.1110483411",
        "pub.1095689025",
        "pub.1148724973",
        "pub.1150300437",
        "pub.1104889497",
        "pub.1133546374",
        "pub.1144693497",
        "pub.1099871933",
        "pub.1106361351",
        "pub.1125817026",
        "pub.1145098268",
        "pub.1145704608",
        "pub.1144540725",
        "pub.1143931885",
        "pub.1032545369",
        "pub.1007991390",
        "pub.1093497718",
        "pub.1143203722",
        "pub.1149826275",
        "pub.1151381232",
        "pub.1149197279",
        "pub.1150586663",
        "pub.1145605030",
        "pub.1140246728",
        "pub.1083547958",
        "pub.1130054100",
        "pub.1146622433",
        "pub.1148099551",
        "pub.1061696700",
        "pub.1017148227",
        "pub.1128708772",
        "pub.1134740689",
        "pub.1133610153",
        "pub.1144935864",
        "pub.1147208859",
        "pub.1029323761",
        "pub.1059415113",
        "pub.1149310111",
        "pub.1150221899",
        "pub.1150465167",
        "pub.1139450711",
        "pub.1127233537",
        "pub.1002971161",
        "pub.1079398950",
        "pub.1147005745",
        "pub.1095273555",
        "pub.1122993442",
        "pub.1145685504",
        "pub.1129912946",
        "pub.1146214930",
        "pub.1100060688",
        "pub.1150128749",
        "pub.1136605545",
        "pub.1028741304",
        "pub.1100060309",
        "pub.1091584850",
        "pub.1007681175",
        "pub.1143493364",
        "pub.1032947319",
        "pub.1143888232",
        "pub.1109780853",
        "pub.1037611228",
        "pub.1074217286",
        "pub.1125799248",
        "pub.1037643686",
        "pub.1023070025",
        "pub.1137892537",
        "pub.1144934002",
        "pub.1150981081",
        "pub.1150562404",
        "pub.1061218965",
        "pub.1135040940",
        "pub.1033178586",
        "pub.1101698055",
        "pub.1130682342",
        "pub.1146096404",
        "pub.1137293438",
        "pub.1148443195",
        "pub.1092184633",
        "pub.1150561933",
        "pub.1038241010",
        "pub.1095850372",
        "pub.1146329337",
        "pub.1150497553",
        "pub.1132357851",
        "pub.1110834605",
        "pub.1149595983",
        "pub.1093606237",
        "pub.1017157001",
        "pub.1072401142",
        "pub.1095837190",
        "pub.1151032806",
        "pub.1028121501",
        "pub.1084904832",
        "pub.1133998714",
        "pub.1128130850",
        "pub.1016849966",
        "pub.1149273494",
        "pub.1040981735",
        "pub.1044712559",
        "pub.1148692085",
        "pub.1150795185",
        "pub.1061524522",
        "pub.1148973326",
        "pub.1107863606",
        "pub.1148730746",
        "pub.1004707137",
        "pub.1093359587",
        "pub.1008016534",
        "pub.1127526321",
        "pub.1001383204",
        "pub.1034782135",
        "pub.1148972226",
        "pub.1020667374",
        "pub.1125165425",
        "pub.1008065360",
        "pub.1135825080",
        "pub.1146056932",
        "pub.1141491165",
        "pub.1150781775",
        "pub.1145018152",
        "pub.1107102652",
        "pub.1125055168",
        "pub.1148653413",
        "pub.1094184821",
        "pub.1146173806",
        "pub.1147979098",
        "pub.1000482947",
        "pub.1132453175",
        "pub.1095796303",
        "pub.1144406289",
        "pub.1130794671",
        "pub.1149142777",
        "pub.1047030096",
        "pub.1124213246",
        "pub.1117347988",
        "pub.1144600197",
        "pub.1127856839",
        "pub.1139282527",
        "pub.1017056153",
        "pub.1035284136",
        "pub.1087262358",
        "pub.1100836499",
        "pub.1144469647",
        "pub.1150402730",
        "pub.1103666754",
        "pub.1132888338",
        "pub.1147620436",
        "pub.1144911894",
        "pub.1148321566",
        "pub.1138176020",
        "pub.1147808818",
        "pub.1151000078",
        "pub.1143999882",
        "pub.1112970034",
        "pub.1010287313",
        "pub.1152826576",
        "pub.1146040406",
        "pub.1113264539",
        "pub.1095573598",
        "pub.1146301626",
        "pub.1144290611",
        "pub.1147832474",
        "pub.1147121099",
        "pub.1101884306",
        "pub.1085642448",
        "pub.1143629599",
        "pub.1147666095",
        "pub.1125957982",
        "pub.1150916703",
        "pub.1129600573",
        "pub.1003651104",
        "pub.1110923421",
        "pub.1147767975",
        "pub.1095811486",
        "pub.1128516840",
        "pub.1105029479",
        "pub.1130274783",
        "pub.1117136950",
        "pub.1086033983",
        "pub.1047442752",
        "pub.1127703360",
        "pub.1103932719",
        "pub.1124405276",
        "pub.1120305818",
        "pub.1140047363",
        "pub.1134979027",
        "pub.1061179979",
        "pub.1027130015",
        "pub.1145669782",
        "pub.1145800160",
        "pub.1150224415",
        "pub.1126845364",
        "pub.1061445785",
        "pub.1146017052",
        "pub.1134709739",
        "pub.1109977170",
        "pub.1147586140",
        "pub.1061696734",
        "pub.1141075792",
        "pub.1144813060",
        "pub.1090904008",
        "pub.1031287496",
        "pub.1146238751",
        "pub.1146162827",
        "pub.1150209163",
        "pub.1091822546",
        "pub.1117688881",
        "pub.1034610587",
        "pub.1024407424",
        "pub.1094013807",
        "pub.1132472148",
        "pub.1084896429",
        "pub.1125327706",
        "pub.1149182964",
        "pub.1149793073",
        "pub.1145227867",
        "pub.1147649356",
        "pub.1043194917",
        "pub.1145428405",
        "pub.1123669031",
        "pub.1017904023",
        "pub.1148374914",
        "pub.1150077185",
        "pub.1154597975",
        "pub.1150554183",
        "pub.1112944570",
        "pub.1107775000",
        "pub.1058083481",
        "pub.1148255668",
        "pub.1091930620",
        "pub.1148795773",
        "pub.1025201909",
        "pub.1144934027",
        "pub.1146775652",
        "pub.1149885125",
        "pub.1105148233",
        "pub.1122282542",
        "pub.1137535177",
        "pub.1148838230",
        "pub.1124212817",
        "pub.1053620624",
        "pub.1147404013",
        "pub.1140631574",
        "pub.1090858803",
        "pub.1143590904",
        "pub.1061172126",
        "pub.1112165416",
        "pub.1095843442",
        "pub.1132334559",
        "pub.1006399356",
        "pub.1047059751",
        "pub.1084904229",
        "pub.1147448383",
        "pub.1100060307",
        "pub.1061745216",
        "pub.1130635670",
        "pub.1149635347",
        "pub.1148072869",
        "pub.1014968475",
        "pub.1100766146"
      ],
      "concepts_scores": [
        {
          "concept": "convolutional neural network",
          "relevance": 0.862
        },
        {
          "concept": "deep learning",
          "relevance": 0.785
        },
        {
          "concept": "neural network",
          "relevance": 0.779
        },
        {
          "concept": "convolutional neural network components",
          "relevance": 0.714
        },
        {
          "concept": "traditional machine learning techniques",
          "relevance": 0.708
        },
        {
          "concept": "analysis of medical images",
          "relevance": 0.693
        },
        {
          "concept": "medical image registration",
          "relevance": 0.679
        },
        {
          "concept": "multi-lingual translations",
          "relevance": 0.679
        },
        {
          "concept": "machine learning techniques",
          "relevance": 0.672
        },
        {
          "concept": "effective learning ability",
          "relevance": 0.663
        },
        {
          "concept": "information retrieval",
          "relevance": 0.645
        },
        {
          "concept": "object detection",
          "relevance": 0.644
        },
        {
          "concept": "anomaly detection",
          "relevance": 0.644
        },
        {
          "concept": "speech recognition",
          "relevance": 0.634
        },
        {
          "concept": "hyperparameter optimization",
          "relevance": 0.634
        },
        {
          "concept": "learning techniques",
          "relevance": 0.627
        },
        {
          "concept": "activation function",
          "relevance": 0.627
        },
        {
          "concept": "language processing",
          "relevance": 0.626
        },
        {
          "concept": "loss function",
          "relevance": 0.624
        },
        {
          "concept": "medical images",
          "relevance": 0.621
        },
        {
          "concept": "image registration",
          "relevance": 0.585
        },
        {
          "concept": "network",
          "relevance": 0.58
        },
        {
          "concept": "learning ability",
          "relevance": 0.567
        },
        {
          "concept": "learning",
          "relevance": 0.545
        },
        {
          "concept": "architectural innovation",
          "relevance": 0.544
        },
        {
          "concept": "representation styles",
          "relevance": 0.501
        },
        {
          "concept": "hyperparameters",
          "relevance": 0.495
        },
        {
          "concept": "Neural",
          "relevance": 0.489
        },
        {
          "concept": "convolution",
          "relevance": 0.488
        },
        {
          "concept": "performance",
          "relevance": 0.484
        },
        {
          "concept": "Deep",
          "relevance": 0.483
        },
        {
          "concept": "video",
          "relevance": 0.481
        },
        {
          "concept": "retrieval",
          "relevance": 0.467
        },
        {
          "concept": "execution",
          "relevance": 0.467
        },
        {
          "concept": "detection",
          "relevance": 0.465
        },
        {
          "concept": "recognition",
          "relevance": 0.437
        },
        {
          "concept": "optimization",
          "relevance": 0.432
        },
        {
          "concept": "regularization",
          "relevance": 0.426
        },
        {
          "concept": "information",
          "relevance": 0.42
        },
        {
          "concept": "speech",
          "relevance": 0.416
        },
        {
          "concept": "images",
          "relevance": 0.414
        },
        {
          "concept": "taxonomy",
          "relevance": 0.407
        },
        {
          "concept": "features",
          "relevance": 0.402
        },
        {
          "concept": "model",
          "relevance": 0.402
        },
        {
          "concept": "segments",
          "relevance": 0.394
        },
        {
          "concept": "applications",
          "relevance": 0.394
        },
        {
          "concept": "registration",
          "relevance": 0.393
        },
        {
          "concept": "operation",
          "relevance": 0.382
        },
        {
          "concept": "augmentation",
          "relevance": 0.376
        },
        {
          "concept": "reconstruction",
          "relevance": 0.374
        },
        {
          "concept": "technique",
          "relevance": 0.373
        },
        {
          "concept": "function",
          "relevance": 0.353
        },
        {
          "concept": "innovation",
          "relevance": 0.353
        },
        {
          "concept": "translation",
          "relevance": 0.343
        },
        {
          "concept": "data",
          "relevance": 0.332
        },
        {
          "concept": "process",
          "relevance": 0.329
        },
        {
          "concept": "ability",
          "relevance": 0.303
        },
        {
          "concept": "anomalies",
          "relevance": 0.3
        },
        {
          "concept": "components",
          "relevance": 0.294
        },
        {
          "concept": "accomplishments",
          "relevance": 0.273
        },
        {
          "concept": "area",
          "relevance": 0.266
        },
        {
          "concept": "analysis",
          "relevance": 0.263
        },
        {
          "concept": "momentum",
          "relevance": 0.257
        },
        {
          "concept": "depth",
          "relevance": 0.255
        },
        {
          "concept": "survey",
          "relevance": 0.25
        },
        {
          "concept": "loss",
          "relevance": 0.24
        },
        {
          "concept": "width",
          "relevance": 0.236
        },
        {
          "concept": "medication",
          "relevance": 0.175
        },
        {
          "concept": "activity",
          "relevance": 0.171
        }
      ]
    },
    {
      "paperId": "pub.1154597975",
      "doi": "10.1002/widm.1484",
      "title": "Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges",
      "year": 2023,
      "citationCount": 505,
      "fieldCitationRatio": 319.58,
      "abstract": "Abstract Most machine learning algorithms are configured by a set of hyperparameters whose values must be carefully chosen and which often considerably impact performance. To avoid a time‐consuming and irreproducible manual process of trial‐and‐error to find well‐performing hyperparameter configurations, various automatic hyperparameter optimization (HPO) methods—for example, based on resampling error estimation for supervised machine learning—can be employed. After introducing HPO from a general perspective, this paper reviews important HPO methods, from simple techniques such as grid or random search to more advanced methods like evolution strategies, Bayesian optimization, Hyperband, and racing. This work gives practical recommendations regarding important choices to be made when conducting HPO, including the HPO algorithms themselves, performance evaluation, how to combine HPO with machine learning pipelines, runtime improvements, and parallelization.  This article is categorized under:   Algorithmic Development > Statistics   Technologies > Machine Learning   Technologies > Prediction   ",
      "reference_ids": [
        "pub.1062859099",
        "pub.1098728832",
        "pub.1105723708",
        "pub.1069420824",
        "pub.1000587720",
        "pub.1068672633",
        "pub.1140364118",
        "pub.1014963376",
        "pub.1052722418",
        "pub.1137507214",
        "pub.1139594192",
        "pub.1032573094",
        "pub.1129629919",
        "pub.1049502513",
        "pub.1013060970",
        "pub.1105690023",
        "pub.1151637203",
        "pub.1126590298",
        "pub.1129599631",
        "pub.1121857292",
        "pub.1105591850",
        "pub.1043152849",
        "pub.1033487243",
        "pub.1119923293",
        "pub.1094845958",
        "pub.1121268381",
        "pub.1020902633",
        "pub.1014107644",
        "pub.1050578268",
        "pub.1051445048",
        "pub.1028718727",
        "pub.1006432560",
        "pub.1139594186",
        "pub.1049093966",
        "pub.1042218394",
        "pub.1046778023",
        "pub.1029460773",
        "pub.1114522680",
        "pub.1125956665",
        "pub.1105674394",
        "pub.1132889696",
        "pub.1094362510",
        "pub.1005659556",
        "pub.1004779713",
        "pub.1140412578",
        "pub.1119913561",
        "pub.1108066659",
        "pub.1068672759",
        "pub.1096107362",
        "pub.1005297347",
        "pub.1113544633",
        "pub.1128852974",
        "pub.1009975913",
        "pub.1105296443",
        "pub.1046796099",
        "pub.1148916905",
        "pub.1074226330",
        "pub.1128226882",
        "pub.1148956150",
        "pub.1092957245",
        "pub.1150865628",
        "pub.1151387316",
        "pub.1123295816",
        "pub.1128853018",
        "pub.1023112939",
        "pub.1044602777",
        "pub.1036497930",
        "pub.1136592329",
        "pub.1046266444",
        "pub.1001144859",
        "pub.1114720164",
        "pub.1051911019",
        "pub.1107966222",
        "pub.1015012143",
        "pub.1014075849",
        "pub.1122414355",
        "pub.1031133866",
        "pub.1003193818",
        "pub.1125414339",
        "pub.1058285186",
        "pub.1119923257",
        "pub.1129913733",
        "pub.1026092553",
        "pub.1140363739",
        "pub.1059968890",
        "pub.1037495722",
        "pub.1124688016",
        "pub.1046124636",
        "pub.1009040383",
        "pub.1012424050",
        "pub.1031240616",
        "pub.1110618927",
        "pub.1068672600",
        "pub.1093183918",
        "pub.1005665561",
        "pub.1130333118",
        "pub.1148954953",
        "pub.1035515706",
        "pub.1068672403",
        "pub.1077858166",
        "pub.1120757994",
        "pub.1013038565",
        "pub.1040108561"
      ],
      "concepts_scores": [
        {
          "concept": "hyperparameter optimization",
          "relevance": 0.73
        },
        {
          "concept": "automatic hyperparameter optimization",
          "relevance": 0.64
        },
        {
          "concept": "machine learning technology",
          "relevance": 0.623
        },
        {
          "concept": "machine learning algorithms",
          "relevance": 0.622
        },
        {
          "concept": "machine learning pipeline",
          "relevance": 0.619
        },
        {
          "concept": "hyperparameter configurations",
          "relevance": 0.596
        },
        {
          "concept": "learning algorithms",
          "relevance": 0.586
        },
        {
          "concept": "learning pipeline",
          "relevance": 0.58
        },
        {
          "concept": "evolution strategy",
          "relevance": 0.574
        },
        {
          "concept": "runtime improvement",
          "relevance": 0.574
        },
        {
          "concept": "Bayesian optimization",
          "relevance": 0.57
        },
        {
          "concept": "random search",
          "relevance": 0.567
        },
        {
          "concept": "learning technology",
          "relevance": 0.564
        },
        {
          "concept": "performance evaluation",
          "relevance": 0.56
        },
        {
          "concept": "manual process",
          "relevance": 0.556
        },
        {
          "concept": "hyperparameters",
          "relevance": 0.531
        },
        {
          "concept": "learning—can",
          "relevance": 0.512
        },
        {
          "concept": "time-consuming",
          "relevance": 0.505
        },
        {
          "concept": "advanced methods",
          "relevance": 0.482
        },
        {
          "concept": "technology",
          "relevance": 0.467
        },
        {
          "concept": "optimization",
          "relevance": 0.463
        },
        {
          "concept": "runtime",
          "relevance": 0.459
        },
        {
          "concept": "error estimates",
          "relevance": 0.456
        },
        {
          "concept": "Hyperband",
          "relevance": 0.453
        },
        {
          "concept": "performance",
          "relevance": 0.448
        },
        {
          "concept": "algorithm",
          "relevance": 0.441
        },
        {
          "concept": "machine",
          "relevance": 0.423
        },
        {
          "concept": "impact performance",
          "relevance": 0.41
        },
        {
          "concept": "method",
          "relevance": 0.394
        },
        {
          "concept": "parallel",
          "relevance": 0.393
        },
        {
          "concept": "pipeline",
          "relevance": 0.39
        },
        {
          "concept": "grid",
          "relevance": 0.384
        },
        {
          "concept": "search",
          "relevance": 0.379
        },
        {
          "concept": "technique",
          "relevance": 0.345
        },
        {
          "concept": "evaluation",
          "relevance": 0.34
        },
        {
          "concept": "prediction",
          "relevance": 0.331
        },
        {
          "concept": "estimation",
          "relevance": 0.33
        },
        {
          "concept": "configuration",
          "relevance": 0.309
        },
        {
          "concept": "improvement",
          "relevance": 0.309
        },
        {
          "concept": "process",
          "relevance": 0.305
        },
        {
          "concept": "recommendations",
          "relevance": 0.299
        },
        {
          "concept": "strategies",
          "relevance": 0.295
        },
        {
          "concept": "Abstract",
          "relevance": 0.279
        },
        {
          "concept": "article",
          "relevance": 0.263
        },
        {
          "concept": "evolution",
          "relevance": 0.251
        },
        {
          "concept": "statistically",
          "relevance": 0.241
        },
        {
          "concept": "race",
          "relevance": 0.235
        },
        {
          "concept": "values",
          "relevance": 0.223
        }
      ]
    },
    {
      "paperId": "pub.1129629919",
      "doi": "10.1016/j.neucom.2020.07.061",
      "title": "On hyperparameter optimization of machine learning algorithms: Theory and practice",
      "year": 2020,
      "citationCount": 2326,
      "fieldCitationRatio": 651.4,
      "abstract": "Machine learning algorithms have been used widely in various applications and areas. To fit a machine learning model into different problems, its hyper-parameters must be tuned. Selecting the best hyper-parameter configuration for machine learning models has a direct impact on the model’s performance. It often requires deep knowledge of machine learning algorithms and appropriate hyper-parameter optimization techniques. Although several automatic optimization techniques exist, they have different strengths and drawbacks when applied to different types of problems. In this paper, optimizing the hyper-parameters of common machine learning models is studied. We introduce several state-of-the-art optimization techniques and discuss how to apply them to machine learning algorithms. Many available libraries and frameworks developed for hyper-parameter optimization problems are provided, and some open challenges of hyper-parameter optimization research are also discussed in this paper. Moreover, experiments are conducted on benchmark datasets to compare the performance of different optimization methods and provide practical examples of hyper-parameter optimization. This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively.",
      "reference_ids": [
        "pub.1091974293",
        "pub.1052722418",
        "pub.1093928339",
        "pub.1004736268",
        "pub.1092614055",
        "pub.1045983517",
        "pub.1026969566",
        "pub.1024645111",
        "pub.1125163245",
        "pub.1129567086",
        "pub.1014048710",
        "pub.1110458978",
        "pub.1148955299",
        "pub.1047764219",
        "pub.1093429641",
        "pub.1112289796",
        "pub.1068001420",
        "pub.1058284124",
        "pub.1099746543",
        "pub.1112289828",
        "pub.1061793765",
        "pub.1130417470",
        "pub.1093999634",
        "pub.1040107931",
        "pub.1073324283",
        "pub.1090598380",
        "pub.1111020765",
        "pub.1111911923",
        "pub.1127418862",
        "pub.1017161803",
        "pub.1113409239",
        "pub.1036186540",
        "pub.1093202857",
        "pub.1125158645",
        "pub.1061122456",
        "pub.1027647445",
        "pub.1026366252",
        "pub.1067368962",
        "pub.1105501397",
        "pub.1017229575",
        "pub.1034654478",
        "pub.1083761087",
        "pub.1132814443",
        "pub.1068918732",
        "pub.1094583285",
        "pub.1100736048",
        "pub.1125687533",
        "pub.1010224512",
        "pub.1092667573",
        "pub.1005898790",
        "pub.1028714677",
        "pub.1148916926",
        "pub.1041426697",
        "pub.1084031378",
        "pub.1110323748",
        "pub.1061231968",
        "pub.1095403774",
        "pub.1090281911",
        "pub.1062856710",
        "pub.1027036883",
        "pub.1039153602",
        "pub.1062898966",
        "pub.1022438744",
        "pub.1091667766",
        "pub.1094846187",
        "pub.1107706546",
        "pub.1061320038",
        "pub.1105391257",
        "pub.1106875674",
        "pub.1001327449",
        "pub.1114803069",
        "pub.1040437725"
      ],
      "concepts_scores": [
        {
          "concept": "machine learning algorithms",
          "relevance": 0.821
        },
        {
          "concept": "machine learning models",
          "relevance": 0.803
        },
        {
          "concept": "hyper-parameter configurations",
          "relevance": 0.793
        },
        {
          "concept": "learning algorithms",
          "relevance": 0.774
        },
        {
          "concept": "learning models",
          "relevance": 0.748
        },
        {
          "concept": "hyper-parameters",
          "relevance": 0.724
        },
        {
          "concept": "hyper-parameter optimization problem",
          "relevance": 0.71
        },
        {
          "concept": "optimization techniques",
          "relevance": 0.698
        },
        {
          "concept": "hyper-parameter optimization techniques",
          "relevance": 0.695
        },
        {
          "concept": "hyper-parameter optimization",
          "relevance": 0.681
        },
        {
          "concept": "automatic optimization techniques",
          "relevance": 0.645
        },
        {
          "concept": "hyperparameter optimization",
          "relevance": 0.625
        },
        {
          "concept": "survey paper",
          "relevance": 0.611
        },
        {
          "concept": "data analysts",
          "relevance": 0.592
        },
        {
          "concept": "optimization problem",
          "relevance": 0.591
        },
        {
          "concept": "algorithm",
          "relevance": 0.583
        },
        {
          "concept": "machine",
          "relevance": 0.564
        },
        {
          "concept": "optimization method",
          "relevance": 0.539
        },
        {
          "concept": "optimization research",
          "relevance": 0.531
        },
        {
          "concept": "model performance",
          "relevance": 0.519
        },
        {
          "concept": "optimization",
          "relevance": 0.519
        },
        {
          "concept": "industrial users",
          "relevance": 0.514
        },
        {
          "concept": "deep knowledge",
          "relevance": 0.506
        },
        {
          "concept": "hyperparameters",
          "relevance": 0.489
        },
        {
          "concept": "users",
          "relevance": 0.482
        },
        {
          "concept": "performance",
          "relevance": 0.477
        },
        {
          "concept": "dataset",
          "relevance": 0.469
        },
        {
          "concept": "technique",
          "relevance": 0.448
        },
        {
          "concept": "data",
          "relevance": 0.448
        },
        {
          "concept": "library",
          "relevance": 0.44
        },
        {
          "concept": "model",
          "relevance": 0.427
        },
        {
          "concept": "drawbacks",
          "relevance": 0.415
        },
        {
          "concept": "framework",
          "relevance": 0.414
        },
        {
          "concept": "analysts",
          "relevance": 0.394
        },
        {
          "concept": "applications",
          "relevance": 0.389
        },
        {
          "concept": "research",
          "relevance": 0.387
        },
        {
          "concept": "configuration",
          "relevance": 0.382
        },
        {
          "concept": "method",
          "relevance": 0.363
        },
        {
          "concept": "experiments",
          "relevance": 0.344
        },
        {
          "concept": "theory",
          "relevance": 0.275
        },
        {
          "concept": "practice",
          "relevance": 0.265
        },
        {
          "concept": "area",
          "relevance": 0.262
        },
        {
          "concept": "strength",
          "relevance": 0.26
        },
        {
          "concept": "impact",
          "relevance": 0.251
        },
        {
          "concept": "survey",
          "relevance": 0.247
        },
        {
          "concept": "problem",
          "relevance": 0.24
        },
        {
          "concept": "paper",
          "relevance": 0.23
        }
      ]
    },
    {
      "paperId": "pub.1110458978",
      "doi": "10.1111/j.2517-6161.1996.tb02080.x",
      "title": "Regression Shrinkage and Selection Via the Lasso",
      "year": 1996,
      "citationCount": 40160,
      "fieldCitationRatio": NaN,
      "abstract": "SUMMARY We propose a new method for estimation in linear models. The ‘lasso’ minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.",
      "reference_ids": [
        "pub.1064408764",
        "pub.1069473952",
        "pub.1064407855",
        "pub.1078888895",
        "pub.1109705929",
        "pub.1058286776",
        "pub.1095821131",
        "pub.1016957463",
        "pub.1058304383",
        "pub.1058304437",
        "pub.1110458930",
        "pub.1110458741",
        "pub.1045549108"
      ],
      "concepts_scores": [
        {
          "concept": "general regression model",
          "relevance": 0.65
        },
        {
          "concept": "ridge regression",
          "relevance": 0.648
        },
        {
          "concept": "function estimation",
          "relevance": 0.625
        },
        {
          "concept": "simulation study",
          "relevance": 0.608
        },
        {
          "concept": "regression shrinkage",
          "relevance": 0.607
        },
        {
          "concept": "residual sum",
          "relevance": 0.59
        },
        {
          "concept": "interpretable models",
          "relevance": 0.576
        },
        {
          "concept": "tree-based models",
          "relevance": 0.572
        },
        {
          "concept": "linear model",
          "relevance": 0.529
        },
        {
          "concept": "LASSO",
          "relevance": 0.51
        },
        {
          "concept": "absolute value",
          "relevance": 0.502
        },
        {
          "concept": "estimation",
          "relevance": 0.487
        },
        {
          "concept": "Donoho",
          "relevance": 0.479
        },
        {
          "concept": "sum",
          "relevance": 0.476
        },
        {
          "concept": "statistical model",
          "relevance": 0.462
        },
        {
          "concept": "extension",
          "relevance": 0.424
        },
        {
          "concept": "regression models",
          "relevance": 0.417
        },
        {
          "concept": "coefficient",
          "relevance": 0.414
        },
        {
          "concept": "square",
          "relevance": 0.407
        },
        {
          "concept": "model",
          "relevance": 0.392
        },
        {
          "concept": "selection",
          "relevance": 0.383
        },
        {
          "concept": "constant",
          "relevance": 0.37
        },
        {
          "concept": "simulation",
          "relevance": 0.368
        },
        {
          "concept": "stability",
          "relevance": 0.355
        },
        {
          "concept": "properties",
          "relevance": 0.345
        },
        {
          "concept": "regression",
          "relevance": 0.336
        },
        {
          "concept": "method",
          "relevance": 0.333
        },
        {
          "concept": "Johnston",
          "relevance": 0.312
        },
        {
          "concept": "ideas",
          "relevance": 0.301
        },
        {
          "concept": "shrinkage",
          "relevance": 0.291
        },
        {
          "concept": "values",
          "relevance": 0.259
        },
        {
          "concept": "nature",
          "relevance": 0.245
        },
        {
          "concept": "ridge",
          "relevance": 0.219
        },
        {
          "concept": "relationship",
          "relevance": 0.206
        },
        {
          "concept": "study",
          "relevance": 0.172
        }
      ]
    },
    {
      "paperId": "pub.1114803069",
      "doi": "10.1007/978-3-030-05318-5_8",
      "title": "TPOT: A Tree-Based Pipeline Optimization Tool for Automating Machine Learning",
      "year": 2019,
      "citationCount": 283,
      "fieldCitationRatio": 71.03,
      "abstract": "As data science becomes increasingly mainstream, there will be an ever-growing demand for data science tools that are more accessible, flexible, and scalable. In response to this demand, automated machine learning (AutoML) researchers have begun building systems that automate the process of designing and optimizing machine learning pipelines. In this chapter we present TPOT v0.3, an open source genetic programming-based AutoML system that optimizes a series of feature preprocessors and machine learning models with the goal of maximizing classification accuracy on a supervised classification task. We benchmark TPOT on a series of 150 supervised classification tasks and find that it significantly outperforms a basic machine learning analysis in 21 of them, while experiencing minimal degradation in accuracy on 4 of the benchmarks—all without any domain knowledge nor human input. As such, genetic programming-based AutoML systems show considerable promise in the AutoML domain.",
      "reference_ids": [
        "pub.1003637697",
        "pub.1046508379",
        "pub.1012458241",
        "pub.1061172126",
        "pub.1061605101",
        "pub.1020126070",
        "pub.1019065813",
        "pub.1108496411",
        "pub.1021899069",
        "pub.1004395558",
        "pub.1099539218",
        "pub.1107038474",
        "pub.1032573094",
        "pub.1046796099",
        "pub.1050551621",
        "pub.1099597262"
      ],
      "concepts_scores": [
        {
          "concept": "supervised classification task",
          "relevance": 0.752
        },
        {
          "concept": "AutoML systems",
          "relevance": 0.7
        },
        {
          "concept": "classification task",
          "relevance": 0.696
        },
        {
          "concept": "optimal machine learning pipeline",
          "relevance": 0.647
        },
        {
          "concept": "automated machine learning",
          "relevance": 0.635
        },
        {
          "concept": "Tree-based Pipeline Optimization Tool",
          "relevance": 0.634
        },
        {
          "concept": "machine learning pipeline",
          "relevance": 0.626
        },
        {
          "concept": "machine learning models",
          "relevance": 0.615
        },
        {
          "concept": "domain knowledge",
          "relevance": 0.598
        },
        {
          "concept": "classification accuracy",
          "relevance": 0.588
        },
        {
          "concept": "learning pipeline",
          "relevance": 0.587
        },
        {
          "concept": "machine learning",
          "relevance": 0.582
        },
        {
          "concept": "human input",
          "relevance": 0.575
        },
        {
          "concept": "learning models",
          "relevance": 0.573
        },
        {
          "concept": "data science tools",
          "relevance": 0.569
        },
        {
          "concept": "data science",
          "relevance": 0.567
        },
        {
          "concept": "machine",
          "relevance": 0.495
        },
        {
          "concept": "task",
          "relevance": 0.493
        },
        {
          "concept": "machine learning analysis",
          "relevance": 0.493
        },
        {
          "concept": "optimization tool",
          "relevance": 0.49
        },
        {
          "concept": "learning analysis",
          "relevance": 0.487
        },
        {
          "concept": "science tools",
          "relevance": 0.486
        },
        {
          "concept": "building systems",
          "relevance": 0.474
        },
        {
          "concept": "accuracy",
          "relevance": 0.47
        },
        {
          "concept": "AutoML",
          "relevance": 0.467
        },
        {
          "concept": "preprocessor",
          "relevance": 0.458
        },
        {
          "concept": "system",
          "relevance": 0.432
        },
        {
          "concept": "domain",
          "relevance": 0.428
        },
        {
          "concept": "data",
          "relevance": 0.425
        },
        {
          "concept": "classification",
          "relevance": 0.422
        },
        {
          "concept": "learning",
          "relevance": 0.419
        },
        {
          "concept": "tools",
          "relevance": 0.412
        },
        {
          "concept": "minimal degradation",
          "relevance": 0.41
        },
        {
          "concept": "Tpot",
          "relevance": 0.397
        },
        {
          "concept": "input",
          "relevance": 0.396
        },
        {
          "concept": "pipeline",
          "relevance": 0.394
        },
        {
          "concept": "features",
          "relevance": 0.376
        },
        {
          "concept": "goal",
          "relevance": 0.348
        },
        {
          "concept": "knowledge",
          "relevance": 0.341
        },
        {
          "concept": "model",
          "relevance": 0.325
        },
        {
          "concept": "research",
          "relevance": 0.317
        },
        {
          "concept": "data",
          "relevance": 0.31
        },
        {
          "concept": "science",
          "relevance": 0.308
        },
        {
          "concept": "process",
          "relevance": 0.308
        },
        {
          "concept": "building",
          "relevance": 0.294
        },
        {
          "concept": "analysis",
          "relevance": 0.246
        },
        {
          "concept": "degradation",
          "relevance": 0.214
        },
        {
          "concept": "response",
          "relevance": 0.189
        }
      ]
    },
    {
      "paperId": "pub.1130333118",
      "doi": "10.1080/10556788.2020.1808977",
      "title": "COCO: a platform for comparing continuous optimizers in a black-box setting",
      "year": 2020,
      "citationCount": 333,
      "fieldCitationRatio": 92.67,
      "abstract": "We introduce COCO, an open-source platform for Comparing Continuous Optimizers in a black-box setting. COCO aims at automatizing the tedious and repetitive task of benchmarking numerical optimization algorithms to the greatest possible extent. The platform and the underlying methodology allow to benchmark in the same framework deterministic and stochastic solvers for both single and multiobjective optimization. We present the rationals behind the (decade-long) development of the platform as a general proposition for guidelines towards better benchmarking. We detail underlying fundamental concepts of COCO such as the definition of a problem as a function instance, the underlying idea of instances, the use of target values, and runtime defined by the number of function calls as the central performance measure. Finally, we give a quick overview of the basic code structure and the currently available test suites.",
      "reference_ids": [
        "pub.1012855244",
        "pub.1015042367",
        "pub.1059685636",
        "pub.1025049790",
        "pub.1044226636",
        "pub.1093288427",
        "pub.1043056536",
        "pub.1127185937",
        "pub.1022038375",
        "pub.1117747766",
        "pub.1042357322",
        "pub.1033788404",
        "pub.1051773708",
        "pub.1020275728",
        "pub.1106294815",
        "pub.1000203916",
        "pub.1048733464",
        "pub.1097022579",
        "pub.1125279271",
        "pub.1050716670",
        "pub.1049019576",
        "pub.1010909792",
        "pub.1040788378",
        "pub.1007597686",
        "pub.1004777117",
        "pub.1045061286",
        "pub.1000260595",
        "pub.1061172126",
        "pub.1061398159",
        "pub.1062443404",
        "pub.1052654109",
        "pub.1043067538",
        "pub.1091834728",
        "pub.1000595399",
        "pub.1025382520",
        "pub.1093138115",
        "pub.1092172459",
        "pub.1095092719",
        "pub.1024238828",
        "pub.1022185599",
        "pub.1043473749",
        "pub.1105400893",
        "pub.1011728458",
        "pub.1031419449",
        "pub.1062837548",
        "pub.1117747703",
        "pub.1015376096",
        "pub.1062854757",
        "pub.1105400884",
        "pub.1035449866",
        "pub.1014117674",
        "pub.1010260443",
        "pub.1029457454",
        "pub.1061604798",
        "pub.1110040882",
        "pub.1008568979",
        "pub.1021131854"
      ],
      "concepts_scores": [
        {
          "concept": "black-box setting",
          "relevance": 0.737
        },
        {
          "concept": "Comparing Continuous Optimizers",
          "relevance": 0.716
        },
        {
          "concept": "continuous optimization",
          "relevance": 0.645
        },
        {
          "concept": "black-box",
          "relevance": 0.642
        },
        {
          "concept": "open-source platform",
          "relevance": 0.613
        },
        {
          "concept": "central performance measure",
          "relevance": 0.592
        },
        {
          "concept": "test suite",
          "relevance": 0.588
        },
        {
          "concept": "code structure",
          "relevance": 0.58
        },
        {
          "concept": "function instances",
          "relevance": 0.576
        },
        {
          "concept": "optimization algorithm",
          "relevance": 0.555
        },
        {
          "concept": "numerical optimization algorithm",
          "relevance": 0.542
        },
        {
          "concept": "stochastic solver",
          "relevance": 0.536
        },
        {
          "concept": "COCO",
          "relevance": 0.519
        },
        {
          "concept": "multiobjective optimization",
          "relevance": 0.518
        },
        {
          "concept": "repetitive tasks",
          "relevance": 0.506
        },
        {
          "concept": "performance measures",
          "relevance": 0.499
        },
        {
          "concept": "platform",
          "relevance": 0.496
        },
        {
          "concept": "optimization",
          "relevance": 0.48
        },
        {
          "concept": "runtime",
          "relevance": 0.453
        },
        {
          "concept": "instances",
          "relevance": 0.436
        },
        {
          "concept": "algorithm",
          "relevance": 0.435
        },
        {
          "concept": "benchmarks",
          "relevance": 0.423
        },
        {
          "concept": "code",
          "relevance": 0.422
        },
        {
          "concept": "task",
          "relevance": 0.415
        },
        {
          "concept": "target values",
          "relevance": 0.408
        },
        {
          "concept": "solver",
          "relevance": 0.407
        },
        {
          "concept": "sets",
          "relevance": 0.4
        },
        {
          "concept": "framework",
          "relevance": 0.383
        },
        {
          "concept": "suite",
          "relevance": 0.366
        },
        {
          "concept": "concept",
          "relevance": 0.333
        },
        {
          "concept": "methodology",
          "relevance": 0.331
        },
        {
          "concept": "definition",
          "relevance": 0.325
        },
        {
          "concept": "function",
          "relevance": 0.322
        },
        {
          "concept": "proposition",
          "relevance": 0.311
        },
        {
          "concept": "target",
          "relevance": 0.278
        },
        {
          "concept": "development",
          "relevance": 0.261
        },
        {
          "concept": "structure",
          "relevance": 0.243
        },
        {
          "concept": "problem",
          "relevance": 0.242
        },
        {
          "concept": "rationality",
          "relevance": 0.238
        },
        {
          "concept": "test",
          "relevance": 0.238
        },
        {
          "concept": "measurements",
          "relevance": 0.233
        },
        {
          "concept": "guidelines",
          "relevance": 0.231
        },
        {
          "concept": "values",
          "relevance": 0.22
        }
      ]
    },
    {
      "paperId": "pub.1061172126",
      "doi": "10.1109/4235.996017",
      "title": "A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II",
      "year": 2002,
      "citationCount": 38356,
      "fieldCitationRatio": 7203.15,
      "abstract": "Multiobjective evolutionary algorithms (EAs) that use nondominated sorting and sharing have been criticized mainly for their: 1) $O(MN^{3})$ computational complexity (where $M$ is the number of objectives and $N$ is the population size); 2) nonelitism approach; and 3) the need for specifying a sharing parameter. In this paper, we suggest a nondominated sorting-based multiobjective EA (MOEA), called nondominated sorting genetic algorithm II (NSGA-II), which alleviates all the above three difficulties. Specifically, a fast nondominated sorting approach with $O(MN^{2})$ computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best (with respect to fitness and spread) $N$ solutions. Simulation results on difficult test problems show that the proposed NSGA-II, in most problems, is able to find much better spread of solutions and better convergence near the true Pareto-optimal front compared to Pareto-archived evolution strategy and strength-Pareto EA—two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multiobjective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective seven-constraint nonlinear problem, are compared with another constrained multiobjective optimizer and much better performance of NSGA-II is observed.",
      "reference_ids": [
        "pub.1029969435",
        "pub.1014057085",
        "pub.1024732816",
        "pub.1001922045",
        "pub.1008568979",
        "pub.1061157569",
        "pub.1038305726",
        "pub.1061157568",
        "pub.1094003336",
        "pub.1095436217",
        "pub.1093675900",
        "pub.1026010259",
        "pub.1012647124"
      ],
      "concepts_scores": [
        {
          "concept": "Pareto-optimal front",
          "relevance": 0.704
        },
        {
          "concept": "computational complexity",
          "relevance": 0.697
        },
        {
          "concept": "evolutionary algorithm",
          "relevance": 0.696
        },
        {
          "concept": "NSGA-II",
          "relevance": 0.679
        },
        {
          "concept": "Pareto Archived Evolution Strategy",
          "relevance": 0.672
        },
        {
          "concept": "multiobjective evolutionary algorithm",
          "relevance": 0.653
        },
        {
          "concept": "performance of NSGA-II",
          "relevance": 0.644
        },
        {
          "concept": "spread of solutions",
          "relevance": 0.617
        },
        {
          "concept": "test problems",
          "relevance": 0.61
        },
        {
          "concept": "evolution strategy",
          "relevance": 0.589
        },
        {
          "concept": "mating pool",
          "relevance": 0.567
        },
        {
          "concept": "genetic algorithm",
          "relevance": 0.566
        },
        {
          "concept": "sorting genetic algorithm",
          "relevance": 0.557
        },
        {
          "concept": "simulation results",
          "relevance": 0.553
        },
        {
          "concept": "definition of dominance",
          "relevance": 0.552
        },
        {
          "concept": "multiobjective problem",
          "relevance": 0.55
        },
        {
          "concept": "offspring population",
          "relevance": 0.545
        },
        {
          "concept": "MOEA",
          "relevance": 0.541
        },
        {
          "concept": "multiobjective optimization",
          "relevance": 0.539
        },
        {
          "concept": "algorithm",
          "relevance": 0.525
        },
        {
          "concept": "constrained NSGA-II",
          "relevance": 0.519
        },
        {
          "concept": "selection operator",
          "relevance": 0.512
        },
        {
          "concept": "simulation",
          "relevance": 0.447
        },
        {
          "concept": "optimization",
          "relevance": 0.411
        },
        {
          "concept": "sharing",
          "relevance": 0.409
        },
        {
          "concept": "convergence",
          "relevance": 0.406
        },
        {
          "concept": "performance",
          "relevance": 0.397
        },
        {
          "concept": "solution",
          "relevance": 0.393
        },
        {
          "concept": "sorting",
          "relevance": 0.391
        },
        {
          "concept": "complex",
          "relevance": 0.383
        },
        {
          "concept": "operation",
          "relevance": 0.362
        },
        {
          "concept": "definition",
          "relevance": 0.338
        },
        {
          "concept": "selection",
          "relevance": 0.33
        },
        {
          "concept": "difficulties",
          "relevance": 0.312
        },
        {
          "concept": "results",
          "relevance": 0.304
        },
        {
          "concept": "strategies",
          "relevance": 0.303
        },
        {
          "concept": "parameters",
          "relevance": 0.288
        },
        {
          "concept": "test",
          "relevance": 0.286
        },
        {
          "concept": "front",
          "relevance": 0.278
        },
        {
          "concept": "problem",
          "relevance": 0.26
        },
        {
          "concept": "spread",
          "relevance": 0.257
        },
        {
          "concept": "pool",
          "relevance": 0.245
        },
        {
          "concept": "offspring",
          "relevance": 0.203
        },
        {
          "concept": "dominance",
          "relevance": 0.188
        },
        {
          "concept": "approach",
          "relevance": 0.187
        },
        {
          "concept": "population",
          "relevance": 0.173
        },
        {
          "concept": "nonelites",
          "relevance": 0.161
        },
        {
          "concept": "parents",
          "relevance": 0.151
        }
      ]
    },
    {
      "paperId": "pub.1061398159",
      "doi": "10.1109/mcse.2007.55",
      "title": "Matplotlib: A 2D Graphics Environment",
      "year": 2007,
      "citationCount": 33158,
      "fieldCitationRatio": 6639.48,
      "abstract": "Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems",
      "reference_ids": NaN,
      "concepts_scores": [
        {
          "concept": "application development",
          "relevance": 0.603
        },
        {
          "concept": "user interface",
          "relevance": 0.602
        },
        {
          "concept": "image generation",
          "relevance": 0.601
        },
        {
          "concept": "operating system",
          "relevance": 0.594
        },
        {
          "concept": "graphics package",
          "relevance": 0.593
        },
        {
          "concept": "interactive script",
          "relevance": 0.587
        },
        {
          "concept": "Matplotlib",
          "relevance": 0.469
        },
        {
          "concept": "users",
          "relevance": 0.463
        },
        {
          "concept": "Python",
          "relevance": 0.452
        },
        {
          "concept": "scripts",
          "relevance": 0.418
        },
        {
          "concept": "applications",
          "relevance": 0.373
        },
        {
          "concept": "interface",
          "relevance": 0.368
        },
        {
          "concept": "system",
          "relevance": 0.36
        },
        {
          "concept": "package",
          "relevance": 0.33
        },
        {
          "concept": "generation",
          "relevance": 0.309
        },
        {
          "concept": "development",
          "relevance": 0.271
        }
      ]
    },
    {
      "paperId": "pub.1150586663",
      "doi": "10.3390/app12178643",
      "title": "A Comparison of Pooling Methods for Convolutional Neural Networks",
      "year": 2022,
      "citationCount": 201,
      "fieldCitationRatio": 80.35,
      "abstract": "One of the most promising techniques used in various sciences is deep neural networks (DNNs). A special type of DNN called a convolutional neural network (CNN) consists of several convolutional layers, each preceded by an activation function and a pooling layer. The feature map of the previous layer is sampled by the pooling layer (that seems to be an important layer) to create a new feature map with condensed resolution. This layer significantly reduces the spatial dimension of the input. It always accomplished two main goals. As a first step, it reduces the number of parameters or weights to minimize computational costs. The second step is to prevent the overfitting of the network. In addition, pooling techniques can significantly reduce model training time and computational costs. This paper provides a critical understanding of traditional and modern pooling techniques and highlights the strengths and weaknesses for readers. Moreover, the performance of pooling techniques on different datasets is qualitatively evaluated and reviewed. This study is expected to contribute to a comprehensive understanding of the importance of CNNs and pooling techniques in computer vision challenges.",
      "reference_ids": [
        "pub.1129661683",
        "pub.1150866687",
        "pub.1106226286",
        "pub.1017395132",
        "pub.1091050316",
        "pub.1011335860",
        "pub.1061179979",
        "pub.1051559570",
        "pub.1134595023",
        "pub.1151379998",
        "pub.1135326194",
        "pub.1140556851",
        "pub.1110013546",
        "pub.1095595879",
        "pub.1127670057",
        "pub.1095843442",
        "pub.1123646734",
        "pub.1128401914",
        "pub.1140469627",
        "pub.1149897869",
        "pub.1122025329",
        "pub.1135842164",
        "pub.1093671727",
        "pub.1026943262",
        "pub.1094727707",
        "pub.1095837447",
        "pub.1124464712",
        "pub.1144636380",
        "pub.1147258099",
        "pub.1095611654",
        "pub.1129325492",
        "pub.1145902012",
        "pub.1061744812",
        "pub.1140253993",
        "pub.1095692097",
        "pub.1138794258",
        "pub.1139046456",
        "pub.1017904023",
        "pub.1113358802",
        "pub.1135656125",
        "pub.1085641964",
        "pub.1135825542",
        "pub.1061100768",
        "pub.1118389371",
        "pub.1140686947",
        "pub.1032233097",
        "pub.1104478124",
        "pub.1141409369",
        "pub.1150867257",
        "pub.1107574889",
        "pub.1114030976",
        "pub.1138916295",
        "pub.1084736192",
        "pub.1018367015",
        "pub.1103640159",
        "pub.1008345178",
        "pub.1130148193",
        "pub.1110721083",
        "pub.1142596061",
        "pub.1115605901",
        "pub.1107486919",
        "pub.1127148667",
        "pub.1117730339",
        "pub.1125165964"
      ],
      "concepts_scores": [
        {
          "concept": "convolutional neural network",
          "relevance": 0.822
        },
        {
          "concept": "deep neural networks",
          "relevance": 0.812
        },
        {
          "concept": "neural network",
          "relevance": 0.737
        },
        {
          "concept": "feature maps",
          "relevance": 0.719
        },
        {
          "concept": "pooling layer",
          "relevance": 0.718
        },
        {
          "concept": "pooling technique",
          "relevance": 0.685
        },
        {
          "concept": "computational cost",
          "relevance": 0.68
        },
        {
          "concept": "computer vision challenges",
          "relevance": 0.673
        },
        {
          "concept": "model training time",
          "relevance": 0.664
        },
        {
          "concept": "vision challenges",
          "relevance": 0.621
        },
        {
          "concept": "convolutional layers",
          "relevance": 0.62
        },
        {
          "concept": "training time",
          "relevance": 0.611
        },
        {
          "concept": "activation function",
          "relevance": 0.604
        },
        {
          "concept": "pooling method",
          "relevance": 0.591
        },
        {
          "concept": "condensed resolution",
          "relevance": 0.579
        },
        {
          "concept": "network",
          "relevance": 0.558
        },
        {
          "concept": "overfitting",
          "relevance": 0.478
        },
        {
          "concept": "convolution",
          "relevance": 0.469
        },
        {
          "concept": "dataset",
          "relevance": 0.457
        },
        {
          "concept": "spatial dimensions",
          "relevance": 0.453
        },
        {
          "concept": "maps",
          "relevance": 0.45
        },
        {
          "concept": "computer",
          "relevance": 0.45
        },
        {
          "concept": "technique",
          "relevance": 0.448
        },
        {
          "concept": "features",
          "relevance": 0.448
        },
        {
          "concept": "cost",
          "relevance": 0.423
        },
        {
          "concept": "input",
          "relevance": 0.408
        },
        {
          "concept": "performance",
          "relevance": 0.402
        },
        {
          "concept": "goal",
          "relevance": 0.359
        },
        {
          "concept": "method",
          "relevance": 0.354
        },
        {
          "concept": "layer",
          "relevance": 0.344
        },
        {
          "concept": "challenges",
          "relevance": 0.344
        },
        {
          "concept": "model",
          "relevance": 0.334
        },
        {
          "concept": "weakness",
          "relevance": 0.331
        },
        {
          "concept": "science",
          "relevance": 0.318
        },
        {
          "concept": "readers",
          "relevance": 0.317
        },
        {
          "concept": "dimensions",
          "relevance": 0.312
        },
        {
          "concept": "resolution",
          "relevance": 0.311
        },
        {
          "concept": "time",
          "relevance": 0.305
        },
        {
          "concept": "function",
          "relevance": 0.293
        },
        {
          "concept": "parameters",
          "relevance": 0.292
        },
        {
          "concept": "understanding",
          "relevance": 0.282
        },
        {
          "concept": "comparison",
          "relevance": 0.276
        },
        {
          "concept": "comprehensive understanding",
          "relevance": 0.271
        },
        {
          "concept": "weight",
          "relevance": 0.27
        },
        {
          "concept": "pool",
          "relevance": 0.248
        },
        {
          "concept": "strength",
          "relevance": 0.195
        },
        {
          "concept": "study",
          "relevance": 0.183
        },
        {
          "concept": "activity",
          "relevance": 0.165
        }
      ]
    },
    {
      "paperId": "pub.1139046456",
      "doi": "10.1145/3448250",
      "title": "Deep learning for AI",
      "year": 2021,
      "citationCount": 540,
      "fieldCitationRatio": 168.29,
      "abstract": "How can neural networks learn the rich internal representations required for difficult tasks such as recognizing objects or understanding language?",
      "reference_ids": [
        "pub.1061516742",
        "pub.1094758581",
        "pub.1093359587",
        "pub.1008345178",
        "pub.1125915369",
        "pub.1062620611",
        "pub.1110923421",
        "pub.1049253184",
        "pub.1018367015",
        "pub.1010020120",
        "pub.1050466409",
        "pub.1038140272",
        "pub.1132270339",
        "pub.1051732355",
        "pub.1095689025",
        "pub.1092406650",
        "pub.1061423808",
        "pub.1034444281",
        "pub.1129913470",
        "pub.1004607132",
        "pub.1085642448",
        "pub.1052031051",
        "pub.1004707137",
        "pub.1086365707",
        "pub.1061218427",
        "pub.1094942882",
        "pub.1086364805",
        "pub.1061179979",
        "pub.1039427823",
        "pub.1035788679",
        "pub.1095055093",
        "pub.1129913169",
        "pub.1093416695",
        "pub.1014405626",
        "pub.1049584474",
        "pub.1014567293",
        "pub.1049023394"
      ],
      "concepts_scores": [
        {
          "concept": "deep learning",
          "relevance": 0.609
        },
        {
          "concept": "neural network",
          "relevance": 0.604
        },
        {
          "concept": "difficult tasks",
          "relevance": 0.548
        },
        {
          "concept": "network",
          "relevance": 0.45
        },
        {
          "concept": "task",
          "relevance": 0.437
        },
        {
          "concept": "AI",
          "relevance": 0.434
        },
        {
          "concept": "learning",
          "relevance": 0.43
        },
        {
          "concept": "language",
          "relevance": 0.401
        },
        {
          "concept": "objective",
          "relevance": 0.369
        }
      ]
    },
    {
      "paperId": "pub.1093359587",
      "doi": "10.1109/cvpr.2016.90",
      "title": "Deep Residual Learning for Image Recognition",
      "year": 2016,
      "citationCount": 186455,
      "fieldCitationRatio": 36441.39,
      "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers-8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions11http://image-net.org/challenges/LSVRC/2015/ and http://mscoco.org/dataset/#detections-challenge2015., where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation. http://image-net.org/challenges/LSVRC/2015/ and http://mscoco.org/dataset/#detections-challenge2015.",
      "reference_ids": [
        "pub.1061744812",
        "pub.1008345178",
        "pub.1033229571",
        "pub.1037602011",
        "pub.1085642448",
        "pub.1061743975",
        "pub.1032233097",
        "pub.1093456265",
        "pub.1095559903",
        "pub.1014796149",
        "pub.1033986161",
        "pub.1061218416",
        "pub.1099341617",
        "pub.1098556598",
        "pub.1061745117",
        "pub.1061744117",
        "pub.1038140272",
        "pub.1098665985",
        "pub.1061156500",
        "pub.1045321436",
        "pub.1094727707",
        "pub.1030406568",
        "pub.1165598000",
        "pub.1095573598",
        "pub.1050111762",
        "pub.1093626237",
        "pub.1036869950",
        "pub.1094291017",
        "pub.1093828312"
      ],
      "concepts_scores": [
        {
          "concept": "residual nets",
          "relevance": 0.756
        },
        {
          "concept": "COCO object detection dataset",
          "relevance": 0.693
        },
        {
          "concept": "deep residual net",
          "relevance": 0.675
        },
        {
          "concept": "object detection datasets",
          "relevance": 0.673
        },
        {
          "concept": "residual learning framework",
          "relevance": 0.671
        },
        {
          "concept": "training of network",
          "relevance": 0.66
        },
        {
          "concept": "visual recognition tasks",
          "relevance": 0.659
        },
        {
          "concept": "learning residual functions",
          "relevance": 0.657
        },
        {
          "concept": "CIFAR-10",
          "relevance": 0.624
        },
        {
          "concept": "depth of representations",
          "relevance": 0.624
        },
        {
          "concept": "detection dataset",
          "relevance": 0.623
        },
        {
          "concept": "COCO detection",
          "relevance": 0.623
        },
        {
          "concept": "ImageNet dataset",
          "relevance": 0.622
        },
        {
          "concept": "deep representations",
          "relevance": 0.621
        },
        {
          "concept": "VGG-Net",
          "relevance": 0.619
        },
        {
          "concept": "classification task",
          "relevance": 0.619
        },
        {
          "concept": "residual network",
          "relevance": 0.614
        },
        {
          "concept": "learning framework",
          "relevance": 0.613
        },
        {
          "concept": "neural network",
          "relevance": 0.606
        },
        {
          "concept": "layer input",
          "relevance": 0.605
        },
        {
          "concept": "ImageNet",
          "relevance": 0.595
        },
        {
          "concept": "recognition task",
          "relevance": 0.593
        },
        {
          "concept": "ILSVRC",
          "relevance": 0.568
        },
        {
          "concept": "COCO",
          "relevance": 0.557
        },
        {
          "concept": "network",
          "relevance": 0.548
        },
        {
          "concept": "task",
          "relevance": 0.533
        },
        {
          "concept": "dataset",
          "relevance": 0.529
        },
        {
          "concept": "comprehensive empirical evidence",
          "relevance": 0.526
        },
        {
          "concept": "nets",
          "relevance": 0.506
        },
        {
          "concept": "representation",
          "relevance": 0.495
        },
        {
          "concept": "VGG",
          "relevance": 0.486
        },
        {
          "concept": "detection",
          "relevance": 0.448
        },
        {
          "concept": "classification",
          "relevance": 0.435
        },
        {
          "concept": "accuracy",
          "relevance": 0.418
        },
        {
          "concept": "input",
          "relevance": 0.408
        },
        {
          "concept": "framework",
          "relevance": 0.404
        },
        {
          "concept": "error",
          "relevance": 0.401
        },
        {
          "concept": "training",
          "relevance": 0.399
        },
        {
          "concept": "ensemble",
          "relevance": 0.392
        },
        {
          "concept": "segments",
          "relevance": 0.379
        },
        {
          "concept": "submission",
          "relevance": 0.378
        },
        {
          "concept": "residual function",
          "relevance": 0.365
        },
        {
          "concept": "function",
          "relevance": 0.339
        },
        {
          "concept": "layer",
          "relevance": 0.336
        },
        {
          "concept": "localization",
          "relevance": 0.336
        },
        {
          "concept": "complex",
          "relevance": 0.335
        },
        {
          "concept": "improvement",
          "relevance": 0.322
        },
        {
          "concept": "empirical evidence",
          "relevance": 0.321
        },
        {
          "concept": "depth",
          "relevance": 0.299
        },
        {
          "concept": "foundations",
          "relevance": 0.292
        },
        {
          "concept": "increasing depth",
          "relevance": 0.282
        },
        {
          "concept": "analysis",
          "relevance": 0.253
        },
        {
          "concept": "test",
          "relevance": 0.251
        },
        {
          "concept": "evidence",
          "relevance": 0.177
        }
      ]
    },
    {
      "paperId": "pub.1085642448",
      "doi": "10.1145/3065386",
      "title": "ImageNet classification with deep convolutional neural networks",
      "year": 2017,
      "citationCount": 49626,
      "fieldCitationRatio": 10004.01,
      "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.",
      "reference_ids": [
        "pub.1094646180",
        "pub.1024739340",
        "pub.1020853978",
        "pub.1094291017",
        "pub.1027534025",
        "pub.1010421612",
        "pub.1094709720",
        "pub.1034831185",
        "pub.1094246303",
        "pub.1033296596",
        "pub.1093359587",
        "pub.1093416695",
        "pub.1045861574",
        "pub.1025918724",
        "pub.1016635886",
        "pub.1051709453",
        "pub.1004476131",
        "pub.1004784969",
        "pub.1094714779"
      ],
      "concepts_scores": [
        {
          "concept": "deep convolutional neural network",
          "relevance": 0.788
        },
        {
          "concept": "convolutional neural network",
          "relevance": 0.768
        },
        {
          "concept": "neural network",
          "relevance": 0.735
        },
        {
          "concept": "error rate",
          "relevance": 0.691
        },
        {
          "concept": "efficient GPU implementation",
          "relevance": 0.669
        },
        {
          "concept": "max-pooling layers",
          "relevance": 0.668
        },
        {
          "concept": "test error rate",
          "relevance": 0.65
        },
        {
          "concept": "ImageNet classification",
          "relevance": 0.624
        },
        {
          "concept": "ILSVRC-2012",
          "relevance": 0.622
        },
        {
          "concept": "convolutional layers",
          "relevance": 0.619
        },
        {
          "concept": "GPU implementation",
          "relevance": 0.617
        },
        {
          "concept": "top-5",
          "relevance": 0.606
        },
        {
          "concept": "convolution operation",
          "relevance": 0.602
        },
        {
          "concept": "regularization method",
          "relevance": 0.569
        },
        {
          "concept": "high-resolution images",
          "relevance": 0.568
        },
        {
          "concept": "ImageNet",
          "relevance": 0.565
        },
        {
          "concept": "network",
          "relevance": 0.547
        },
        {
          "concept": "test data",
          "relevance": 0.507
        },
        {
          "concept": "softmax",
          "relevance": 0.487
        },
        {
          "concept": "overfitting",
          "relevance": 0.477
        },
        {
          "concept": "convolution",
          "relevance": 0.468
        },
        {
          "concept": "classification",
          "relevance": 0.434
        },
        {
          "concept": "implementation",
          "relevance": 0.414
        },
        {
          "concept": "regularization",
          "relevance": 0.41
        },
        {
          "concept": "error",
          "relevance": 0.4
        },
        {
          "concept": "images",
          "relevance": 0.398
        },
        {
          "concept": "training",
          "relevance": 0.398
        },
        {
          "concept": "operation",
          "relevance": 0.367
        },
        {
          "concept": "method",
          "relevance": 0.353
        },
        {
          "concept": "class",
          "relevance": 0.341
        },
        {
          "concept": "layer",
          "relevance": 0.341
        },
        {
          "concept": "neurons",
          "relevance": 0.336
        },
        {
          "concept": "model",
          "relevance": 0.334
        },
        {
          "concept": "dropout",
          "relevance": 0.328
        },
        {
          "concept": "data",
          "relevance": 0.319
        },
        {
          "concept": "variants",
          "relevance": 0.296
        },
        {
          "concept": "parameters",
          "relevance": 0.291
        },
        {
          "concept": "entry",
          "relevance": 0.279
        },
        {
          "concept": "rate",
          "relevance": 0.27
        },
        {
          "concept": "competition",
          "relevance": 0.27
        },
        {
          "concept": "test",
          "relevance": 0.25
        },
        {
          "concept": "contest",
          "relevance": 0.248
        }
      ]
    },
    {
      "paperId": "pub.1145902012",
      "doi": "10.1109/iccv48922.2021.01019",
      "title": "Refining activation downsampling with SoftPool",
      "year": 2021,
      "citationCount": 236,
      "fieldCitationRatio": 71.96,
      "abstract": "Convolutional Neural Networks (CNNs) use pooling to decrease the size of activation maps. This process is crucial to increase the receptive fields and to reduce computational requirements of subsequent convolutions. An important feature of the pooling operation is the minimization of information loss, with respect to the initial activation maps, without a significant impact on the computation and memory overhead. To meet these requirements, we propose SoftPool: a fast and efficient method for exponentially weighted activation downsampling. Through experiments across a range of architectures and pooling methods, we demonstrate that SoftPool can retain more information in the reduced activation maps. This refined downsampling leads to improvements in a CNN’s classification accuracy. Experiments with pooling layer substitutions on ImageNet1K show an increase in accuracy over both original architectures and other pooling methods. We also test SoftPool on video datasets for action recognition. Again, through the direct replacement of pooling layers, we observe consistent performance improvements while computational loads and memory requirements remain limited1.",
      "reference_ids": [
        "pub.1093990376",
        "pub.1100060307",
        "pub.1110721083",
        "pub.1120757994",
        "pub.1125156095",
        "pub.1009767488",
        "pub.1094476634",
        "pub.1110720809",
        "pub.1105796929",
        "pub.1095836985",
        "pub.1120397518",
        "pub.1017904023",
        "pub.1095837447",
        "pub.1104413659",
        "pub.1093359587",
        "pub.1129912519",
        "pub.1100060309",
        "pub.1107454634",
        "pub.1093497718",
        "pub.1010537723",
        "pub.1020267307",
        "pub.1095843442",
        "pub.1094512911",
        "pub.1048367524",
        "pub.1095180230",
        "pub.1096897141",
        "pub.1132676622",
        "pub.1061179979",
        "pub.1095850372",
        "pub.1094291017",
        "pub.1035393709",
        "pub.1125163921",
        "pub.1125165964",
        "pub.1123988710",
        "pub.1125156209",
        "pub.1095506116",
        "pub.1061640964",
        "pub.1125156786",
        "pub.1037325004",
        "pub.1095271325"
      ],
      "concepts_scores": [
        {
          "concept": "convolutional neural network",
          "relevance": 0.81
        },
        {
          "concept": "CNN classification accuracy",
          "relevance": 0.694
        },
        {
          "concept": "pooling method",
          "relevance": 0.687
        },
        {
          "concept": "minimization of information loss",
          "relevance": 0.683
        },
        {
          "concept": "activation maps",
          "relevance": 0.657
        },
        {
          "concept": "ImageNet1K",
          "relevance": 0.627
        },
        {
          "concept": "video datasets",
          "relevance": 0.626
        },
        {
          "concept": "action recognition",
          "relevance": 0.625
        },
        {
          "concept": "pooling operations",
          "relevance": 0.619
        },
        {
          "concept": "reduced computational requirements",
          "relevance": 0.612
        },
        {
          "concept": "SoftPool",
          "relevance": 0.607
        },
        {
          "concept": "neural network",
          "relevance": 0.607
        },
        {
          "concept": "classification accuracy",
          "relevance": 0.607
        },
        {
          "concept": "information loss",
          "relevance": 0.605
        },
        {
          "concept": "memory requirements",
          "relevance": 0.599
        },
        {
          "concept": "computational load",
          "relevance": 0.598
        },
        {
          "concept": "computational requirements",
          "relevance": 0.591
        },
        {
          "concept": "downsampling",
          "relevance": 0.586
        },
        {
          "concept": "original architecture",
          "relevance": 0.584
        },
        {
          "concept": "performance improvement",
          "relevance": 0.582
        },
        {
          "concept": "receptive fields",
          "relevance": 0.561
        },
        {
          "concept": "convolution",
          "relevance": 0.545
        },
        {
          "concept": "architecture",
          "relevance": 0.527
        },
        {
          "concept": "requirements",
          "relevance": 0.487
        },
        {
          "concept": "accuracy",
          "relevance": 0.485
        },
        {
          "concept": "efficient method",
          "relevance": 0.484
        },
        {
          "concept": "maps",
          "relevance": 0.474
        },
        {
          "concept": "video",
          "relevance": 0.464
        },
        {
          "concept": "layer substitution",
          "relevance": 0.46
        },
        {
          "concept": "dataset",
          "relevance": 0.458
        },
        {
          "concept": "network",
          "relevance": 0.452
        },
        {
          "concept": "computer",
          "relevance": 0.451
        },
        {
          "concept": "memory",
          "relevance": 0.45
        },
        {
          "concept": "method",
          "relevance": 0.431
        },
        {
          "concept": "recognition",
          "relevance": 0.421
        },
        {
          "concept": "information",
          "relevance": 0.406
        },
        {
          "concept": "performance",
          "relevance": 0.403
        },
        {
          "concept": "experiments",
          "relevance": 0.389
        },
        {
          "concept": "exponential",
          "relevance": 0.374
        },
        {
          "concept": "improvement",
          "relevance": 0.374
        },
        {
          "concept": "operation",
          "relevance": 0.368
        },
        {
          "concept": "minimization",
          "relevance": 0.352
        },
        {
          "concept": "layer",
          "relevance": 0.342
        },
        {
          "concept": "process",
          "relevance": 0.318
        },
        {
          "concept": "load",
          "relevance": 0.315
        },
        {
          "concept": "field",
          "relevance": 0.29
        },
        {
          "concept": "pool",
          "relevance": 0.288
        },
        {
          "concept": "limited1",
          "relevance": 0.273
        },
        {
          "concept": "size",
          "relevance": 0.261
        },
        {
          "concept": "action",
          "relevance": 0.257
        },
        {
          "concept": "impact",
          "relevance": 0.245
        },
        {
          "concept": "loss",
          "relevance": 0.232
        },
        {
          "concept": "increase",
          "relevance": 0.214
        },
        {
          "concept": "replacement",
          "relevance": 0.212
        },
        {
          "concept": "substitution",
          "relevance": 0.174
        },
        {
          "concept": "activity",
          "relevance": 0.165
        }
      ]
    },
    {
      "paperId": "pub.1095843442",
      "doi": "10.1109/cvpr.2017.243",
      "title": "Densely Connected Convolutional Networks",
      "year": 2017,
      "citationCount": 33927,
      "fieldCitationRatio": 6839.28,
      "abstract": "Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with $L$ layers have $L$ connections—one between each layer and its subsequent layer—our network has $\\frac{L(L+1)}{2}$ direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet.",
      "reference_ids": [
        "pub.1039042955",
        "pub.1094291017",
        "pub.1003844693",
        "pub.1008345178",
        "pub.1063405080",
        "pub.1093626237",
        "pub.1093658325",
        "pub.1095686079",
        "pub.1093828312",
        "pub.1095689025",
        "pub.1095420134",
        "pub.1093359587",
        "pub.1037192953",
        "pub.1009767488",
        "pub.1085642448",
        "pub.1061179979",
        "pub.1093497718"
      ],
      "concepts_scores": [
        {
          "concept": "convolutional network",
          "relevance": 0.73
        },
        {
          "concept": "feature-maps",
          "relevance": 0.699
        },
        {
          "concept": "competitive object recognition benchmark tasks",
          "relevance": 0.68
        },
        {
          "concept": "vanishing-gradient problem",
          "relevance": 0.652
        },
        {
          "concept": "dense convolutional network",
          "relevance": 0.647
        },
        {
          "concept": "pre-trained models",
          "relevance": 0.647
        },
        {
          "concept": "feed-forward fashion",
          "relevance": 0.631
        },
        {
          "concept": "benchmark tasks",
          "relevance": 0.603
        },
        {
          "concept": "L$ layers",
          "relevance": 0.602
        },
        {
          "concept": "feature propagation",
          "relevance": 0.602
        },
        {
          "concept": "DenseNet",
          "relevance": 0.572
        },
        {
          "concept": "network",
          "relevance": 0.542
        },
        {
          "concept": "short connections",
          "relevance": 0.542
        },
        {
          "concept": "input",
          "relevance": 0.482
        },
        {
          "concept": "architecture",
          "relevance": 0.441
        },
        {
          "concept": "computer",
          "relevance": 0.437
        },
        {
          "concept": "code",
          "relevance": 0.433
        },
        {
          "concept": "task",
          "relevance": 0.426
        },
        {
          "concept": "reuse",
          "relevance": 0.421
        },
        {
          "concept": "connection",
          "relevance": 0.408
        },
        {
          "concept": "performance",
          "relevance": 0.391
        },
        {
          "concept": "features",
          "relevance": 0.376
        },
        {
          "concept": "output",
          "relevance": 0.372
        },
        {
          "concept": "layer",
          "relevance": 0.335
        },
        {
          "concept": "model",
          "relevance": 0.325
        },
        {
          "concept": "fashion",
          "relevance": 0.315
        },
        {
          "concept": "propagation",
          "relevance": 0.315
        },
        {
          "concept": "improvement",
          "relevance": 0.313
        },
        {
          "concept": "parameters",
          "relevance": 0.284
        },
        {
          "concept": "densely",
          "relevance": 0.283
        },
        {
          "concept": "observations",
          "relevance": 0.203
        },
        {
          "concept": "problem",
          "relevance": 0.198
        }
      ]
    },
    {
      "paperId": "pub.1100060307",
      "doi": "10.1109/iccv.2017.322",
      "title": "Mask R-CNN",
      "year": 2017,
      "citationCount": 23345,
      "fieldCitationRatio": 4896.65,
      "abstract": "We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.",
      "reference_ids": [
        "pub.1095604624",
        "pub.1045321436",
        "pub.1093518416",
        "pub.1095840375",
        "pub.1095686079",
        "pub.1094727707",
        "pub.1093292479",
        "pub.1061745117",
        "pub.1093359587",
        "pub.1085642448",
        "pub.1094164376",
        "pub.1095850372",
        "pub.1093572203",
        "pub.1008345178",
        "pub.1095573598",
        "pub.1095646840",
        "pub.1095837104",
        "pub.1095839166",
        "pub.1094492451",
        "pub.1003201959",
        "pub.1030874879",
        "pub.1061744921",
        "pub.1061744812",
        "pub.1093700510",
        "pub.1001688760",
        "pub.1095852454",
        "pub.1093921969",
        "pub.1093626237",
        "pub.1033900312"
      ],
      "concepts_scores": [
        {
          "concept": "Mask R-CNN",
          "relevance": 0.818
        },
        {
          "concept": "R-CNN",
          "relevance": 0.771
        },
        {
          "concept": "high-quality segmentation masks",
          "relevance": 0.695
        },
        {
          "concept": "COCO suite of challenges",
          "relevance": 0.695
        },
        {
          "concept": "person keypoint detection",
          "relevance": 0.677
        },
        {
          "concept": "single-model entries",
          "relevance": 0.677
        },
        {
          "concept": "instance-level recognition",
          "relevance": 0.677
        },
        {
          "concept": "estimate human pose",
          "relevance": 0.675
        },
        {
          "concept": "object instance segmentation",
          "relevance": 0.672
        },
        {
          "concept": "Faster R-CNN",
          "relevance": 0.669
        },
        {
          "concept": "Faster R-CNN",
          "relevance": 0.668
        },
        {
          "concept": "human pose",
          "relevance": 0.626
        },
        {
          "concept": "keypoint detection",
          "relevance": 0.624
        },
        {
          "concept": "object masks",
          "relevance": 0.622
        },
        {
          "concept": "object detection",
          "relevance": 0.622
        },
        {
          "concept": "instance segmentation",
          "relevance": 0.62
        },
        {
          "concept": "segmentation masks",
          "relevance": 0.616
        },
        {
          "concept": "box recognition",
          "relevance": 0.586
        },
        {
          "concept": "solid baseline",
          "relevance": 0.577
        },
        {
          "concept": "suite of challenges",
          "relevance": 0.573
        },
        {
          "concept": "COCO",
          "relevance": 0.523
        },
        {
          "concept": "task",
          "relevance": 0.509
        },
        {
          "concept": "recognition",
          "relevance": 0.489
        },
        {
          "concept": "mask",
          "relevance": 0.486
        },
        {
          "concept": "pose",
          "relevance": 0.473
        },
        {
          "concept": "Faster",
          "relevance": 0.472
        },
        {
          "concept": "effective approach",
          "relevance": 0.455
        },
        {
          "concept": "objective",
          "relevance": 0.451
        },
        {
          "concept": "detection",
          "relevance": 0.45
        },
        {
          "concept": "code",
          "relevance": 0.447
        },
        {
          "concept": "segments",
          "relevance": 0.441
        },
        {
          "concept": "tricks",
          "relevance": 0.418
        },
        {
          "concept": "tracking",
          "relevance": 0.411
        },
        {
          "concept": "framework",
          "relevance": 0.405
        },
        {
          "concept": "images",
          "relevance": 0.4
        },
        {
          "concept": "box",
          "relevance": 0.367
        },
        {
          "concept": "winners",
          "relevance": 0.366
        },
        {
          "concept": "method",
          "relevance": 0.355
        },
        {
          "concept": "challenges",
          "relevance": 0.346
        },
        {
          "concept": "research",
          "relevance": 0.327
        },
        {
          "concept": "results",
          "relevance": 0.309
        },
        {
          "concept": "branches",
          "relevance": 0.307
        },
        {
          "concept": "persons",
          "relevance": 0.292
        },
        {
          "concept": "entry",
          "relevance": 0.281
        },
        {
          "concept": "baseline",
          "relevance": 0.249
        },
        {
          "concept": "approach",
          "relevance": 0.218
        }
      ]
    }
  ],
  "evolution_links": [
    {
      "source": "pub.1156949961",
      "target": "pub.1154597975",
      "source_title": "On the Analyses of Medical Images Using Traditional Machine Learning Techniques and Convolutional Neural Networks",
      "target_title": "Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges"
    },
    {
      "source": "pub.1154597975",
      "target": "pub.1129629919",
      "source_title": "Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges",
      "target_title": "On hyperparameter optimization of machine learning algorithms: Theory and practice"
    },
    {
      "source": "pub.1129629919",
      "target": "pub.1110458978",
      "source_title": "On hyperparameter optimization of machine learning algorithms: Theory and practice",
      "target_title": "Regression Shrinkage and Selection Via the Lasso"
    },
    {
      "source": "pub.1129629919",
      "target": "pub.1114803069",
      "source_title": "On hyperparameter optimization of machine learning algorithms: Theory and practice",
      "target_title": "TPOT: A Tree-Based Pipeline Optimization Tool for Automating Machine Learning"
    },
    {
      "source": "pub.1154597975",
      "target": "pub.1130333118",
      "source_title": "Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges",
      "target_title": "COCO: a platform for comparing continuous optimizers in a black-box setting"
    },
    {
      "source": "pub.1130333118",
      "target": "pub.1061172126",
      "source_title": "COCO: a platform for comparing continuous optimizers in a black-box setting",
      "target_title": "A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II"
    },
    {
      "source": "pub.1130333118",
      "target": "pub.1061398159",
      "source_title": "COCO: a platform for comparing continuous optimizers in a black-box setting",
      "target_title": "Matplotlib: A 2D Graphics Environment"
    },
    {
      "source": "pub.1156949961",
      "target": "pub.1150586663",
      "source_title": "On the Analyses of Medical Images Using Traditional Machine Learning Techniques and Convolutional Neural Networks",
      "target_title": "A Comparison of Pooling Methods for Convolutional Neural Networks"
    },
    {
      "source": "pub.1150586663",
      "target": "pub.1139046456",
      "source_title": "A Comparison of Pooling Methods for Convolutional Neural Networks",
      "target_title": "Deep learning for AI"
    },
    {
      "source": "pub.1139046456",
      "target": "pub.1093359587",
      "source_title": "Deep learning for AI",
      "target_title": "Deep Residual Learning for Image Recognition"
    },
    {
      "source": "pub.1139046456",
      "target": "pub.1085642448",
      "source_title": "Deep learning for AI",
      "target_title": "ImageNet classification with deep convolutional neural networks"
    },
    {
      "source": "pub.1150586663",
      "target": "pub.1145902012",
      "source_title": "A Comparison of Pooling Methods for Convolutional Neural Networks",
      "target_title": "Refining activation downsampling with SoftPool"
    },
    {
      "source": "pub.1145902012",
      "target": "pub.1095843442",
      "source_title": "Refining activation downsampling with SoftPool",
      "target_title": "Densely Connected Convolutional Networks"
    },
    {
      "source": "pub.1145902012",
      "target": "pub.1100060307",
      "source_title": "Refining activation downsampling with SoftPool",
      "target_title": "Mask R-CNN"
    }
  ]
}