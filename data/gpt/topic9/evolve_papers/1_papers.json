{
  "papers": [
    {
      "paperId": "pub.1152843639",
      "doi": "10.1145/3571730",
      "title": "Survey of Hallucination in Natural Language Generation",
      "year": 2023,
      "citationCount": 1847,
      "fieldCitationRatio": 1078.6,
      "abstract": "Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before. In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG. ",
      "reference_ids": [
        "pub.1123570624",
        "pub.1143949401",
        "pub.1126570785",
        "pub.1128856723",
        "pub.1144982970",
        "pub.1145454307",
        "pub.1121024955",
        "pub.1121025075",
        "pub.1148391803",
        "pub.1096025524",
        "pub.1121024805",
        "pub.1119910017",
        "pub.1148391058",
        "pub.1123570637",
        "pub.1148410624",
        "pub.1148390672",
        "pub.1166381551",
        "pub.1096026172",
        "pub.1144245207",
        "pub.1129757287",
        "pub.1133175179",
        "pub.1068001300",
        "pub.1123023851",
        "pub.1142062013",
        "pub.1000158521",
        "pub.1143948900",
        "pub.1138445754",
        "pub.1129757334",
        "pub.1138840721",
        "pub.1129757335",
        "pub.1129757285",
        "pub.1148390710",
        "pub.1137377364",
        "pub.1096025763",
        "pub.1129757061",
        "pub.1149741605",
        "pub.1038186930",
        "pub.1144245091",
        "pub.1143949341",
        "pub.1166381400",
        "pub.1012795382",
        "pub.1117660477",
        "pub.1139948293"
      ],
      "concepts_scores": [
        {
          "concept": "natural language generation",
          "relevance": 0.832
        },
        {
          "concept": "data-to-text generation",
          "relevance": 0.803
        },
        {
          "concept": "abstractive summarization",
          "relevance": 0.725
        },
        {
          "concept": "downstream tasks",
          "relevance": 0.721
        },
        {
          "concept": "dialogue generation",
          "relevance": 0.72
        },
        {
          "concept": "language generation",
          "relevance": 0.71
        },
        {
          "concept": "Transformer-based language models",
          "relevance": 0.682
        },
        {
          "concept": "generative question answering",
          "relevance": 0.676
        },
        {
          "concept": "deep learning technology",
          "relevance": 0.662
        },
        {
          "concept": "overview of metrics",
          "relevance": 0.641
        },
        {
          "concept": "question answering",
          "relevance": 0.624
        },
        {
          "concept": "hallucination problem",
          "relevance": 0.62
        },
        {
          "concept": "machine translation",
          "relevance": 0.619
        },
        {
          "concept": "language model",
          "relevance": 0.616
        },
        {
          "concept": "deep learning",
          "relevance": 0.612
        },
        {
          "concept": "user expectations",
          "relevance": 0.611
        },
        {
          "concept": "learning technology",
          "relevance": 0.588
        },
        {
          "concept": "system performance",
          "relevance": 0.57
        },
        {
          "concept": "summarization",
          "relevance": 0.559
        },
        {
          "concept": "years thanks",
          "relevance": 0.516
        },
        {
          "concept": "task",
          "relevance": 0.508
        },
        {
          "concept": "mitigation methods",
          "relevance": 0.495
        },
        {
          "concept": "text",
          "relevance": 0.491
        },
        {
          "concept": "users",
          "relevance": 0.471
        },
        {
          "concept": "metrics",
          "relevance": 0.444
        },
        {
          "concept": "machine",
          "relevance": 0.441
        },
        {
          "concept": "learning",
          "relevance": 0.432
        },
        {
          "concept": "comprehensive manner",
          "relevance": 0.427
        },
        {
          "concept": "scenarios",
          "relevance": 0.419
        },
        {
          "concept": "research progress",
          "relevance": 0.414
        },
        {
          "concept": "dialogue",
          "relevance": 0.411
        },
        {
          "concept": "performance",
          "relevance": 0.403
        },
        {
          "concept": "technology",
          "relevance": 0.401
        },
        {
          "concept": "general overview",
          "relevance": 0.397
        },
        {
          "concept": "generation",
          "relevance": 0.392
        },
        {
          "concept": "thanks",
          "relevance": 0.387
        },
        {
          "concept": "collaborative efforts",
          "relevance": 0.384
        },
        {
          "concept": "research",
          "relevance": 0.378
        },
        {
          "concept": "answers",
          "relevance": 0.377
        },
        {
          "concept": "overview",
          "relevance": 0.376
        },
        {
          "concept": "improved development",
          "relevance": 0.372
        },
        {
          "concept": "system",
          "relevance": 0.367
        },
        {
          "concept": "issues",
          "relevance": 0.362
        },
        {
          "concept": "method",
          "relevance": 0.354
        },
        {
          "concept": "translation",
          "relevance": 0.35
        },
        {
          "concept": "challenges",
          "relevance": 0.345
        },
        {
          "concept": "model",
          "relevance": 0.335
        },
        {
          "concept": "advances",
          "relevance": 0.329
        },
        {
          "concept": "efforts",
          "relevance": 0.325
        },
        {
          "concept": "development",
          "relevance": 0.319
        },
        {
          "concept": "manner",
          "relevance": 0.311
        },
        {
          "concept": "nature",
          "relevance": 0.307
        },
        {
          "concept": "direction",
          "relevance": 0.299
        },
        {
          "concept": "survey",
          "relevance": 0.298
        },
        {
          "concept": "mitigation",
          "relevance": 0.296
        },
        {
          "concept": "parts",
          "relevance": 0.291
        },
        {
          "concept": "expectations",
          "relevance": 0.26
        },
        {
          "concept": "measurements",
          "relevance": 0.246
        },
        {
          "concept": "progression",
          "relevance": 0.231
        },
        {
          "concept": "hallucinations",
          "relevance": 0.218
        },
        {
          "concept": "study",
          "relevance": 0.21
        },
        {
          "concept": "years",
          "relevance": 0.192
        },
        {
          "concept": "problem",
          "relevance": 0.18
        }
      ]
    },
    {
      "paperId": "pub.1145454307",
      "doi": "10.1162/tacl_a_00453",
      "title": "SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization",
      "year": 2022,
      "citationCount": 84,
      "fieldCitationRatio": 32.93,
      "abstract": "Abstract\n                  In the summarization domain, a key requirement for summaries is to be factually consistent with the input document. Previous work has found that natural language inference (NLI) models do not perform competitively when applied to inconsistency detection. In this work, we revisit the use of NLI for inconsistency detection, finding that past work suffered from a mismatch in input granularity between NLI datasets (sentence-level), and inconsistency detection (document level). We provide a highly effective and light-weight method called SummaCConv that enables NLI models to be successfully used for this task by segmenting documents into sentence units and aggregating scores between pairs of sentences. We furthermore introduce a new benchmark called SummaC (Summary Consistency) which consists of six large inconsistency detection datasets. On this dataset, SummaCConv obtains state-of-the-art results with a balanced accuracy of 74.4%, a 5% improvement compared with prior work.",
      "reference_ids": [
        "pub.1044522995",
        "pub.1099106053",
        "pub.1139947594",
        "pub.1133174463",
        "pub.1133176794",
        "pub.1122290839",
        "pub.1129757043",
        "pub.1099113832",
        "pub.1104321191",
        "pub.1138840568",
        "pub.1139947074",
        "pub.1133174462",
        "pub.1133177266",
        "pub.1137573792",
        "pub.1095428650",
        "pub.1129757057",
        "pub.1118169633",
        "pub.1129756745",
        "pub.1098653816",
        "pub.1104321397",
        "pub.1133175502",
        "pub.1139947551",
        "pub.1104321164",
        "pub.1117658852",
        "pub.1004984215",
        "pub.1138840677",
        "pub.1047286548",
        "pub.1133174687",
        "pub.1122290337",
        "pub.1133175338",
        "pub.1119910017",
        "pub.1129757061",
        "pub.1143949301"
      ],
      "concepts_scores": [
        {
          "concept": "natural language inference",
          "relevance": 0.863
        },
        {
          "concept": "inconsistency detection",
          "relevance": 0.771
        },
        {
          "concept": "natural language inference dataset",
          "relevance": 0.714
        },
        {
          "concept": "natural language inference model",
          "relevance": 0.706
        },
        {
          "concept": "light-weight method",
          "relevance": 0.695
        },
        {
          "concept": "pairs of sentences",
          "relevance": 0.644
        },
        {
          "concept": "language inference",
          "relevance": 0.642
        },
        {
          "concept": "detection dataset",
          "relevance": 0.642
        },
        {
          "concept": "input document",
          "relevance": 0.641
        },
        {
          "concept": "input granularity",
          "relevance": 0.635
        },
        {
          "concept": "segmenting documents",
          "relevance": 0.628
        },
        {
          "concept": "document level",
          "relevance": 0.625
        },
        {
          "concept": "sentence-level",
          "relevance": 0.622
        },
        {
          "concept": "balanced accuracy",
          "relevance": 0.584
        },
        {
          "concept": "summarization",
          "relevance": 0.576
        },
        {
          "concept": "dataset",
          "relevance": 0.573
        },
        {
          "concept": "sentence units",
          "relevance": 0.548
        },
        {
          "concept": "documents",
          "relevance": 0.508
        },
        {
          "concept": "SUMMAC",
          "relevance": 0.508
        },
        {
          "concept": "detection",
          "relevance": 0.494
        },
        {
          "concept": "input",
          "relevance": 0.487
        },
        {
          "concept": "sentences",
          "relevance": 0.483
        },
        {
          "concept": "granularity",
          "relevance": 0.476
        },
        {
          "concept": "inconsistencies",
          "relevance": 0.461
        },
        {
          "concept": "benchmarks",
          "relevance": 0.46
        },
        {
          "concept": "task",
          "relevance": 0.452
        },
        {
          "concept": "aggregate score",
          "relevance": 0.431
        },
        {
          "concept": "accuracy",
          "relevance": 0.431
        },
        {
          "concept": "inference",
          "relevance": 0.43
        },
        {
          "concept": "model",
          "relevance": 0.419
        },
        {
          "concept": "domain",
          "relevance": 0.393
        },
        {
          "concept": "re-visited",
          "relevance": 0.389
        },
        {
          "concept": "summary",
          "relevance": 0.369
        },
        {
          "concept": "method",
          "relevance": 0.365
        },
        {
          "concept": "consistency",
          "relevance": 0.364
        },
        {
          "concept": "Abstract",
          "relevance": 0.347
        },
        {
          "concept": "improvement",
          "relevance": 0.332
        },
        {
          "concept": "mismatch",
          "relevance": 0.327
        },
        {
          "concept": "pairs",
          "relevance": 0.321
        },
        {
          "concept": "results",
          "relevance": 0.318
        },
        {
          "concept": "units",
          "relevance": 0.244
        },
        {
          "concept": "scores",
          "relevance": 0.223
        },
        {
          "concept": "levels",
          "relevance": 0.21
        }
      ]
    },
    {
      "paperId": "pub.1137573792",
      "doi": "10.1162/tacl_a_00373",
      "title": "SummEval: Re-evaluating Summarization Evaluation",
      "year": 2021,
      "citationCount": 196,
      "fieldCitationRatio": 59.0,
      "abstract": "Abstract\n                  The scarcity of comprehensive up-to-date studies on evaluation metrics for text summarization and the lack of consensus regarding evaluation protocols continue to inhibit progress. We address the existing shortcomings of summarization evaluation methods along five dimensions: 1) we re-evaluate 14 automatic evaluation metrics in a comprehensive and consistent fashion using neural summarization model outputs along with expert and crowd-sourced human annotations; 2) we consistently benchmark 23 recent summarization models using the aforementioned automatic evaluation metrics; 3) we assemble the largest collection of summaries generated by models trained on the CNN/DailyMail news dataset and share it in a unified format; 4) we implement and share a toolkit that provides an extensible and unified API for evaluating summarization models across a broad range of automatic metrics; and 5) we assemble and share the largest and most diverse, in terms of model types, collection of human judgments of model-generated summaries on the CNN/Daily Mail dataset annotated by both expert judges and crowd-source workers. We hope that this work will help promote a more complete evaluation protocol for text summarization as well as advance research in developing evaluation metrics that better correlate with human judgments.",
      "reference_ids": [
        "pub.1117658731",
        "pub.1129757057",
        "pub.1104321155",
        "pub.1117659387",
        "pub.1104321248",
        "pub.1133174463",
        "pub.1099097107",
        "pub.1121024922",
        "pub.1053468661",
        "pub.1099106200",
        "pub.1129756745",
        "pub.1117658853",
        "pub.1122290337",
        "pub.1096025521",
        "pub.1099239594",
        "pub.1104321397",
        "pub.1117658734",
        "pub.1117659340",
        "pub.1133175763",
        "pub.1099105991",
        "pub.1117659388",
        "pub.1099179676",
        "pub.1129757334",
        "pub.1122290070",
        "pub.1117659089",
        "pub.1129756691",
        "pub.1099204495",
        "pub.1121024856",
        "pub.1117658735",
        "pub.1129757053",
        "pub.1117659391",
        "pub.1117658854",
        "pub.1121025287",
        "pub.1122290404",
        "pub.1122290068",
        "pub.1099113832",
        "pub.1117659086",
        "pub.1133174738",
        "pub.1095795137",
        "pub.1122290324",
        "pub.1050378128",
        "pub.1121025094",
        "pub.1117659390",
        "pub.1122290340",
        "pub.1121025091",
        "pub.1001381236",
        "pub.1117659055",
        "pub.1100517192"
      ],
      "concepts_scores": [
        {
          "concept": "automatic evaluation metrics",
          "relevance": 0.789
        },
        {
          "concept": "evaluation metrics",
          "relevance": 0.764
        },
        {
          "concept": "summarization model",
          "relevance": 0.731
        },
        {
          "concept": "CNN/Daily Mail dataset",
          "relevance": 0.681
        },
        {
          "concept": "crowd-sourced workers",
          "relevance": 0.655
        },
        {
          "concept": "evaluation protocol",
          "relevance": 0.64
        },
        {
          "concept": "text summarization",
          "relevance": 0.631
        },
        {
          "concept": "collection of summaries",
          "relevance": 0.631
        },
        {
          "concept": "Mail dataset",
          "relevance": 0.631
        },
        {
          "concept": "summarization evaluation",
          "relevance": 0.63
        },
        {
          "concept": "automatic metrics",
          "relevance": 0.629
        },
        {
          "concept": "human annotators",
          "relevance": 0.625
        },
        {
          "concept": "news dataset",
          "relevance": 0.622
        },
        {
          "concept": "summarization",
          "relevance": 0.602
        },
        {
          "concept": "human judgment",
          "relevance": 0.595
        },
        {
          "concept": "unified format",
          "relevance": 0.58
        },
        {
          "concept": "metrics",
          "relevance": 0.557
        },
        {
          "concept": "dataset",
          "relevance": 0.535
        },
        {
          "concept": "evaluation method",
          "relevance": 0.521
        },
        {
          "concept": "CNN/DailyMail",
          "relevance": 0.496
        },
        {
          "concept": "model types",
          "relevance": 0.489
        },
        {
          "concept": "protocol",
          "relevance": 0.461
        },
        {
          "concept": "API",
          "relevance": 0.452
        },
        {
          "concept": "annotation",
          "relevance": 0.451
        },
        {
          "concept": "evaluation",
          "relevance": 0.446
        },
        {
          "concept": "toolkit",
          "relevance": 0.438
        },
        {
          "concept": "up-to-date studies",
          "relevance": 0.426
        },
        {
          "concept": "model",
          "relevance": 0.418
        },
        {
          "concept": "collection",
          "relevance": 0.418
        },
        {
          "concept": "text",
          "relevance": 0.407
        },
        {
          "concept": "model output",
          "relevance": 0.407
        },
        {
          "concept": "output",
          "relevance": 0.387
        },
        {
          "concept": "expert judges",
          "relevance": 0.386
        },
        {
          "concept": "summary",
          "relevance": 0.361
        },
        {
          "concept": "method",
          "relevance": 0.357
        },
        {
          "concept": "Abstract",
          "relevance": 0.34
        },
        {
          "concept": "research",
          "relevance": 0.329
        },
        {
          "concept": "dimensions",
          "relevance": 0.315
        },
        {
          "concept": "judgment",
          "relevance": 0.31
        },
        {
          "concept": "scarcity",
          "relevance": 0.299
        },
        {
          "concept": "consensus",
          "relevance": 0.297
        },
        {
          "concept": "judges",
          "relevance": 0.275
        },
        {
          "concept": "lack",
          "relevance": 0.271
        },
        {
          "concept": "lack of consensus",
          "relevance": 0.257
        },
        {
          "concept": "type",
          "relevance": 0.213
        },
        {
          "concept": "study",
          "relevance": 0.203
        },
        {
          "concept": "progression",
          "relevance": 0.201
        },
        {
          "concept": "formation",
          "relevance": 0.201
        },
        {
          "concept": "workers",
          "relevance": 0.199
        },
        {
          "concept": "inhibit progression",
          "relevance": 0.189
        }
      ]
    },
    {
      "paperId": "pub.1138445754",
      "doi": "10.1162/tacl_a_00381",
      "title": "Data-to-text Generation with Macro Planning",
      "year": 2021,
      "citationCount": 30,
      "fieldCitationRatio": 9.59,
      "abstract": "Abstract\n                  Recent approaches to data-to-text generation have adopted the very successful encoder-decoder architecture or variants thereof. These models generate text that is fluent (but often imprecise) and perform quite poorly at selecting appropriate content and ordering it coherently. To overcome some of these issues, we propose a neural model with a macro planning stage followed by a generation stage reminiscent of traditional methods which embrace separate modules for planning and surface realization. Macro plans represent high level organization of important content such as entities, events, and their interactions; they are learned from data and given as input to the generator. Extensive experiments on two data-to-text benchmarks (RotoWire and MLB) show that our approach outperforms competitive baselines in terms of automatic and human evaluation.",
      "reference_ids": [
        "pub.1098653543",
        "pub.1122290069",
        "pub.1122290588",
        "pub.1096025897",
        "pub.1099106144",
        "pub.1117659068",
        "pub.1038140272",
        "pub.1120612801",
        "pub.1098653447",
        "pub.1096025161",
        "pub.1015694236",
        "pub.1003959523",
        "pub.1099151192",
        "pub.1099239542",
        "pub.1100516923",
        "pub.1121024794",
        "pub.1039164248",
        "pub.1099239594",
        "pub.1121024787",
        "pub.1099113450",
        "pub.1129059410",
        "pub.1099166702",
        "pub.1117659390",
        "pub.1098713046",
        "pub.1042606509",
        "pub.1122290939",
        "pub.1124059238",
        "pub.1117659836",
        "pub.1100517464",
        "pub.1126624485",
        "pub.1025630552",
        "pub.1099151287",
        "pub.1122290327",
        "pub.1098668654",
        "pub.1122290551",
        "pub.1099113598",
        "pub.1099244389",
        "pub.1121574820",
        "pub.1104321227",
        "pub.1123570628",
        "pub.1105690140",
        "pub.1124059240",
        "pub.1122290338"
      ],
      "concepts_scores": [
        {
          "concept": "data-to-text generation",
          "relevance": 0.82
        },
        {
          "concept": "encoder-decoder architecture",
          "relevance": 0.685
        },
        {
          "concept": "competitive baselines",
          "relevance": 0.638
        },
        {
          "concept": "human evaluation",
          "relevance": 0.628
        },
        {
          "concept": "neural model",
          "relevance": 0.62
        },
        {
          "concept": "recent approaches",
          "relevance": 0.588
        },
        {
          "concept": "Abstract Recent approaches",
          "relevance": 0.556
        },
        {
          "concept": "traditional methods",
          "relevance": 0.538
        },
        {
          "concept": "surface realization",
          "relevance": 0.526
        },
        {
          "concept": "generation stage",
          "relevance": 0.516
        },
        {
          "concept": "architecture",
          "relevance": 0.464
        },
        {
          "concept": "benchmarks",
          "relevance": 0.456
        },
        {
          "concept": "planning stage",
          "relevance": 0.403
        },
        {
          "concept": "generation",
          "relevance": 0.397
        },
        {
          "concept": "model",
          "relevance": 0.396
        },
        {
          "concept": "planning",
          "relevance": 0.392
        },
        {
          "concept": "modulation",
          "relevance": 0.386
        },
        {
          "concept": "macro-planning",
          "relevance": 0.385
        },
        {
          "concept": "entities",
          "relevance": 0.373
        },
        {
          "concept": "issues",
          "relevance": 0.37
        },
        {
          "concept": "method",
          "relevance": 0.362
        },
        {
          "concept": "evaluation",
          "relevance": 0.362
        },
        {
          "concept": "realization",
          "relevance": 0.36
        },
        {
          "concept": "experiments",
          "relevance": 0.343
        },
        {
          "concept": "data",
          "relevance": 0.327
        },
        {
          "concept": "variants",
          "relevance": 0.303
        },
        {
          "concept": "Abstract",
          "relevance": 0.297
        },
        {
          "concept": "content",
          "relevance": 0.297
        },
        {
          "concept": "stage",
          "relevance": 0.28
        },
        {
          "concept": "organization",
          "relevance": 0.258
        },
        {
          "concept": "events",
          "relevance": 0.257
        },
        {
          "concept": "macro-",
          "relevance": 0.255
        },
        {
          "concept": "interaction",
          "relevance": 0.253
        },
        {
          "concept": "baseline",
          "relevance": 0.253
        },
        {
          "concept": "surface",
          "relevance": 0.242
        },
        {
          "concept": "approach",
          "relevance": 0.217
        }
      ]
    },
    {
      "paperId": "pub.1120612801",
      "doi": "10.1609/aaai.v33i01.33016908",
      "title": "Data-to-Text Generation with Content Selection and Planning",
      "year": 2019,
      "citationCount": 142,
      "fieldCitationRatio": 34.03,
      "abstract": "Recent advances in data-to-text generation have led to the use of large-scale datasets and neural network models which are trained end-to-end, without explicitly modeling what to say and in what order. In this work, we present a neural network architecture which incorporates content selection and planning without sacrificing end-to-end training. We decompose the generation task into two stages. Given a corpus of data records (paired with descriptive documents), we first generate a content plan highlighting which information should be mentioned and in which order and then generate the document while taking the content plan into account. Automatic and human-based evaluation experiments show that our model1 outperforms strong baselines improving the state-of-the-art on the recently released RotoWIRE dataset.",
      "reference_ids": [
        "pub.1039164248",
        "pub.1025630552",
        "pub.1105690140",
        "pub.1052094181",
        "pub.1042606509",
        "pub.1096025779",
        "pub.1015694236",
        "pub.1105689891",
        "pub.1098713046",
        "pub.1104321227",
        "pub.1030556430",
        "pub.1099239542"
      ],
      "concepts_scores": [
        {
          "concept": "data-to-text generation",
          "relevance": 0.83
        },
        {
          "concept": "end-to-end training",
          "relevance": 0.715
        },
        {
          "concept": "trained end-to-end",
          "relevance": 0.714
        },
        {
          "concept": "neural network architecture",
          "relevance": 0.691
        },
        {
          "concept": "content selection",
          "relevance": 0.689
        },
        {
          "concept": "data-to-text",
          "relevance": 0.688
        },
        {
          "concept": "large-scale datasets",
          "relevance": 0.682
        },
        {
          "concept": "end-to-end",
          "relevance": 0.68
        },
        {
          "concept": "neural network model",
          "relevance": 0.669
        },
        {
          "concept": "content planning",
          "relevance": 0.647
        },
        {
          "concept": "ROTOWIRE dataset",
          "relevance": 0.647
        },
        {
          "concept": "network architecture",
          "relevance": 0.637
        },
        {
          "concept": "evaluation experiments",
          "relevance": 0.613
        },
        {
          "concept": "generation task",
          "relevance": 0.603
        },
        {
          "concept": "network model",
          "relevance": 0.602
        },
        {
          "concept": "dataset",
          "relevance": 0.548
        },
        {
          "concept": "data records",
          "relevance": 0.539
        },
        {
          "concept": "ROTOWIRE",
          "relevance": 0.509
        },
        {
          "concept": "architecture",
          "relevance": 0.47
        },
        {
          "concept": "task",
          "relevance": 0.454
        },
        {
          "concept": "corpus",
          "relevance": 0.43
        },
        {
          "concept": "information",
          "relevance": 0.419
        },
        {
          "concept": "documents",
          "relevance": 0.419
        },
        {
          "concept": "training",
          "relevance": 0.413
        },
        {
          "concept": "planning",
          "relevance": 0.404
        },
        {
          "concept": "selection",
          "relevance": 0.401
        },
        {
          "concept": "generation",
          "relevance": 0.395
        },
        {
          "concept": "experiments",
          "relevance": 0.347
        },
        {
          "concept": "model",
          "relevance": 0.346
        },
        {
          "concept": "content",
          "relevance": 0.322
        },
        {
          "concept": "model1",
          "relevance": 0.318
        },
        {
          "concept": "records",
          "relevance": 0.293
        },
        {
          "concept": "baseline",
          "relevance": 0.257
        },
        {
          "concept": "stage",
          "relevance": 0.245
        }
      ]
    },
    {
      "paperId": "pub.1042606509",
      "doi": "10.1017/s1351324997001502",
      "title": "Building applied natural language generation systems",
      "year": 1997,
      "citationCount": 318,
      "fieldCitationRatio": NaN,
      "abstract": "In this article, we give an overview of Natural Language Generation (NLG) from an applied system-building perspective. The article includes a discussion of when NLG techniques should be used; suggestions for carrying out requirements analyses; and a description of the basic NLG tasks of content determination, discourse planning, sentence aggregation, lexicalization, referring expression generation, and linguistic realisation. Throughout, the emphasis is on established techniques that can be used to build simple but practical working systems now. We also provide pointers to techniques in the literature that are appropriate for more complicated scenarios.",
      "reference_ids": [
        "pub.1032004886",
        "pub.1020809816",
        "pub.1005287009",
        "pub.1041452964",
        "pub.1043147238",
        "pub.1020926924",
        "pub.1022029791",
        "pub.1020760244",
        "pub.1023231653",
        "pub.1025630552",
        "pub.1042067399",
        "pub.1028327370",
        "pub.1004683410",
        "pub.1044084883",
        "pub.1061205001",
        "pub.1099174565",
        "pub.1023400219",
        "pub.1099240012"
      ],
      "concepts_scores": [
        {
          "concept": "natural language generation",
          "relevance": 0.724
        },
        {
          "concept": "natural language generation system",
          "relevance": 0.61
        },
        {
          "concept": "language generation system",
          "relevance": 0.599
        },
        {
          "concept": "natural language generation tasks",
          "relevance": 0.594
        },
        {
          "concept": "natural language generation techniques",
          "relevance": 0.589
        },
        {
          "concept": "linguistic realisations",
          "relevance": 0.564
        },
        {
          "concept": "discourse planning",
          "relevance": 0.555
        },
        {
          "concept": "language generation",
          "relevance": 0.546
        },
        {
          "concept": "expression generation",
          "relevance": 0.533
        },
        {
          "concept": "requirements analysis",
          "relevance": 0.523
        },
        {
          "concept": "complicated scenarios",
          "relevance": 0.486
        },
        {
          "concept": "lexicalization",
          "relevance": 0.442
        },
        {
          "concept": "work systems",
          "relevance": 0.442
        },
        {
          "concept": "discourse",
          "relevance": 0.434
        },
        {
          "concept": "sentences",
          "relevance": 0.434
        },
        {
          "concept": "article",
          "relevance": 0.379
        },
        {
          "concept": "technique",
          "relevance": 0.377
        },
        {
          "concept": "realisation",
          "relevance": 0.372
        },
        {
          "concept": "discussion",
          "relevance": 0.368
        },
        {
          "concept": "system",
          "relevance": 0.365
        },
        {
          "concept": "perspective",
          "relevance": 0.362
        },
        {
          "concept": "scenarios",
          "relevance": 0.361
        },
        {
          "concept": "requirements",
          "relevance": 0.344
        },
        {
          "concept": "generation system",
          "relevance": 0.343
        },
        {
          "concept": "work",
          "relevance": 0.343
        },
        {
          "concept": "suggestions",
          "relevance": 0.342
        },
        {
          "concept": "literature",
          "relevance": 0.32
        },
        {
          "concept": "generation",
          "relevance": 0.313
        },
        {
          "concept": "description",
          "relevance": 0.311
        },
        {
          "concept": "overview",
          "relevance": 0.282
        },
        {
          "concept": "planning",
          "relevance": 0.272
        },
        {
          "concept": "content determination",
          "relevance": 0.25
        },
        {
          "concept": "analysis",
          "relevance": 0.246
        },
        {
          "concept": "aggregation",
          "relevance": 0.243
        },
        {
          "concept": "expression",
          "relevance": 0.214
        },
        {
          "concept": "determination",
          "relevance": 0.153
        }
      ]
    },
    {
      "paperId": "pub.1025630552",
      "doi": "10.1016/0004-3702(93)90021-3",
      "title": "Automated discourse generation using discourse structure relations",
      "year": 1993,
      "citationCount": 142,
      "fieldCitationRatio": NaN,
      "abstract": "This paper summarizes work over the past five years on the automated planning and generation of multisentence texts using discourse structure relations, placing it in context of ongoing efforts by computational linguists and linguists to understand the structure of discourse. Based on a series of studies by the author and others, the paper describes how the orientation of generation toward communicative intentions illuminates the central structural role played by intersegment discourse relations. It outlines several facets of discourse structure relations as they are required by and used in text planners—their nature, number, and extension to associated tasks such as sentence planning and text formatting.",
      "reference_ids": [
        "pub.1069812877",
        "pub.1099166711",
        "pub.1037303786",
        "pub.1000496983",
        "pub.1005287009",
        "pub.1004383799",
        "pub.1070242203",
        "pub.1008972089",
        "pub.1011045038",
        "pub.1099166712",
        "pub.1099166671",
        "pub.1046731074",
        "pub.1032327158",
        "pub.1036982275",
        "pub.1053325846",
        "pub.1035713675",
        "pub.1005152511",
        "pub.1021644034",
        "pub.1028832653",
        "pub.1096912999",
        "pub.1035048203",
        "pub.1099166710",
        "pub.1027495752",
        "pub.1053410727",
        "pub.1099166713",
        "pub.1031101672",
        "pub.1050987771",
        "pub.1001593820",
        "pub.1026618176",
        "pub.1020609782",
        "pub.1028327370",
        "pub.1031947905",
        "pub.1099166608",
        "pub.1099166555",
        "pub.1021691054",
        "pub.1034537941",
        "pub.1124059241",
        "pub.1052902278",
        "pub.1006047926",
        "pub.1091750560",
        "pub.1098678735",
        "pub.1013519494",
        "pub.1024417107",
        "pub.1032278878",
        "pub.1038349124"
      ],
      "concepts_scores": [
        {
          "concept": "discourse structure relations",
          "relevance": 0.705
        },
        {
          "concept": "structure of discourse",
          "relevance": 0.598
        },
        {
          "concept": "structural relations",
          "relevance": 0.558
        },
        {
          "concept": "discourse generation",
          "relevance": 0.553
        },
        {
          "concept": "communicative intentions",
          "relevance": 0.553
        },
        {
          "concept": "computational linguistics",
          "relevance": 0.55
        },
        {
          "concept": "discourse relations",
          "relevance": 0.55
        },
        {
          "concept": "sentence planning",
          "relevance": 0.547
        },
        {
          "concept": "discourse",
          "relevance": 0.529
        },
        {
          "concept": "central structural role",
          "relevance": 0.519
        },
        {
          "concept": "linguistics",
          "relevance": 0.506
        },
        {
          "concept": "automated planning",
          "relevance": 0.43
        },
        {
          "concept": "sentences",
          "relevance": 0.428
        },
        {
          "concept": "text",
          "relevance": 0.425
        },
        {
          "concept": "relations",
          "relevance": 0.42
        },
        {
          "concept": "series of studies",
          "relevance": 0.388
        },
        {
          "concept": "authors",
          "relevance": 0.347
        },
        {
          "concept": "intention",
          "relevance": 0.332
        },
        {
          "concept": "task",
          "relevance": 0.323
        },
        {
          "concept": "nature",
          "relevance": 0.305
        },
        {
          "concept": "role",
          "relevance": 0.293
        },
        {
          "concept": "planning",
          "relevance": 0.287
        },
        {
          "concept": "paper",
          "relevance": 0.284
        },
        {
          "concept": "generation",
          "relevance": 0.26
        },
        {
          "concept": "extension",
          "relevance": 0.259
        },
        {
          "concept": "orientation",
          "relevance": 0.257
        },
        {
          "concept": "structural role",
          "relevance": 0.255
        },
        {
          "concept": "study",
          "relevance": 0.242
        },
        {
          "concept": "years",
          "relevance": 0.221
        },
        {
          "concept": "series",
          "relevance": 0.208
        },
        {
          "concept": "structure",
          "relevance": 0.199
        },
        {
          "concept": "formation",
          "relevance": 0.19
        },
        {
          "concept": "number",
          "relevance": 0.187
        }
      ]
    },
    {
      "paperId": "pub.1126624485",
      "doi": "10.1007/978-3-030-45439-5_5",
      "title": "A Hierarchical Model for Data-to-Text Generation",
      "year": 2020,
      "citationCount": 35,
      "fieldCitationRatio": 7.98,
      "abstract": "Transcribing structured data into natural language descriptions has emerged as a challenging task, referred to as “data-to-text”. These structures generally regroup multiple elements, as well as their attributes. Most attempts rely on translation encoder-decoder methods which linearize elements into a sequence. This however loses most of the structure contained in the data. In this work, we propose to overpass this limitation with a hierarchical model that encodes the data-structure at the element-level and the structure level. Evaluations on RotoWire show the effectiveness of our model w.r.t. qualitative and quantitative metrics.",
      "reference_ids": [
        "pub.1099106144",
        "pub.1099115153",
        "pub.1117659068",
        "pub.1112367816",
        "pub.1104321294",
        "pub.1096025521",
        "pub.1101242761",
        "pub.1120624968",
        "pub.1067368216",
        "pub.1099113450",
        "pub.1120612801",
        "pub.1117659002",
        "pub.1118155269",
        "pub.1127294909",
        "pub.1100516923",
        "pub.1047976186",
        "pub.1096025897",
        "pub.1118155219",
        "pub.1121024787",
        "pub.1100517458",
        "pub.1148956479",
        "pub.1096143767",
        "pub.1099239594",
        "pub.1105690140",
        "pub.1051608226",
        "pub.1098653447",
        "pub.1091601724",
        "pub.1099236163",
        "pub.1022036358",
        "pub.1028327370",
        "pub.1117660390"
      ],
      "concepts_scores": [
        {
          "concept": "data-to-text",
          "relevance": 0.768
        },
        {
          "concept": "data-to-text generation",
          "relevance": 0.691
        },
        {
          "concept": "transcribing structured data",
          "relevance": 0.673
        },
        {
          "concept": "encoder-decoder methods",
          "relevance": 0.673
        },
        {
          "concept": "natural language descriptions",
          "relevance": 0.667
        },
        {
          "concept": "language description",
          "relevance": 0.606
        },
        {
          "concept": "data structures",
          "relevance": 0.606
        },
        {
          "concept": "model w.",
          "relevance": 0.597
        },
        {
          "concept": "hierarchical model",
          "relevance": 0.558
        },
        {
          "concept": "ROTOWIRE",
          "relevance": 0.491
        },
        {
          "concept": "structural data",
          "relevance": 0.476
        },
        {
          "concept": "task",
          "relevance": 0.437
        },
        {
          "concept": "hierarchically",
          "relevance": 0.414
        },
        {
          "concept": "linear elements",
          "relevance": 0.407
        },
        {
          "concept": "model",
          "relevance": 0.405
        },
        {
          "concept": "multiple elements",
          "relevance": 0.402
        },
        {
          "concept": "attributes",
          "relevance": 0.388
        },
        {
          "concept": "data",
          "relevance": 0.369
        },
        {
          "concept": "method",
          "relevance": 0.353
        },
        {
          "concept": "evaluation",
          "relevance": 0.353
        },
        {
          "concept": "description",
          "relevance": 0.33
        },
        {
          "concept": "translation",
          "relevance": 0.329
        },
        {
          "concept": "elements",
          "relevance": 0.327
        },
        {
          "concept": "structural level",
          "relevance": 0.319
        },
        {
          "concept": "generation",
          "relevance": 0.313
        },
        {
          "concept": "structure",
          "relevance": 0.311
        },
        {
          "concept": "limitations",
          "relevance": 0.287
        },
        {
          "concept": "element levels",
          "relevance": 0.273
        },
        {
          "concept": "sequence",
          "relevance": 0.269
        },
        {
          "concept": "levels",
          "relevance": 0.203
        },
        {
          "concept": "effect",
          "relevance": 0.2
        }
      ]
    },
    {
      "paperId": "pub.1099239594",
      "doi": "10.3115/1073083.1073135",
      "title": "BLEU: a method for automatic evaluation of machine translation",
      "year": 2001,
      "citationCount": 11516,
      "fieldCitationRatio": 3629.45,
      "abstract": "Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.",
      "reference_ids": NaN,
      "concepts_scores": [
        {
          "concept": "evaluation of machine translation",
          "relevance": 0.757
        },
        {
          "concept": "human evaluation",
          "relevance": 0.713
        },
        {
          "concept": "machine translation",
          "relevance": 0.682
        },
        {
          "concept": "automatic evaluation of machine translation",
          "relevance": 0.667
        },
        {
          "concept": "human evaluation of machine translation",
          "relevance": 0.649
        },
        {
          "concept": "machine translation evaluation",
          "relevance": 0.641
        },
        {
          "concept": "language-independent",
          "relevance": 0.582
        },
        {
          "concept": "automatic evaluation",
          "relevance": 0.571
        },
        {
          "concept": "human judges",
          "relevance": 0.568
        },
        {
          "concept": "translation evaluation",
          "relevance": 0.555
        },
        {
          "concept": "human labor",
          "relevance": 0.505
        },
        {
          "concept": "translation",
          "relevance": 0.474
        },
        {
          "concept": "evaluation",
          "relevance": 0.418
        },
        {
          "concept": "method",
          "relevance": 0.41
        },
        {
          "concept": "understudies",
          "relevance": 0.407
        },
        {
          "concept": "cost",
          "relevance": 0.349
        },
        {
          "concept": "judges",
          "relevance": 0.333
        },
        {
          "concept": "frequent evaluation",
          "relevance": 0.307
        },
        {
          "concept": "labor",
          "relevance": 0.302
        },
        {
          "concept": "months",
          "relevance": 0.249
        },
        {
          "concept": "marginal cost",
          "relevance": 0.227
        }
      ]
    },
    {
      "paperId": "pub.1099236163",
      "doi": "10.3115/1075218.1075255",
      "title": "An improved error model for noisy channel spelling correction",
      "year": 2000,
      "citationCount": 285,
      "fieldCitationRatio": 92.57,
      "abstract": "The noisy channel model has been applied to a wide range of problems, including spelling correction. These models consist of two components: a source model and a channel model. Very little research has gone into improving the channel model for spelling correction. This paper describes a new channel model for spelling correction, based on generic string to string edits. Using this model gives significant performance improvements compared to previously proposed models.",
      "reference_ids": [
        "pub.1045958859",
        "pub.1003629836",
        "pub.1045913764",
        "pub.1049869810",
        "pub.1009790886",
        "pub.1049170127",
        "pub.1041939294",
        "pub.1014052572",
        "pub.1019558950"
      ],
      "concepts_scores": [
        {
          "concept": "channel model",
          "relevance": 0.662
        },
        {
          "concept": "spelling correction",
          "relevance": 0.66
        },
        {
          "concept": "noisy channel model",
          "relevance": 0.579
        },
        {
          "concept": "significant performance improvement",
          "relevance": 0.576
        },
        {
          "concept": "string editing",
          "relevance": 0.526
        },
        {
          "concept": "performance improvement",
          "relevance": 0.511
        },
        {
          "concept": "proposed models",
          "relevance": 0.466
        },
        {
          "concept": "error model",
          "relevance": 0.452
        },
        {
          "concept": "source model",
          "relevance": 0.445
        },
        {
          "concept": "channel",
          "relevance": 0.427
        },
        {
          "concept": "improved error model",
          "relevance": 0.411
        },
        {
          "concept": "model",
          "relevance": 0.367
        },
        {
          "concept": "correction",
          "relevance": 0.367
        },
        {
          "concept": "string",
          "relevance": 0.326
        },
        {
          "concept": "editing",
          "relevance": 0.313
        },
        {
          "concept": "spelling",
          "relevance": 0.293
        },
        {
          "concept": "research",
          "relevance": 0.287
        },
        {
          "concept": "improvement",
          "relevance": 0.283
        },
        {
          "concept": "problem",
          "relevance": 0.28
        },
        {
          "concept": "components",
          "relevance": 0.276
        },
        {
          "concept": "source",
          "relevance": 0.252
        },
        {
          "concept": "paper",
          "relevance": 0.216
        }
      ]
    }
  ],
  "evolution_links": [
    {
      "source": "pub.1152843639",
      "target": "pub.1145454307",
      "source_title": "Survey of Hallucination in Natural Language Generation",
      "target_title": "SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization"
    },
    {
      "source": "pub.1145454307",
      "target": "pub.1137573792",
      "source_title": "SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization",
      "target_title": "SummEval: Re-evaluating Summarization Evaluation"
    },
    {
      "source": "pub.1152843639",
      "target": "pub.1138445754",
      "source_title": "Survey of Hallucination in Natural Language Generation",
      "target_title": "Data-to-text Generation with Macro Planning"
    },
    {
      "source": "pub.1138445754",
      "target": "pub.1120612801",
      "source_title": "Data-to-text Generation with Macro Planning",
      "target_title": "Data-to-Text Generation with Content Selection and Planning"
    },
    {
      "source": "pub.1120612801",
      "target": "pub.1042606509",
      "source_title": "Data-to-Text Generation with Content Selection and Planning",
      "target_title": "Building applied natural language generation systems"
    },
    {
      "source": "pub.1120612801",
      "target": "pub.1025630552",
      "source_title": "Data-to-Text Generation with Content Selection and Planning",
      "target_title": "Automated discourse generation using discourse structure relations"
    },
    {
      "source": "pub.1138445754",
      "target": "pub.1126624485",
      "source_title": "Data-to-text Generation with Macro Planning",
      "target_title": "A Hierarchical Model for Data-to-Text Generation"
    },
    {
      "source": "pub.1126624485",
      "target": "pub.1099239594",
      "source_title": "A Hierarchical Model for Data-to-Text Generation",
      "target_title": "BLEU: a method for automatic evaluation of machine translation"
    },
    {
      "source": "pub.1126624485",
      "target": "pub.1099236163",
      "source_title": "A Hierarchical Model for Data-to-Text Generation",
      "target_title": "An improved error model for noisy channel spelling correction"
    }
  ]
}