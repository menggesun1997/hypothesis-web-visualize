{
  "before_idea": {
    "title": "Contextualizing Self-Consistency Metrics with Online Health Discourse Analysis",
    "Problem_Statement": "Current intrinsic evaluation metrics like self-consistency and perplexity treat model outputs in isolation, lacking sensitivity to social context and discourse dynamics prevalent in online health communities. This inhibits evaluating LLMs' real-world social impact relevance, especially in digital health.",
    "Motivation": "This research addresses the external/novel gap between online spaces and social sciences, particularly integrating discourse moves and digital health concepts with intrinsic LLM evaluation metrics, as identified in the map's hidden bridges. It moves beyond static perplexity to a context-aware evaluation.",
    "Proposed_Method": "Develop a hybrid intrinsic evaluation metric that augments self-consistency with discourse move recognition modules trained on health-focused online forums. The method extracts discourse features (e.g., question, affirmation, caution) and computes context-conditioned consistency scores reflecting alignment with community norms and social support dynamics. This combines qualitative discourse analysis methodologies from social sciences with computational LLM metrics to generate socially-informed evaluation results.",
    "Step_by_Step_Experiment_Plan": "1. Collect datasets from online health forums, Reddit health communities, and digital health Q&A platforms.\n2. Annotate discourse moves using expert social science coding protocols.\n3. Fine-tune discourse move classifiers.\n4. Implement self-consistency evaluation modified to weight responses by discourse move types.\n5. Baseline against standard self-consistency and perplexity.\n6. Evaluate correlations with human social impact assessments and domain expert ratings.\n7. Perform ablation to isolate each component’s contribution.",
    "Test_Case_Examples": "Input: \"What are safe treatments for mild anxiety during pregnancy?\" \nExpected Output: Self-consistency scores differ when model answers repeatedly caution and cite social support sources vs. generic medical advice. Higher contextual self-consistency when responses align with discourse moves encouraging community care and respect for psychosocial distress.",
    "Fallback_Plan": "If discourse move recognition proves noisy, fallback to simpler sentiment analysis integration. Alternatively, use rule-based lexicons of social support terms as proxies. Conduct user studies to validate metric relevance if computational correlations falter."
  },
  "after_idea": {
    "ideas": [
      {
        "title": "Contextualizing Self-Consistency Metrics with Discourse-Driven Evaluation in Online Health Communities",
        "Problem_Statement": "Current intrinsic evaluation metrics for large language models (LLMs), such as self-consistency and perplexity, predominantly assess outputs in isolation, lacking integration of the nuanced social context and discourse dynamics inherent in online health communities. This gap limits the ability to effectively evaluate LLM outputs' alignment with community norms, social support mechanisms, and health communication effectiveness, thereby constraining assessments of their real-world social impact in digital health domains.",
        "Motivation": "While existing metrics provide valuable intrinsic measures, they insufficiently capture how LLM outputs resonate within complex, diverse online health interactions, where discourse moves such as questions, affirmations, and cautions critically shape user perception and social support quality. Our approach addresses this gap by systematically incorporating discourse move recognition into evaluation metrics, grounded in a rich theoretical framework and preliminary qualitative evidence linking discourse moves to user perceptions of social support and health communication efficacy. Unlike simpler sentiment or thematic weighting methods, our method emphasizes discourse moves as key predictors of performance expectancy and technological acceptance in digital health settings. This novel, socially-informed evaluation bridges computational linguistics and health informatics, enhancing understanding and measurement of LLM social impact, with explicit consideration of variations across communities and contexts. By integrating concepts like structural equation modeling and determinants of user intention from the Technology Acceptance Model, our proposal advances evaluation methodologies beyond the current state-of-the-art, addressing existing limitations identified in the novelty screening.",
        "Proposed_Method": "We propose a hybrid evaluation framework that enriches self-consistency metrics by conditioning them on discourse move recognition modules specifically trained on diverse online health community data. \n\n1. Discourse Move Recognition: Using deep neural networks fine-tuned with annotated health forum corpora, we identify discourse moves (e.g., question, affirmation, caution, elaboration) validated through expert coding and statistical modeling. \n\n2. Theoretical Justification & Modeling: We incorporate structural equation modeling to empirically validate the influence of identified discourse moves on users' performance expectancy and intention to trust and utilize LLM-generated health information, leveraging constructs from the Technology Acceptance Model and integrating hedonic motivation and effort expectancy as predictors.\n\n3. Context-Conditioned Metric: Self-consistency scores are weighted by discourse move types, reflecting their differential roles in fostering social support, technological transparency, and effective communication in digital health. This weighting is dynamically adjusted based on community-specific discourse norms learned from data, enabling adaptability to discourse heterogeneity.\n\n4. Mixed-Methods Validation: The approach is complemented by a mixed-methods study involving mental health professionals and community members to triangulate computational metrics with qualitative perceptions of social support and communication effectiveness.\n\nThis interdisciplinary method surpasses simpler sentiment or thematic weighting by focusing on discourse structure and social-cognitive determinants, yielding a robust, socially grounded evaluation metric that meaningfully improves assessment of LLM outputs in health contexts.",
        "Step_by_Step_Experiment_Plan": "1. Data Collection: Compile datasets from diverse online health communities, including Reddit health forums, digital health Q&A sites, and specialized mental health discussion groups.\n2. Annotation: Employ expert social scientists and health informatics specialists to annotate discourse moves using standardized coding protocols, ensuring inclusion of diverse community norms.\n3. Classifier Training: Train and validate deep neural network classifiers for targeted discourse move recognition; perform error analysis and iterative refinement.\n4. Structural Equation Modeling: Conduct SEM analyses linking discourse move prevalence with survey-based measures of users' performance expectancy, intention to use, trust, and hedonic motivation, collected via mixed-method studies.\n5. Metric Implementation: Develop the discourse-weighted self-consistency evaluation, incorporating community-adaptive weighting schemes derived from SEM results.\n6. Benchmarking: Compare the new metric against standard self-consistency and perplexity metrics across datasets.\n7. Human Evaluation: Collaborate with mental health professionals and community users to assess correlation of metric outcomes with perceived social support quality and communication effectiveness.\n8. Ablation Study: Systematically remove or alter individual components (discourse moves, weighting strategies, community adaptation) to evaluate their impact.\n9. Fallback & Sensitivity Analysis: If discourse move recognition proves unreliable for particular communities, test fallback approaches using sentiment analysis and lexicons, and analyze sensitivity of metric performance.\n",
        "Test_Case_Examples": "Input: \"What are safe treatments for mild anxiety during pregnancy?\"\n- Scenario A: Model responses repeatedly incorporate cautions about medication risks, affirm community support resources, and clarify psychosocial considerations.\n- Scenario B: Model responses provide generic medical advice without engagement in discourse moves.\nExpected Outcome:\n- Our discourse-weighted self-consistency scores are higher and more stable in Scenario A reflecting meaningful alignment with supportive, cautious discourse norms valued in the community.\n- Standard metrics fail to differentiate the nuanced quality and social support orientation between these scenarios, demonstrating the advantage of our approach.",
        "Fallback_Plan": "If discourse move classification accuracy does not meet robustness thresholds due to community diversity or annotation challenges, we will pivot to a fallback approach incorporating sentiment analysis and rule-based lexicons of social support and cautionary terminology as proxies for discourse moves. Additionally, we will enhance the mixed-methods study component to include comprehensive user and expert feedback to validate metric relevance and interpretability independently of discourse classification fidelity. Exploratory unsupervised or semi-supervised approaches will also be considered to capture latent discourse features without heavy annotation burdens, ensuring metric adaptability and sustained social impact relevance."
      }
    ]
  },
  "feedback_results": {
    "keywords_query": [
      "self-consistency metrics",
      "online health discourse",
      "LLM evaluation",
      "social context",
      "digital health",
      "intrinsic evaluation"
    ],
    "direct_cooccurrence_count": 4147,
    "min_pmi_score_value": 2.529915813198278,
    "avg_pmi_score_value": 3.8888544825794797,
    "novelty": "NOV-COMPETITIVE",
    "future_suggestions_categories": [
      "32 Biomedical and Clinical Sciences",
      "52 Psychology",
      "3901 Curriculum and Pedagogy"
    ],
    "future_suggestions_concepts": [
      "deep neural networks",
      "structural equation modeling",
      "performance expectancy",
      "determinants of users’ intention",
      "interactive perception",
      "predictors of performance expectancy",
      "influence of hedonic motivation",
      "technological transparency",
      "hedonic motivation",
      "evaluation metrics",
      "mental health professionals",
      "traditional technology acceptance model",
      "School of Education",
      "University School of Education",
      "mixed-methods study",
      "self-regulated learning",
      "Biomedical and Health Informatics",
      "effort expectancy"
    ],
    "internal_review": {
      "critiques": [
        {
          "feedback_code": "SOU-ASSUMPTION",
          "feedback_content": "The core assumption that discourse moves such as question, affirmation, and caution can be reliably recognized and meaningfully weighted in self-consistency metrics needs stronger empirical justification upfront. Online health discourse is highly diverse and noisy, and the social impact relevance of these discourse moves might vary significantly across communities. The proposal should explicitly clarify and support why conditioning self-consistency on these specific discourse moves will systematically improve evaluation of LLM outputs in digital health, distinguishing this from simpler sentiment or thematic weighting approaches. Addressing this will strengthen the soundness of the foundational premise underlying the method's expected benefits and avoid overgeneralization risks inherent in social discourse modeling for LLM evaluation purposes. Consider elaborating on theoretical or preliminary qualitative evidence that links discourse moves to user perception of social support and health communication effectiveness, beyond the current social sciences coding references, to solidify this assumption's validity and clarity in the Proposed_Method section of the proposal."
        }
      ]
    }
  }
}