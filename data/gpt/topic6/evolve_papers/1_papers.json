{
  "papers": [
    {
      "paperId": "pub.1173010337",
      "doi": "10.1109/tse.2024.3411928",
      "title": "LUNA: A Model-Based Universal Analysis Framework for Large Language Models",
      "year": 2024,
      "citationCount": 7,
      "fieldCitationRatio": NaN,
      "abstract": "Over the past decade, Artificial Intelligence (AI) has had great success recently and is being used in a wide range of academic and industrial fields. More recently, Large Language Models (LLMs) have made rapid advancements that have propelled AI to a new level, enabling and empowering even more diverse applications and industrial domains with intelligence, particularly in areas like software engineering and natural language processing. Nevertheless, a number of emerging trustworthiness concerns and issues exhibited in LLMs, e.g., robustness and hallucination, have already recently received much attention, without properly solving which the widespread adoption of LLMs could be greatly hindered in practice. The distinctive characteristics of LLMs, such as the self-attention mechanism, extremely large neural network scale, and autoregressive generation usage contexts, differ from classic AI software based on Convolutional Neural Networks and Recurrent Neural Networks and present new challenges for quality analysis. Up to the present, it still lacks universal and systematic analysis techniques for LLMs despite the urgent industrial demand across diverse domains. Towards bridging such a gap, in this paper, we initiate an early exploratory study and propose a universal analysis framework for LLMs, named LUNA, which is designed to be general and extensible and enables versatile analysis of LLMs from multiple quality perspectives in a human-interpretable manner. In particular, we first leverage the data from desired trustworthiness perspectives to construct an abstract model as an auxiliary analysis asset and proxy, which is empowered by various abstract model construction methods built-in LUNA. To assess the quality of the abstract model, we collect and define a number of evaluation metrics, aiming at both the abstract model level and the semantics level. Then, the semantics, which is the degree of satisfaction of the LLM w.r.t. the trustworthiness perspective, is bound to and enriches the abstract model with semantics, which enables more detailed analysis applications for diverse purposes, e.g., abnormal behavior detection. To better understand the potential usefulness of our analysis framework LUNA, we conduct a large-scale evaluation, the results of which demonstrate that 1) the abstract model has the potential to distinguish normal and abnormal behavior in LLM, 2) LUNA is effective for the real-world analysis of LLMs in practice, and the hyperparameter settings influence the performance, 3) different evaluation metrics are in different correlations with the analysis performance. In order to encourage further studies in the quality assurance of LLMs, we made all of the code and more detailed experimental results data available on the supplementary website of this paper https://sites.google.com/view/llm-luna.",
      "reference_ids": [
        "pub.1133174910",
        "pub.1009830327",
        "pub.1069893862",
        "pub.1153500306",
        "pub.1030131329",
        "pub.1111818053",
        "pub.1053401567",
        "pub.1152843639",
        "pub.1148899978",
        "pub.1139947961",
        "pub.1142488686",
        "pub.1134935926",
        "pub.1099151330",
        "pub.1153875873",
        "pub.1149257021",
        "pub.1140253467",
        "pub.1104321164",
        "pub.1110893725",
        "pub.1061218416",
        "pub.1174225619",
        "pub.1117659083",
        "pub.1162804688",
        "pub.1148898541",
        "pub.1143949641",
        "pub.1147477829",
        "pub.1150969295",
        "pub.1138840721",
        "pub.1096026172",
        "pub.1105386422",
        "pub.1169031165",
        "pub.1011120195",
        "pub.1021462929",
        "pub.1160172954",
        "pub.1166874087",
        "pub.1158361897",
        "pub.1091744995",
        "pub.1106260441",
        "pub.1149507899",
        "pub.1145901038",
        "pub.1169428166",
        "pub.1139947100",
        "pub.1095000174",
        "pub.1150209017",
        "pub.1114538820",
        "pub.1142776491",
        "pub.1101302565",
        "pub.1160717395",
        "pub.1008823158",
        "pub.1100551911",
        "pub.1151332162",
        "pub.1132675058",
        "pub.1150997559",
        "pub.1129757112",
        "pub.1021751435",
        "pub.1151709682",
        "pub.1169562619",
        "pub.1129756745",
        "pub.1160715392",
        "pub.1044318118",
        "pub.1121025488",
        "pub.1160766715",
        "pub.1059415839",
        "pub.1117659701",
        "pub.1026547604",
        "pub.1133174463",
        "pub.1149073079",
        "pub.1139579204",
        "pub.1148390762",
        "pub.1123866096",
        "pub.1148390933",
        "pub.1153372824",
        "pub.1121024672",
        "pub.1160643524",
        "pub.1168304308",
        "pub.1137865991",
        "pub.1157410140",
        "pub.1150861241",
        "pub.1147218299",
        "pub.1064408694",
        "pub.1168533982",
        "pub.1106260412",
        "pub.1149507921",
        "pub.1160719237",
        "pub.1166873008",
        "pub.1172955190",
        "pub.1148581733",
        "pub.1166872883",
        "pub.1160713483",
        "pub.1061158344",
        "pub.1098698150",
        "pub.1092570953",
        "pub.1016946568",
        "pub.1166873099",
        "pub.1168149665",
        "pub.1158636894",
        "pub.1010157474",
        "pub.1110028606",
        "pub.1149215241",
        "pub.1160722338",
        "pub.1120262019",
        "pub.1133175312",
        "pub.1149215192",
        "pub.1160651870",
        "pub.1148390672",
        "pub.1024610917",
        "pub.1149658132",
        "pub.1159792567",
        "pub.1163878636",
        "pub.1160651474",
        "pub.1003897036",
        "pub.1061385404",
        "pub.1159149016",
        "pub.1154263506",
        "pub.1154263398",
        "pub.1160718848",
        "pub.1156069812",
        "pub.1160647437",
        "pub.1141849313",
        "pub.1134914400",
        "pub.1175845134",
        "pub.1140253418",
        "pub.1149741066",
        "pub.1168377680",
        "pub.1143949474",
        "pub.1122290272",
        "pub.1163044197",
        "pub.1162691927",
        "pub.1144826152",
        "pub.1172779221",
        "pub.1149299491",
        "pub.1044522995",
        "pub.1154263446",
        "pub.1174224985",
        "pub.1001727638",
        "pub.1160653681",
        "pub.1106260426",
        "pub.1117946312",
        "pub.1123987127",
        "pub.1143949401",
        "pub.1163376142",
        "pub.1147514535",
        "pub.1149256987",
        "pub.1120600818",
        "pub.1140080916",
        "pub.1160714163",
        "pub.1129757334",
        "pub.1037368667",
        "pub.1132552360",
        "pub.1149507907",
        "pub.1168777865",
        "pub.1135710434",
        "pub.1154881766",
        "pub.1118769417",
        "pub.1110590164",
        "pub.1158403697",
        "pub.1150865782",
        "pub.1042997205",
        "pub.1157409389",
        "pub.1139579218",
        "pub.1131375770"
      ],
      "concepts_scores": [
        {
          "concept": "abstract model",
          "relevance": 0.752
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.751
        },
        {
          "concept": "language model",
          "relevance": 0.737
        },
        {
          "concept": "evaluation metrics",
          "relevance": 0.732
        },
        {
          "concept": "neural network",
          "relevance": 0.726
        },
        {
          "concept": "self-attention mechanism",
          "relevance": 0.692
        },
        {
          "concept": "recurrent neural network",
          "relevance": 0.691
        },
        {
          "concept": "abstract modeling level",
          "relevance": 0.689
        },
        {
          "concept": "convolutional neural network",
          "relevance": 0.687
        },
        {
          "concept": "natural language processing",
          "relevance": 0.685
        },
        {
          "concept": "neural network scale",
          "relevance": 0.681
        },
        {
          "concept": "software engineering",
          "relevance": 0.645
        },
        {
          "concept": "hyperparameter settings",
          "relevance": 0.638
        },
        {
          "concept": "analysis framework",
          "relevance": 0.631
        },
        {
          "concept": "usage contexts",
          "relevance": 0.63
        },
        {
          "concept": "language processing",
          "relevance": 0.623
        },
        {
          "concept": "trustworthiness concerns",
          "relevance": 0.622
        },
        {
          "concept": "large-scale evaluation",
          "relevance": 0.619
        },
        {
          "concept": "AI software",
          "relevance": 0.616
        },
        {
          "concept": "semantic level",
          "relevance": 0.616
        },
        {
          "concept": "diverse domains",
          "relevance": 0.615
        },
        {
          "concept": "industrial domains",
          "relevance": 0.614
        },
        {
          "concept": "analysis applications",
          "relevance": 0.605
        },
        {
          "concept": "network scale",
          "relevance": 0.601
        },
        {
          "concept": "semantics",
          "relevance": 0.596
        },
        {
          "concept": "model level",
          "relevance": 0.59
        },
        {
          "concept": "analysis performance",
          "relevance": 0.584
        },
        {
          "concept": "quality perspective",
          "relevance": 0.568
        },
        {
          "concept": "trustworthiness",
          "relevance": 0.559
        },
        {
          "concept": "intelligence",
          "relevance": 0.54
        },
        {
          "concept": "network",
          "relevance": 0.54
        },
        {
          "concept": "software",
          "relevance": 0.536
        },
        {
          "concept": "abnormal behavior",
          "relevance": 0.536
        },
        {
          "concept": "metrics",
          "relevance": 0.531
        },
        {
          "concept": "systematic analysis techniques",
          "relevance": 0.517
        },
        {
          "concept": "diverse applications",
          "relevance": 0.509
        },
        {
          "concept": "industrial fields",
          "relevance": 0.496
        },
        {
          "concept": "diverse purposes",
          "relevance": 0.494
        },
        {
          "concept": "hyperparameters",
          "relevance": 0.493
        },
        {
          "concept": "convolution",
          "relevance": 0.486
        },
        {
          "concept": "quality analysis",
          "relevance": 0.485
        },
        {
          "concept": "framework",
          "relevance": 0.484
        },
        {
          "concept": "language",
          "relevance": 0.482
        },
        {
          "concept": "performance",
          "relevance": 0.482
        },
        {
          "concept": "early exploratory studies",
          "relevance": 0.471
        },
        {
          "concept": "analysis techniques",
          "relevance": 0.467
        },
        {
          "concept": "LLM",
          "relevance": 0.462
        },
        {
          "concept": "code",
          "relevance": 0.461
        },
        {
          "concept": "domain",
          "relevance": 0.456
        },
        {
          "concept": "degree of satisfaction",
          "relevance": 0.456
        },
        {
          "concept": "Artificial",
          "relevance": 0.454
        },
        {
          "concept": "applications",
          "relevance": 0.454
        },
        {
          "concept": "robustness",
          "relevance": 0.449
        },
        {
          "concept": "quality assurance",
          "relevance": 0.449
        },
        {
          "concept": "evaluation",
          "relevance": 0.446
        },
        {
          "concept": "websites",
          "relevance": 0.438
        },
        {
          "concept": "results data",
          "relevance": 0.437
        },
        {
          "concept": "quality",
          "relevance": 0.433
        },
        {
          "concept": "model",
          "relevance": 0.432
        },
        {
          "concept": "real-world analysis",
          "relevance": 0.414
        },
        {
          "concept": "industrial demand",
          "relevance": 0.402
        },
        {
          "concept": "adoption",
          "relevance": 0.397
        },
        {
          "concept": "exploratory study",
          "relevance": 0.391
        },
        {
          "concept": "data",
          "relevance": 0.383
        },
        {
          "concept": "experimental results data",
          "relevance": 0.381
        },
        {
          "concept": "engineering",
          "relevance": 0.378
        },
        {
          "concept": "perspective",
          "relevance": 0.378
        },
        {
          "concept": "sets",
          "relevance": 0.377
        },
        {
          "concept": "issues",
          "relevance": 0.374
        },
        {
          "concept": "technique",
          "relevance": 0.372
        },
        {
          "concept": "context",
          "relevance": 0.343
        },
        {
          "concept": "advances",
          "relevance": 0.34
        },
        {
          "concept": "attention",
          "relevance": 0.331
        },
        {
          "concept": "assets",
          "relevance": 0.33
        },
        {
          "concept": "purposes",
          "relevance": 0.33
        },
        {
          "concept": "process",
          "relevance": 0.328
        },
        {
          "concept": "analysis",
          "relevance": 0.327
        },
        {
          "concept": "demand",
          "relevance": 0.324
        },
        {
          "concept": "proxies",
          "relevance": 0.322
        },
        {
          "concept": "success",
          "relevance": 0.319
        },
        {
          "concept": "results",
          "relevance": 0.318
        },
        {
          "concept": "practice",
          "relevance": 0.31
        },
        {
          "concept": "satisfaction",
          "relevance": 0.306
        },
        {
          "concept": "Luna",
          "relevance": 0.305
        },
        {
          "concept": "field",
          "relevance": 0.299
        },
        {
          "concept": "gap",
          "relevance": 0.289
        },
        {
          "concept": "concerns",
          "relevance": 0.284
        },
        {
          "concept": "behavior",
          "relevance": 0.27
        },
        {
          "concept": "characteristics",
          "relevance": 0.265
        },
        {
          "concept": "use",
          "relevance": 0.259
        },
        {
          "concept": "levels",
          "relevance": 0.256
        },
        {
          "concept": "potential use",
          "relevance": 0.25
        },
        {
          "concept": "mechanism",
          "relevance": 0.242
        },
        {
          "concept": "scale",
          "relevance": 0.241
        },
        {
          "concept": "hallucinations",
          "relevance": 0.24
        },
        {
          "concept": "degree",
          "relevance": 0.235
        },
        {
          "concept": "potential",
          "relevance": 0.222
        },
        {
          "concept": "study",
          "relevance": 0.219
        },
        {
          "concept": "correlation",
          "relevance": 0.219
        },
        {
          "concept": "recurrence",
          "relevance": 0.08
        }
      ]
    },
    {
      "paperId": "pub.1163376142",
      "doi": "10.1016/j.metrad.2023.100017",
      "title": "Summary of ChatGPT-Related research and perspective towards the future of large language models",
      "year": 2023,
      "citationCount": 570,
      "fieldCitationRatio": 360.72,
      "abstract": "This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and GPT-4) research, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs' adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT-related research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field.",
      "reference_ids": [
        "pub.1169640240",
        "pub.1078724256",
        "pub.1157618732",
        "pub.1162804688",
        "pub.1121377009",
        "pub.1166874504",
        "pub.1131470522",
        "pub.1153710853",
        "pub.1156504714",
        "pub.1157198221",
        "pub.1157954426",
        "pub.1124549128",
        "pub.1169640331",
        "pub.1120612821",
        "pub.1157891790",
        "pub.1160512280",
        "pub.1138337775",
        "pub.1154268382",
        "pub.1166873208",
        "pub.1157617446",
        "pub.1099106183",
        "pub.1013440088",
        "pub.1163045923",
        "pub.1164705743",
        "pub.1156207635",
        "pub.1069893862",
        "pub.1131675336",
        "pub.1122290536",
        "pub.1167962128",
        "pub.1158483299",
        "pub.1139947240",
        "pub.1156959061",
        "pub.1159883202",
        "pub.1159948202",
        "pub.1162804699",
        "pub.1160813867",
        "pub.1160651852",
        "pub.1155323044",
        "pub.1160408384",
        "pub.1116663009",
        "pub.1133176810",
        "pub.1159720705",
        "pub.1156043617",
        "pub.1156207650",
        "pub.1122518813",
        "pub.1169025466"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.66
        },
        {
          "concept": "natural language processing applications",
          "relevance": 0.636
        },
        {
          "concept": "language processing applications",
          "relevance": 0.62
        },
        {
          "concept": "word-cloud representations",
          "relevance": 0.589
        },
        {
          "concept": "reinforcement learning",
          "relevance": 0.573
        },
        {
          "concept": "human feedback",
          "relevance": 0.57
        },
        {
          "concept": "application domains",
          "relevance": 0.569
        },
        {
          "concept": "pre-training",
          "relevance": 0.558
        },
        {
          "concept": "processing applications",
          "relevance": 0.552
        },
        {
          "concept": "diverse domains",
          "relevance": 0.551
        },
        {
          "concept": "cloud representation",
          "relevance": 0.538
        },
        {
          "concept": "fine-tuning",
          "relevance": 0.531
        },
        {
          "concept": "comprehensive survey",
          "relevance": 0.505
        },
        {
          "concept": "in-depth analysis",
          "relevance": 0.471
        },
        {
          "concept": "ChatGPT",
          "relevance": 0.449
        },
        {
          "concept": "language",
          "relevance": 0.431
        },
        {
          "concept": "arXiv",
          "relevance": 0.429
        },
        {
          "concept": "applications",
          "relevance": 0.427
        },
        {
          "concept": "relevant papers",
          "relevance": 0.414
        },
        {
          "concept": "domain",
          "relevance": 0.409
        },
        {
          "concept": "learning",
          "relevance": 0.4
        },
        {
          "concept": "representation",
          "relevance": 0.396
        },
        {
          "concept": "increasing interest",
          "relevance": 0.385
        },
        {
          "concept": "LLM",
          "relevance": 0.383
        },
        {
          "concept": "capability",
          "relevance": 0.376
        },
        {
          "concept": "performance",
          "relevance": 0.373
        },
        {
          "concept": "research",
          "relevance": 0.368
        },
        {
          "concept": "model",
          "relevance": 0.359
        },
        {
          "concept": "feedback",
          "relevance": 0.357
        },
        {
          "concept": "words",
          "relevance": 0.348
        },
        {
          "concept": "study endeavors",
          "relevance": 0.336
        },
        {
          "concept": "reinforcement",
          "relevance": 0.33
        },
        {
          "concept": "adaptation",
          "relevance": 0.329
        },
        {
          "concept": "knowledge",
          "relevance": 0.325
        },
        {
          "concept": "instruction",
          "relevance": 0.309
        },
        {
          "concept": "advances",
          "relevance": 0.305
        },
        {
          "concept": "ethical concerns",
          "relevance": 0.296
        },
        {
          "concept": "endeavors",
          "relevance": 0.28
        },
        {
          "concept": "perspective",
          "relevance": 0.278
        },
        {
          "concept": "direction",
          "relevance": 0.277
        },
        {
          "concept": "analysis",
          "relevance": 0.272
        },
        {
          "concept": "interest",
          "relevance": 0.272
        },
        {
          "concept": "history",
          "relevance": 0.265
        },
        {
          "concept": "physics",
          "relevance": 0.258
        },
        {
          "concept": "concerns",
          "relevance": 0.255
        },
        {
          "concept": "humans",
          "relevance": 0.253
        },
        {
          "concept": "education",
          "relevance": 0.25
        },
        {
          "concept": "mathematics",
          "relevance": 0.248
        },
        {
          "concept": "distribution",
          "relevance": 0.237
        },
        {
          "concept": "potential implications",
          "relevance": 0.223
        },
        {
          "concept": "distribution analysis",
          "relevance": 0.222
        },
        {
          "concept": "implications",
          "relevance": 0.208
        },
        {
          "concept": "series",
          "relevance": 0.207
        },
        {
          "concept": "potential",
          "relevance": 0.199
        },
        {
          "concept": "paper",
          "relevance": 0.191
        },
        {
          "concept": "medicine",
          "relevance": 0.179
        },
        {
          "concept": "study",
          "relevance": 0.169
        },
        {
          "concept": "findings",
          "relevance": 0.165
        },
        {
          "concept": "GPT",
          "relevance": 0.101
        }
      ]
    },
    {
      "paperId": "pub.1164705743",
      "doi": "10.1007/s00330-023-10213-1",
      "title": "ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports",
      "year": 2023,
      "citationCount": 405,
      "fieldCitationRatio": 322.62,
      "abstract": "ObjectivesTo assess the quality of simplified radiology reports generated with the large language model (LLM) ChatGPT and to discuss challenges and chances of ChatGPT-like LLMs for medical text simplification.MethodsIn this exploratory case study, a radiologist created three fictitious radiology reports which we simplified by prompting ChatGPT with “Explain this medical report to a child using simple language.” In a questionnaire, we tasked 15 radiologists to rate the quality of the simplified radiology reports with respect to their factual correctness, completeness, and potential harm for patients. We used Likert scale analysis and inductive free-text categorization to assess the quality of the simplified reports.ResultsMost radiologists agreed that the simplified reports were factually correct, complete, and not potentially harmful to the patient. Nevertheless, instances of incorrect statements, missed relevant medical information, and potentially harmful passages were reported.ConclusionWhile we see a need for further adaption to the medical field, the initial insights of this study indicate a tremendous potential in using LLMs like ChatGPT to improve patient-centered care in radiology and other medical domains.Clinical relevance statementPatients have started to use ChatGPT to simplify and explain their medical reports, which is expected to affect patient-doctor interaction. This phenomenon raises several opportunities and challenges for clinical routine.Key Points• Patients have started to use ChatGPT to simplify their medical reports, but their quality was unknown.• In a questionnaire, most participating radiologists overall asserted good quality to radiology reports simplified with ChatGPT. However, they also highlighted a notable presence of errors, potentially leading patients to draw harmful conclusions.• Large language models such as ChatGPT have vast potential to enhance patient-centered care in radiology and other medical domains. To realize this potential while minimizing harm, they need supervision by medical experts and adaption to the medical field.Graphical Abstract",
      "reference_ids": [
        "pub.1138305898",
        "pub.1120882528",
        "pub.1108734890",
        "pub.1150392229",
        "pub.1139947961",
        "pub.1117660211",
        "pub.1149740848",
        "pub.1160635088",
        "pub.1067340875",
        "pub.1039586136",
        "pub.1129756915",
        "pub.1111271153",
        "pub.1107513488",
        "pub.1163991170",
        "pub.1099120510",
        "pub.1136054193",
        "pub.1110953740",
        "pub.1148390672",
        "pub.1124484286",
        "pub.1141942664",
        "pub.1143672116",
        "pub.1099870475",
        "pub.1135710434"
      ],
      "concepts_scores": [
        {
          "concept": "patient-centered care",
          "relevance": 0.707
        },
        {
          "concept": "language model",
          "relevance": 0.694
        },
        {
          "concept": "medical domain",
          "relevance": 0.69
        },
        {
          "concept": "improve patient-centered care",
          "relevance": 0.627
        },
        {
          "concept": "exploratory case study",
          "relevance": 0.623
        },
        {
          "concept": "medical reports",
          "relevance": 0.606
        },
        {
          "concept": "radiology reports",
          "relevance": 0.604
        },
        {
          "concept": "medical field",
          "relevance": 0.6
        },
        {
          "concept": "presence of errors",
          "relevance": 0.597
        },
        {
          "concept": "ChatGPT",
          "relevance": 0.59
        },
        {
          "concept": "text simplification",
          "relevance": 0.59
        },
        {
          "concept": "patient-doctor interaction",
          "relevance": 0.587
        },
        {
          "concept": "relevant medical information",
          "relevance": 0.583
        },
        {
          "concept": "medical experts",
          "relevance": 0.562
        },
        {
          "concept": "medical information",
          "relevance": 0.537
        },
        {
          "concept": "case study",
          "relevance": 0.524
        },
        {
          "concept": "care",
          "relevance": 0.496
        },
        {
          "concept": "questionnaire",
          "relevance": 0.479
        },
        {
          "concept": "language",
          "relevance": 0.476
        },
        {
          "concept": "radiology",
          "relevance": 0.443
        },
        {
          "concept": "Likert scale analysis",
          "relevance": 0.438
        },
        {
          "concept": "patients",
          "relevance": 0.437
        },
        {
          "concept": "domain",
          "relevance": 0.43
        },
        {
          "concept": "quality",
          "relevance": 0.429
        },
        {
          "concept": "LLM",
          "relevance": 0.423
        },
        {
          "concept": "clinical routine",
          "relevance": 0.421
        },
        {
          "concept": "ResultsMost",
          "relevance": 0.418
        },
        {
          "concept": "radiologists",
          "relevance": 0.409
        },
        {
          "concept": "ConclusionWhile",
          "relevance": 0.404
        },
        {
          "concept": "reports",
          "relevance": 0.403
        },
        {
          "concept": "harm",
          "relevance": 0.402
        },
        {
          "concept": "categorization",
          "relevance": 0.396
        },
        {
          "concept": "Likert",
          "relevance": 0.395
        },
        {
          "concept": "information",
          "relevance": 0.394
        },
        {
          "concept": "error",
          "relevance": 0.39
        },
        {
          "concept": "experts",
          "relevance": 0.39
        },
        {
          "concept": "challenges",
          "relevance": 0.388
        },
        {
          "concept": "model",
          "relevance": 0.377
        },
        {
          "concept": "children",
          "relevance": 0.377
        },
        {
          "concept": "medicine",
          "relevance": 0.376
        },
        {
          "concept": "study",
          "relevance": 0.376
        },
        {
          "concept": "incorrect statements",
          "relevance": 0.374
        },
        {
          "concept": "supervision",
          "relevance": 0.368
        },
        {
          "concept": "simplification",
          "relevance": 0.352
        },
        {
          "concept": "completion",
          "relevance": 0.348
        },
        {
          "concept": "adaptation",
          "relevance": 0.346
        },
        {
          "concept": "routine",
          "relevance": 0.345
        },
        {
          "concept": "correction",
          "relevance": 0.328
        },
        {
          "concept": "field",
          "relevance": 0.326
        },
        {
          "concept": "opportunities",
          "relevance": 0.322
        },
        {
          "concept": "statements",
          "relevance": 0.32
        },
        {
          "concept": "chance",
          "relevance": 0.309
        },
        {
          "concept": "conclusions",
          "relevance": 0.303
        },
        {
          "concept": "scaling analysis",
          "relevance": 0.279
        },
        {
          "concept": "analysis",
          "relevance": 0.273
        },
        {
          "concept": "potential",
          "relevance": 0.253
        },
        {
          "concept": "presence",
          "relevance": 0.245
        },
        {
          "concept": "interaction",
          "relevance": 0.241
        },
        {
          "concept": "passage",
          "relevance": 0.228
        },
        {
          "concept": "phenomenon",
          "relevance": 0.203
        }
      ]
    },
    {
      "paperId": "pub.1120882528",
      "doi": "10.1093/bioinformatics/btz682",
      "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
      "year": 2019,
      "citationCount": 4518,
      "fieldCitationRatio": 987.97,
      "abstract": "MOTIVATION: Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora.\nRESULTS: We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62% F1 score improvement), biomedical relation extraction (2.80% F1 score improvement) and biomedical question answering (12.24% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts.\nAVAILABILITY AND IMPLEMENTATION: We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert.",
      "reference_ids": [
        "pub.1118170219",
        "pub.1118170218",
        "pub.1115960165",
        "pub.1099110523",
        "pub.1009125239",
        "pub.1019551002",
        "pub.1113294470",
        "pub.1107540402",
        "pub.1118169521",
        "pub.1092960287",
        "pub.1005860045",
        "pub.1084853448",
        "pub.1017592817",
        "pub.1099140177",
        "pub.1104317006",
        "pub.1041411233",
        "pub.1037494609",
        "pub.1048097290",
        "pub.1084178230",
        "pub.1032444382",
        "pub.1024359916",
        "pub.1096025084",
        "pub.1104357988",
        "pub.1105865815",
        "pub.1046305214"
      ],
      "concepts_scores": [
        {
          "concept": "natural language processing",
          "relevance": 0.789
        },
        {
          "concept": "biomedical text mining",
          "relevance": 0.785
        },
        {
          "concept": "state-of-the-art models",
          "relevance": 0.774
        },
        {
          "concept": "biomedical text mining tasks",
          "relevance": 0.767
        },
        {
          "concept": "language representation model",
          "relevance": 0.758
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.758
        },
        {
          "concept": "biomedical corpora",
          "relevance": 0.756
        },
        {
          "concept": "text mining tasks",
          "relevance": 0.755
        },
        {
          "concept": "text mining",
          "relevance": 0.709
        },
        {
          "concept": "mining tasks",
          "relevance": 0.705
        },
        {
          "concept": "representation model",
          "relevance": 0.69
        },
        {
          "concept": "development of effective biomedical text mining models",
          "relevance": 0.688
        },
        {
          "concept": "general domain corpora",
          "relevance": 0.661
        },
        {
          "concept": "biomedical relation extraction",
          "relevance": 0.656
        },
        {
          "concept": "biomedical question answering",
          "relevance": 0.655
        },
        {
          "concept": "pre-trained BERT",
          "relevance": 0.654
        },
        {
          "concept": "language model BERT",
          "relevance": 0.651
        },
        {
          "concept": "pre-trained weights",
          "relevance": 0.651
        },
        {
          "concept": "text mining models",
          "relevance": 0.649
        },
        {
          "concept": "word distribution shift",
          "relevance": 0.648
        },
        {
          "concept": "domain corpus",
          "relevance": 0.611
        },
        {
          "concept": "question answering",
          "relevance": 0.61
        },
        {
          "concept": "biomedical documents",
          "relevance": 0.609
        },
        {
          "concept": "relation extraction",
          "relevance": 0.609
        },
        {
          "concept": "entity recognition",
          "relevance": 0.608
        },
        {
          "concept": "model BERT",
          "relevance": 0.604
        },
        {
          "concept": "source code",
          "relevance": 0.6
        },
        {
          "concept": "deep learning",
          "relevance": 0.598
        },
        {
          "concept": "biomedical text",
          "relevance": 0.598
        },
        {
          "concept": "language processing",
          "relevance": 0.59
        },
        {
          "concept": "pre-training",
          "relevance": 0.59
        },
        {
          "concept": "mining model",
          "relevance": 0.588
        },
        {
          "concept": "BioBERT",
          "relevance": 0.587
        },
        {
          "concept": "BERT",
          "relevance": 0.586
        },
        {
          "concept": "biomedical literature",
          "relevance": 0.556
        },
        {
          "concept": "distribution shifts",
          "relevance": 0.53
        },
        {
          "concept": "task",
          "relevance": 0.522
        },
        {
          "concept": "corpus",
          "relevance": 0.507
        },
        {
          "concept": "mining",
          "relevance": 0.503
        },
        {
          "concept": "architecture",
          "relevance": 0.445
        },
        {
          "concept": "code",
          "relevance": 0.436
        },
        {
          "concept": "learning",
          "relevance": 0.422
        },
        {
          "concept": "recognition",
          "relevance": 0.412
        },
        {
          "concept": "model",
          "relevance": 0.408
        },
        {
          "concept": "documents",
          "relevance": 0.397
        },
        {
          "concept": "information",
          "relevance": 0.397
        },
        {
          "concept": "text",
          "relevance": 0.395
        },
        {
          "concept": "language",
          "relevance": 0.394
        },
        {
          "concept": "performance",
          "relevance": 0.394
        },
        {
          "concept": "unsatisfactory results",
          "relevance": 0.384
        },
        {
          "concept": "analysis results",
          "relevance": 0.382
        },
        {
          "concept": "words",
          "relevance": 0.375
        },
        {
          "concept": "answers",
          "relevance": 0.368
        },
        {
          "concept": "entities",
          "relevance": 0.357
        },
        {
          "concept": "results",
          "relevance": 0.349
        },
        {
          "concept": "advances",
          "relevance": 0.322
        },
        {
          "concept": "research",
          "relevance": 0.319
        },
        {
          "concept": "process",
          "relevance": 0.31
        },
        {
          "concept": "extraction",
          "relevance": 0.308
        },
        {
          "concept": "literature",
          "relevance": 0.282
        },
        {
          "concept": "source",
          "relevance": 0.281
        },
        {
          "concept": "development",
          "relevance": 0.269
        },
        {
          "concept": "weight",
          "relevance": 0.265
        },
        {
          "concept": "shift",
          "relevance": 0.248
        },
        {
          "concept": "analysis",
          "relevance": 0.248
        },
        {
          "concept": "progression",
          "relevance": 0.213
        }
      ]
    },
    {
      "paperId": "pub.1135710434",
      "doi": "10.1145/3442188.3445922",
      "title": "On the Dangers of Stochastic Parrots",
      "year": 2021,
      "citationCount": 3504,
      "fieldCitationRatio": 3455.33,
      "abstract": "The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.",
      "reference_ids": [
        "pub.1125041917",
        "pub.1130315096",
        "pub.1132673693",
        "pub.1123773517",
        "pub.1125798967",
        "pub.1017035478",
        "pub.1032202015",
        "pub.1121025467",
        "pub.1121025485",
        "pub.1123778584",
        "pub.1128856734",
        "pub.1129926886",
        "pub.1000120992",
        "pub.1099113809",
        "pub.1121024947",
        "pub.1123132008",
        "pub.1031732216",
        "pub.1139255870",
        "pub.1111334730",
        "pub.1152417508",
        "pub.1061180209",
        "pub.1051758447",
        "pub.1021080654",
        "pub.1003268395",
        "pub.1023730237",
        "pub.1102821228",
        "pub.1053126851",
        "pub.1040632585",
        "pub.1005452468",
        "pub.1032338077",
        "pub.1113128256",
        "pub.1122290356",
        "pub.1044943146",
        "pub.1030531895",
        "pub.1023091413",
        "pub.1036017766",
        "pub.1092025836",
        "pub.1128856715",
        "pub.1103729151",
        "pub.1083902442",
        "pub.1117660148",
        "pub.1111607515",
        "pub.1133361901",
        "pub.1134315451",
        "pub.1083882403",
        "pub.1138871273",
        "pub.1010680957"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.646
        },
        {
          "concept": "English",
          "relevance": 0.522
        },
        {
          "concept": "language",
          "relevance": 0.517
        },
        {
          "concept": "pretrained models",
          "relevance": 0.474
        },
        {
          "concept": "NLP",
          "relevance": 0.433
        },
        {
          "concept": "research directions",
          "relevance": 0.415
        },
        {
          "concept": "BERT",
          "relevance": 0.403
        },
        {
          "concept": "architectural innovation",
          "relevance": 0.401
        },
        {
          "concept": "planning approach",
          "relevance": 0.398
        },
        {
          "concept": "research",
          "relevance": 0.396
        },
        {
          "concept": "leaderboard",
          "relevance": 0.368
        },
        {
          "concept": "dataset",
          "relevance": 0.351
        },
        {
          "concept": "deployment",
          "relevance": 0.35
        },
        {
          "concept": "danger",
          "relevance": 0.349
        },
        {
          "concept": "Web",
          "relevance": 0.344
        },
        {
          "concept": "benchmarks",
          "relevance": 0.342
        },
        {
          "concept": "task",
          "relevance": 0.336
        },
        {
          "concept": "model",
          "relevance": 0.312
        },
        {
          "concept": "boundaries",
          "relevance": 0.312
        },
        {
          "concept": "innovation",
          "relevance": 0.311
        },
        {
          "concept": "technology",
          "relevance": 0.307
        },
        {
          "concept": "parrots",
          "relevance": 0.303
        },
        {
          "concept": "development",
          "relevance": 0.3
        },
        {
          "concept": "path",
          "relevance": 0.298
        },
        {
          "concept": "investment resources",
          "relevance": 0.297
        },
        {
          "concept": "stakeholder values",
          "relevance": 0.295
        },
        {
          "concept": "resources",
          "relevance": 0.289
        },
        {
          "concept": "goal",
          "relevance": 0.284
        },
        {
          "concept": "cost",
          "relevance": 0.28
        },
        {
          "concept": "methodology",
          "relevance": 0.268
        },
        {
          "concept": "Development Goals",
          "relevance": 0.268
        },
        {
          "concept": "financial costs",
          "relevance": 0.261
        },
        {
          "concept": "approach",
          "relevance": 0.255
        },
        {
          "concept": "exercise",
          "relevance": 0.241
        },
        {
          "concept": "recommendations",
          "relevance": 0.239
        },
        {
          "concept": "stakeholders",
          "relevance": 0.236
        },
        {
          "concept": "state",
          "relevance": 0.234
        },
        {
          "concept": "years",
          "relevance": 0.23
        },
        {
          "concept": "direction",
          "relevance": 0.229
        },
        {
          "concept": "variants",
          "relevance": 0.227
        },
        {
          "concept": "risk",
          "relevance": 0.203
        },
        {
          "concept": "size",
          "relevance": 0.2
        },
        {
          "concept": "values",
          "relevance": 0.178
        }
      ]
    },
    {
      "paperId": "pub.1159948202",
      "doi": "10.3390/ph16060891",
      "title": "The Role of AI in Drug Discovery: Challenges, Opportunities, and Strategies",
      "year": 2023,
      "citationCount": 362,
      "fieldCitationRatio": 163.5,
      "abstract": "Artificial intelligence (AI) has the potential to revolutionize the drug discovery process, offering improved efficiency, accuracy, and speed. However, the successful application of AI is dependent on the availability of high-quality data, the addressing of ethical concerns, and the recognition of the limitations of AI-based approaches. In this article, the benefits, challenges, and drawbacks of AI in this field are reviewed, and possible strategies and approaches for overcoming the present obstacles are proposed. The use of data augmentation, explainable AI, and the integration of AI with traditional experimental methods, as well as the potential advantages of AI in pharmaceutical research, are also discussed. Overall, this review highlights the potential of AI in drug discovery and provides insights into the challenges and opportunities for realizing its potential in this field. <i>Note from the human authors</i>: This article was created to test the ability of ChatGPT, a chatbot based on the GPT-3.5 language model, in terms of assisting human authors in writing review articles. The text generated by the AI following our instructions (see Supporting Information) was used as a starting point, and its ability to automatically generate content was evaluated. After conducting a thorough review, the human authors practically rewrote the manuscript, striving to maintain a balance between the original proposal and the scientific criteria. The advantages and limitations of using AI for this purpose are discussed in the last section.",
      "reference_ids": [
        "pub.1111918634",
        "pub.1139915761",
        "pub.1136366983",
        "pub.1110125878",
        "pub.1138173142",
        "pub.1130037035",
        "pub.1110259746",
        "pub.1111913742",
        "pub.1146624805",
        "pub.1106467297",
        "pub.1141547419",
        "pub.1127091746",
        "pub.1135157314",
        "pub.1104304271",
        "pub.1131923985",
        "pub.1145720630",
        "pub.1015357772",
        "pub.1130958795",
        "pub.1137716983",
        "pub.1138940717",
        "pub.1140039426",
        "pub.1141880619",
        "pub.1135039600",
        "pub.1149376659",
        "pub.1140999156",
        "pub.1142689186",
        "pub.1123669031",
        "pub.1100346759",
        "pub.1133277655",
        "pub.1133339409",
        "pub.1135378660",
        "pub.1150278755",
        "pub.1142386998",
        "pub.1146252255",
        "pub.1113378385",
        "pub.1103242128",
        "pub.1137136567",
        "pub.1149798674",
        "pub.1121084491",
        "pub.1104587065",
        "pub.1145992557",
        "pub.1145582443",
        "pub.1111261024",
        "pub.1127443761",
        "pub.1146439414",
        "pub.1142245816",
        "pub.1151689241",
        "pub.1043921708",
        "pub.1113493075",
        "pub.1122092023",
        "pub.1112970204",
        "pub.1043501890",
        "pub.1135013019",
        "pub.1130150686"
      ],
      "concepts_scores": [
        {
          "concept": "artificial intelligence",
          "relevance": 0.665
        },
        {
          "concept": "human authority",
          "relevance": 0.575
        },
        {
          "concept": "integration of AI",
          "relevance": 0.573
        },
        {
          "concept": "AI-based approaches",
          "relevance": 0.57
        },
        {
          "concept": "application of AI",
          "relevance": 0.567
        },
        {
          "concept": "potential of AI",
          "relevance": 0.564
        },
        {
          "concept": "drawbacks of AI",
          "relevance": 0.556
        },
        {
          "concept": "language model",
          "relevance": 0.548
        },
        {
          "concept": "data augmentation",
          "relevance": 0.546
        },
        {
          "concept": "availability of high-quality data",
          "relevance": 0.522
        },
        {
          "concept": "drug discovery",
          "relevance": 0.501
        },
        {
          "concept": "discovery process",
          "relevance": 0.499
        },
        {
          "concept": "drug discovery process",
          "relevance": 0.492
        },
        {
          "concept": "improve efficiency",
          "relevance": 0.444
        },
        {
          "concept": "high-quality data",
          "relevance": 0.441
        },
        {
          "concept": "ChatGPT",
          "relevance": 0.432
        },
        {
          "concept": "original proposal",
          "relevance": 0.431
        },
        {
          "concept": "chatbot",
          "relevance": 0.425
        },
        {
          "concept": "intelligence",
          "relevance": 0.402
        },
        {
          "concept": "pharmaceutical research",
          "relevance": 0.396
        },
        {
          "concept": "data",
          "relevance": 0.39
        },
        {
          "concept": "recognition",
          "relevance": 0.375
        },
        {
          "concept": "challenges",
          "relevance": 0.373
        },
        {
          "concept": "accuracy",
          "relevance": 0.372
        },
        {
          "concept": "drawbacks",
          "relevance": 0.361
        },
        {
          "concept": "obstacles",
          "relevance": 0.36
        },
        {
          "concept": "text",
          "relevance": 0.359
        },
        {
          "concept": "proposal",
          "relevance": 0.352
        },
        {
          "concept": "applications",
          "relevance": 0.338
        },
        {
          "concept": "experimental methods",
          "relevance": 0.331
        },
        {
          "concept": "potential advantages",
          "relevance": 0.329
        },
        {
          "concept": "discovery",
          "relevance": 0.325
        },
        {
          "concept": "augmentation",
          "relevance": 0.322
        },
        {
          "concept": "speed",
          "relevance": 0.319
        },
        {
          "concept": "strategies",
          "relevance": 0.317
        },
        {
          "concept": "method",
          "relevance": 0.315
        },
        {
          "concept": "integration",
          "relevance": 0.313
        },
        {
          "concept": "efficiency",
          "relevance": 0.312
        },
        {
          "concept": "opportunities",
          "relevance": 0.304
        },
        {
          "concept": "model",
          "relevance": 0.298
        },
        {
          "concept": "limitations",
          "relevance": 0.297
        },
        {
          "concept": "instruction",
          "relevance": 0.297
        },
        {
          "concept": "potential",
          "relevance": 0.296
        },
        {
          "concept": "advantage",
          "relevance": 0.296
        },
        {
          "concept": "research",
          "relevance": 0.291
        },
        {
          "concept": "authors",
          "relevance": 0.29
        },
        {
          "concept": "data",
          "relevance": 0.285
        },
        {
          "concept": "availability",
          "relevance": 0.284
        },
        {
          "concept": "article",
          "relevance": 0.283
        },
        {
          "concept": "process",
          "relevance": 0.282
        },
        {
          "concept": "review article",
          "relevance": 0.281
        },
        {
          "concept": "benefits",
          "relevance": 0.269
        },
        {
          "concept": "manuscript",
          "relevance": 0.264
        },
        {
          "concept": "scientific criteria",
          "relevance": 0.262
        },
        {
          "concept": "criteria",
          "relevance": 0.259
        },
        {
          "concept": "field",
          "relevance": 0.258
        },
        {
          "concept": "drug",
          "relevance": 0.257
        },
        {
          "concept": "concerns",
          "relevance": 0.245
        },
        {
          "concept": "ethical concerns",
          "relevance": 0.242
        },
        {
          "concept": "balance",
          "relevance": 0.237
        },
        {
          "concept": "content",
          "relevance": 0.224
        },
        {
          "concept": "review",
          "relevance": 0.197
        },
        {
          "concept": "approach",
          "relevance": 0.191
        },
        {
          "concept": "section",
          "relevance": 0.17
        }
      ]
    },
    {
      "paperId": "pub.1142245816",
      "doi": "10.1016/j.xinn.2021.100179",
      "title": "Artificial intelligence: A powerful paradigm for scientific research",
      "year": 2021,
      "citationCount": 1132,
      "fieldCitationRatio": 1424.94,
      "abstract": "Artificial intelligence (AI) coupled with promising machine learning (ML) techniques well known from computer science is broadly affecting many aspects of various fields including science and technology, industry, and even our day-to-day life. The ML techniques have been developed to analyze high-throughput data with a view to obtaining useful insights, categorizing, predicting, and making evidence-based decisions in novel ways, which will promote the growth of novel applications and fuel the sustainable booming of AI. This paper undertakes a comprehensive survey on the development and application of AI in different aspects of fundamental sciences, including information science, mathematics, medical science, materials science, geoscience, life science, physics, and chemistry. The challenges that each discipline of science meets, and the potentials of AI techniques to handle these challenges, are discussed in detail. Moreover, we shed light on new research trends entailing the integration of AI into each scientific discipline. The aim of this paper is to provide a broad research guideline on fundamental sciences with potential infusion of AI, to help motivate researchers to deeply understand the state-of-the-art applications of AI-based fundamental sciences, and thereby to help promote the continuous development of these fundamental sciences.",
      "reference_ids": [
        "pub.1051807434",
        "pub.1105862496",
        "pub.1042538861",
        "pub.1107279410",
        "pub.1105643744",
        "pub.1100241802",
        "pub.1060763899",
        "pub.1125604682",
        "pub.1112238428",
        "pub.1117049058",
        "pub.1015994362",
        "pub.1112085726",
        "pub.1125085621",
        "pub.1137604320",
        "pub.1041589907",
        "pub.1061646286",
        "pub.1005138990",
        "pub.1095236289",
        "pub.1106904485",
        "pub.1123509962",
        "pub.1010020120",
        "pub.1113356001",
        "pub.1104530205",
        "pub.1110788995",
        "pub.1112394532",
        "pub.1044804364",
        "pub.1139461330",
        "pub.1112363277",
        "pub.1038320716",
        "pub.1062505415",
        "pub.1134787343",
        "pub.1101384525",
        "pub.1127686448",
        "pub.1138306137",
        "pub.1123212207",
        "pub.1138465694",
        "pub.1103598913",
        "pub.1051631434",
        "pub.1120977780",
        "pub.1103168555",
        "pub.1099653146",
        "pub.1133875551",
        "pub.1104383901",
        "pub.1059156779",
        "pub.1111979755",
        "pub.1124294646",
        "pub.1015195293",
        "pub.1135552445",
        "pub.1023250347",
        "pub.1135034445",
        "pub.1110200248",
        "pub.1137806220",
        "pub.1026163953",
        "pub.1111839122",
        "pub.1009302366",
        "pub.1025150743",
        "pub.1129058619",
        "pub.1136302703",
        "pub.1004707137",
        "pub.1113623547",
        "pub.1139939037",
        "pub.1139020168",
        "pub.1136404699",
        "pub.1124802409",
        "pub.1131996366",
        "pub.1101227419",
        "pub.1107320076",
        "pub.1085562969",
        "pub.1132946400",
        "pub.1140977019",
        "pub.1044277134",
        "pub.1110272275",
        "pub.1134429293",
        "pub.1130863323",
        "pub.1132294806",
        "pub.1136211650",
        "pub.1132821350",
        "pub.1136331468",
        "pub.1128608026",
        "pub.1138426472",
        "pub.1091295574",
        "pub.1105322090",
        "pub.1139853407",
        "pub.1040716830",
        "pub.1124047839",
        "pub.1138790218",
        "pub.1062444502",
        "pub.1016961599",
        "pub.1128875149",
        "pub.1130045693",
        "pub.1132734016",
        "pub.1134705924",
        "pub.1013265188",
        "pub.1105714173",
        "pub.1125124191",
        "pub.1033705757",
        "pub.1122274570",
        "pub.1103283053",
        "pub.1120955833",
        "pub.1112388964",
        "pub.1112682991",
        "pub.1002235418",
        "pub.1128423125",
        "pub.1004945078",
        "pub.1121925677",
        "pub.1108334024",
        "pub.1123511899",
        "pub.1094030466",
        "pub.1076279586",
        "pub.1011982186",
        "pub.1137500968",
        "pub.1107806027",
        "pub.1120764136",
        "pub.1131312326",
        "pub.1044651743",
        "pub.1060756782",
        "pub.1113467964",
        "pub.1125823843",
        "pub.1122915581",
        "pub.1125837361",
        "pub.1133918352",
        "pub.1014554982",
        "pub.1129537557",
        "pub.1134680342",
        "pub.1150165564",
        "pub.1131649977",
        "pub.1045596512",
        "pub.1125131297",
        "pub.1090806672",
        "pub.1115557286",
        "pub.1120210846",
        "pub.1122238913",
        "pub.1028715170",
        "pub.1004607132",
        "pub.1037811822",
        "pub.1136299251",
        "pub.1132935976",
        "pub.1107453405",
        "pub.1128766358",
        "pub.1071475834",
        "pub.1127940685",
        "pub.1106257059",
        "pub.1123536889",
        "pub.1130767724",
        "pub.1131099150",
        "pub.1009917438",
        "pub.1110703757",
        "pub.1127553971",
        "pub.1114351993",
        "pub.1127185975",
        "pub.1002198958",
        "pub.1051499494",
        "pub.1138783575",
        "pub.1130866582",
        "pub.1109912872",
        "pub.1117193250",
        "pub.1112394050",
        "pub.1132596728",
        "pub.1135294771",
        "pub.1091489914",
        "pub.1084756327",
        "pub.1139695116",
        "pub.1129905568",
        "pub.1105914852",
        "pub.1086004247"
      ],
      "concepts_scores": [
        {
          "concept": "machine learning",
          "relevance": 0.697
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.694
        },
        {
          "concept": "potential of AI techniques",
          "relevance": 0.668
        },
        {
          "concept": "booming of AI",
          "relevance": 0.666
        },
        {
          "concept": "integration of AI",
          "relevance": 0.646
        },
        {
          "concept": "application of AI",
          "relevance": 0.639
        },
        {
          "concept": "AI techniques",
          "relevance": 0.61
        },
        {
          "concept": "computer science",
          "relevance": 0.602
        },
        {
          "concept": "ML techniques",
          "relevance": 0.601
        },
        {
          "concept": "information science",
          "relevance": 0.597
        },
        {
          "concept": "day-to-day life",
          "relevance": 0.581
        },
        {
          "concept": "research trends",
          "relevance": 0.554
        },
        {
          "concept": "comprehensive survey",
          "relevance": 0.547
        },
        {
          "concept": "infusion of AI",
          "relevance": 0.528
        },
        {
          "concept": "continuous development",
          "relevance": 0.514
        },
        {
          "concept": "disciplines of science",
          "relevance": 0.507
        },
        {
          "concept": "applications",
          "relevance": 0.463
        },
        {
          "concept": "high-throughput data",
          "relevance": 0.46
        },
        {
          "concept": "scientific disciplines",
          "relevance": 0.455
        },
        {
          "concept": "intelligence",
          "relevance": 0.452
        },
        {
          "concept": "computer",
          "relevance": 0.452
        },
        {
          "concept": "machine",
          "relevance": 0.442
        },
        {
          "concept": "technique",
          "relevance": 0.439
        },
        {
          "concept": "scientific research",
          "relevance": 0.436
        },
        {
          "concept": "learning",
          "relevance": 0.433
        },
        {
          "concept": "fundamental science",
          "relevance": 0.43
        },
        {
          "concept": "research guidelines",
          "relevance": 0.42
        },
        {
          "concept": "life sciences",
          "relevance": 0.412
        },
        {
          "concept": "information",
          "relevance": 0.406
        },
        {
          "concept": "research",
          "relevance": 0.405
        },
        {
          "concept": "technology",
          "relevance": 0.401
        },
        {
          "concept": "paradigm",
          "relevance": 0.4
        },
        {
          "concept": "science",
          "relevance": 0.399
        },
        {
          "concept": "geoscience",
          "relevance": 0.394
        },
        {
          "concept": "affected many aspects",
          "relevance": 0.392
        },
        {
          "concept": "decision",
          "relevance": 0.388
        },
        {
          "concept": "disciplines",
          "relevance": 0.38
        },
        {
          "concept": "evidence-based decisions",
          "relevance": 0.37
        },
        {
          "concept": "Medical Sciences",
          "relevance": 0.37
        },
        {
          "concept": "integration",
          "relevance": 0.353
        },
        {
          "concept": "life",
          "relevance": 0.326
        },
        {
          "concept": "data",
          "relevance": 0.321
        },
        {
          "concept": "development",
          "relevance": 0.32
        },
        {
          "concept": "industry",
          "relevance": 0.318
        },
        {
          "concept": "mathematics",
          "relevance": 0.317
        },
        {
          "concept": "aspects",
          "relevance": 0.311
        },
        {
          "concept": "materials science",
          "relevance": 0.307
        },
        {
          "concept": "field",
          "relevance": 0.29
        },
        {
          "concept": "physics",
          "relevance": 0.279
        },
        {
          "concept": "boom",
          "relevance": 0.278
        },
        {
          "concept": "trends",
          "relevance": 0.253
        },
        {
          "concept": "materials",
          "relevance": 0.248
        },
        {
          "concept": "guidelines",
          "relevance": 0.245
        },
        {
          "concept": "survey",
          "relevance": 0.241
        },
        {
          "concept": "chemistry",
          "relevance": 0.235
        },
        {
          "concept": "potential",
          "relevance": 0.216
        },
        {
          "concept": "growth",
          "relevance": 0.153
        }
      ]
    },
    {
      "paperId": "pub.1146252255",
      "doi": "10.3389/fsurg.2022.862322",
      "title": "Legal and Ethical Consideration in Artificial Intelligence in Healthcare: Who Takes Responsibility?",
      "year": 2022,
      "citationCount": 624,
      "fieldCitationRatio": 314.63,
      "abstract": "The legal and ethical issues that confront society due to Artificial Intelligence (AI) include privacy and surveillance, bias or discrimination, and potentially the philosophical challenge is the role of human judgment. Concerns about newer digital technologies becoming a new source of inaccuracy and data breaches have arisen as a result of its use. Mistakes in the procedure or protocol in the field of healthcare can have devastating consequences for the patient who is the victim of the error. Because patients come into contact with physicians at moments in their lives when they are most vulnerable, it is crucial to remember this. Currently, there are no well-defined regulations in place to address the legal and ethical issues that may arise due to the use of artificial intelligence in healthcare settings. This review attempts to address these pertinent issues highlighting the need for algorithmic transparency, privacy, and protection of all the beneficiaries involved and cybersecurity of associated vulnerabilities.",
      "reference_ids": [
        "pub.1109930717",
        "pub.1129127292",
        "pub.1029126697",
        "pub.1137670811",
        "pub.1115973682",
        "pub.1127957277",
        "pub.1106324231",
        "pub.1123821189",
        "pub.1113644465",
        "pub.1128417439",
        "pub.1105338530",
        "pub.1117808890",
        "pub.1122811544",
        "pub.1113405928",
        "pub.1132291696",
        "pub.1050643021",
        "pub.1131788757",
        "pub.1103786570",
        "pub.1048138889",
        "pub.1128777655",
        "pub.1129662423",
        "pub.1004245407",
        "pub.1132044794",
        "pub.1044881360",
        "pub.1129385242",
        "pub.1044354182",
        "pub.1106026187",
        "pub.1139663140",
        "pub.1139208980",
        "pub.1092579618",
        "pub.1113160716",
        "pub.1027698286",
        "pub.1130693385",
        "pub.1124280343",
        "pub.1126903063",
        "pub.1122798733",
        "pub.1141273859",
        "pub.1017816021"
      ],
      "concepts_scores": [
        {
          "concept": "ethical issues",
          "relevance": 0.59
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.579
        },
        {
          "concept": "philosophical challenges",
          "relevance": 0.516
        },
        {
          "concept": "field of healthcare",
          "relevance": 0.505
        },
        {
          "concept": "algorithmic transparency",
          "relevance": 0.5
        },
        {
          "concept": "ethical considerations",
          "relevance": 0.497
        },
        {
          "concept": "data breaches",
          "relevance": 0.481
        },
        {
          "concept": "human judgment",
          "relevance": 0.461
        },
        {
          "concept": "taking responsibility",
          "relevance": 0.457
        },
        {
          "concept": "contact with physicians",
          "relevance": 0.447
        },
        {
          "concept": "privacy",
          "relevance": 0.434
        },
        {
          "concept": "intelligence",
          "relevance": 0.429
        },
        {
          "concept": "digital technologies",
          "relevance": 0.426
        },
        {
          "concept": "issues",
          "relevance": 0.418
        },
        {
          "concept": "victims",
          "relevance": 0.408
        },
        {
          "concept": "ethics",
          "relevance": 0.406
        },
        {
          "concept": "breach",
          "relevance": 0.402
        },
        {
          "concept": "Artificial",
          "relevance": 0.398
        },
        {
          "concept": "judgment",
          "relevance": 0.382
        },
        {
          "concept": "protection",
          "relevance": 0.379
        },
        {
          "concept": "cybersecurity",
          "relevance": 0.377
        },
        {
          "concept": "society",
          "relevance": 0.372
        },
        {
          "concept": "patients",
          "relevance": 0.364
        },
        {
          "concept": "beneficiaries",
          "relevance": 0.361
        },
        {
          "concept": "regulation",
          "relevance": 0.354
        },
        {
          "concept": "transparency",
          "relevance": 0.351
        },
        {
          "concept": "data",
          "relevance": 0.342
        },
        {
          "concept": "mistakes",
          "relevance": 0.34
        },
        {
          "concept": "discrimination",
          "relevance": 0.335
        },
        {
          "concept": "concerns",
          "relevance": 0.331
        },
        {
          "concept": "healthcare",
          "relevance": 0.33
        },
        {
          "concept": "life",
          "relevance": 0.33
        },
        {
          "concept": "healthcare settings",
          "relevance": 0.33
        },
        {
          "concept": "sources of inaccuracy",
          "relevance": 0.329
        },
        {
          "concept": "considerations",
          "relevance": 0.322
        },
        {
          "concept": "consequences",
          "relevance": 0.321
        },
        {
          "concept": "error",
          "relevance": 0.314
        },
        {
          "concept": "technology",
          "relevance": 0.313
        },
        {
          "concept": "vulnerability",
          "relevance": 0.309
        },
        {
          "concept": "protocol",
          "relevance": 0.308
        },
        {
          "concept": "challenges",
          "relevance": 0.292
        },
        {
          "concept": "physicians",
          "relevance": 0.289
        },
        {
          "concept": "sets",
          "relevance": 0.285
        },
        {
          "concept": "surveillance",
          "relevance": 0.283
        },
        {
          "concept": "inaccuracy",
          "relevance": 0.282
        },
        {
          "concept": "review",
          "relevance": 0.267
        },
        {
          "concept": "response",
          "relevance": 0.252
        },
        {
          "concept": "procedure",
          "relevance": 0.252
        },
        {
          "concept": "moment",
          "relevance": 0.249
        },
        {
          "concept": "bias",
          "relevance": 0.237
        },
        {
          "concept": "field",
          "relevance": 0.227
        },
        {
          "concept": "source",
          "relevance": 0.225
        },
        {
          "concept": "contact",
          "relevance": 0.183
        }
      ]
    },
    {
      "paperId": "pub.1168533982",
      "doi": "10.1162/tacl_a_00632",
      "title": "Benchmarking Large Language Models for News Summarization",
      "year": 2024,
      "citationCount": 225,
      "fieldCitationRatio": NaN,
      "abstract": "Abstract Large language models (LLMs) have shown promise for automatic summarization but the reasons behind their successes are poorly understood. By conducting a human evaluation on ten LLMs across different pretraining methods, prompts, and model scales, we make two important observations. First, we find instruction tuning, not model size, is the key to the LLM’s zero-shot summarization capability. Second, existing studies have been limited by low-quality references, leading to underestimates of human performance and lower few-shot and finetuning performance. To better evaluate LLMs, we perform human evaluation over high-quality summaries we collect from freelance writers. Despite major stylistic differences such as the amount of paraphrasing, we find that LLM summaries are judged to be on par with human written summaries.",
      "reference_ids": [
        "pub.1031530281",
        "pub.1099179674",
        "pub.1099205936",
        "pub.1133175338",
        "pub.1036653390",
        "pub.1051212681",
        "pub.1068001281",
        "pub.1119360854",
        "pub.1099239520",
        "pub.1117658852",
        "pub.1099239647",
        "pub.1129757057",
        "pub.1129757285",
        "pub.1152010610",
        "pub.1149741351",
        "pub.1099150806",
        "pub.1148390648",
        "pub.1158361897",
        "pub.1133174738",
        "pub.1002453584",
        "pub.1133176766",
        "pub.1013935660",
        "pub.1096025521",
        "pub.1023286624",
        "pub.1122290404",
        "pub.1148390532",
        "pub.1137573792",
        "pub.1029676611",
        "pub.1021371949",
        "pub.1129757335",
        "pub.1099106022",
        "pub.1129756745",
        "pub.1117659390",
        "pub.1145454307",
        "pub.1144244779",
        "pub.1045320298",
        "pub.1163043613",
        "pub.1104321155",
        "pub.1053571364",
        "pub.1129757334",
        "pub.1105579325",
        "pub.1043122306"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.689
        },
        {
          "concept": "human evaluation",
          "relevance": 0.646
        },
        {
          "concept": "news summarization",
          "relevance": 0.61
        },
        {
          "concept": "stylistic differences",
          "relevance": 0.606
        },
        {
          "concept": "freelance writer",
          "relevance": 0.587
        },
        {
          "concept": "automatic summarization",
          "relevance": 0.573
        },
        {
          "concept": "summarization capabilities",
          "relevance": 0.553
        },
        {
          "concept": "few-shot",
          "relevance": 0.551
        },
        {
          "concept": "pretraining method",
          "relevance": 0.548
        },
        {
          "concept": "model size",
          "relevance": 0.533
        },
        {
          "concept": "human performance",
          "relevance": 0.508
        },
        {
          "concept": "summarization",
          "relevance": 0.493
        },
        {
          "concept": "news",
          "relevance": 0.48
        },
        {
          "concept": "paraphrasing",
          "relevance": 0.478
        },
        {
          "concept": "writers",
          "relevance": 0.475
        },
        {
          "concept": "freelancers",
          "relevance": 0.462
        },
        {
          "concept": "instruction",
          "relevance": 0.434
        },
        {
          "concept": "performance",
          "relevance": 0.412
        },
        {
          "concept": "pretraining",
          "relevance": 0.406
        },
        {
          "concept": "model scale",
          "relevance": 0.364
        },
        {
          "concept": "evaluation",
          "relevance": 0.363
        },
        {
          "concept": "model",
          "relevance": 0.359
        },
        {
          "concept": "capability",
          "relevance": 0.358
        },
        {
          "concept": "tuning",
          "relevance": 0.335
        },
        {
          "concept": "reference",
          "relevance": 0.333
        },
        {
          "concept": "summary",
          "relevance": 0.316
        },
        {
          "concept": "method",
          "relevance": 0.313
        },
        {
          "concept": "success",
          "relevance": 0.292
        },
        {
          "concept": "underestimation",
          "relevance": 0.292
        },
        {
          "concept": "study",
          "relevance": 0.268
        },
        {
          "concept": "differences",
          "relevance": 0.268
        },
        {
          "concept": "observations",
          "relevance": 0.267
        },
        {
          "concept": "scale",
          "relevance": 0.253
        },
        {
          "concept": "size",
          "relevance": 0.231
        },
        {
          "concept": "amount",
          "relevance": 0.225
        }
      ]
    },
    {
      "paperId": "pub.1158361897",
      "doi": "10.1111/nyas.15007",
      "title": "Holistic Evaluation of Language Models",
      "year": 2023,
      "citationCount": 198,
      "fieldCitationRatio": 125.3,
      "abstract": "Language models (LMs) like GPT-3, PaLM, and ChatGPT are the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of LMs. LMs can serve many purposes and their behavior should satisfy many desiderata. To navigate the vast space of potential scenarios and metrics, we taxonomize the space and select representative subsets. We evaluate models on 16 core scenarios and 7 metrics, exposing important trade-offs. We supplement our core evaluation with seven targeted evaluations to deeply analyze specific aspects (including world knowledge, reasoning, regurgitation of copyrighted content, and generation of disinformation). We benchmark 30 LMs, from OpenAI, Microsoft, Google, Meta, Cohere, AI21 Labs, and others. Prior to HELM, models were evaluated on just 17.9% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0%: all 30 models are now benchmarked under the same standardized conditions. Our evaluation surfaces 25 top-level findings. For full transparency, we release all raw model prompts and completions publicly. HELM is a living benchmark for the community, continuously updated with new scenarios, metrics, and models https://crfm.stanford.edu/helm/latest/.",
      "reference_ids": [
        "pub.1143223853",
        "pub.1035788679",
        "pub.1004610763",
        "pub.1017974835",
        "pub.1138840570",
        "pub.1061518060",
        "pub.1133177154",
        "pub.1163041499",
        "pub.1006825520",
        "pub.1051294395",
        "pub.1047765706",
        "pub.1117660148",
        "pub.1099110523",
        "pub.1095689025",
        "pub.1045494205",
        "pub.1138840503",
        "pub.1163041514",
        "pub.1099201763",
        "pub.1139948409",
        "pub.1099106053",
        "pub.1133174687",
        "pub.1148815077",
        "pub.1163045487",
        "pub.1098653837",
        "pub.1104321292",
        "pub.1040280730",
        "pub.1061443284",
        "pub.1027296971",
        "pub.1160041843",
        "pub.1052867467",
        "pub.1133175312"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.653
        },
        {
          "concept": "language technology",
          "relevance": 0.507
        },
        {
          "concept": "GPT-3",
          "relevance": 0.506
        },
        {
          "concept": "representative subsets",
          "relevance": 0.484
        },
        {
          "concept": "metrics",
          "relevance": 0.458
        },
        {
          "concept": "evaluation model",
          "relevance": 0.455
        },
        {
          "concept": "scenarios",
          "relevance": 0.443
        },
        {
          "concept": "trade-offs",
          "relevance": 0.429
        },
        {
          "concept": "analyze specific aspects",
          "relevance": 0.417
        },
        {
          "concept": "OpenAI",
          "relevance": 0.415
        },
        {
          "concept": "ChatGPT",
          "relevance": 0.412
        },
        {
          "concept": "language",
          "relevance": 0.396
        },
        {
          "concept": "Microsoft",
          "relevance": 0.384
        },
        {
          "concept": "holistic evaluation",
          "relevance": 0.379
        },
        {
          "concept": "benchmarks",
          "relevance": 0.379
        },
        {
          "concept": "model",
          "relevance": 0.355
        },
        {
          "concept": "potential scenarios",
          "relevance": 0.351
        },
        {
          "concept": "evaluation",
          "relevance": 0.349
        },
        {
          "concept": "prominent models",
          "relevance": 0.347
        },
        {
          "concept": "capability",
          "relevance": 0.345
        },
        {
          "concept": "transparency",
          "relevance": 0.342
        },
        {
          "concept": "technology",
          "relevance": 0.34
        },
        {
          "concept": "Google",
          "relevance": 0.338
        },
        {
          "concept": "desiderata",
          "relevance": 0.322
        },
        {
          "concept": "specific aspects",
          "relevance": 0.322
        },
        {
          "concept": "core scenarios",
          "relevance": 0.312
        },
        {
          "concept": "space",
          "relevance": 0.302
        },
        {
          "concept": "lab",
          "relevance": 0.299
        },
        {
          "concept": "model prompt",
          "relevance": 0.298
        },
        {
          "concept": "meta",
          "relevance": 0.296
        },
        {
          "concept": "core",
          "relevance": 0.29
        },
        {
          "concept": "target evaluation",
          "relevance": 0.29
        },
        {
          "concept": "subsets",
          "relevance": 0.289
        },
        {
          "concept": "purposes",
          "relevance": 0.271
        },
        {
          "concept": "coherence",
          "relevance": 0.271
        },
        {
          "concept": "aspects",
          "relevance": 0.263
        },
        {
          "concept": "completion",
          "relevance": 0.26
        },
        {
          "concept": "prompts",
          "relevance": 0.256
        },
        {
          "concept": "limitations",
          "relevance": 0.245
        },
        {
          "concept": "behavior",
          "relevance": 0.222
        },
        {
          "concept": "community",
          "relevance": 0.22
        },
        {
          "concept": "palm",
          "relevance": 0.196
        },
        {
          "concept": "standard conditions",
          "relevance": 0.186
        },
        {
          "concept": "risk",
          "relevance": 0.173
        },
        {
          "concept": "conditions",
          "relevance": 0.172
        }
      ]
    },
    {
      "paperId": "pub.1095689025",
      "doi": "10.1109/cvpr.2009.5206848",
      "title": "ImageNet: A large-scale hierarchical image database",
      "year": 2009,
      "citationCount": 48560,
      "fieldCitationRatio": 11425.11,
      "abstract": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.",
      "reference_ids": [
        "pub.1002200216",
        "pub.1002707761",
        "pub.1093839826",
        "pub.1094055038",
        "pub.1045945012",
        "pub.1093423587",
        "pub.1094700637",
        "pub.1093888066",
        "pub.1061743490",
        "pub.1022501172",
        "pub.1093301542",
        "pub.1017544873",
        "pub.1027534025",
        "pub.1038699157",
        "pub.1061743121",
        "pub.1093557144",
        "pub.1021652857",
        "pub.1052687286",
        "pub.1045723254"
      ],
      "concepts_scores": [
        {
          "concept": "semantic hierarchy of WordNet",
          "relevance": 0.695
        },
        {
          "concept": "hierarchical structure of ImageNet",
          "relevance": 0.695
        },
        {
          "concept": "explosion of image data",
          "relevance": 0.676
        },
        {
          "concept": "large-scale ontologies",
          "relevance": 0.673
        },
        {
          "concept": "computer vision community",
          "relevance": 0.673
        },
        {
          "concept": "synsets of WordNet",
          "relevance": 0.665
        },
        {
          "concept": "data collection scheme",
          "relevance": 0.658
        },
        {
          "concept": "large-scale databases",
          "relevance": 0.644
        },
        {
          "concept": "multimedia data",
          "relevance": 0.625
        },
        {
          "concept": "vision community",
          "relevance": 0.624
        },
        {
          "concept": "annotated images",
          "relevance": 0.619
        },
        {
          "concept": "image classification",
          "relevance": 0.618
        },
        {
          "concept": "semantic hierarchy",
          "relevance": 0.617
        },
        {
          "concept": "WordNet structure",
          "relevance": 0.616
        },
        {
          "concept": "image datasets",
          "relevance": 0.615
        },
        {
          "concept": "object clustering",
          "relevance": 0.613
        },
        {
          "concept": "ImageNet",
          "relevance": 0.611
        },
        {
          "concept": "object recognition",
          "relevance": 0.599
        },
        {
          "concept": "WordNet",
          "relevance": 0.593
        },
        {
          "concept": "Amazon Mechanical Turk",
          "relevance": 0.59
        },
        {
          "concept": "collection scheme",
          "relevance": 0.588
        },
        {
          "concept": "image data",
          "relevance": 0.56
        },
        {
          "concept": "synsets",
          "relevance": 0.556
        },
        {
          "concept": "Mechanical Turk",
          "relevance": 0.547
        },
        {
          "concept": "ontology of images",
          "relevance": 0.536
        },
        {
          "concept": "robust model",
          "relevance": 0.527
        },
        {
          "concept": "hierarchical structure",
          "relevance": 0.518
        },
        {
          "concept": "images",
          "relevance": 0.499
        },
        {
          "concept": "multimedia",
          "relevance": 0.477
        },
        {
          "concept": "Internet",
          "relevance": 0.468
        },
        {
          "concept": "algorithm",
          "relevance": 0.461
        },
        {
          "concept": "dataset",
          "relevance": 0.458
        },
        {
          "concept": "subtrees",
          "relevance": 0.457
        },
        {
          "concept": "database",
          "relevance": 0.455
        },
        {
          "concept": "computer",
          "relevance": 0.451
        },
        {
          "concept": "task",
          "relevance": 0.439
        },
        {
          "concept": "scheme",
          "relevance": 0.439
        },
        {
          "concept": "classification",
          "relevance": 0.436
        },
        {
          "concept": "recognition",
          "relevance": 0.422
        },
        {
          "concept": "accuracy",
          "relevance": 0.419
        },
        {
          "concept": "data",
          "relevance": 0.396
        },
        {
          "concept": "Amazon",
          "relevance": 0.387
        },
        {
          "concept": "applications",
          "relevance": 0.38
        },
        {
          "concept": "clusters",
          "relevance": 0.374
        },
        {
          "concept": "objective",
          "relevance": 0.37
        },
        {
          "concept": "Turks",
          "relevance": 0.355
        },
        {
          "concept": "model",
          "relevance": 0.335
        },
        {
          "concept": "diversity",
          "relevance": 0.335
        },
        {
          "concept": "backbone",
          "relevance": 0.333
        },
        {
          "concept": "research",
          "relevance": 0.327
        },
        {
          "concept": "explosion",
          "relevance": 0.321
        },
        {
          "concept": "opportunities",
          "relevance": 0.295
        },
        {
          "concept": "scale",
          "relevance": 0.28
        },
        {
          "concept": "average",
          "relevance": 0.273
        },
        {
          "concept": "community",
          "relevance": 0.26
        },
        {
          "concept": "structure",
          "relevance": 0.257
        },
        {
          "concept": "analysis",
          "relevance": 0.254
        },
        {
          "concept": "use",
          "relevance": 0.251
        },
        {
          "concept": "index",
          "relevance": 0.226
        },
        {
          "concept": "potential",
          "relevance": 0.215
        }
      ]
    },
    {
      "paperId": "pub.1143223853",
      "doi": "10.1145/3458817.3476209",
      "title": "Efficient large-scale language model training on GPU clusters using megatron-LM",
      "year": 2021,
      "citationCount": 425,
      "fieldCitationRatio": 152.4,
      "abstract": "Large language models have led to state-of-the-art accuracies across several tasks. However, training these models efficiently is challenging because: a) GPU memory capacity is limited, making it impossible to fit large models on even a multi-GPU server, and b) the number of compute operations required can result in unrealistically long training times. Consequently, new methods of model parallelism such as tensor and pipeline parallelism have been proposed. Unfortunately, naive usage of these methods leads to scaling issues at thousands of GPUs. In this paper, we show how tensor, pipeline, and data parallelism can be composed to scale to thousands of GPUs. We propose a novel interleaved pipelining schedule that can improve throughput by 10+% with memory footprint comparable to existing approaches. Our approach allows us to perform training iterations on a model with 1 trillion parameters at 502 petaFLOP/s on 3072 GPUs (per-GPU throughput of 52% of theoretical peak).",
      "reference_ids": [
        "pub.1135417899",
        "pub.1061523268"
      ],
      "concepts_scores": [
        {
          "concept": "state-of-the-art accuracy",
          "relevance": 0.697
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.671
        },
        {
          "concept": "language model training",
          "relevance": 0.668
        },
        {
          "concept": "GPU memory capacity",
          "relevance": 0.662
        },
        {
          "concept": "multi-GPU servers",
          "relevance": 0.647
        },
        {
          "concept": "training iterations",
          "relevance": 0.622
        },
        {
          "concept": "GPU cluster",
          "relevance": 0.619
        },
        {
          "concept": "multi-GPU",
          "relevance": 0.618
        },
        {
          "concept": "language model",
          "relevance": 0.617
        },
        {
          "concept": "memory footprint",
          "relevance": 0.616
        },
        {
          "concept": "model parallelism",
          "relevance": 0.611
        },
        {
          "concept": "data parallelism",
          "relevance": 0.611
        },
        {
          "concept": "pipeline parallelism",
          "relevance": 0.609
        },
        {
          "concept": "model training",
          "relevance": 0.606
        },
        {
          "concept": "naive usage",
          "relevance": 0.603
        },
        {
          "concept": "GPU",
          "relevance": 0.602
        },
        {
          "concept": "computational operations",
          "relevance": 0.596
        },
        {
          "concept": "memory capacity",
          "relevance": 0.52
        },
        {
          "concept": "parallel",
          "relevance": 0.498
        },
        {
          "concept": "server",
          "relevance": 0.48
        },
        {
          "concept": "pipeline",
          "relevance": 0.471
        },
        {
          "concept": "throughput",
          "relevance": 0.47
        },
        {
          "concept": "training",
          "relevance": 0.463
        },
        {
          "concept": "scaling issues",
          "relevance": 0.462
        },
        {
          "concept": "computer",
          "relevance": 0.451
        },
        {
          "concept": "task",
          "relevance": 0.439
        },
        {
          "concept": "iteration",
          "relevance": 0.438
        },
        {
          "concept": "accuracy",
          "relevance": 0.419
        },
        {
          "concept": "model",
          "relevance": 0.415
        },
        {
          "concept": "method",
          "relevance": 0.411
        },
        {
          "concept": "usage",
          "relevance": 0.409
        },
        {
          "concept": "language",
          "relevance": 0.403
        },
        {
          "concept": "scheduling",
          "relevance": 0.402
        },
        {
          "concept": "memory",
          "relevance": 0.389
        },
        {
          "concept": "tensor",
          "relevance": 0.381
        },
        {
          "concept": "clusters",
          "relevance": 0.374
        },
        {
          "concept": "operation",
          "relevance": 0.369
        },
        {
          "concept": "issues",
          "relevance": 0.363
        },
        {
          "concept": "trillion",
          "relevance": 0.338
        },
        {
          "concept": "footprint",
          "relevance": 0.334
        },
        {
          "concept": "data",
          "relevance": 0.32
        },
        {
          "concept": "parameters",
          "relevance": 0.293
        },
        {
          "concept": "capacity",
          "relevance": 0.257
        },
        {
          "concept": "approach",
          "relevance": 0.251
        },
        {
          "concept": "scale",
          "relevance": 0.234
        }
      ]
    },
    {
      "paperId": "pub.1137573792",
      "doi": "10.1162/tacl_a_00373",
      "title": "SummEval: Re-evaluating Summarization Evaluation",
      "year": 2021,
      "citationCount": 196,
      "fieldCitationRatio": 59.0,
      "abstract": "Abstract\n                  The scarcity of comprehensive up-to-date studies on evaluation metrics for text summarization and the lack of consensus regarding evaluation protocols continue to inhibit progress. We address the existing shortcomings of summarization evaluation methods along five dimensions: 1) we re-evaluate 14 automatic evaluation metrics in a comprehensive and consistent fashion using neural summarization model outputs along with expert and crowd-sourced human annotations; 2) we consistently benchmark 23 recent summarization models using the aforementioned automatic evaluation metrics; 3) we assemble the largest collection of summaries generated by models trained on the CNN/DailyMail news dataset and share it in a unified format; 4) we implement and share a toolkit that provides an extensible and unified API for evaluating summarization models across a broad range of automatic metrics; and 5) we assemble and share the largest and most diverse, in terms of model types, collection of human judgments of model-generated summaries on the CNN/Daily Mail dataset annotated by both expert judges and crowd-source workers. We hope that this work will help promote a more complete evaluation protocol for text summarization as well as advance research in developing evaluation metrics that better correlate with human judgments.",
      "reference_ids": [
        "pub.1117658731",
        "pub.1129757057",
        "pub.1104321155",
        "pub.1117659387",
        "pub.1104321248",
        "pub.1133174463",
        "pub.1099097107",
        "pub.1121024922",
        "pub.1053468661",
        "pub.1099106200",
        "pub.1129756745",
        "pub.1117658853",
        "pub.1122290337",
        "pub.1096025521",
        "pub.1099239594",
        "pub.1104321397",
        "pub.1117658734",
        "pub.1117659340",
        "pub.1133175763",
        "pub.1099105991",
        "pub.1117659388",
        "pub.1099179676",
        "pub.1129757334",
        "pub.1122290070",
        "pub.1117659089",
        "pub.1129756691",
        "pub.1099204495",
        "pub.1121024856",
        "pub.1117658735",
        "pub.1129757053",
        "pub.1117659391",
        "pub.1117658854",
        "pub.1121025287",
        "pub.1122290404",
        "pub.1122290068",
        "pub.1099113832",
        "pub.1117659086",
        "pub.1133174738",
        "pub.1095795137",
        "pub.1122290324",
        "pub.1050378128",
        "pub.1121025094",
        "pub.1117659390",
        "pub.1122290340",
        "pub.1121025091",
        "pub.1001381236",
        "pub.1117659055",
        "pub.1100517192"
      ],
      "concepts_scores": [
        {
          "concept": "automatic evaluation metrics",
          "relevance": 0.789
        },
        {
          "concept": "evaluation metrics",
          "relevance": 0.764
        },
        {
          "concept": "summarization model",
          "relevance": 0.731
        },
        {
          "concept": "CNN/Daily Mail dataset",
          "relevance": 0.681
        },
        {
          "concept": "crowd-sourced workers",
          "relevance": 0.655
        },
        {
          "concept": "evaluation protocol",
          "relevance": 0.64
        },
        {
          "concept": "text summarization",
          "relevance": 0.631
        },
        {
          "concept": "collection of summaries",
          "relevance": 0.631
        },
        {
          "concept": "Mail dataset",
          "relevance": 0.631
        },
        {
          "concept": "summarization evaluation",
          "relevance": 0.63
        },
        {
          "concept": "automatic metrics",
          "relevance": 0.629
        },
        {
          "concept": "human annotators",
          "relevance": 0.625
        },
        {
          "concept": "news dataset",
          "relevance": 0.622
        },
        {
          "concept": "summarization",
          "relevance": 0.602
        },
        {
          "concept": "human judgment",
          "relevance": 0.595
        },
        {
          "concept": "unified format",
          "relevance": 0.58
        },
        {
          "concept": "metrics",
          "relevance": 0.557
        },
        {
          "concept": "dataset",
          "relevance": 0.535
        },
        {
          "concept": "evaluation method",
          "relevance": 0.521
        },
        {
          "concept": "CNN/DailyMail",
          "relevance": 0.496
        },
        {
          "concept": "model types",
          "relevance": 0.489
        },
        {
          "concept": "protocol",
          "relevance": 0.461
        },
        {
          "concept": "API",
          "relevance": 0.452
        },
        {
          "concept": "annotation",
          "relevance": 0.451
        },
        {
          "concept": "evaluation",
          "relevance": 0.446
        },
        {
          "concept": "toolkit",
          "relevance": 0.438
        },
        {
          "concept": "up-to-date studies",
          "relevance": 0.426
        },
        {
          "concept": "model",
          "relevance": 0.418
        },
        {
          "concept": "collection",
          "relevance": 0.418
        },
        {
          "concept": "text",
          "relevance": 0.407
        },
        {
          "concept": "model output",
          "relevance": 0.407
        },
        {
          "concept": "output",
          "relevance": 0.387
        },
        {
          "concept": "expert judges",
          "relevance": 0.386
        },
        {
          "concept": "summary",
          "relevance": 0.361
        },
        {
          "concept": "method",
          "relevance": 0.357
        },
        {
          "concept": "Abstract",
          "relevance": 0.34
        },
        {
          "concept": "research",
          "relevance": 0.329
        },
        {
          "concept": "dimensions",
          "relevance": 0.315
        },
        {
          "concept": "judgment",
          "relevance": 0.31
        },
        {
          "concept": "scarcity",
          "relevance": 0.299
        },
        {
          "concept": "consensus",
          "relevance": 0.297
        },
        {
          "concept": "judges",
          "relevance": 0.275
        },
        {
          "concept": "lack",
          "relevance": 0.271
        },
        {
          "concept": "lack of consensus",
          "relevance": 0.257
        },
        {
          "concept": "type",
          "relevance": 0.213
        },
        {
          "concept": "study",
          "relevance": 0.203
        },
        {
          "concept": "progression",
          "relevance": 0.201
        },
        {
          "concept": "formation",
          "relevance": 0.201
        },
        {
          "concept": "workers",
          "relevance": 0.199
        },
        {
          "concept": "inhibit progression",
          "relevance": 0.189
        }
      ]
    }
  ],
  "evolution_links": [
    {
      "source": "pub.1173010337",
      "target": "pub.1163376142",
      "source_title": "LUNA: A Model-Based Universal Analysis Framework for Large Language Models",
      "target_title": "Summary of ChatGPT-Related research and perspective towards the future of large language models"
    },
    {
      "source": "pub.1163376142",
      "target": "pub.1164705743",
      "source_title": "Summary of ChatGPT-Related research and perspective towards the future of large language models",
      "target_title": "ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports"
    },
    {
      "source": "pub.1164705743",
      "target": "pub.1120882528",
      "source_title": "ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports",
      "target_title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"
    },
    {
      "source": "pub.1164705743",
      "target": "pub.1135710434",
      "source_title": "ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports",
      "target_title": "On the Dangers of Stochastic Parrots"
    },
    {
      "source": "pub.1163376142",
      "target": "pub.1159948202",
      "source_title": "Summary of ChatGPT-Related research and perspective towards the future of large language models",
      "target_title": "The Role of AI in Drug Discovery: Challenges, Opportunities, and Strategies"
    },
    {
      "source": "pub.1159948202",
      "target": "pub.1142245816",
      "source_title": "The Role of AI in Drug Discovery: Challenges, Opportunities, and Strategies",
      "target_title": "Artificial intelligence: A powerful paradigm for scientific research"
    },
    {
      "source": "pub.1159948202",
      "target": "pub.1146252255",
      "source_title": "The Role of AI in Drug Discovery: Challenges, Opportunities, and Strategies",
      "target_title": "Legal and Ethical Consideration in Artificial Intelligence in Healthcare: Who Takes Responsibility?"
    },
    {
      "source": "pub.1173010337",
      "target": "pub.1168533982",
      "source_title": "LUNA: A Model-Based Universal Analysis Framework for Large Language Models",
      "target_title": "Benchmarking Large Language Models for News Summarization"
    },
    {
      "source": "pub.1168533982",
      "target": "pub.1158361897",
      "source_title": "Benchmarking Large Language Models for News Summarization",
      "target_title": "Holistic Evaluation of Language Models"
    },
    {
      "source": "pub.1158361897",
      "target": "pub.1095689025",
      "source_title": "Holistic Evaluation of Language Models",
      "target_title": "ImageNet: A large-scale hierarchical image database"
    },
    {
      "source": "pub.1158361897",
      "target": "pub.1143223853",
      "source_title": "Holistic Evaluation of Language Models",
      "target_title": "Efficient large-scale language model training on GPU clusters using megatron-LM"
    },
    {
      "source": "pub.1168533982",
      "target": "pub.1137573792",
      "source_title": "Benchmarking Large Language Models for News Summarization",
      "target_title": "SummEval: Re-evaluating Summarization Evaluation"
    }
  ]
}