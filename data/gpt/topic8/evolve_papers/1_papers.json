{
  "papers": [
    {
      "paperId": "pub.1163533062",
      "doi": "10.1007/s12559-023-10179-8",
      "title": "Interpreting Black-Box Models: A Review on Explainable Artificial Intelligence",
      "year": 2023,
      "citationCount": 694,
      "fieldCitationRatio": 439.19,
      "abstract": "Recent years have seen a tremendous growth in Artificial Intelligence (AI)-based methodological development in a broad range of domains. In this rapidly evolving field, large number of methods are being reported using machine learning (ML) and Deep Learning (DL) models. Majority of these models are inherently complex and lacks explanations of the decision making process causing these models to be termed as 'Black-Box'. One of the major bottlenecks to adopt such models in mission-critical application domains, such as banking, e-commerce, healthcare, and public services and safety, is the difficulty in interpreting them. Due to the rapid proleferation of these AI models, explaining their learning and decision making process are getting harder which require transparency and easy predictability. Aiming to collate the current state-of-the-art in interpreting the black-box models, this study provides a comprehensive analysis of the explainable AI (XAI) models. To reduce false negative and false positive outcomes of these back-box models, finding flaws in them is still difficult and inefficient. In this paper, the development of XAI is reviewed meticulously through careful selection and analysis of the current state-of-the-art of XAI research. It also provides a comprehensive and in-depth evaluation of the XAI frameworks and their efficacy to serve as a starting point of XAI for applied and theoretical researchers. Towards the end, it highlights emerging and critical issues pertaining to XAI research to showcase major, model-specific trends for better explanation, enhanced transparency, and improved prediction accuracy.",
      "reference_ids": [
        "pub.1148956109",
        "pub.1093270996",
        "pub.1142568599",
        "pub.1148580632",
        "pub.1128394885",
        "pub.1101491119",
        "pub.1133236642",
        "pub.1158993741",
        "pub.1140323967",
        "pub.1126030749",
        "pub.1152730551",
        "pub.1085642448",
        "pub.1151550100",
        "pub.1003469755",
        "pub.1024739340",
        "pub.1145040198",
        "pub.1154685338",
        "pub.1020605803",
        "pub.1148154177",
        "pub.1135709265",
        "pub.1132244902",
        "pub.1140076554",
        "pub.1123669031",
        "pub.1148627687",
        "pub.1159390220",
        "pub.1039084461",
        "pub.1092331989",
        "pub.1130542975",
        "pub.1149234188",
        "pub.1151231722",
        "pub.1137938003",
        "pub.1067242363",
        "pub.1024830223",
        "pub.1136933157",
        "pub.1061719264",
        "pub.1158403450",
        "pub.1105312436",
        "pub.1038436955",
        "pub.1138615907",
        "pub.1139629150",
        "pub.1142386613",
        "pub.1120763348",
        "pub.1015018067",
        "pub.1111165352",
        "pub.1032233097",
        "pub.1027897187",
        "pub.1138493931",
        "pub.1045871111",
        "pub.1124215602",
        "pub.1143048689",
        "pub.1152294570",
        "pub.1095258848",
        "pub.1147031203",
        "pub.1062965084",
        "pub.1028574329",
        "pub.1051413569",
        "pub.1124410024",
        "pub.1121662958",
        "pub.1157076824",
        "pub.1093194973",
        "pub.1111349438",
        "pub.1027822400",
        "pub.1067339747",
        "pub.1094339327",
        "pub.1129135804",
        "pub.1140124602",
        "pub.1145669815",
        "pub.1105267403",
        "pub.1150075357",
        "pub.1143148767",
        "pub.1107064439",
        "pub.1135911907",
        "pub.1126277589",
        "pub.1094434189",
        "pub.1144561428",
        "pub.1126789249",
        "pub.1158301269",
        "pub.1131296888",
        "pub.1147625701",
        "pub.1085709278",
        "pub.1133501461",
        "pub.1103242128",
        "pub.1100060663",
        "pub.1106289667",
        "pub.1009767488",
        "pub.1124464884",
        "pub.1132949057",
        "pub.1144622565",
        "pub.1125567189",
        "pub.1157255153",
        "pub.1148352506",
        "pub.1084112523",
        "pub.1107865769",
        "pub.1136738729",
        "pub.1135101554",
        "pub.1148627884",
        "pub.1147290270",
        "pub.1124238672",
        "pub.1155677122",
        "pub.1139435743",
        "pub.1058368938",
        "pub.1041224658",
        "pub.1092723101",
        "pub.1103568851",
        "pub.1117945959",
        "pub.1128205418",
        "pub.1148951306",
        "pub.1030645893",
        "pub.1099151330",
        "pub.1141232782",
        "pub.1039427823",
        "pub.1154180470",
        "pub.1045321436",
        "pub.1107651665",
        "pub.1113814588",
        "pub.1037292812",
        "pub.1146246594",
        "pub.1064395048",
        "pub.1064392198",
        "pub.1144912454",
        "pub.1134304670",
        "pub.1159955961",
        "pub.1028169001",
        "pub.1150861343",
        "pub.1112676463",
        "pub.1091189429",
        "pub.1131933523",
        "pub.1143006355",
        "pub.1157834138",
        "pub.1137507049",
        "pub.1146057604",
        "pub.1140876140",
        "pub.1154477026",
        "pub.1139853736",
        "pub.1125586380",
        "pub.1147616318",
        "pub.1111517565",
        "pub.1111399924"
      ],
      "concepts_scores": [
        {
          "concept": "black-box models",
          "relevance": 0.689
        },
        {
          "concept": "XAI research",
          "relevance": 0.675
        },
        {
          "concept": "deep learning",
          "relevance": 0.673
        },
        {
          "concept": "machine learning",
          "relevance": 0.661
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.658
        },
        {
          "concept": "black-box",
          "relevance": 0.644
        },
        {
          "concept": "decision making process",
          "relevance": 0.635
        },
        {
          "concept": "Explainable Artificial Intelligence",
          "relevance": 0.633
        },
        {
          "concept": "prediction accuracy",
          "relevance": 0.598
        },
        {
          "concept": "XAI framework",
          "relevance": 0.587
        },
        {
          "concept": "application domains",
          "relevance": 0.584
        },
        {
          "concept": "improve prediction accuracy",
          "relevance": 0.584
        },
        {
          "concept": "XAI",
          "relevance": 0.574
        },
        {
          "concept": "e-commerce",
          "relevance": 0.571
        },
        {
          "concept": "AI models",
          "relevance": 0.565
        },
        {
          "concept": "back-box",
          "relevance": 0.513
        },
        {
          "concept": "learning",
          "relevance": 0.499
        },
        {
          "concept": "intelligence",
          "relevance": 0.497
        },
        {
          "concept": "accuracy",
          "relevance": 0.461
        },
        {
          "concept": "explainability",
          "relevance": 0.448
        },
        {
          "concept": "Deep",
          "relevance": 0.443
        },
        {
          "concept": "enhance transparency",
          "relevance": 0.442
        },
        {
          "concept": "public services",
          "relevance": 0.441
        },
        {
          "concept": "decision",
          "relevance": 0.426
        },
        {
          "concept": "machine",
          "relevance": 0.419
        },
        {
          "concept": "Artificial",
          "relevance": 0.418
        },
        {
          "concept": "AI",
          "relevance": 0.414
        },
        {
          "concept": "theoretical research",
          "relevance": 0.41
        },
        {
          "concept": "bottleneck",
          "relevance": 0.404
        },
        {
          "concept": "transparency",
          "relevance": 0.402
        },
        {
          "concept": "model",
          "relevance": 0.398
        },
        {
          "concept": "framework",
          "relevance": 0.384
        },
        {
          "concept": "services",
          "relevance": 0.383
        },
        {
          "concept": "research",
          "relevance": 0.378
        },
        {
          "concept": "positive outcomes",
          "relevance": 0.376
        },
        {
          "concept": "domain",
          "relevance": 0.363
        },
        {
          "concept": "comprehensive analysis",
          "relevance": 0.358
        },
        {
          "concept": "process",
          "relevance": 0.349
        },
        {
          "concept": "methodological developments",
          "relevance": 0.343
        },
        {
          "concept": "method",
          "relevance": 0.337
        },
        {
          "concept": "evaluation",
          "relevance": 0.337
        },
        {
          "concept": "healthcare",
          "relevance": 0.33
        },
        {
          "concept": "prediction",
          "relevance": 0.328
        },
        {
          "concept": "selection",
          "relevance": 0.319
        },
        {
          "concept": "development",
          "relevance": 0.303
        },
        {
          "concept": "difficulties",
          "relevance": 0.301
        },
        {
          "concept": "safety",
          "relevance": 0.293
        },
        {
          "concept": "analysis",
          "relevance": 0.279
        },
        {
          "concept": "explanation",
          "relevance": 0.265
        },
        {
          "concept": "trends",
          "relevance": 0.259
        },
        {
          "concept": "study",
          "relevance": 0.227
        },
        {
          "concept": "growth",
          "relevance": 0.219
        },
        {
          "concept": "review",
          "relevance": 0.215
        },
        {
          "concept": "Majority",
          "relevance": 0.213
        },
        {
          "concept": "outcomes",
          "relevance": 0.21
        },
        {
          "concept": "years",
          "relevance": 0.201
        },
        {
          "concept": "efficacy",
          "relevance": 0.153
        }
      ]
    },
    {
      "paperId": "pub.1148956109",
      "doi": "10.1609/aaai.v32i1.11491",
      "title": "Anchors: High-Precision Model-Agnostic Explanations",
      "year": 2018,
      "citationCount": 1344,
      "fieldCitationRatio": 358.35,
      "abstract": "We introduce a novel model-agnostic system that explains the behavior of complex models with high-precision rules called anchors, representing local, \"sufficient\" conditions for predictions. We propose an algorithm to efficiently compute these explanations for any black-box model with high-probability guarantees. We demonstrate the flexibility of anchors by explaining a myriad of different models for different domains and tasks. In a user study, we show that anchors enable users to predict how a model would behave on unseen instances with less effort and higher precision, as compared to existing linear explanations or no explanations.",
      "reference_ids": [
        "pub.1036627537",
        "pub.1052511411",
        "pub.1035893296",
        "pub.1045977640",
        "pub.1032448819"
      ],
      "concepts_scores": [
        {
          "concept": "high-precision rules",
          "relevance": 0.69
        },
        {
          "concept": "behavior of complex models",
          "relevance": 0.676
        },
        {
          "concept": "high-probability guarantees",
          "relevance": 0.676
        },
        {
          "concept": "black-box models",
          "relevance": 0.639
        },
        {
          "concept": "user study",
          "relevance": 0.636
        },
        {
          "concept": "users",
          "relevance": 0.557
        },
        {
          "concept": "high precision",
          "relevance": 0.527
        },
        {
          "concept": "complex models",
          "relevance": 0.492
        },
        {
          "concept": "guarantees",
          "relevance": 0.477
        },
        {
          "concept": "algorithm",
          "relevance": 0.47
        },
        {
          "concept": "task",
          "relevance": 0.448
        },
        {
          "concept": "model",
          "relevance": 0.423
        },
        {
          "concept": "rules",
          "relevance": 0.414
        },
        {
          "concept": "flexibility",
          "relevance": 0.396
        },
        {
          "concept": "anchor",
          "relevance": 0.391
        },
        {
          "concept": "domain",
          "relevance": 0.39
        },
        {
          "concept": "precision",
          "relevance": 0.39
        },
        {
          "concept": "system",
          "relevance": 0.374
        },
        {
          "concept": "prediction",
          "relevance": 0.352
        },
        {
          "concept": "efforts",
          "relevance": 0.332
        },
        {
          "concept": "myriad",
          "relevance": 0.298
        },
        {
          "concept": "behavior",
          "relevance": 0.267
        },
        {
          "concept": "explanation",
          "relevance": 0.246
        },
        {
          "concept": "conditions",
          "relevance": 0.208
        },
        {
          "concept": "study",
          "relevance": 0.187
        }
      ]
    },
    {
      "paperId": "pub.1045977640",
      "doi": "10.1007/978-3-540-88693-8_52",
      "title": "Quick Shift and Kernel Methods for Mode Seeking",
      "year": 2008,
      "citationCount": 763,
      "fieldCitationRatio": 158.65,
      "abstract": "We show that the complexity of the recently introduced medoid-shift algorithm in clustering N points is O(N2), with a small constant, if the underlying distance is Euclidean. This makes medoid shift considerably faster than mean shift, contrarily to what previously believed. We then exploit kernel methods to extend both mean shift and the improved medoid shift to a large family of distances, with complexity bounded by the effective rank of the resulting kernel matrix, and with explicit regularization constraints. Finally, we show that, under certain conditions, medoid shift fails to cluster data points belonging to the same mode, resulting in over-fragmentation. We propose remedies for this problem, by introducing a novel, simple and extremely efficient clustering algorithm, called quick shift, that explicitly trades off under- and over-fragmentation. Like medoid shift, quick shift operates in non-Euclidean spaces in a straightforward manner. We also show that the accelerated medoid shift can be used to initialize mean shift for increased efficiency. We illustrate our algorithms to clustering data on manifolds, image segmentation, and the automatic discovery of visual categories.",
      "reference_ids": [
        "pub.1094049331",
        "pub.1040335305",
        "pub.1061531698",
        "pub.1013998211",
        "pub.1095517793",
        "pub.1061155588",
        "pub.1093178998",
        "pub.1051758982",
        "pub.1094523579",
        "pub.1061156233",
        "pub.1020176705",
        "pub.1095466292",
        "pub.1008205152",
        "pub.1095493794",
        "pub.1095064571",
        "pub.1095377820",
        "pub.1061647566",
        "pub.1094229715"
      ],
      "concepts_scores": [
        {
          "concept": "cluster data points",
          "relevance": 0.646
        },
        {
          "concept": "non-Euclidean space",
          "relevance": 0.619
        },
        {
          "concept": "automatic discovery",
          "relevance": 0.603
        },
        {
          "concept": "kernel matrix",
          "relevance": 0.596
        },
        {
          "concept": "clustering algorithm",
          "relevance": 0.594
        },
        {
          "concept": "image segmentation",
          "relevance": 0.594
        },
        {
          "concept": "regularization constraints",
          "relevance": 0.587
        },
        {
          "concept": "kernel methods",
          "relevance": 0.577
        },
        {
          "concept": "visual categories",
          "relevance": 0.556
        },
        {
          "concept": "medoids",
          "relevance": 0.55
        },
        {
          "concept": "effective rank",
          "relevance": 0.548
        },
        {
          "concept": "data points",
          "relevance": 0.547
        },
        {
          "concept": "algorithm",
          "relevance": 0.545
        },
        {
          "concept": "clustered data",
          "relevance": 0.54
        },
        {
          "concept": "kernel",
          "relevance": 0.495
        },
        {
          "concept": "over-fragmentation",
          "relevance": 0.476
        },
        {
          "concept": "n-point",
          "relevance": 0.474
        },
        {
          "concept": "increased efficiency",
          "relevance": 0.443
        },
        {
          "concept": "regularization",
          "relevance": 0.4
        },
        {
          "concept": "constraints",
          "relevance": 0.392
        },
        {
          "concept": "images",
          "relevance": 0.389
        },
        {
          "concept": "distance",
          "relevance": 0.387
        },
        {
          "concept": "rank",
          "relevance": 0.386
        },
        {
          "concept": "complex",
          "relevance": 0.378
        },
        {
          "concept": "manifolds",
          "relevance": 0.374
        },
        {
          "concept": "segments",
          "relevance": 0.37
        },
        {
          "concept": "clusters",
          "relevance": 0.364
        },
        {
          "concept": "space",
          "relevance": 0.346
        },
        {
          "concept": "method",
          "relevance": 0.345
        },
        {
          "concept": "efficiency",
          "relevance": 0.342
        },
        {
          "concept": "point",
          "relevance": 0.314
        },
        {
          "concept": "matrix",
          "relevance": 0.313
        },
        {
          "concept": "data",
          "relevance": 0.311
        },
        {
          "concept": "problem",
          "relevance": 0.307
        },
        {
          "concept": "categories",
          "relevance": 0.301
        },
        {
          "concept": "mode",
          "relevance": 0.243
        },
        {
          "concept": "shift",
          "relevance": 0.237
        },
        {
          "concept": "remediation",
          "relevance": 0.156
        }
      ]
    },
    {
      "paperId": "pub.1061155588",
      "doi": "10.1109/34.1000236",
      "title": "Mean shift: a robust approach toward feature space analysis",
      "year": 2002,
      "citationCount": 9231,
      "fieldCitationRatio": 1792.38,
      "abstract": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance.",
      "reference_ids": [
        "pub.1061239520",
        "pub.1061239571",
        "pub.1013204100",
        "pub.1061647566",
        "pub.1021993026",
        "pub.1061156511",
        "pub.1061227792",
        "pub.1093644132",
        "pub.1061156901",
        "pub.1095642608",
        "pub.1058305341",
        "pub.1110458712",
        "pub.1061240168",
        "pub.1061156999",
        "pub.1093688695",
        "pub.1095356986",
        "pub.1017529757",
        "pub.1095616234",
        "pub.1044578666",
        "pub.1059420978",
        "pub.1042480796",
        "pub.1061157039",
        "pub.1095307959",
        "pub.1014200037",
        "pub.1027299385",
        "pub.1024339779",
        "pub.1095204797",
        "pub.1030628924",
        "pub.1005851761",
        "pub.1018182673",
        "pub.1061157134",
        "pub.1095805528",
        "pub.1093342324",
        "pub.1109727533",
        "pub.1061156233",
        "pub.1061156625",
        "pub.1061239477",
        "pub.1095466292",
        "pub.1061239720",
        "pub.1038538491",
        "pub.1061157169",
        "pub.1061156705",
        "pub.1061228850",
        "pub.1053283771",
        "pub.1061742121",
        "pub.1098552241",
        "pub.1023431552",
        "pub.1061156448",
        "pub.1094023374",
        "pub.1032390074",
        "pub.1094164268"
      ],
      "concepts_scores": [
        {
          "concept": "multimodal feature space",
          "relevance": 0.609
        },
        {
          "concept": "feature space",
          "relevance": 0.564
        },
        {
          "concept": "image segmentation",
          "relevance": 0.556
        },
        {
          "concept": "color images",
          "relevance": 0.556
        },
        {
          "concept": "pattern recognition procedure",
          "relevance": 0.54
        },
        {
          "concept": "gray levels",
          "relevance": 0.538
        },
        {
          "concept": "computational modules",
          "relevance": 0.537
        },
        {
          "concept": "kernel regression",
          "relevance": 0.531
        },
        {
          "concept": "Nadaraya-Watson estimator",
          "relevance": 0.525
        },
        {
          "concept": "robust M-estimators",
          "relevance": 0.524
        },
        {
          "concept": "recognition procedure",
          "relevance": 0.517
        },
        {
          "concept": "experimental results",
          "relevance": 0.502
        },
        {
          "concept": "discrete data",
          "relevance": 0.501
        },
        {
          "concept": "algorithm",
          "relevance": 0.485
        },
        {
          "concept": "M-estimators",
          "relevance": 0.48
        },
        {
          "concept": "excellent performance",
          "relevance": 0.468
        },
        {
          "concept": "robust approach",
          "relevance": 0.466
        },
        {
          "concept": "stationary points",
          "relevance": 0.458
        },
        {
          "concept": "space analysis",
          "relevance": 0.457
        },
        {
          "concept": "density function",
          "relevance": 0.456
        },
        {
          "concept": "non-parametric techniques",
          "relevance": 0.438
        },
        {
          "concept": "images",
          "relevance": 0.422
        },
        {
          "concept": "kernel",
          "relevance": 0.4
        },
        {
          "concept": "technique",
          "relevance": 0.38
        },
        {
          "concept": "space",
          "relevance": 0.378
        },
        {
          "concept": "convergence",
          "relevance": 0.375
        },
        {
          "concept": "smoothing",
          "relevance": 0.373
        },
        {
          "concept": "input",
          "relevance": 0.372
        },
        {
          "concept": "performance",
          "relevance": 0.367
        },
        {
          "concept": "nearest",
          "relevance": 0.361
        },
        {
          "concept": "segments",
          "relevance": 0.346
        },
        {
          "concept": "applications",
          "relevance": 0.346
        },
        {
          "concept": "modulation",
          "relevance": 0.344
        },
        {
          "concept": "clusters",
          "relevance": 0.34
        },
        {
          "concept": "estimation",
          "relevance": 0.318
        },
        {
          "concept": "color",
          "relevance": 0.311
        },
        {
          "concept": "location",
          "relevance": 0.296
        },
        {
          "concept": "point",
          "relevance": 0.294
        },
        {
          "concept": "data",
          "relevance": 0.291
        },
        {
          "concept": "density",
          "relevance": 0.291
        },
        {
          "concept": "resolution",
          "relevance": 0.284
        },
        {
          "concept": "analysis",
          "relevance": 0.281
        },
        {
          "concept": "function",
          "relevance": 0.281
        },
        {
          "concept": "results",
          "relevance": 0.281
        },
        {
          "concept": "parameters",
          "relevance": 0.266
        },
        {
          "concept": "mode",
          "relevance": 0.261
        },
        {
          "concept": "regression",
          "relevance": 0.235
        },
        {
          "concept": "procedure",
          "relevance": 0.228
        },
        {
          "concept": "approach",
          "relevance": 0.203
        },
        {
          "concept": "shift",
          "relevance": 0.184
        }
      ]
    },
    {
      "paperId": "pub.1061156233",
      "doi": "10.1109/34.400568",
      "title": "Mean shift, mode seeking, and clustering",
      "year": 1995,
      "citationCount": 3088,
      "fieldCitationRatio": NaN,
      "abstract": "Mean shift, a simple interactive procedure that shifts each data point to the average of data points in its neighborhood is generalized and analyzed in the paper. This generalization makes some k-means like clustering algorithms its special cases. It is shown that mean shift is a mode-seeking process on the surface constructed with a \"shadow\" kernal. For Gaussian kernels, mean shift is a gradient mapping. Convergence is studied for mean shift iterations. Cluster analysis if treated as a deterministic problem of finding a fixed point of mean shift that characterizes the data. Applications in clustering and Hough transform are demonstrated. Mean shift is also considered as an evolutionary strategy that performs multistart global optimization.<>",
      "reference_ids": [
        "pub.1060802009",
        "pub.1061647566",
        "pub.1061742013",
        "pub.1061742165",
        "pub.1061155880",
        "pub.1109705894",
        "pub.1032807851",
        "pub.1016789646"
      ],
      "concepts_scores": [
        {
          "concept": "mean shift",
          "relevance": 0.62
        },
        {
          "concept": "mode-seeking process",
          "relevance": 0.59
        },
        {
          "concept": "mode seeking",
          "relevance": 0.545
        },
        {
          "concept": "Gaussian kernel",
          "relevance": 0.534
        },
        {
          "concept": "Hough transform",
          "relevance": 0.53
        },
        {
          "concept": "k-means",
          "relevance": 0.528
        },
        {
          "concept": "global optimization",
          "relevance": 0.507
        },
        {
          "concept": "gradient map",
          "relevance": 0.505
        },
        {
          "concept": "data points",
          "relevance": 0.498
        },
        {
          "concept": "evolutionary strategy",
          "relevance": 0.498
        },
        {
          "concept": "interactive procedure",
          "relevance": 0.482
        },
        {
          "concept": "deterministic problem",
          "relevance": 0.455
        },
        {
          "concept": "data points",
          "relevance": 0.446
        },
        {
          "concept": "Hough",
          "relevance": 0.415
        },
        {
          "concept": "algorithm",
          "relevance": 0.407
        },
        {
          "concept": "clusters",
          "relevance": 0.402
        },
        {
          "concept": "kernel",
          "relevance": 0.389
        },
        {
          "concept": "optimization",
          "relevance": 0.369
        },
        {
          "concept": "convergence",
          "relevance": 0.365
        },
        {
          "concept": "generalization",
          "relevance": 0.348
        },
        {
          "concept": "maps",
          "relevance": 0.345
        },
        {
          "concept": "applications",
          "relevance": 0.336
        },
        {
          "concept": "point",
          "relevance": 0.331
        },
        {
          "concept": "data",
          "relevance": 0.328
        },
        {
          "concept": "neighborhood",
          "relevance": 0.325
        },
        {
          "concept": "transformation",
          "relevance": 0.324
        },
        {
          "concept": "cluster analysis",
          "relevance": 0.311
        },
        {
          "concept": "problem",
          "relevance": 0.3
        },
        {
          "concept": "seeking",
          "relevance": 0.285
        },
        {
          "concept": "process",
          "relevance": 0.281
        },
        {
          "concept": "strategies",
          "relevance": 0.272
        },
        {
          "concept": "gradient",
          "relevance": 0.254
        },
        {
          "concept": "average",
          "relevance": 0.241
        },
        {
          "concept": "shift",
          "relevance": 0.238
        },
        {
          "concept": "cases",
          "relevance": 0.236
        },
        {
          "concept": "surface",
          "relevance": 0.227
        },
        {
          "concept": "analysis",
          "relevance": 0.225
        },
        {
          "concept": "mode",
          "relevance": 0.221
        },
        {
          "concept": "procedure",
          "relevance": 0.221
        }
      ]
    },
    {
      "paperId": "pub.1035893296",
      "doi": "10.1017/cbo9781139177801.004",
      "title": "Submodular Function Maximization",
      "year": 2014,
      "citationCount": 513,
      "fieldCitationRatio": 114.52,
      "abstract": "In this chapter we will introduce submodularity and some of its generalizations, illustrate how it arises in various applications, and discuss algorithms for optimizing submodular functions. Submodularity is a property of set functions with deep theoretical consequences and far-reaching applications. At first glance it seems very similar to concavity, in other ways it resembles convexity. It appears in a wide variety of applications: in Computer Science it has recently been identified and utilized in domains such as viral marketing [39], information gathering [44], image segmentation [10, 40, 36], document summarization [56], and speeding up satisfiability solvers [73]. Our emphasis in this chapter is on maximization; there are many important results and applications related to minimizing submodular functions that we do not cover. As a concrete running example, we will consider the problem of deploying sensors in a drinking water distribution network (see Figure 3.1) in order to detect contamination. In this domain, we may have a model of how contaminants, accidentally or maliciously introduced into the network, spread over time. Such a model then allows to quantify the benefit f(A) of deploying sensors at a particular set A of locations (junctions or pipes in the network) in terms of the detection performance (such as average time to detection). Based on this notion of utility, we then wish to find an optimal subset A ⊆ V of locations maximizing the utility, maxAf(A), subject to some constraints (such as bounded cost). This application requires solving a difficult real-world optimization problem, that can be handled with the techniques discussed in this chapter (Krause et al. [49] show in detail how submodular optimization can be applied in this domain.)",
      "reference_ids": NaN,
      "concepts_scores": [
        {
          "concept": "problem of deploying sensors",
          "relevance": 0.708
        },
        {
          "concept": "submodular function",
          "relevance": 0.656
        },
        {
          "concept": "document summarization",
          "relevance": 0.639
        },
        {
          "concept": "satisfiability solvers",
          "relevance": 0.637
        },
        {
          "concept": "deployed sensors",
          "relevance": 0.631
        },
        {
          "concept": "image segmentation",
          "relevance": 0.623
        },
        {
          "concept": "running example",
          "relevance": 0.622
        },
        {
          "concept": "optimal subset",
          "relevance": 0.616
        },
        {
          "concept": "computer science",
          "relevance": 0.613
        },
        {
          "concept": "detection performance",
          "relevance": 0.611
        },
        {
          "concept": "viral marketing",
          "relevance": 0.602
        },
        {
          "concept": "optimization problem",
          "relevance": 0.589
        },
        {
          "concept": "submodularity",
          "relevance": 0.547
        },
        {
          "concept": "water distribution networks",
          "relevance": 0.535
        },
        {
          "concept": "network",
          "relevance": 0.533
        },
        {
          "concept": "sensor",
          "relevance": 0.526
        },
        {
          "concept": "distribution network",
          "relevance": 0.498
        },
        {
          "concept": "satisfiability",
          "relevance": 0.497
        },
        {
          "concept": "summarization",
          "relevance": 0.492
        },
        {
          "concept": "applications",
          "relevance": 0.479
        },
        {
          "concept": "drinking water distribution networks",
          "relevance": 0.473
        },
        {
          "concept": "algorithm",
          "relevance": 0.469
        },
        {
          "concept": "computer",
          "relevance": 0.46
        },
        {
          "concept": "domain",
          "relevance": 0.451
        },
        {
          "concept": "solver",
          "relevance": 0.438
        },
        {
          "concept": "maximization",
          "relevance": 0.43
        },
        {
          "concept": "optimization",
          "relevance": 0.425
        },
        {
          "concept": "information",
          "relevance": 0.414
        },
        {
          "concept": "performance",
          "relevance": 0.411
        },
        {
          "concept": "constraints",
          "relevance": 0.41
        },
        {
          "concept": "images",
          "relevance": 0.408
        },
        {
          "concept": "generalization",
          "relevance": 0.401
        },
        {
          "concept": "model",
          "relevance": 0.396
        },
        {
          "concept": "detection",
          "relevance": 0.395
        },
        {
          "concept": "theoretical consequences",
          "relevance": 0.39
        },
        {
          "concept": "segments",
          "relevance": 0.388
        },
        {
          "concept": "location",
          "relevance": 0.384
        },
        {
          "concept": "F(A",
          "relevance": 0.381
        },
        {
          "concept": "examples",
          "relevance": 0.38
        },
        {
          "concept": "convexity",
          "relevance": 0.376
        },
        {
          "concept": "technique",
          "relevance": 0.367
        },
        {
          "concept": "problem",
          "relevance": 0.366
        },
        {
          "concept": "function",
          "relevance": 0.364
        },
        {
          "concept": "subsets",
          "relevance": 0.347
        },
        {
          "concept": "utilization",
          "relevance": 0.338
        },
        {
          "concept": "concavity",
          "relevance": 0.336
        },
        {
          "concept": "science",
          "relevance": 0.325
        },
        {
          "concept": "results",
          "relevance": 0.315
        },
        {
          "concept": "benefits",
          "relevance": 0.309
        },
        {
          "concept": "detect contamination",
          "relevance": 0.282
        },
        {
          "concept": "V-",
          "relevance": 0.279
        },
        {
          "concept": "market",
          "relevance": 0.273
        },
        {
          "concept": "contamination",
          "relevance": 0.258
        },
        {
          "concept": "consequences",
          "relevance": 0.209
        },
        {
          "concept": "drinking",
          "relevance": 0.189
        }
      ]
    },
    {
      "paperId": "pub.1158993741",
      "doi": "10.1057/s41599-023-01816-6",
      "title": "Emotion classification for short texts: an improved multi-label method",
      "year": 2023,
      "citationCount": 178,
      "fieldCitationRatio": 117.45,
      "abstract": "The process of computationally identifying and categorizing opinions expressed in a piece of text is of great importance to support better understanding and services to online users in the digital environment. However, accurate and fast multi-label automatic classification is still insufficient. By considering not only individual in-sentence features but also the features in the adjacent sentences and the full text of the tweet, this study adjusted the Multi-label K-Nearest Neighbors (MLkNN) classifier to allow iterative corrections of the multi-label emotion classification. It applies the new method to improve both the accuracy and speed of emotion classification for short texts on Twitter. By carrying out three groups of experiments on the Twitter corpus, this study compares the performance of the base classifier of MLkNN, the sample-based MLkNN (S-MLkNN), and the label-based MLkNN (L-MLkNN). The results show that the improved MLkNN algorithm can effectively improve the accuracy of emotion classification of short texts, especially when the value of K in the MLkNN base classifier is 8, and the value of α is 0.7, and the improved L-MLkNN algorithm outperforms the other methods in the overall performance and the recall rate reaches 0.8019. This study attempts to obtain an efficient classifier with smaller training samples and lower training costs for sentiment analysis. It is suggested that future studies should pay more attention to balancing the efficiency of the model with smaller training sample sizes and the completeness of the model to cover various scenarios.",
      "reference_ids": [
        "pub.1128402571",
        "pub.1052389807",
        "pub.1105723503",
        "pub.1141840745",
        "pub.1042969557",
        "pub.1104273441",
        "pub.1105195572",
        "pub.1146236719",
        "pub.1125628670",
        "pub.1140103699",
        "pub.1125456972",
        "pub.1094963253",
        "pub.1050641652",
        "pub.1117014092",
        "pub.1129635017",
        "pub.1105862411",
        "pub.1148214889",
        "pub.1131205775",
        "pub.1148539363",
        "pub.1061661554",
        "pub.1136642500",
        "pub.1095005830",
        "pub.1052033444",
        "pub.1137548628",
        "pub.1123130830",
        "pub.1040708172",
        "pub.1146700068",
        "pub.1025474787",
        "pub.1094074204",
        "pub.1107971921",
        "pub.1105213821",
        "pub.1130275307",
        "pub.1018231160",
        "pub.1007473425",
        "pub.1121304596",
        "pub.1038558086",
        "pub.1132947445",
        "pub.1093517670"
      ],
      "concepts_scores": [
        {
          "concept": "emotion classification",
          "relevance": 0.78
        },
        {
          "concept": "base classifiers",
          "relevance": 0.727
        },
        {
          "concept": "multi-label emotion classification",
          "relevance": 0.701
        },
        {
          "concept": "accuracy of emotion classification",
          "relevance": 0.699
        },
        {
          "concept": "multi-label k-nearest neighbor",
          "relevance": 0.695
        },
        {
          "concept": "multi-label methods",
          "relevance": 0.678
        },
        {
          "concept": "k-nearest neighbor",
          "relevance": 0.661
        },
        {
          "concept": "training sample size",
          "relevance": 0.656
        },
        {
          "concept": "efficient classifier",
          "relevance": 0.624
        },
        {
          "concept": "sentiment analysis",
          "relevance": 0.622
        },
        {
          "concept": "training samples",
          "relevance": 0.619
        },
        {
          "concept": "Twitter corpus",
          "relevance": 0.615
        },
        {
          "concept": "online users",
          "relevance": 0.613
        },
        {
          "concept": "automatic classification",
          "relevance": 0.611
        },
        {
          "concept": "MLKNN",
          "relevance": 0.61
        },
        {
          "concept": "recall rate",
          "relevance": 0.602
        },
        {
          "concept": "training costs",
          "relevance": 0.593
        },
        {
          "concept": "adjacent sentences",
          "relevance": 0.591
        },
        {
          "concept": "classifier",
          "relevance": 0.563
        },
        {
          "concept": "classification",
          "relevance": 0.548
        },
        {
          "concept": "overall performance",
          "relevance": 0.546
        },
        {
          "concept": "digital environment",
          "relevance": 0.541
        },
        {
          "concept": "Twitter",
          "relevance": 0.541
        },
        {
          "concept": "algorithm",
          "relevance": 0.539
        },
        {
          "concept": "groups of experiments",
          "relevance": 0.536
        },
        {
          "concept": "iterative correction",
          "relevance": 0.517
        },
        {
          "concept": "training",
          "relevance": 0.491
        },
        {
          "concept": "accuracy",
          "relevance": 0.49
        },
        {
          "concept": "users",
          "relevance": 0.476
        },
        {
          "concept": "text",
          "relevance": 0.473
        },
        {
          "concept": "tweets",
          "relevance": 0.473
        },
        {
          "concept": "performance",
          "relevance": 0.472
        },
        {
          "concept": "features",
          "relevance": 0.454
        },
        {
          "concept": "sentiment",
          "relevance": 0.444
        },
        {
          "concept": "method",
          "relevance": 0.436
        },
        {
          "concept": "neighboring",
          "relevance": 0.428
        },
        {
          "concept": "scenarios",
          "relevance": 0.424
        },
        {
          "concept": "corpus",
          "relevance": 0.42
        },
        {
          "concept": "recall",
          "relevance": 0.419
        },
        {
          "concept": "sentences",
          "relevance": 0.409
        },
        {
          "concept": "services",
          "relevance": 0.408
        },
        {
          "concept": "model",
          "relevance": 0.392
        },
        {
          "concept": "environment",
          "relevance": 0.381
        },
        {
          "concept": "cost",
          "relevance": 0.37
        },
        {
          "concept": "speed",
          "relevance": 0.363
        },
        {
          "concept": "efficiency",
          "relevance": 0.355
        },
        {
          "concept": "emotions",
          "relevance": 0.354
        },
        {
          "concept": "base",
          "relevance": 0.342
        },
        {
          "concept": "correction",
          "relevance": 0.341
        },
        {
          "concept": "experiments",
          "relevance": 0.34
        },
        {
          "concept": "attention",
          "relevance": 0.324
        },
        {
          "concept": "process",
          "relevance": 0.321
        },
        {
          "concept": "results",
          "relevance": 0.312
        },
        {
          "concept": "completion",
          "relevance": 0.31
        },
        {
          "concept": "fasting",
          "relevance": 0.307
        },
        {
          "concept": "opinion",
          "relevance": 0.305
        },
        {
          "concept": "understanding",
          "relevance": 0.286
        },
        {
          "concept": "size",
          "relevance": 0.264
        },
        {
          "concept": "sample size",
          "relevance": 0.259
        },
        {
          "concept": "analysis",
          "relevance": 0.257
        },
        {
          "concept": "rate",
          "relevance": 0.237
        },
        {
          "concept": "study",
          "relevance": 0.229
        },
        {
          "concept": "samples",
          "relevance": 0.194
        },
        {
          "concept": "group",
          "relevance": 0.158
        }
      ]
    },
    {
      "paperId": "pub.1148214889",
      "doi": "10.1016/j.dajour.2022.100071",
      "title": "A comparative analysis of K-Nearest Neighbor, Genetic, Support Vector Machine, Decision Tree, and Long Short Term Memory algorithms in machine learning",
      "year": 2022,
      "citationCount": 464,
      "fieldCitationRatio": 185.5,
      "abstract": "Machine learning (ML) is a new-age thriving technology, which facilitates computers to read and interpret from the previously present data automatically. It makes use of multiple algorithms to build models, mathematical in nature, and then makes predictions for the new data using the past data and knowledge. Lately, it has been adopted for text detection, hate speech detection, recommender system, face detection, and more. In this paper, majorly all the aspects concerning five machine learning algorithms namely-K-Nearest Neighbor (KNN), Genetic Algorithm (GA), Support Vector Machine (SVM), Decision Tree (DT) , and Long Short Term Memory (LSTM) network have been discussed in great detail which is a prerequisite for venturing into the field of ML. This paper throws light on various new results and conclusions related to these algorithms via research and review of recently published papers that carried out quantitative and qualitative research on real-time problems, mainly predictive analytics in multidisciplinary fields. This paper also talks about the circumstantial origin of these algorithms, which although has been rarely talked about in previous publications, is a preeminent point of discussion for ML enthusiasts and amateurs, both. To explain and understand the accuracy, robustness, and reliability of the algorithms, they were exhaustively reviewed and researched in all aspects qualitatively and quantitatively, wherein the LSTM network and SVM algorithm have projected a superior behavior over the rest. The paper answers all relevant questions that may arise during the study of these algorithms ranging from their origin, to their definition, methodologies of execution, real-time applications attached with sufficient novel evidence, followed by the advantages and major trade-offs; lastly an elaborate comparison of their performances on quantitative and qualitative grounds has been presented. To conclude, the paper also highlights the future scope of ML algorithms and artificial intelligence in the coming times and their roles in automation and holistic development, not just in technology-related aspects but also, the humanitarian aspects, finally followed by reliable and relevant conclusions derived from this exhaustive research.",
      "reference_ids": [
        "pub.1061719235",
        "pub.1130376862",
        "pub.1141180287",
        "pub.1093683247",
        "pub.1134438528",
        "pub.1098689922",
        "pub.1135785848",
        "pub.1015098538",
        "pub.1125284768",
        "pub.1130219625",
        "pub.1135785897",
        "pub.1061806268",
        "pub.1035043672",
        "pub.1138661361",
        "pub.1139872315",
        "pub.1126761033",
        "pub.1090697718",
        "pub.1128723727",
        "pub.1027055246",
        "pub.1139865312",
        "pub.1130219527",
        "pub.1100483478",
        "pub.1135785899",
        "pub.1094634740",
        "pub.1103329256",
        "pub.1130219671",
        "pub.1135785908",
        "pub.1131162829",
        "pub.1124904707",
        "pub.1070006951",
        "pub.1109706498",
        "pub.1112877077",
        "pub.1121662649",
        "pub.1105081603",
        "pub.1130210250",
        "pub.1095586003",
        "pub.1130219563",
        "pub.1138402604",
        "pub.1103314982",
        "pub.1029730970",
        "pub.1090980667",
        "pub.1038140272",
        "pub.1061792985",
        "pub.1061647607"
      ],
      "concepts_scores": [
        {
          "concept": "long short-term memory",
          "relevance": 0.798
        },
        {
          "concept": "support vector machine",
          "relevance": 0.784
        },
        {
          "concept": "machine learning",
          "relevance": 0.713
        },
        {
          "concept": "decision tree",
          "relevance": 0.704
        },
        {
          "concept": "vector machine",
          "relevance": 0.68
        },
        {
          "concept": "long short-term memory network",
          "relevance": 0.663
        },
        {
          "concept": "hate speech detection",
          "relevance": 0.655
        },
        {
          "concept": "genetic algorithm",
          "relevance": 0.65
        },
        {
          "concept": "long short-term memory algorithm",
          "relevance": 0.646
        },
        {
          "concept": "k-nearest neighbor",
          "relevance": 0.638
        },
        {
          "concept": "real-time applications",
          "relevance": 0.638
        },
        {
          "concept": "short-term memory algorithm",
          "relevance": 0.637
        },
        {
          "concept": "support vector machine algorithm",
          "relevance": 0.636
        },
        {
          "concept": "real-time problems",
          "relevance": 0.63
        },
        {
          "concept": "field of ML",
          "relevance": 0.627
        },
        {
          "concept": "ML enthusiasts",
          "relevance": 0.612
        },
        {
          "concept": "text detection",
          "relevance": 0.611
        },
        {
          "concept": "short-term memory",
          "relevance": 0.61
        },
        {
          "concept": "face detection",
          "relevance": 0.608
        },
        {
          "concept": "recommender systems",
          "relevance": 0.604
        },
        {
          "concept": "speech detection",
          "relevance": 0.602
        },
        {
          "concept": "memory algorithm",
          "relevance": 0.589
        },
        {
          "concept": "term memory",
          "relevance": 0.585
        },
        {
          "concept": "multiplication algorithm",
          "relevance": 0.584
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.584
        },
        {
          "concept": "ML algorithms",
          "relevance": 0.58
        },
        {
          "concept": "technology-related aspects",
          "relevance": 0.578
        },
        {
          "concept": "predictive analytics",
          "relevance": 0.566
        },
        {
          "concept": "algorithm",
          "relevance": 0.561
        },
        {
          "concept": "machine",
          "relevance": 0.537
        },
        {
          "concept": "network",
          "relevance": 0.511
        },
        {
          "concept": "methodology of execution",
          "relevance": 0.499
        },
        {
          "concept": "circumstantial origins",
          "relevance": 0.493
        },
        {
          "concept": "trade-offs",
          "relevance": 0.493
        },
        {
          "concept": "learning",
          "relevance": 0.488
        },
        {
          "concept": "neighboring",
          "relevance": 0.479
        },
        {
          "concept": "building models",
          "relevance": 0.463
        },
        {
          "concept": "KNN",
          "relevance": 0.462
        },
        {
          "concept": "detection",
          "relevance": 0.46
        },
        {
          "concept": "multidisciplinary field",
          "relevance": 0.452
        },
        {
          "concept": "intelligence",
          "relevance": 0.441
        },
        {
          "concept": "computer",
          "relevance": 0.44
        },
        {
          "concept": "execution",
          "relevance": 0.439
        },
        {
          "concept": "automation",
          "relevance": 0.439
        },
        {
          "concept": "decision",
          "relevance": 0.437
        },
        {
          "concept": "robustness",
          "relevance": 0.424
        },
        {
          "concept": "trees",
          "relevance": 0.412
        },
        {
          "concept": "accuracy",
          "relevance": 0.409
        },
        {
          "concept": "comparative analysis",
          "relevance": 0.405
        },
        {
          "concept": "superior behavior",
          "relevance": 0.396
        },
        {
          "concept": "exhaustive research",
          "relevance": 0.395
        },
        {
          "concept": "text",
          "relevance": 0.394
        },
        {
          "concept": "performance",
          "relevance": 0.393
        },
        {
          "concept": "support",
          "relevance": 0.391
        },
        {
          "concept": "technology",
          "relevance": 0.391
        },
        {
          "concept": "research",
          "relevance": 0.388
        },
        {
          "concept": "data",
          "relevance": 0.38
        },
        {
          "concept": "memory",
          "relevance": 0.379
        },
        {
          "concept": "analytes",
          "relevance": 0.372
        },
        {
          "concept": "applications",
          "relevance": 0.371
        },
        {
          "concept": "face",
          "relevance": 0.365
        },
        {
          "concept": "longer",
          "relevance": 0.36
        },
        {
          "concept": "system",
          "relevance": 0.358
        },
        {
          "concept": "reliability",
          "relevance": 0.354
        },
        {
          "concept": "aspects",
          "relevance": 0.351
        },
        {
          "concept": "relevant questions",
          "relevance": 0.344
        },
        {
          "concept": "knowledge",
          "relevance": 0.343
        },
        {
          "concept": "methodology",
          "relevance": 0.342
        },
        {
          "concept": "relevant conclusions",
          "relevance": 0.341
        },
        {
          "concept": "prediction",
          "relevance": 0.337
        },
        {
          "concept": "definition",
          "relevance": 0.335
        },
        {
          "concept": "qualitative grounds",
          "relevance": 0.335
        },
        {
          "concept": "enthusiasts",
          "relevance": 0.333
        },
        {
          "concept": "field",
          "relevance": 0.328
        },
        {
          "concept": "model",
          "relevance": 0.327
        },
        {
          "concept": "publications",
          "relevance": 0.31
        },
        {
          "concept": "recommendations",
          "relevance": 0.304
        },
        {
          "concept": "results",
          "relevance": 0.301
        },
        {
          "concept": "holistic development",
          "relevance": 0.283
        },
        {
          "concept": "qualitative research",
          "relevance": 0.27
        },
        {
          "concept": "comparison",
          "relevance": 0.27
        },
        {
          "concept": "development",
          "relevance": 0.269
        },
        {
          "concept": "origin",
          "relevance": 0.257
        },
        {
          "concept": "nature",
          "relevance": 0.255
        },
        {
          "concept": "discussion",
          "relevance": 0.255
        },
        {
          "concept": "behavior",
          "relevance": 0.255
        },
        {
          "concept": "questions",
          "relevance": 0.25
        },
        {
          "concept": "amateurs",
          "relevance": 0.249
        },
        {
          "concept": "conclusions",
          "relevance": 0.248
        },
        {
          "concept": "ground",
          "relevance": 0.229
        },
        {
          "concept": "humanitarian aspects",
          "relevance": 0.227
        },
        {
          "concept": "rest",
          "relevance": 0.214
        },
        {
          "concept": "problem",
          "relevance": 0.194
        },
        {
          "concept": "review",
          "relevance": 0.187
        },
        {
          "concept": "study",
          "relevance": 0.179
        },
        {
          "concept": "evidence",
          "relevance": 0.17
        }
      ]
    },
    {
      "paperId": "pub.1128723727",
      "doi": "10.1109/ice348803.2020.9122958",
      "title": "Heart Disease Prediction Using Machine Learning Algorithms",
      "year": 2020,
      "citationCount": 300,
      "fieldCitationRatio": 68.38,
      "abstract": "Heart plays significant role in living organisms. Diagnosis and prediction of heart related diseases requires more precision, perfection and correctness because a little mistake can cause fatigue problem or death of the person, there are numerous death cases related to heart and their counting is increasing exponentially day by day. To deal with the problem there is essential need of prediction system for awareness about diseases. Machine learning is the branch of Artificial Intelligence(AI), it provides prestigious support in predicting any kind of event which take training from natural events. In this paper, we calculate accuracy of machine learning algorithms for predicting heart disease, for this algorithms are k-nearest neighbor, decision tree, linear regression and support vector machine(SVM) by using UCI repository dataset for training and testing. For implementation of Python programming Anaconda(jupytor) notebook is best tool, which have many type of library, header file, that make the work more accurate and precise.",
      "reference_ids": [
        "pub.1107391188",
        "pub.1119980649",
        "pub.1067314531",
        "pub.1095277404",
        "pub.1005477051",
        "pub.1117372909"
      ],
      "concepts_scores": [
        {
          "concept": "machine learning algorithms",
          "relevance": 0.765
        },
        {
          "concept": "learning algorithms",
          "relevance": 0.721
        },
        {
          "concept": "accuracy of machine learning algorithms",
          "relevance": 0.701
        },
        {
          "concept": "UCI repository datasets",
          "relevance": 0.684
        },
        {
          "concept": "heart disease prediction",
          "relevance": 0.673
        },
        {
          "concept": "predicting heart disease",
          "relevance": 0.673
        },
        {
          "concept": "Support Vector Machine(SVM",
          "relevance": 0.673
        },
        {
          "concept": "k-nearest neighbor",
          "relevance": 0.666
        },
        {
          "concept": "prediction of heart related diseases",
          "relevance": 0.637
        },
        {
          "concept": "increasing exponentially day",
          "relevance": 0.637
        },
        {
          "concept": "repository datasets",
          "relevance": 0.633
        },
        {
          "concept": "header files",
          "relevance": 0.629
        },
        {
          "concept": "Vector Machine(SVM",
          "relevance": 0.624
        },
        {
          "concept": "heart related diseases",
          "relevance": 0.623
        },
        {
          "concept": "Artificial Intelligence(AI",
          "relevance": 0.622
        },
        {
          "concept": "k-nearest",
          "relevance": 0.615
        },
        {
          "concept": "machine learning",
          "relevance": 0.612
        },
        {
          "concept": "decision tree",
          "relevance": 0.604
        },
        {
          "concept": "disease prediction",
          "relevance": 0.592
        },
        {
          "concept": "algorithm",
          "relevance": 0.57
        },
        {
          "concept": "prediction system",
          "relevance": 0.534
        },
        {
          "concept": "machine",
          "relevance": 0.521
        },
        {
          "concept": "UCI",
          "relevance": 0.499
        },
        {
          "concept": "header",
          "relevance": 0.477
        },
        {
          "concept": "training",
          "relevance": 0.472
        },
        {
          "concept": "calculation accuracy",
          "relevance": 0.467
        },
        {
          "concept": "dataset",
          "relevance": 0.467
        },
        {
          "concept": "files",
          "relevance": 0.451
        },
        {
          "concept": "learning",
          "relevance": 0.44
        },
        {
          "concept": "library",
          "relevance": 0.438
        },
        {
          "concept": "neighboring",
          "relevance": 0.431
        },
        {
          "concept": "prediction",
          "relevance": 0.427
        },
        {
          "concept": "implementation",
          "relevance": 0.424
        },
        {
          "concept": "living organisms",
          "relevance": 0.397
        },
        {
          "concept": "decision",
          "relevance": 0.394
        },
        {
          "concept": "precision",
          "relevance": 0.389
        },
        {
          "concept": "system",
          "relevance": 0.374
        },
        {
          "concept": "tools",
          "relevance": 0.374
        },
        {
          "concept": "trees",
          "relevance": 0.371
        },
        {
          "concept": "support",
          "relevance": 0.353
        },
        {
          "concept": "linear regression",
          "relevance": 0.348
        },
        {
          "concept": "fatigue problems",
          "relevance": 0.346
        },
        {
          "concept": "correction",
          "relevance": 0.344
        },
        {
          "concept": "natural events",
          "relevance": 0.341
        },
        {
          "concept": "related diseases",
          "relevance": 0.324
        },
        {
          "concept": "disease",
          "relevance": 0.301
        },
        {
          "concept": "persons",
          "relevance": 0.297
        },
        {
          "concept": "death",
          "relevance": 0.29
        },
        {
          "concept": "awareness",
          "relevance": 0.288
        },
        {
          "concept": "organization",
          "relevance": 0.28
        },
        {
          "concept": "events",
          "relevance": 0.279
        },
        {
          "concept": "branches",
          "relevance": 0.27
        },
        {
          "concept": "regression",
          "relevance": 0.263
        },
        {
          "concept": "test",
          "relevance": 0.256
        },
        {
          "concept": "living",
          "relevance": 0.248
        },
        {
          "concept": "perfection",
          "relevance": 0.232
        },
        {
          "concept": "days",
          "relevance": 0.23
        },
        {
          "concept": "count",
          "relevance": 0.222
        },
        {
          "concept": "heart",
          "relevance": 0.198
        },
        {
          "concept": "diagnosis",
          "relevance": 0.187
        },
        {
          "concept": "heart disease",
          "relevance": 0.178
        },
        {
          "concept": "fatigue",
          "relevance": 0.153
        },
        {
          "concept": "problem",
          "relevance": 0.149
        }
      ]
    },
    {
      "paperId": "pub.1125284768",
      "doi": "10.3390/e22030261",
      "title": "A Method Based on GA-CNN-LSTM for Daily Tourist Flow Prediction at Scenic Spots",
      "year": 2020,
      "citationCount": 47,
      "fieldCitationRatio": NaN,
      "abstract": "Accurate tourist flow prediction is key to ensuring the normal operation of popular scenic spots. However, one single model cannot effectively grasp the characteristics of the data and make accurate predictions because of the strong nonlinear characteristics of daily tourist flow data. Accordingly, this study predicts daily tourist flow in Huangshan Scenic Spot in China. A prediction method (GA-CNN-LSTM) which combines convolutional neural network (CNN) and long-short-term memory network (LSTM) and optimized by genetic algorithm (GA) is established. First, network search data, meteorological data, and other data are constructed into continuous feature maps. Then, feature vectors are extracted by convolutional neural network (CNN). Finally, the feature vectors are input into long-short-term memory network (LSTM) in time series for prediction. Moreover, GA is used to scientifically select the number of neurons in the CNN-LSTM model. Data is preprocessed and normalized before prediction. The accuracy of GA-CNN-LSTM is evaluated using mean absolute percentage error (MAPE), mean absolute error (MAE), Pearson correlation coefficient and index of agreement (IA). For a fair comparison, GA-CNN-LSTM model is compared with CNN-LSTM, LSTM, CNN and the back propagation neural network (BP). The experimental results show that GA-CNN-LSTM model is approximately 8.22% higher than CNN-LSTM on the performance of MAPE.",
      "reference_ids": [
        "pub.1018449823",
        "pub.1028515016",
        "pub.1061179979",
        "pub.1095380520",
        "pub.1114037395",
        "pub.1037702631",
        "pub.1117059758",
        "pub.1124067298",
        "pub.1113893302",
        "pub.1123589568",
        "pub.1116562079",
        "pub.1103249353",
        "pub.1052867467",
        "pub.1007964110",
        "pub.1016670322",
        "pub.1121989374",
        "pub.1022351194",
        "pub.1096030455",
        "pub.1047509697",
        "pub.1072793918",
        "pub.1111345088",
        "pub.1105683447",
        "pub.1113642271",
        "pub.1012129444",
        "pub.1105699111",
        "pub.1038140272",
        "pub.1042641512",
        "pub.1105462987",
        "pub.1024766909"
      ],
      "concepts_scores": [
        {
          "concept": "long short-term memory network",
          "relevance": 0.553
        },
        {
          "concept": "convolutional neural network",
          "relevance": 0.542
        },
        {
          "concept": "back-propagation neural network",
          "relevance": 0.501
        },
        {
          "concept": "mean absolute error",
          "relevance": 0.493
        },
        {
          "concept": "neural network",
          "relevance": 0.482
        },
        {
          "concept": "CNN-LSTM",
          "relevance": 0.481
        },
        {
          "concept": "scenic spots",
          "relevance": 0.48
        },
        {
          "concept": "feature vector",
          "relevance": 0.466
        },
        {
          "concept": "flow prediction",
          "relevance": 0.458
        },
        {
          "concept": "genetic algorithm",
          "relevance": 0.457
        },
        {
          "concept": "memory network",
          "relevance": 0.454
        },
        {
          "concept": "meteorological data",
          "relevance": 0.452
        },
        {
          "concept": "continuous feature maps",
          "relevance": 0.438
        },
        {
          "concept": "flow data",
          "relevance": 0.425
        },
        {
          "concept": "time series",
          "relevance": 0.423
        },
        {
          "concept": "propagation neural network",
          "relevance": 0.422
        },
        {
          "concept": "CNN-LSTM model",
          "relevance": 0.418
        },
        {
          "concept": "network search data",
          "relevance": 0.409
        },
        {
          "concept": "feature maps",
          "relevance": 0.406
        },
        {
          "concept": "nonlinear characteristics",
          "relevance": 0.401
        },
        {
          "concept": "tourist flow",
          "relevance": 0.4
        },
        {
          "concept": "experimental results",
          "relevance": 0.373
        },
        {
          "concept": "network",
          "relevance": 0.368
        },
        {
          "concept": "absolute error",
          "relevance": 0.364
        },
        {
          "concept": "search data",
          "relevance": 0.344
        },
        {
          "concept": "prediction method",
          "relevance": 0.342
        },
        {
          "concept": "correlation coefficient",
          "relevance": 0.342
        },
        {
          "concept": "accurate prediction",
          "relevance": 0.34
        },
        {
          "concept": "Huangshan",
          "relevance": 0.339
        },
        {
          "concept": "prediction",
          "relevance": 0.317
        },
        {
          "concept": "China",
          "relevance": 0.316
        },
        {
          "concept": "data",
          "relevance": 0.314
        },
        {
          "concept": "tourists",
          "relevance": 0.313
        },
        {
          "concept": "MAPE",
          "relevance": 0.307
        },
        {
          "concept": "model",
          "relevance": 0.303
        },
        {
          "concept": "Pearson correlation coefficient",
          "relevance": 0.302
        },
        {
          "concept": "algorithm",
          "relevance": 0.301
        },
        {
          "concept": "vector",
          "relevance": 0.297
        },
        {
          "concept": "features",
          "relevance": 0.294
        },
        {
          "concept": "maps",
          "relevance": 0.293
        },
        {
          "concept": "flow",
          "relevance": 0.289
        },
        {
          "concept": "spots",
          "relevance": 0.288
        },
        {
          "concept": "daily",
          "relevance": 0.282
        },
        {
          "concept": "method",
          "relevance": 0.281
        },
        {
          "concept": "performance",
          "relevance": 0.275
        },
        {
          "concept": "accuracy",
          "relevance": 0.274
        },
        {
          "concept": "series",
          "relevance": 0.271
        },
        {
          "concept": "input",
          "relevance": 0.267
        },
        {
          "concept": "operation",
          "relevance": 0.266
        },
        {
          "concept": "coefficient",
          "relevance": 0.266
        },
        {
          "concept": "error",
          "relevance": 0.264
        },
        {
          "concept": "characteristics",
          "relevance": 0.241
        },
        {
          "concept": "comparison",
          "relevance": 0.235
        },
        {
          "concept": "IA",
          "relevance": 0.233
        },
        {
          "concept": "results",
          "relevance": 0.229
        },
        {
          "concept": "time",
          "relevance": 0.226
        },
        {
          "concept": "study",
          "relevance": 0.195
        },
        {
          "concept": "Pearson",
          "relevance": 0.193
        },
        {
          "concept": "neurons",
          "relevance": 0.191
        }
      ]
    },
    {
      "paperId": "pub.1146236719",
      "doi": "10.1016/j.jksuci.2022.02.025",
      "title": "Bidirectional convolutional recurrent neural network architecture with group-wise enhancement mechanism for text sentiment classification",
      "year": 2022,
      "citationCount": 272,
      "fieldCitationRatio": 108.74,
      "abstract": "Sentiment analysis has been a well-studied research direction in computational linguistics. Deep neural network models, including convolutional neural networks (CNN) and recurrent neural networks (RNN), yield promising results on text classification tasks. RNN-based architectures, such as, long short-term memory (LSTM) and gated recurrent unit (GRU) can process sequences of any length. However, using them in the feature extraction layer of a deep neural network architecture increases the dimensionality of the feature space. In addition, such models value different features equally. To solve these issues, we propose a bidirectional convolutional recurrent neural network architecture, which utilizes two separate bidirectional LSTM and GRU layers, to derive both past and future contexts by connecting two hidden layers of opposite directions to the same context. The group-wise enhancement mechanism has been employed on the features extracted by bidirectional layers, which divides features into multiple classes, enhancing important features in each group while weakening the less important ones. The presented scheme employs convolution and pooling layers to extract high level features and to reduce the dimensionality of the feature space. The experimental results indicate that the presented bidirectional convolutional recurrent neural network architecture with group-wise enhancement mechanism can outperform the state-of-the-art results for sentiment analysis.",
      "reference_ids": [
        "pub.1099106256",
        "pub.1085117100",
        "pub.1095773414",
        "pub.1129155557",
        "pub.1048467713",
        "pub.1100562598",
        "pub.1099110546",
        "pub.1125036019",
        "pub.1136677771",
        "pub.1046933995",
        "pub.1038140272",
        "pub.1094978757",
        "pub.1101526574",
        "pub.1084083329",
        "pub.1098653575",
        "pub.1037702319",
        "pub.1099115161",
        "pub.1105752126",
        "pub.1121650042",
        "pub.1061406588",
        "pub.1110957738",
        "pub.1130538031",
        "pub.1001513720",
        "pub.1111822112",
        "pub.1016913022",
        "pub.1033448195",
        "pub.1103793690",
        "pub.1137284665",
        "pub.1150866105",
        "pub.1090339145",
        "pub.1073451194",
        "pub.1118086576",
        "pub.1039220326",
        "pub.1096026335",
        "pub.1128829265",
        "pub.1027636235",
        "pub.1122188366",
        "pub.1072617140",
        "pub.1094050167",
        "pub.1014889589",
        "pub.1061662115",
        "pub.1092758679",
        "pub.1017556268",
        "pub.1037144794",
        "pub.1111313548",
        "pub.1099110523",
        "pub.1134829224",
        "pub.1101846824",
        "pub.1104266743",
        "pub.1093695022",
        "pub.1107126607",
        "pub.1099110544",
        "pub.1127377410",
        "pub.1110805538",
        "pub.1002075763",
        "pub.1091621170",
        "pub.1093616383",
        "pub.1101748462",
        "pub.1043444072",
        "pub.1099221859",
        "pub.1126862968",
        "pub.1032663204"
      ],
      "concepts_scores": [
        {
          "concept": "convolutional recurrent neural network architecture",
          "relevance": 0.882
        },
        {
          "concept": "recurrent neural network architecture",
          "relevance": 0.87
        },
        {
          "concept": "neural network architecture",
          "relevance": 0.86
        },
        {
          "concept": "long short-term memory",
          "relevance": 0.85
        },
        {
          "concept": "gated recurrent unit",
          "relevance": 0.833
        },
        {
          "concept": "recurrent neural network",
          "relevance": 0.805
        },
        {
          "concept": "convolutional neural network",
          "relevance": 0.8
        },
        {
          "concept": "network architecture",
          "relevance": 0.792
        },
        {
          "concept": "feature space",
          "relevance": 0.745
        },
        {
          "concept": "sentiment analysis",
          "relevance": 0.74
        },
        {
          "concept": "neural network",
          "relevance": 0.73
        },
        {
          "concept": "state-of-the-art results",
          "relevance": 0.722
        },
        {
          "concept": "deep neural network architecture",
          "relevance": 0.715
        },
        {
          "concept": "bidirectional long short-term memory",
          "relevance": 0.715
        },
        {
          "concept": "extract high-level features",
          "relevance": 0.715
        },
        {
          "concept": "deep neural network model",
          "relevance": 0.707
        },
        {
          "concept": "gated recurrent unit layers",
          "relevance": 0.705
        },
        {
          "concept": "text sentiment classification",
          "relevance": 0.701
        },
        {
          "concept": "RNN-based architectures",
          "relevance": 0.698
        },
        {
          "concept": "high-level features",
          "relevance": 0.696
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.696
        },
        {
          "concept": "neural network model",
          "relevance": 0.672
        },
        {
          "concept": "short-term memory",
          "relevance": 0.65
        },
        {
          "concept": "sentiment classification",
          "relevance": 0.649
        },
        {
          "concept": "pooling layer",
          "relevance": 0.645
        },
        {
          "concept": "classification task",
          "relevance": 0.644
        },
        {
          "concept": "level features",
          "relevance": 0.641
        },
        {
          "concept": "recurrent unit",
          "relevance": 0.636
        },
        {
          "concept": "hidden layer",
          "relevance": 0.633
        },
        {
          "concept": "computational linguistics",
          "relevance": 0.618
        },
        {
          "concept": "bidirectional layer",
          "relevance": 0.608
        },
        {
          "concept": "network model",
          "relevance": 0.605
        },
        {
          "concept": "multiple classes",
          "relevance": 0.593
        },
        {
          "concept": "architecture",
          "relevance": 0.588
        },
        {
          "concept": "extraction layer",
          "relevance": 0.581
        },
        {
          "concept": "experimental results",
          "relevance": 0.573
        },
        {
          "concept": "research directions",
          "relevance": 0.563
        },
        {
          "concept": "network",
          "relevance": 0.543
        },
        {
          "concept": "dimensionality",
          "relevance": 0.542
        },
        {
          "concept": "classification",
          "relevance": 0.524
        },
        {
          "concept": "features",
          "relevance": 0.503
        },
        {
          "concept": "convolution",
          "relevance": 0.489
        },
        {
          "concept": "sentiment",
          "relevance": 0.457
        },
        {
          "concept": "task",
          "relevance": 0.456
        },
        {
          "concept": "space",
          "relevance": 0.428
        },
        {
          "concept": "text",
          "relevance": 0.419
        },
        {
          "concept": "enhancement mechanism",
          "relevance": 0.406
        },
        {
          "concept": "memory",
          "relevance": 0.404
        },
        {
          "concept": "model",
          "relevance": 0.403
        },
        {
          "concept": "context",
          "relevance": 0.4
        },
        {
          "concept": "results",
          "relevance": 0.39
        },
        {
          "concept": "issues",
          "relevance": 0.376
        },
        {
          "concept": "direction",
          "relevance": 0.36
        },
        {
          "concept": "layer",
          "relevance": 0.358
        },
        {
          "concept": "class",
          "relevance": 0.355
        },
        {
          "concept": "research",
          "relevance": 0.339
        },
        {
          "concept": "extraction",
          "relevance": 0.327
        },
        {
          "concept": "analysis",
          "relevance": 0.305
        },
        {
          "concept": "linguistics",
          "relevance": 0.305
        },
        {
          "concept": "mechanism",
          "relevance": 0.297
        },
        {
          "concept": "sequence",
          "relevance": 0.281
        },
        {
          "concept": "units",
          "relevance": 0.247
        },
        {
          "concept": "length",
          "relevance": 0.218
        },
        {
          "concept": "group",
          "relevance": 0.162
        }
      ]
    },
    {
      "paperId": "pub.1105752126",
      "doi": "10.1109/mci.2018.2840738",
      "title": "Recent Trends in Deep Learning Based Natural Language Processing",
      "year": 2018,
      "citationCount": 2906,
      "fieldCitationRatio": 646.65,
      "abstract": "Deep learning methods employ multiple processing layers to learn hierarchical representations of data, and have produced state-of-the-art results in many domains. Recently, a variety of model designs and methods have blossomed in the context of natural language processing (NLP). In this paper, we review significant deep learning related models and methods that have been employed for numerous NLP tasks and provide a walk-through of their evolution. We also summarize, compare and contrast the various models and put forward a detailed understanding of the past, present and future of deep learning in NLP.",
      "reference_ids": [
        "pub.1098652931",
        "pub.1001381236",
        "pub.1061517330",
        "pub.1099127768",
        "pub.1035788679",
        "pub.1100516800",
        "pub.1061406613",
        "pub.1100659839",
        "pub.1049656935",
        "pub.1099150709",
        "pub.1099114765",
        "pub.1105690098",
        "pub.1036313689",
        "pub.1093645378",
        "pub.1099110216",
        "pub.1099115141",
        "pub.1099110187",
        "pub.1003896352",
        "pub.1098653446",
        "pub.1099115033",
        "pub.1099106145",
        "pub.1105690056",
        "pub.1043444329",
        "pub.1095157363",
        "pub.1099110544",
        "pub.1061517439",
        "pub.1099110754",
        "pub.1044144911",
        "pub.1099115119",
        "pub.1090339145",
        "pub.1100516715",
        "pub.1100640022",
        "pub.1099114453",
        "pub.1049421294",
        "pub.1002522091",
        "pub.1052031051",
        "pub.1099120551",
        "pub.1099221982",
        "pub.1098653277",
        "pub.1099150725",
        "pub.1038140272",
        "pub.1099221859",
        "pub.1099113530",
        "pub.1100516695",
        "pub.1049163532",
        "pub.1028341849",
        "pub.1099115161",
        "pub.1061297724",
        "pub.1099115040",
        "pub.1093777731",
        "pub.1096026130",
        "pub.1037432371",
        "pub.1099106022",
        "pub.1099110442",
        "pub.1099151389",
        "pub.1099113671",
        "pub.1099110546",
        "pub.1096025525",
        "pub.1093787097",
        "pub.1100516915",
        "pub.1093616383",
        "pub.1099113805",
        "pub.1061144393",
        "pub.1096025485",
        "pub.1105674405",
        "pub.1096025151",
        "pub.1099110648",
        "pub.1100516967",
        "pub.1099110523",
        "pub.1099105807",
        "pub.1110957692",
        "pub.1010020120",
        "pub.1096025321",
        "pub.1099110732",
        "pub.1100516741",
        "pub.1099110726",
        "pub.1110957745",
        "pub.1099114441",
        "pub.1099115024",
        "pub.1016881216",
        "pub.1110957760",
        "pub.1099113670",
        "pub.1099239594",
        "pub.1096025337",
        "pub.1096025502",
        "pub.1099115039",
        "pub.1079258573",
        "pub.1093208464"
      ],
      "concepts_scores": [
        {
          "concept": "natural language processing",
          "relevance": 0.819
        },
        {
          "concept": "language processing",
          "relevance": 0.692
        },
        {
          "concept": "future of deep learning",
          "relevance": 0.687
        },
        {
          "concept": "context of natural language processing",
          "relevance": 0.684
        },
        {
          "concept": "natural language processing tasks",
          "relevance": 0.684
        },
        {
          "concept": "hierarchical representations of data",
          "relevance": 0.683
        },
        {
          "concept": "deep learning methods",
          "relevance": 0.653
        },
        {
          "concept": "representation of data",
          "relevance": 0.646
        },
        {
          "concept": "hierarchical representation",
          "relevance": 0.606
        },
        {
          "concept": "deep learning",
          "relevance": 0.606
        },
        {
          "concept": "learning methods",
          "relevance": 0.595
        },
        {
          "concept": "relational model",
          "relevance": 0.568
        },
        {
          "concept": "model design",
          "relevance": 0.541
        },
        {
          "concept": "Deep",
          "relevance": 0.462
        },
        {
          "concept": "task",
          "relevance": 0.435
        },
        {
          "concept": "learning",
          "relevance": 0.428
        },
        {
          "concept": "method",
          "relevance": 0.427
        },
        {
          "concept": "model",
          "relevance": 0.403
        },
        {
          "concept": "domain",
          "relevance": 0.378
        },
        {
          "concept": "process",
          "relevance": 0.364
        },
        {
          "concept": "design",
          "relevance": 0.351
        },
        {
          "concept": "context",
          "relevance": 0.329
        },
        {
          "concept": "data",
          "relevance": 0.317
        },
        {
          "concept": "results",
          "relevance": 0.306
        },
        {
          "concept": "future",
          "relevance": 0.276
        },
        {
          "concept": "evolution",
          "relevance": 0.259
        },
        {
          "concept": "trends",
          "relevance": 0.25
        }
      ]
    },
    {
      "paperId": "pub.1137284665",
      "doi": "10.1145/3439726",
      "title": "Deep Learning--based Text Classification",
      "year": 2021,
      "citationCount": 1290,
      "fieldCitationRatio": 407.57,
      "abstract": "Deep learning--based models have surpassed classical machine learning--based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this article, we provide a comprehensive review of more than 150 deep learning--based models for text classification developed in recent years, and we discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and we discuss future research directions.",
      "reference_ids": [
        "pub.1099113480",
        "pub.1098653272",
        "pub.1112294238",
        "pub.1104321191",
        "pub.1099151287",
        "pub.1099106159",
        "pub.1123112941",
        "pub.1026437304",
        "pub.1003342487",
        "pub.1098653816",
        "pub.1096025551",
        "pub.1120590151",
        "pub.1122290427",
        "pub.1099106324",
        "pub.1099113472",
        "pub.1096025493",
        "pub.1099151294",
        "pub.1050749011",
        "pub.1099127747",
        "pub.1011792924",
        "pub.1129756778",
        "pub.1117659708",
        "pub.1093616383",
        "pub.1018466450",
        "pub.1062950852",
        "pub.1099151290",
        "pub.1117659127",
        "pub.1099106145",
        "pub.1038811532",
        "pub.1099110546",
        "pub.1098653837",
        "pub.1099113805",
        "pub.1099138490",
        "pub.1120624965",
        "pub.1120962464",
        "pub.1038772296",
        "pub.1122291185",
        "pub.1092439218",
        "pub.1104321292",
        "pub.1099106215",
        "pub.1100885471",
        "pub.1121025182",
        "pub.1121024742",
        "pub.1099106144",
        "pub.1061179979",
        "pub.1117659358",
        "pub.1105386763",
        "pub.1105386744",
        "pub.1093359587",
        "pub.1121875948",
        "pub.1052509117",
        "pub.1099106258",
        "pub.1122290362",
        "pub.1107775000",
        "pub.1129756768",
        "pub.1032314453",
        "pub.1099115173",
        "pub.1121790962",
        "pub.1117659543",
        "pub.1099113694",
        "pub.1012153938",
        "pub.1044144911",
        "pub.1099105797",
        "pub.1099110648",
        "pub.1004010489",
        "pub.1117824104",
        "pub.1101396975",
        "pub.1098653343",
        "pub.1105386754",
        "pub.1100517425",
        "pub.1121025298",
        "pub.1096025280",
        "pub.1099110523",
        "pub.1099201585",
        "pub.1091081925",
        "pub.1007936248",
        "pub.1098652919",
        "pub.1120624943",
        "pub.1094564413",
        "pub.1110957738",
        "pub.1096024064",
        "pub.1130538031",
        "pub.1141942664",
        "pub.1128856734",
        "pub.1109352312",
        "pub.1120757992",
        "pub.1096024344",
        "pub.1091105805",
        "pub.1120612805",
        "pub.1129757043",
        "pub.1113697716",
        "pub.1096026344"
      ],
      "concepts_scores": [
        {
          "concept": "deep learning",
          "relevance": 0.694
        },
        {
          "concept": "natural language inference",
          "relevance": 0.66
        },
        {
          "concept": "deep learning models",
          "relevance": 0.643
        },
        {
          "concept": "news categorization",
          "relevance": 0.613
        },
        {
          "concept": "language inference",
          "relevance": 0.611
        },
        {
          "concept": "classification task",
          "relevance": 0.608
        },
        {
          "concept": "sentiment analysis",
          "relevance": 0.603
        },
        {
          "concept": "machine learning",
          "relevance": 0.589
        },
        {
          "concept": "learning models",
          "relevance": 0.579
        },
        {
          "concept": "technical contribution",
          "relevance": 0.578
        },
        {
          "concept": "research directions",
          "relevance": 0.532
        },
        {
          "concept": "classification",
          "relevance": 0.519
        },
        {
          "concept": "learning",
          "relevance": 0.515
        },
        {
          "concept": "dataset",
          "relevance": 0.449
        },
        {
          "concept": "benchmarks",
          "relevance": 0.438
        },
        {
          "concept": "machine",
          "relevance": 0.433
        },
        {
          "concept": "sentiment",
          "relevance": 0.431
        },
        {
          "concept": "task",
          "relevance": 0.43
        },
        {
          "concept": "inference",
          "relevance": 0.409
        },
        {
          "concept": "categorization",
          "relevance": 0.4
        },
        {
          "concept": "model",
          "relevance": 0.399
        },
        {
          "concept": "performance",
          "relevance": 0.395
        },
        {
          "concept": "answers",
          "relevance": 0.369
        },
        {
          "concept": "news",
          "relevance": 0.363
        },
        {
          "concept": "comprehensive review",
          "relevance": 0.36
        },
        {
          "concept": "similarity",
          "relevance": 0.359
        },
        {
          "concept": "quantitative analysis",
          "relevance": 0.33
        },
        {
          "concept": "research",
          "relevance": 0.32
        },
        {
          "concept": "direction",
          "relevance": 0.293
        },
        {
          "concept": "analysis",
          "relevance": 0.288
        },
        {
          "concept": "contribution",
          "relevance": 0.281
        },
        {
          "concept": "review",
          "relevance": 0.187
        },
        {
          "concept": "years",
          "relevance": 0.187
        },
        {
          "concept": "strength",
          "relevance": 0.182
        },
        {
          "concept": "approach",
          "relevance": 0.168
        }
      ]
    }
  ],
  "evolution_links": [
    {
      "source": "pub.1163533062",
      "target": "pub.1148956109",
      "source_title": "Interpreting Black-Box Models: A Review on Explainable Artificial Intelligence",
      "target_title": "Anchors: High-Precision Model-Agnostic Explanations"
    },
    {
      "source": "pub.1148956109",
      "target": "pub.1045977640",
      "source_title": "Anchors: High-Precision Model-Agnostic Explanations",
      "target_title": "Quick Shift and Kernel Methods for Mode Seeking"
    },
    {
      "source": "pub.1045977640",
      "target": "pub.1061155588",
      "source_title": "Quick Shift and Kernel Methods for Mode Seeking",
      "target_title": "Mean shift: a robust approach toward feature space analysis"
    },
    {
      "source": "pub.1045977640",
      "target": "pub.1061156233",
      "source_title": "Quick Shift and Kernel Methods for Mode Seeking",
      "target_title": "Mean shift, mode seeking, and clustering"
    },
    {
      "source": "pub.1148956109",
      "target": "pub.1035893296",
      "source_title": "Anchors: High-Precision Model-Agnostic Explanations",
      "target_title": "Submodular Function Maximization"
    },
    {
      "source": "pub.1163533062",
      "target": "pub.1158993741",
      "source_title": "Interpreting Black-Box Models: A Review on Explainable Artificial Intelligence",
      "target_title": "Emotion classification for short texts: an improved multi-label method"
    },
    {
      "source": "pub.1158993741",
      "target": "pub.1148214889",
      "source_title": "Emotion classification for short texts: an improved multi-label method",
      "target_title": "A comparative analysis of K-Nearest Neighbor, Genetic, Support Vector Machine, Decision Tree, and Long Short Term Memory algorithms in machine learning"
    },
    {
      "source": "pub.1148214889",
      "target": "pub.1128723727",
      "source_title": "A comparative analysis of K-Nearest Neighbor, Genetic, Support Vector Machine, Decision Tree, and Long Short Term Memory algorithms in machine learning",
      "target_title": "Heart Disease Prediction Using Machine Learning Algorithms"
    },
    {
      "source": "pub.1148214889",
      "target": "pub.1125284768",
      "source_title": "A comparative analysis of K-Nearest Neighbor, Genetic, Support Vector Machine, Decision Tree, and Long Short Term Memory algorithms in machine learning",
      "target_title": "A Method Based on GA-CNN-LSTM for Daily Tourist Flow Prediction at Scenic Spots"
    },
    {
      "source": "pub.1158993741",
      "target": "pub.1146236719",
      "source_title": "Emotion classification for short texts: an improved multi-label method",
      "target_title": "Bidirectional convolutional recurrent neural network architecture with group-wise enhancement mechanism for text sentiment classification"
    },
    {
      "source": "pub.1146236719",
      "target": "pub.1105752126",
      "source_title": "Bidirectional convolutional recurrent neural network architecture with group-wise enhancement mechanism for text sentiment classification",
      "target_title": "Recent Trends in Deep Learning Based Natural Language Processing"
    },
    {
      "source": "pub.1146236719",
      "target": "pub.1137284665",
      "source_title": "Bidirectional convolutional recurrent neural network architecture with group-wise enhancement mechanism for text sentiment classification",
      "target_title": "Deep Learning--based Text Classification"
    }
  ]
}