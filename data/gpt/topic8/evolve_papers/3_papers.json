{
  "papers": [
    {
      "paperId": "pub.1169214707",
      "doi": "10.1109/tpami.2024.3367329",
      "title": "A Comprehensive Survey of Continual Learning: Theory, Method and Application",
      "year": 2024,
      "citationCount": 399,
      "fieldCitationRatio": NaN,
      "abstract": "To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.",
      "reference_ids": [
        "pub.1152327207",
        "pub.1151380491",
        "pub.1151380515",
        "pub.1151381228",
        "pub.1142379730",
        "pub.1118769417",
        "pub.1125158642",
        "pub.1150867110",
        "pub.1149513912",
        "pub.1130070816",
        "pub.1138871514",
        "pub.1123988629",
        "pub.1151379629",
        "pub.1146502115",
        "pub.1140847351",
        "pub.1137774891",
        "pub.1107463212",
        "pub.1032573094",
        "pub.1132542310",
        "pub.1145901917",
        "pub.1129913715",
        "pub.1125154518",
        "pub.1152354870",
        "pub.1136588160",
        "pub.1129723930",
        "pub.1140814422",
        "pub.1152028510",
        "pub.1140363563",
        "pub.1129913397",
        "pub.1151379628",
        "pub.1152256384",
        "pub.1132547033",
        "pub.1129723937",
        "pub.1149207398",
        "pub.1152354863",
        "pub.1151381229",
        "pub.1132271025",
        "pub.1142379095",
        "pub.1142387693",
        "pub.1121796205",
        "pub.1142375601",
        "pub.1129913855",
        "pub.1152311278",
        "pub.1132964291",
        "pub.1110303596",
        "pub.1140672281",
        "pub.1151380984",
        "pub.1154707822",
        "pub.1123925730",
        "pub.1153918241",
        "pub.1142371380",
        "pub.1155160450",
        "pub.1123987570",
        "pub.1128856734",
        "pub.1129912895",
        "pub.1129913196",
        "pub.1125163717",
        "pub.1151380299",
        "pub.1142371536",
        "pub.1142368227",
        "pub.1151379633",
        "pub.1123988636",
        "pub.1132443519",
        "pub.1150866465",
        "pub.1126983374",
        "pub.1145901918",
        "pub.1125161080",
        "pub.1151381227",
        "pub.1150298647",
        "pub.1132944373",
        "pub.1123987524",
        "pub.1120211203",
        "pub.1152400526",
        "pub.1110720944",
        "pub.1151380336",
        "pub.1152383301",
        "pub.1129913721",
        "pub.1092698424",
        "pub.1132543348",
        "pub.1141844136",
        "pub.1142376590",
        "pub.1154403459",
        "pub.1131569407",
        "pub.1148956288",
        "pub.1111979755",
        "pub.1152389165",
        "pub.1142391898",
        "pub.1107454774",
        "pub.1141168844",
        "pub.1129913889",
        "pub.1003568618",
        "pub.1100060357",
        "pub.1145901931",
        "pub.1129913427",
        "pub.1145901051",
        "pub.1167961433",
        "pub.1101131090",
        "pub.1148390871",
        "pub.1152354891",
        "pub.1152407529",
        "pub.1152026768",
        "pub.1128856289",
        "pub.1123988006",
        "pub.1095850228",
        "pub.1151380337",
        "pub.1146354632",
        "pub.1152354861",
        "pub.1107454745",
        "pub.1152256392",
        "pub.1144866579",
        "pub.1151380545",
        "pub.1158361438",
        "pub.1131260942",
        "pub.1131294493",
        "pub.1084152728",
        "pub.1167962068",
        "pub.1166058915",
        "pub.1145901807",
        "pub.1100060113",
        "pub.1152033281",
        "pub.1160741354",
        "pub.1145902451",
        "pub.1129913369",
        "pub.1145901081",
        "pub.1151380514",
        "pub.1132293252",
        "pub.1151380492",
        "pub.1142408093",
        "pub.1142366094",
        "pub.1150865554",
        "pub.1107463242",
        "pub.1014264293",
        "pub.1014544738",
        "pub.1142367538",
        "pub.1151380041",
        "pub.1151380528",
        "pub.1134455798",
        "pub.1107502646",
        "pub.1152509706",
        "pub.1151379842",
        "pub.1142376466",
        "pub.1142394829",
        "pub.1149215277",
        "pub.1148558672",
        "pub.1135171878",
        "pub.1151380599",
        "pub.1132397689",
        "pub.1142363534",
        "pub.1142370644",
        "pub.1133065211",
        "pub.1127624041",
        "pub.1163453096",
        "pub.1125164483",
        "pub.1152388908",
        "pub.1142372165",
        "pub.1151381002",
        "pub.1129723942",
        "pub.1094049040",
        "pub.1151380547",
        "pub.1152035595",
        "pub.1150866586",
        "pub.1152509731",
        "pub.1173397417",
        "pub.1145901925",
        "pub.1122290441",
        "pub.1152354886",
        "pub.1129913817",
        "pub.1151380540",
        "pub.1142367180",
        "pub.1152509746",
        "pub.1128856192",
        "pub.1129913420",
        "pub.1145901687",
        "pub.1142369405",
        "pub.1156012298",
        "pub.1145901882",
        "pub.1167962097"
      ],
      "concepts_scores": [
        {
          "concept": "stability-plasticity trade-off",
          "relevance": 0.697
        },
        {
          "concept": "continuous learning",
          "relevance": 0.688
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.673
        },
        {
          "concept": "dramatic performance drop",
          "relevance": 0.661
        },
        {
          "concept": "comprehensive survey",
          "relevance": 0.636
        },
        {
          "concept": "catastrophic forgetting",
          "relevance": 0.628
        },
        {
          "concept": "old tasks",
          "relevance": 0.621
        },
        {
          "concept": "intelligent systems",
          "relevance": 0.613
        },
        {
          "concept": "AI systems",
          "relevance": 0.606
        },
        {
          "concept": "performance drop",
          "relevance": 0.594
        },
        {
          "concept": "real-world dynamics",
          "relevance": 0.592
        },
        {
          "concept": "representative methods",
          "relevance": 0.592
        },
        {
          "concept": "context of resource efficiency",
          "relevance": 0.561
        },
        {
          "concept": "learning",
          "relevance": 0.542
        },
        {
          "concept": "resource efficiency",
          "relevance": 0.522
        },
        {
          "concept": "task",
          "relevance": 0.511
        },
        {
          "concept": "trade-offs",
          "relevance": 0.508
        },
        {
          "concept": "empirical results",
          "relevance": 0.49
        },
        {
          "concept": "theoretical foundation",
          "relevance": 0.479
        },
        {
          "concept": "applications",
          "relevance": 0.464
        },
        {
          "concept": "holistic perspective",
          "relevance": 0.436
        },
        {
          "concept": "update",
          "relevance": 0.429
        },
        {
          "concept": "system",
          "relevance": 0.426
        },
        {
          "concept": "method",
          "relevance": 0.412
        },
        {
          "concept": "taxonomy",
          "relevance": 0.395
        },
        {
          "concept": "forgetting",
          "relevance": 0.386
        },
        {
          "concept": "widespread interest",
          "relevance": 0.385
        },
        {
          "concept": "generalizability",
          "relevance": 0.358
        },
        {
          "concept": "exploration",
          "relevance": 0.354
        },
        {
          "concept": "knowledge",
          "relevance": 0.353
        },
        {
          "concept": "efficiency",
          "relevance": 0.353
        },
        {
          "concept": "direction",
          "relevance": 0.348
        },
        {
          "concept": "complex",
          "relevance": 0.337
        },
        {
          "concept": "context",
          "relevance": 0.334
        },
        {
          "concept": "advances",
          "relevance": 0.331
        },
        {
          "concept": "results",
          "relevance": 0.31
        },
        {
          "concept": "strategies",
          "relevance": 0.309
        },
        {
          "concept": "comprehension",
          "relevance": 0.302
        },
        {
          "concept": "perspective",
          "relevance": 0.302
        },
        {
          "concept": "lifetime",
          "relevance": 0.295
        },
        {
          "concept": "interest",
          "relevance": 0.295
        },
        {
          "concept": "foundations",
          "relevance": 0.294
        },
        {
          "concept": "ability",
          "relevance": 0.293
        },
        {
          "concept": "field",
          "relevance": 0.291
        },
        {
          "concept": "dynamics",
          "relevance": 0.274
        },
        {
          "concept": "theory",
          "relevance": 0.27
        },
        {
          "concept": "survey",
          "relevance": 0.242
        },
        {
          "concept": "years",
          "relevance": 0.191
        },
        {
          "concept": "significance",
          "relevance": 0.183
        },
        {
          "concept": "drop",
          "relevance": 0.182
        }
      ]
    },
    {
      "paperId": "pub.1163453096",
      "doi": "10.1109/cvpr52729.2023.01146",
      "title": "CODA-Prompt: COntinual Decomposed Attention-Based Prompting for Rehearsal-Free Continual Learning",
      "year": 2023,
      "citationCount": 164,
      "fieldCitationRatio": 99.73,
      "abstract": "Computer vision models suffer from a phenomenon known as catastrophic forgetting when learning novel concepts from continuously shifting training data. Typical solutions for this continual learning problem require extensive rehearsal of previously seen data, which increases memory costs and may violate data privacy. Recently, the emergence of large-scale pre-trained vision transformer models has enabled prompting approaches as an alternative to data-rehearsal. These approaches rely on a key-query mechanism to generate prompts and have been found to be highly resistant to catastrophic forgetting in the well-established rehearsal-free continual learning setting. However, the key mechanism of these methods is not trained end-to-end with the task sequence. Our experiments show that this leads to a reduction in their plasticity, hence sacrificing new task accuracy, and inability to benefit from expanded parameter capacity. We instead propose to learn a set of prompt components which are assembled with input-conditioned weights to produce input-conditioned prompts, resulting in a novel attention-based end-to-end key-query scheme. Our experiments show that we outperform the current SOTA method DualPrompt on established benchmarks by as much as 4.5% in average final accuracy. We also outperform the state of art by as much as 4.4% accuracy on a continual learning benchmark which contains both class-incremental and domain-incremental task shifts, corresponding to many practical settings. Our code is available at https://github.com/GT-RIPL/CODA-Prompt",
      "reference_ids": [
        "pub.1123987570",
        "pub.1148956268",
        "pub.1084152728",
        "pub.1094342319",
        "pub.1107454774",
        "pub.1140814417",
        "pub.1113265970",
        "pub.1107463212",
        "pub.1111641418",
        "pub.1122290421",
        "pub.1125160666",
        "pub.1152354886",
        "pub.1141844136",
        "pub.1145901816",
        "pub.1123987524",
        "pub.1129723927",
        "pub.1163274340",
        "pub.1151379633",
        "pub.1152256375",
        "pub.1129723940",
        "pub.1151380514",
        "pub.1145901917",
        "pub.1094049040",
        "pub.1145901081",
        "pub.1107463242",
        "pub.1009767488",
        "pub.1123988636",
        "pub.1130070816",
        "pub.1132944373",
        "pub.1123925730",
        "pub.1121401781",
        "pub.1125164483",
        "pub.1142375601",
        "pub.1018486163",
        "pub.1092698424"
      ],
      "concepts_scores": [
        {
          "concept": "catastrophic forgetting",
          "relevance": 0.726
        },
        {
          "concept": "attention-based",
          "relevance": 0.707
        },
        {
          "concept": "computer vision models",
          "relevance": 0.666
        },
        {
          "concept": "learning novel concepts",
          "relevance": 0.66
        },
        {
          "concept": "end-to-end",
          "relevance": 0.66
        },
        {
          "concept": "data privacy",
          "relevance": 0.623
        },
        {
          "concept": "Class-Incremental",
          "relevance": 0.622
        },
        {
          "concept": "training data",
          "relevance": 0.614
        },
        {
          "concept": "memory cost",
          "relevance": 0.614
        },
        {
          "concept": "increased memory cost",
          "relevance": 0.612
        },
        {
          "concept": "vision models",
          "relevance": 0.611
        },
        {
          "concept": "learning problems",
          "relevance": 0.607
        },
        {
          "concept": "final accuracy",
          "relevance": 0.593
        },
        {
          "concept": "task sequence",
          "relevance": 0.576
        },
        {
          "concept": "continuous learning",
          "relevance": 0.565
        },
        {
          "concept": "Typical solutions",
          "relevance": 0.565
        },
        {
          "concept": "task accuracy",
          "relevance": 0.541
        },
        {
          "concept": "novel concepts",
          "relevance": 0.519
        },
        {
          "concept": "benchmarks",
          "relevance": 0.519
        },
        {
          "concept": "accuracy",
          "relevance": 0.511
        },
        {
          "concept": "learning",
          "relevance": 0.502
        },
        {
          "concept": "SOTA",
          "relevance": 0.487
        },
        {
          "concept": "privacy",
          "relevance": 0.481
        },
        {
          "concept": "computer",
          "relevance": 0.452
        },
        {
          "concept": "code",
          "relevance": 0.447
        },
        {
          "concept": "forgetting",
          "relevance": 0.446
        },
        {
          "concept": "task",
          "relevance": 0.44
        },
        {
          "concept": "scheme",
          "relevance": 0.44
        },
        {
          "concept": "training",
          "relevance": 0.401
        },
        {
          "concept": "experiments",
          "relevance": 0.391
        },
        {
          "concept": "data",
          "relevance": 0.39
        },
        {
          "concept": "cost",
          "relevance": 0.367
        },
        {
          "concept": "sets",
          "relevance": 0.366
        },
        {
          "concept": "method",
          "relevance": 0.355
        },
        {
          "concept": "concept",
          "relevance": 0.353
        },
        {
          "concept": "prompts",
          "relevance": 0.35
        },
        {
          "concept": "solution",
          "relevance": 0.346
        },
        {
          "concept": "practice settings",
          "relevance": 0.341
        },
        {
          "concept": "model",
          "relevance": 0.336
        },
        {
          "concept": "alternative",
          "relevance": 0.287
        },
        {
          "concept": "components",
          "relevance": 0.285
        },
        {
          "concept": "mechanism",
          "relevance": 0.273
        },
        {
          "concept": "sequence",
          "relevance": 0.271
        },
        {
          "concept": "weight",
          "relevance": 0.271
        },
        {
          "concept": "extensive rehearsals",
          "relevance": 0.247
        },
        {
          "concept": "emergency",
          "relevance": 0.247
        },
        {
          "concept": "rehearsal",
          "relevance": 0.241
        },
        {
          "concept": "inability",
          "relevance": 0.223
        },
        {
          "concept": "state",
          "relevance": 0.221
        },
        {
          "concept": "prompt component",
          "relevance": 0.212
        },
        {
          "concept": "phenomenon",
          "relevance": 0.21
        },
        {
          "concept": "approach",
          "relevance": 0.207
        },
        {
          "concept": "reduction",
          "relevance": 0.201
        },
        {
          "concept": "problem",
          "relevance": 0.159
        },
        {
          "concept": "plasticity",
          "relevance": 0.147
        }
      ]
    },
    {
      "paperId": "pub.1125160666",
      "doi": "10.1109/iccv.2019.00149",
      "title": "Moment Matching for Multi-Source Domain Adaptation",
      "year": 2019,
      "citationCount": 1298,
      "fieldCitationRatio": 317.94,
      "abstract": "Conventional unsupervised domain adaptation (UDA) assumes that training data are sampled from a single domain. This neglects the more practical scenario where training data are collected from multiple sources, requiring multi-source domain adaptation. We make three major contributions towards addressing this problem. First, we collect and annotate by far the largest UDA dataset, called DomainNet, which contains six domains and about 0.6 million images distributed among 345 categories, addressing the gap in data availability for multi-source UDA research. Second, we propose a new deep learning approach, Moment Matching for Multi-Source Domain Adaptation (M3 SDA), which aims to transfer knowledge learned from multiple labeled source domains to an unlabeled target domain by dynamically aligning moments of their feature distributions. Third, we provide new theoretical insights specifically for moment matching approaches in both single and multiple source domain adaptation. Extensive experiments are conducted to demonstrate the power of our new dataset in benchmarking state-of-the-art multi-source domain adaptation methods, as well as the advantage of our proposed model. Dataset and Code are available at http://ai.bu.edu/M3SDA/",
      "reference_ids": [
        "pub.1061179979",
        "pub.1093359587",
        "pub.1094620819",
        "pub.1095836989",
        "pub.1110720526",
        "pub.1047848527",
        "pub.1109705102",
        "pub.1103850311",
        "pub.1110923466",
        "pub.1095149418",
        "pub.1107454856",
        "pub.1094245618",
        "pub.1041355599",
        "pub.1044527434",
        "pub.1100060605",
        "pub.1093366274",
        "pub.1100060220",
        "pub.1110720551",
        "pub.1020272891",
        "pub.1110720496",
        "pub.1015811776",
        "pub.1029224515",
        "pub.1016961599",
        "pub.1107716068",
        "pub.1100060294"
      ],
      "concepts_scores": [
        {
          "concept": "unsupervised domain adaptation",
          "relevance": 0.838
        },
        {
          "concept": "multi-source domain adaptation",
          "relevance": 0.806
        },
        {
          "concept": "domain adaptation",
          "relevance": 0.762
        },
        {
          "concept": "training data",
          "relevance": 0.711
        },
        {
          "concept": "Conventional unsupervised domain adaptation",
          "relevance": 0.696
        },
        {
          "concept": "unsupervised domain adaptation datasets",
          "relevance": 0.696
        },
        {
          "concept": "multiple labeled source domains",
          "relevance": 0.696
        },
        {
          "concept": "unlabeled target domain",
          "relevance": 0.677
        },
        {
          "concept": "deep learning approach",
          "relevance": 0.656
        },
        {
          "concept": "multi-source",
          "relevance": 0.649
        },
        {
          "concept": "source domain",
          "relevance": 0.618
        },
        {
          "concept": "target domain",
          "relevance": 0.615
        },
        {
          "concept": "learning approach",
          "relevance": 0.594
        },
        {
          "concept": "adaptive method",
          "relevance": 0.592
        },
        {
          "concept": "transfer knowledge",
          "relevance": 0.588
        },
        {
          "concept": "moment matching",
          "relevance": 0.577
        },
        {
          "concept": "dataset",
          "relevance": 0.558
        },
        {
          "concept": "multiple sources",
          "relevance": 0.527
        },
        {
          "concept": "data availability",
          "relevance": 0.523
        },
        {
          "concept": "DomainNet",
          "relevance": 0.494
        },
        {
          "concept": "matching",
          "relevance": 0.476
        },
        {
          "concept": "domain",
          "relevance": 0.465
        },
        {
          "concept": "training",
          "relevance": 0.464
        },
        {
          "concept": "code",
          "relevance": 0.447
        },
        {
          "concept": "adaptation",
          "relevance": 0.446
        },
        {
          "concept": "data",
          "relevance": 0.439
        },
        {
          "concept": "theoretical insights",
          "relevance": 0.405
        },
        {
          "concept": "images",
          "relevance": 0.401
        },
        {
          "concept": "data",
          "relevance": 0.372
        },
        {
          "concept": "method",
          "relevance": 0.355
        },
        {
          "concept": "knowledge",
          "relevance": 0.353
        },
        {
          "concept": "power",
          "relevance": 0.339
        },
        {
          "concept": "experiments",
          "relevance": 0.337
        },
        {
          "concept": "model",
          "relevance": 0.336
        },
        {
          "concept": "research",
          "relevance": 0.328
        },
        {
          "concept": "availability",
          "relevance": 0.321
        },
        {
          "concept": "categories",
          "relevance": 0.311
        },
        {
          "concept": "insights",
          "relevance": 0.292
        },
        {
          "concept": "source",
          "relevance": 0.288
        },
        {
          "concept": "contribution",
          "relevance": 0.287
        },
        {
          "concept": "gap",
          "relevance": 0.28
        },
        {
          "concept": "dynamics",
          "relevance": 0.273
        },
        {
          "concept": "moment",
          "relevance": 0.264
        },
        {
          "concept": "distribution",
          "relevance": 0.257
        },
        {
          "concept": "approach",
          "relevance": 0.147
        },
        {
          "concept": "problem",
          "relevance": 0.14
        }
      ]
    },
    {
      "paperId": "pub.1093359587",
      "doi": "10.1109/cvpr.2016.90",
      "title": "Deep Residual Learning for Image Recognition",
      "year": 2016,
      "citationCount": 186455,
      "fieldCitationRatio": 36441.39,
      "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers-8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions11http://image-net.org/challenges/LSVRC/2015/ and http://mscoco.org/dataset/#detections-challenge2015., where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation. http://image-net.org/challenges/LSVRC/2015/ and http://mscoco.org/dataset/#detections-challenge2015.",
      "reference_ids": [
        "pub.1061744812",
        "pub.1008345178",
        "pub.1033229571",
        "pub.1037602011",
        "pub.1085642448",
        "pub.1061743975",
        "pub.1032233097",
        "pub.1093456265",
        "pub.1095559903",
        "pub.1014796149",
        "pub.1033986161",
        "pub.1061218416",
        "pub.1099341617",
        "pub.1098556598",
        "pub.1061745117",
        "pub.1061744117",
        "pub.1038140272",
        "pub.1098665985",
        "pub.1061156500",
        "pub.1045321436",
        "pub.1094727707",
        "pub.1030406568",
        "pub.1165598000",
        "pub.1095573598",
        "pub.1050111762",
        "pub.1093626237",
        "pub.1036869950",
        "pub.1094291017",
        "pub.1093828312"
      ],
      "concepts_scores": [
        {
          "concept": "residual nets",
          "relevance": 0.756
        },
        {
          "concept": "COCO object detection dataset",
          "relevance": 0.693
        },
        {
          "concept": "deep residual net",
          "relevance": 0.675
        },
        {
          "concept": "object detection datasets",
          "relevance": 0.673
        },
        {
          "concept": "residual learning framework",
          "relevance": 0.671
        },
        {
          "concept": "training of network",
          "relevance": 0.66
        },
        {
          "concept": "visual recognition tasks",
          "relevance": 0.659
        },
        {
          "concept": "learning residual functions",
          "relevance": 0.657
        },
        {
          "concept": "CIFAR-10",
          "relevance": 0.624
        },
        {
          "concept": "depth of representations",
          "relevance": 0.624
        },
        {
          "concept": "detection dataset",
          "relevance": 0.623
        },
        {
          "concept": "COCO detection",
          "relevance": 0.623
        },
        {
          "concept": "ImageNet dataset",
          "relevance": 0.622
        },
        {
          "concept": "deep representations",
          "relevance": 0.621
        },
        {
          "concept": "VGG-Net",
          "relevance": 0.619
        },
        {
          "concept": "classification task",
          "relevance": 0.619
        },
        {
          "concept": "residual network",
          "relevance": 0.614
        },
        {
          "concept": "learning framework",
          "relevance": 0.613
        },
        {
          "concept": "neural network",
          "relevance": 0.606
        },
        {
          "concept": "layer input",
          "relevance": 0.605
        },
        {
          "concept": "ImageNet",
          "relevance": 0.595
        },
        {
          "concept": "recognition task",
          "relevance": 0.593
        },
        {
          "concept": "ILSVRC",
          "relevance": 0.568
        },
        {
          "concept": "COCO",
          "relevance": 0.557
        },
        {
          "concept": "network",
          "relevance": 0.548
        },
        {
          "concept": "task",
          "relevance": 0.533
        },
        {
          "concept": "dataset",
          "relevance": 0.529
        },
        {
          "concept": "comprehensive empirical evidence",
          "relevance": 0.526
        },
        {
          "concept": "nets",
          "relevance": 0.506
        },
        {
          "concept": "representation",
          "relevance": 0.495
        },
        {
          "concept": "VGG",
          "relevance": 0.486
        },
        {
          "concept": "detection",
          "relevance": 0.448
        },
        {
          "concept": "classification",
          "relevance": 0.435
        },
        {
          "concept": "accuracy",
          "relevance": 0.418
        },
        {
          "concept": "input",
          "relevance": 0.408
        },
        {
          "concept": "framework",
          "relevance": 0.404
        },
        {
          "concept": "error",
          "relevance": 0.401
        },
        {
          "concept": "training",
          "relevance": 0.399
        },
        {
          "concept": "ensemble",
          "relevance": 0.392
        },
        {
          "concept": "segments",
          "relevance": 0.379
        },
        {
          "concept": "submission",
          "relevance": 0.378
        },
        {
          "concept": "residual function",
          "relevance": 0.365
        },
        {
          "concept": "function",
          "relevance": 0.339
        },
        {
          "concept": "layer",
          "relevance": 0.336
        },
        {
          "concept": "localization",
          "relevance": 0.336
        },
        {
          "concept": "complex",
          "relevance": 0.335
        },
        {
          "concept": "improvement",
          "relevance": 0.322
        },
        {
          "concept": "empirical evidence",
          "relevance": 0.321
        },
        {
          "concept": "depth",
          "relevance": 0.299
        },
        {
          "concept": "foundations",
          "relevance": 0.292
        },
        {
          "concept": "increasing depth",
          "relevance": 0.282
        },
        {
          "concept": "analysis",
          "relevance": 0.253
        },
        {
          "concept": "test",
          "relevance": 0.251
        },
        {
          "concept": "evidence",
          "relevance": 0.177
        }
      ]
    },
    {
      "paperId": "pub.1061179979",
      "doi": "10.1109/5.726791",
      "title": "Gradient-based learning applied to document recognition",
      "year": 1998,
      "citationCount": 44423,
      "fieldCitationRatio": NaN,
      "abstract": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.",
      "reference_ids": [
        "pub.1004200481",
        "pub.1062950853",
        "pub.1062950852",
        "pub.1027312764",
        "pub.1036379424",
        "pub.1000713558",
        "pub.1006217895",
        "pub.1018201694",
        "pub.1023250347",
        "pub.1000016127",
        "pub.1061228175",
        "pub.1019207387",
        "pub.1086288507",
        "pub.1086216116",
        "pub.1034413587",
        "pub.1060485339",
        "pub.1061646332",
        "pub.1095309580",
        "pub.1086167559",
        "pub.1038954689",
        "pub.1086301166",
        "pub.1093529535",
        "pub.1061164716",
        "pub.1093941314",
        "pub.1042379868",
        "pub.1030233293",
        "pub.1061178917",
        "pub.1061242226",
        "pub.1050663276",
        "pub.1061435623",
        "pub.1061178914",
        "pub.1061218533",
        "pub.1086243962",
        "pub.1093845396",
        "pub.1149908346",
        "pub.1037811822",
        "pub.1105538380",
        "pub.1061218416",
        "pub.1061218807",
        "pub.1060802448",
        "pub.1061156554",
        "pub.1011285402",
        "pub.1061242401",
        "pub.1095122660",
        "pub.1003278937",
        "pub.1008345178",
        "pub.1051218762",
        "pub.1061218224",
        "pub.1086314354",
        "pub.1149907729",
        "pub.1094501760",
        "pub.1061532133",
        "pub.1056860333",
        "pub.1061144393",
        "pub.1086364585",
        "pub.1086263127",
        "pub.1061087448",
        "pub.1094169707",
        "pub.1009117917",
        "pub.1020439953",
        "pub.1061178979",
        "pub.1149909461",
        "pub.1015147529",
        "pub.1061105077",
        "pub.1043194917",
        "pub.1061218251",
        "pub.1086207005",
        "pub.1149909617",
        "pub.1061218851",
        "pub.1093912305"
      ],
      "concepts_scores": [
        {
          "concept": "graph transformer network",
          "relevance": 0.859
        },
        {
          "concept": "transformer network",
          "relevance": 0.777
        },
        {
          "concept": "neural network",
          "relevance": 0.73
        },
        {
          "concept": "gradient-based learning algorithms",
          "relevance": 0.719
        },
        {
          "concept": "handwritten digit recognition task",
          "relevance": 0.713
        },
        {
          "concept": "complex decision surfaces",
          "relevance": 0.702
        },
        {
          "concept": "document recognition system",
          "relevance": 0.701
        },
        {
          "concept": "handwritten character recognition",
          "relevance": 0.699
        },
        {
          "concept": "online handwriting recognition",
          "relevance": 0.698
        },
        {
          "concept": "gradient-based learning",
          "relevance": 0.697
        },
        {
          "concept": "digit recognition task",
          "relevance": 0.691
        },
        {
          "concept": "convolutional neural network",
          "relevance": 0.691
        },
        {
          "concept": "multilayer neural network",
          "relevance": 0.688
        },
        {
          "concept": "high-dimensional patterns",
          "relevance": 0.688
        },
        {
          "concept": "back-propagation algorithm",
          "relevance": 0.675
        },
        {
          "concept": "gradient-based methods",
          "relevance": 0.653
        },
        {
          "concept": "handwritten characters",
          "relevance": 0.648
        },
        {
          "concept": "handwriting recognition",
          "relevance": 0.646
        },
        {
          "concept": "character recognizer",
          "relevance": 0.646
        },
        {
          "concept": "decision surface",
          "relevance": 0.644
        },
        {
          "concept": "character recognition",
          "relevance": 0.642
        },
        {
          "concept": "language model",
          "relevance": 0.641
        },
        {
          "concept": "document recognition",
          "relevance": 0.64
        },
        {
          "concept": "network architecture",
          "relevance": 0.64
        },
        {
          "concept": "recognition system",
          "relevance": 0.639
        },
        {
          "concept": "bank cheques",
          "relevance": 0.639
        },
        {
          "concept": "learning algorithms",
          "relevance": 0.635
        },
        {
          "concept": "learning techniques",
          "relevance": 0.628
        },
        {
          "concept": "overall performance measure",
          "relevance": 0.619
        },
        {
          "concept": "minimal preprocessing",
          "relevance": 0.618
        },
        {
          "concept": "recognition task",
          "relevance": 0.617
        },
        {
          "concept": "learning paradigm",
          "relevance": 0.612
        },
        {
          "concept": "global training",
          "relevance": 0.605
        },
        {
          "concept": "network",
          "relevance": 0.586
        },
        {
          "concept": "segment recognition",
          "relevance": 0.578
        },
        {
          "concept": "multiple modules",
          "relevance": 0.577
        },
        {
          "concept": "training techniques",
          "relevance": 0.574
        },
        {
          "concept": "multimodule system",
          "relevance": 0.567
        },
        {
          "concept": "cheques",
          "relevance": 0.56
        },
        {
          "concept": "algorithm",
          "relevance": 0.554
        },
        {
          "concept": "field extraction",
          "relevance": 0.55
        },
        {
          "concept": "performance measures",
          "relevance": 0.547
        },
        {
          "concept": "learning",
          "relevance": 0.546
        },
        {
          "concept": "recognition",
          "relevance": 0.542
        },
        {
          "concept": "graph",
          "relevance": 0.531
        },
        {
          "concept": "recognizer",
          "relevance": 0.491
        },
        {
          "concept": "preprocessing",
          "relevance": 0.49
        },
        {
          "concept": "reviews various methods",
          "relevance": 0.483
        },
        {
          "concept": "various methods",
          "relevance": 0.482
        },
        {
          "concept": "architecture",
          "relevance": 0.472
        },
        {
          "concept": "system",
          "relevance": 0.463
        },
        {
          "concept": "task",
          "relevance": 0.456
        },
        {
          "concept": "technique",
          "relevance": 0.455
        },
        {
          "concept": "record accuracy",
          "relevance": 0.451
        },
        {
          "concept": "accuracy",
          "relevance": 0.435
        },
        {
          "concept": "business",
          "relevance": 0.427
        },
        {
          "concept": "method",
          "relevance": 0.426
        },
        {
          "concept": "language",
          "relevance": 0.419
        },
        {
          "concept": "paradigm",
          "relevance": 0.415
        },
        {
          "concept": "training",
          "relevance": 0.415
        },
        {
          "concept": "flexibility",
          "relevance": 0.403
        },
        {
          "concept": "segments",
          "relevance": 0.395
        },
        {
          "concept": "modulation",
          "relevance": 0.393
        },
        {
          "concept": "multilayer",
          "relevance": 0.351
        },
        {
          "concept": "experiments",
          "relevance": 0.349
        },
        {
          "concept": "model",
          "relevance": 0.348
        },
        {
          "concept": "extraction",
          "relevance": 0.328
        },
        {
          "concept": "shape",
          "relevance": 0.302
        },
        {
          "concept": "field",
          "relevance": 0.301
        },
        {
          "concept": "gradient",
          "relevance": 0.298
        },
        {
          "concept": "records",
          "relevance": 0.294
        },
        {
          "concept": "banks",
          "relevance": 0.29
        },
        {
          "concept": "patterns",
          "relevance": 0.286
        },
        {
          "concept": "characters",
          "relevance": 0.282
        },
        {
          "concept": "measurements",
          "relevance": 0.255
        },
        {
          "concept": "variables",
          "relevance": 0.236
        },
        {
          "concept": "surface",
          "relevance": 0.166
        },
        {
          "concept": "days",
          "relevance": 0.115
        }
      ]
    },
    {
      "paperId": "pub.1123987570",
      "doi": "10.1109/cvpr.2019.00092",
      "title": "Learning a Unified Classifier Incrementally via Rebalancing",
      "year": 2019,
      "citationCount": 903,
      "fieldCitationRatio": 221.18,
      "abstract": "Conventionally, deep neural networks are trained offline, relying on a large dataset prepared in advance. This paradigm is often challenged in real-world applications, e.g. online services that involve continuous streams of incoming data. Recently, incremental learning receives increasing attention, and is considered as a promising solution to the practical challenges mentioned above. However, it has been observed that incremental learning is subject to a fundamental difficulty – catastrophic forgetting, namely adapting a model to new data often results in severe performance degradation on previous tasks or classes. Our study reveals that the imbalance between previous and new data is a crucial cause to this problem. In this work, we develop a new framework for incrementally learning a unified classifier, i.e. a classifier that treats both old and new classes uniformly. Specifically, we incorporate three components, cosine normalization, less-forget constraint, and inter-class separation, to mitigate the adverse effects of the imbalance. Experiments show that the proposed method can effectively rebalance the training process, thus obtaining superior performance compared to the existing methods. On CIFAR100 and ImageNet, our method can reduce the classification errors by more than 6% and 13% respectively, under the incremental setting of 10 phases.",
      "reference_ids": [
        "pub.1084152728",
        "pub.1084207044",
        "pub.1110720593",
        "pub.1092698424",
        "pub.1094727707",
        "pub.1107703598",
        "pub.1094049040",
        "pub.1100060177",
        "pub.1107454774",
        "pub.1022961138",
        "pub.1094688018",
        "pub.1107262191",
        "pub.1148956385",
        "pub.1085642448",
        "pub.1094491390",
        "pub.1107463242",
        "pub.1111979755",
        "pub.1123925730",
        "pub.1095850228",
        "pub.1095099189",
        "pub.1061661916",
        "pub.1105579550",
        "pub.1107463212",
        "pub.1001122271",
        "pub.1095689025",
        "pub.1110720744"
      ],
      "concepts_scores": [
        {
          "concept": "catastrophic forgetting",
          "relevance": 0.723
        },
        {
          "concept": "incremental learning",
          "relevance": 0.717
        },
        {
          "concept": "inter-class separability",
          "relevance": 0.671
        },
        {
          "concept": "deep neural networks",
          "relevance": 0.668
        },
        {
          "concept": "severe performance degradation",
          "relevance": 0.652
        },
        {
          "concept": "cosine normalization",
          "relevance": 0.616
        },
        {
          "concept": "neural network",
          "relevance": 0.606
        },
        {
          "concept": "classification error",
          "relevance": 0.601
        },
        {
          "concept": "online services",
          "relevance": 0.598
        },
        {
          "concept": "training process",
          "relevance": 0.597
        },
        {
          "concept": "incremental setting",
          "relevance": 0.585
        },
        {
          "concept": "performance degradation",
          "relevance": 0.583
        },
        {
          "concept": "superior performance",
          "relevance": 0.571
        },
        {
          "concept": "continuous stream",
          "relevance": 0.562
        },
        {
          "concept": "learning",
          "relevance": 0.5
        },
        {
          "concept": "CIFAR100",
          "relevance": 0.492
        },
        {
          "concept": "ImageNet",
          "relevance": 0.489
        },
        {
          "concept": "classifier",
          "relevance": 0.48
        },
        {
          "concept": "dataset",
          "relevance": 0.457
        },
        {
          "concept": "network",
          "relevance": 0.451
        },
        {
          "concept": "cosine",
          "relevance": 0.442
        },
        {
          "concept": "task",
          "relevance": 0.438
        },
        {
          "concept": "data",
          "relevance": 0.438
        },
        {
          "concept": "classification",
          "relevance": 0.435
        },
        {
          "concept": "increasing attention",
          "relevance": 0.431
        },
        {
          "concept": "method",
          "relevance": 0.43
        },
        {
          "concept": "framework",
          "relevance": 0.404
        },
        {
          "concept": "services",
          "relevance": 0.403
        },
        {
          "concept": "constraints",
          "relevance": 0.402
        },
        {
          "concept": "performance",
          "relevance": 0.402
        },
        {
          "concept": "error",
          "relevance": 0.401
        },
        {
          "concept": "paradigm",
          "relevance": 0.399
        },
        {
          "concept": "training",
          "relevance": 0.399
        },
        {
          "concept": "class",
          "relevance": 0.395
        },
        {
          "concept": "forgetting",
          "relevance": 0.384
        },
        {
          "concept": "applications",
          "relevance": 0.379
        },
        {
          "concept": "data",
          "relevance": 0.37
        },
        {
          "concept": "sets",
          "relevance": 0.365
        },
        {
          "concept": "solution",
          "relevance": 0.345
        },
        {
          "concept": "challenges",
          "relevance": 0.345
        },
        {
          "concept": "experiments",
          "relevance": 0.336
        },
        {
          "concept": "model",
          "relevance": 0.335
        },
        {
          "concept": "normalization",
          "relevance": 0.333
        },
        {
          "concept": "imbalance",
          "relevance": 0.332
        },
        {
          "concept": "i.",
          "relevance": 0.331
        },
        {
          "concept": "attention",
          "relevance": 0.32
        },
        {
          "concept": "process",
          "relevance": 0.317
        },
        {
          "concept": "difficulties",
          "relevance": 0.316
        },
        {
          "concept": "rebalancing",
          "relevance": 0.305
        },
        {
          "concept": "components",
          "relevance": 0.284
        },
        {
          "concept": "degradation",
          "relevance": 0.213
        },
        {
          "concept": "separation",
          "relevance": 0.209
        },
        {
          "concept": "phase",
          "relevance": 0.208
        },
        {
          "concept": "effect",
          "relevance": 0.201
        },
        {
          "concept": "study",
          "relevance": 0.183
        },
        {
          "concept": "problem",
          "relevance": 0.176
        },
        {
          "concept": "adverse effects",
          "relevance": 0.141
        }
      ]
    },
    {
      "paperId": "pub.1095689025",
      "doi": "10.1109/cvpr.2009.5206848",
      "title": "ImageNet: A large-scale hierarchical image database",
      "year": 2009,
      "citationCount": 48560,
      "fieldCitationRatio": 11425.11,
      "abstract": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.",
      "reference_ids": [
        "pub.1002200216",
        "pub.1002707761",
        "pub.1093839826",
        "pub.1094055038",
        "pub.1045945012",
        "pub.1093423587",
        "pub.1094700637",
        "pub.1093888066",
        "pub.1061743490",
        "pub.1022501172",
        "pub.1093301542",
        "pub.1017544873",
        "pub.1027534025",
        "pub.1038699157",
        "pub.1061743121",
        "pub.1093557144",
        "pub.1021652857",
        "pub.1052687286",
        "pub.1045723254"
      ],
      "concepts_scores": [
        {
          "concept": "semantic hierarchy of WordNet",
          "relevance": 0.695
        },
        {
          "concept": "hierarchical structure of ImageNet",
          "relevance": 0.695
        },
        {
          "concept": "explosion of image data",
          "relevance": 0.676
        },
        {
          "concept": "large-scale ontologies",
          "relevance": 0.673
        },
        {
          "concept": "computer vision community",
          "relevance": 0.673
        },
        {
          "concept": "synsets of WordNet",
          "relevance": 0.665
        },
        {
          "concept": "data collection scheme",
          "relevance": 0.658
        },
        {
          "concept": "large-scale databases",
          "relevance": 0.644
        },
        {
          "concept": "multimedia data",
          "relevance": 0.625
        },
        {
          "concept": "vision community",
          "relevance": 0.624
        },
        {
          "concept": "annotated images",
          "relevance": 0.619
        },
        {
          "concept": "image classification",
          "relevance": 0.618
        },
        {
          "concept": "semantic hierarchy",
          "relevance": 0.617
        },
        {
          "concept": "WordNet structure",
          "relevance": 0.616
        },
        {
          "concept": "image datasets",
          "relevance": 0.615
        },
        {
          "concept": "object clustering",
          "relevance": 0.613
        },
        {
          "concept": "ImageNet",
          "relevance": 0.611
        },
        {
          "concept": "object recognition",
          "relevance": 0.599
        },
        {
          "concept": "WordNet",
          "relevance": 0.593
        },
        {
          "concept": "Amazon Mechanical Turk",
          "relevance": 0.59
        },
        {
          "concept": "collection scheme",
          "relevance": 0.588
        },
        {
          "concept": "image data",
          "relevance": 0.56
        },
        {
          "concept": "synsets",
          "relevance": 0.556
        },
        {
          "concept": "Mechanical Turk",
          "relevance": 0.547
        },
        {
          "concept": "ontology of images",
          "relevance": 0.536
        },
        {
          "concept": "robust model",
          "relevance": 0.527
        },
        {
          "concept": "hierarchical structure",
          "relevance": 0.518
        },
        {
          "concept": "images",
          "relevance": 0.499
        },
        {
          "concept": "multimedia",
          "relevance": 0.477
        },
        {
          "concept": "Internet",
          "relevance": 0.468
        },
        {
          "concept": "algorithm",
          "relevance": 0.461
        },
        {
          "concept": "dataset",
          "relevance": 0.458
        },
        {
          "concept": "subtrees",
          "relevance": 0.457
        },
        {
          "concept": "database",
          "relevance": 0.455
        },
        {
          "concept": "computer",
          "relevance": 0.451
        },
        {
          "concept": "task",
          "relevance": 0.439
        },
        {
          "concept": "scheme",
          "relevance": 0.439
        },
        {
          "concept": "classification",
          "relevance": 0.436
        },
        {
          "concept": "recognition",
          "relevance": 0.422
        },
        {
          "concept": "accuracy",
          "relevance": 0.419
        },
        {
          "concept": "data",
          "relevance": 0.396
        },
        {
          "concept": "Amazon",
          "relevance": 0.387
        },
        {
          "concept": "applications",
          "relevance": 0.38
        },
        {
          "concept": "clusters",
          "relevance": 0.374
        },
        {
          "concept": "objective",
          "relevance": 0.37
        },
        {
          "concept": "Turks",
          "relevance": 0.355
        },
        {
          "concept": "model",
          "relevance": 0.335
        },
        {
          "concept": "diversity",
          "relevance": 0.335
        },
        {
          "concept": "backbone",
          "relevance": 0.333
        },
        {
          "concept": "research",
          "relevance": 0.327
        },
        {
          "concept": "explosion",
          "relevance": 0.321
        },
        {
          "concept": "opportunities",
          "relevance": 0.295
        },
        {
          "concept": "scale",
          "relevance": 0.28
        },
        {
          "concept": "average",
          "relevance": 0.273
        },
        {
          "concept": "community",
          "relevance": 0.26
        },
        {
          "concept": "structure",
          "relevance": 0.257
        },
        {
          "concept": "analysis",
          "relevance": 0.254
        },
        {
          "concept": "use",
          "relevance": 0.251
        },
        {
          "concept": "index",
          "relevance": 0.226
        },
        {
          "concept": "potential",
          "relevance": 0.215
        }
      ]
    },
    {
      "paperId": "pub.1094727707",
      "doi": "10.1109/cvpr.2014.81",
      "title": "Rich feature hierarchies for accurate object detection and semantic segmentation",
      "year": 2014,
      "citationCount": 27463,
      "fieldCitationRatio": 6371.85,
      "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012—achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.",
      "reference_ids": [
        "pub.1093500653",
        "pub.1095689025",
        "pub.1094310450",
        "pub.1093204525",
        "pub.1095432752",
        "pub.1093883984",
        "pub.1011653915",
        "pub.1095420134",
        "pub.1002182143",
        "pub.1091744995",
        "pub.1093948019",
        "pub.1061743745",
        "pub.1003742061",
        "pub.1014968475",
        "pub.1052687286",
        "pub.1033900312",
        "pub.1016635886",
        "pub.1061744113",
        "pub.1061744374",
        "pub.1094492451",
        "pub.1056860333",
        "pub.1091605025",
        "pub.1061156724",
        "pub.1061179979",
        "pub.1093771760",
        "pub.1014796149",
        "pub.1027572846",
        "pub.1093997066",
        "pub.1008345178",
        "pub.1093987027",
        "pub.1094136360"
      ],
      "concepts_scores": [
        {
          "concept": "convolutional neural network",
          "relevance": 0.831
        },
        {
          "concept": "Mean Average Precision",
          "relevance": 0.821
        },
        {
          "concept": "region proposals",
          "relevance": 0.727
        },
        {
          "concept": "multiple low-level image features",
          "relevance": 0.707
        },
        {
          "concept": "high-capacity convolutional neural networks",
          "relevance": 0.707
        },
        {
          "concept": "domain-specific fine-tuning",
          "relevance": 0.701
        },
        {
          "concept": "improves mean average precision",
          "relevance": 0.698
        },
        {
          "concept": "low-level image features",
          "relevance": 0.697
        },
        {
          "concept": "convolutional neural network features",
          "relevance": 0.697
        },
        {
          "concept": "bottom-up region proposals",
          "relevance": 0.694
        },
        {
          "concept": "scalable detection algorithm",
          "relevance": 0.682
        },
        {
          "concept": "PASCAL VOC dataset",
          "relevance": 0.681
        },
        {
          "concept": "supervised pre-training",
          "relevance": 0.68
        },
        {
          "concept": "accurate object detection",
          "relevance": 0.679
        },
        {
          "concept": "object detection performance",
          "relevance": 0.679
        },
        {
          "concept": "labeled training data",
          "relevance": 0.677
        },
        {
          "concept": "significant performance boost",
          "relevance": 0.666
        },
        {
          "concept": "VOC dataset",
          "relevance": 0.631
        },
        {
          "concept": "auxiliary task",
          "relevance": 0.628
        },
        {
          "concept": "object detection",
          "relevance": 0.627
        },
        {
          "concept": "semantic segmentation",
          "relevance": 0.627
        },
        {
          "concept": "segment objects",
          "relevance": 0.622
        },
        {
          "concept": "R-CNN",
          "relevance": 0.622
        },
        {
          "concept": "feature hierarchy",
          "relevance": 0.62
        },
        {
          "concept": "average precision",
          "relevance": 0.618
        },
        {
          "concept": "training data",
          "relevance": 0.618
        },
        {
          "concept": "neural network",
          "relevance": 0.613
        },
        {
          "concept": "detection algorithm",
          "relevance": 0.612
        },
        {
          "concept": "pre-training",
          "relevance": 0.609
        },
        {
          "concept": "performance boost",
          "relevance": 0.607
        },
        {
          "concept": "detection performance",
          "relevance": 0.605
        },
        {
          "concept": "ensemble system",
          "relevance": 0.586
        },
        {
          "concept": "fine-tuning",
          "relevance": 0.58
        },
        {
          "concept": "image features",
          "relevance": 0.57
        },
        {
          "concept": "algorithm",
          "relevance": 0.464
        },
        {
          "concept": "dataset",
          "relevance": 0.462
        },
        {
          "concept": "proposal",
          "relevance": 0.462
        },
        {
          "concept": "network",
          "relevance": 0.456
        },
        {
          "concept": "features",
          "relevance": 0.453
        },
        {
          "concept": "segments",
          "relevance": 0.444
        },
        {
          "concept": "task",
          "relevance": 0.443
        },
        {
          "concept": "objective",
          "relevance": 0.432
        },
        {
          "concept": "method",
          "relevance": 0.414
        },
        {
          "concept": "performance",
          "relevance": 0.407
        },
        {
          "concept": "hierarchy",
          "relevance": 0.399
        },
        {
          "concept": "detection",
          "relevance": 0.391
        },
        {
          "concept": "precision",
          "relevance": 0.386
        },
        {
          "concept": "system",
          "relevance": 0.37
        },
        {
          "concept": "boost",
          "relevance": 0.351
        },
        {
          "concept": "data",
          "relevance": 0.323
        },
        {
          "concept": "VOC",
          "relevance": 0.319
        },
        {
          "concept": "region",
          "relevance": 0.229
        },
        {
          "concept": "years",
          "relevance": 0.192
        }
      ]
    },
    {
      "paperId": "pub.1155160450",
      "doi": "10.1109/wacv56688.2023.00390",
      "title": "FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning",
      "year": 2023,
      "citationCount": 117,
      "fieldCitationRatio": 71.15,
      "abstract": "Exemplar-free class-incremental learning is very challenging due to the negative effect of catastrophic forgetting. A balance between stability and plasticity of the incremental process is needed in order to obtain good accuracy for past as well as new classes. Existing exemplar-free class-incremental methods focus either on successive fine tuning of the model, thus favoring plasticity, or on using a feature extractor fixed after the initial incremental state, thus favoring stability. We introduce a method which combines a fixed feature extractor and a pseudo-features generator to improve the stability-plasticity balance. The generator uses a simple yet effective geometric translation of new class features to create representations of past classes, made of pseudo-features. The translation of features only requires the storage of the centroid representations of past classes to produce their pseudo-features. Actual features of new classes and pseudo-features of past classes are fed into a linear classifier which is trained incrementally to discriminate between all classes. The incremental process is much faster with the proposed method compared to mainstream ones which update the entire deep model. Experiments are performed with three challenging datasets, and different incremental settings. A comparison with ten existing methods shows that our method outperforms the others in most cases. FeTrIL code is available at https://github.com/GregoirePetit/FeTrIL.",
      "reference_ids": [
        "pub.1142393703",
        "pub.1111784269",
        "pub.1085618534",
        "pub.1145901917",
        "pub.1151747997",
        "pub.1107454774",
        "pub.1107352239",
        "pub.1093645378",
        "pub.1094049040",
        "pub.1111346735",
        "pub.1040893066",
        "pub.1092698424",
        "pub.1061744603",
        "pub.1123987524",
        "pub.1111979755",
        "pub.1142390826",
        "pub.1001122271",
        "pub.1129913196",
        "pub.1142020774",
        "pub.1132271025",
        "pub.1007362592",
        "pub.1133310470",
        "pub.1009767488",
        "pub.1084152728",
        "pub.1093359587",
        "pub.1129913721",
        "pub.1132543348",
        "pub.1151380515",
        "pub.1129913817",
        "pub.1142393752",
        "pub.1123481793",
        "pub.1003568618",
        "pub.1123987570",
        "pub.1148956268",
        "pub.1132590815"
      ],
      "concepts_scores": [
        {
          "concept": "class-incremental learning",
          "relevance": 0.688
        },
        {
          "concept": "pseudo-features",
          "relevance": 0.646
        },
        {
          "concept": "effect of catastrophic forgetting",
          "relevance": 0.604
        },
        {
          "concept": "catastrophic forgetting",
          "relevance": 0.55
        },
        {
          "concept": "incremental process",
          "relevance": 0.55
        },
        {
          "concept": "deep models",
          "relevance": 0.547
        },
        {
          "concept": "Class-Incremental",
          "relevance": 0.546
        },
        {
          "concept": "linear classifier",
          "relevance": 0.538
        },
        {
          "concept": "feature translation",
          "relevance": 0.528
        },
        {
          "concept": "incremental setting",
          "relevance": 0.516
        },
        {
          "concept": "geometric translation",
          "relevance": 0.511
        },
        {
          "concept": "incremental state",
          "relevance": 0.462
        },
        {
          "concept": "actual features",
          "relevance": 0.459
        },
        {
          "concept": "mainstream ones",
          "relevance": 0.448
        },
        {
          "concept": "learning",
          "relevance": 0.441
        },
        {
          "concept": "representation",
          "relevance": 0.437
        },
        {
          "concept": "features",
          "relevance": 0.423
        },
        {
          "concept": "classifier",
          "relevance": 0.423
        },
        {
          "concept": "extractor",
          "relevance": 0.41
        },
        {
          "concept": "dataset",
          "relevance": 0.403
        },
        {
          "concept": "code",
          "relevance": 0.393
        },
        {
          "concept": "method",
          "relevance": 0.386
        },
        {
          "concept": "class",
          "relevance": 0.375
        },
        {
          "concept": "centroid",
          "relevance": 0.375
        },
        {
          "concept": "accuracy",
          "relevance": 0.369
        },
        {
          "concept": "translation",
          "relevance": 0.354
        },
        {
          "concept": "model",
          "relevance": 0.341
        },
        {
          "concept": "forgetting",
          "relevance": 0.338
        },
        {
          "concept": "tuning",
          "relevance": 0.334
        },
        {
          "concept": "process",
          "relevance": 0.324
        },
        {
          "concept": "sets",
          "relevance": 0.322
        },
        {
          "concept": "generation",
          "relevance": 0.32
        },
        {
          "concept": "storage",
          "relevance": 0.306
        },
        {
          "concept": "experiments",
          "relevance": 0.296
        },
        {
          "concept": "balance",
          "relevance": 0.272
        },
        {
          "concept": "ones",
          "relevance": 0.269
        },
        {
          "concept": "comparison",
          "relevance": 0.243
        },
        {
          "concept": "stability",
          "relevance": 0.224
        },
        {
          "concept": "cases",
          "relevance": 0.224
        },
        {
          "concept": "plasticity",
          "relevance": 0.21
        },
        {
          "concept": "negative effects",
          "relevance": 0.209
        },
        {
          "concept": "state",
          "relevance": 0.194
        }
      ]
    },
    {
      "paperId": "pub.1123987524",
      "doi": "10.1109/cvpr.2019.00046",
      "title": "Large Scale Incremental Learning",
      "year": 2019,
      "citationCount": 1021,
      "fieldCitationRatio": 250.09,
      "abstract": "Modern machine learning suffers from catastrophic forgetting when learning new classes incrementally. The performance dramatically degrades due to the missing data of old classes. Incremental learning methods have been proposed to retain the knowledge acquired from the old classes, by using knowledge distilling and keeping a few exemplars from the old classes. However, these methods struggle to scale up to a large number of classes. We believe this is because of the combination of two factors: (a) the data imbalance between the old and new classes, and (b) the increasing number of visually similar classes. Distinguishing between an increasing number of visually similar classes is particularly challenging, when the training data is unbalanced. We propose a simple and effective method to address this data imbalance issue. We found that the last fully connected layer has a strong bias towards the new classes, and this bias can be corrected by a linear model. With two bias parameters, our method performs remarkably well on two large datasets: ImageNet (1000 classes) and MS-Celeb-1M (10000 classes), outperforming the state-of-the-art algorithms by 11.1% and 13.2% respectively.",
      "reference_ids": [
        "pub.1008556556",
        "pub.1100060357",
        "pub.1105056095",
        "pub.1093359587",
        "pub.1094049040",
        "pub.1007362592",
        "pub.1009767488",
        "pub.1107454774",
        "pub.1148956322",
        "pub.1061186804",
        "pub.1061744603",
        "pub.1006228130",
        "pub.1093393482",
        "pub.1003568618",
        "pub.1084152728"
      ],
      "concepts_scores": [
        {
          "concept": "visually similar classes",
          "relevance": 0.681
        },
        {
          "concept": "state-of-the-art algorithms",
          "relevance": 0.605
        },
        {
          "concept": "MS-Celeb-1M",
          "relevance": 0.599
        },
        {
          "concept": "old classes",
          "relevance": 0.59
        },
        {
          "concept": "learning new classes",
          "relevance": 0.588
        },
        {
          "concept": "incremental learning method",
          "relevance": 0.585
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.585
        },
        {
          "concept": "similarity classes",
          "relevance": 0.58
        },
        {
          "concept": "data imbalance issue",
          "relevance": 0.578
        },
        {
          "concept": "modern machine learning",
          "relevance": 0.569
        },
        {
          "concept": "catastrophic forgetting",
          "relevance": 0.546
        },
        {
          "concept": "knowledge distillation",
          "relevance": 0.545
        },
        {
          "concept": "data imbalance",
          "relevance": 0.536
        },
        {
          "concept": "training data",
          "relevance": 0.535
        },
        {
          "concept": "imbalance issue",
          "relevance": 0.53
        },
        {
          "concept": "machine learning",
          "relevance": 0.524
        },
        {
          "concept": "learning methods",
          "relevance": 0.524
        },
        {
          "concept": "visualization",
          "relevance": 0.428
        },
        {
          "concept": "ImageNet",
          "relevance": 0.428
        },
        {
          "concept": "missing data",
          "relevance": 0.42
        },
        {
          "concept": "algorithm",
          "relevance": 0.402
        },
        {
          "concept": "dataset",
          "relevance": 0.4
        },
        {
          "concept": "method",
          "relevance": 0.383
        },
        {
          "concept": "data",
          "relevance": 0.382
        },
        {
          "concept": "learning",
          "relevance": 0.377
        },
        {
          "concept": "increasing number",
          "relevance": 0.377
        },
        {
          "concept": "class",
          "relevance": 0.373
        },
        {
          "concept": "new class",
          "relevance": 0.37
        },
        {
          "concept": "effective method",
          "relevance": 0.359
        },
        {
          "concept": "knowledge",
          "relevance": 0.355
        },
        {
          "concept": "bias parameters",
          "relevance": 0.355
        },
        {
          "concept": "performance",
          "relevance": 0.352
        },
        {
          "concept": "training",
          "relevance": 0.349
        },
        {
          "concept": "forgetting",
          "relevance": 0.335
        },
        {
          "concept": "data",
          "relevance": 0.324
        },
        {
          "concept": "exemplars",
          "relevance": 0.319
        },
        {
          "concept": "issues",
          "relevance": 0.316
        },
        {
          "concept": "linear model",
          "relevance": 0.302
        },
        {
          "concept": "model",
          "relevance": 0.292
        },
        {
          "concept": "number",
          "relevance": 0.264
        },
        {
          "concept": "parameters",
          "relevance": 0.255
        },
        {
          "concept": "imbalance",
          "relevance": 0.25
        },
        {
          "concept": "layer",
          "relevance": 0.242
        },
        {
          "concept": "bias",
          "relevance": 0.24
        },
        {
          "concept": "combination",
          "relevance": 0.236
        },
        {
          "concept": "distillation",
          "relevance": 0.22
        },
        {
          "concept": "factors",
          "relevance": 0.178
        }
      ]
    },
    {
      "paperId": "pub.1009767488",
      "doi": "10.1007/s11263-015-0816-y",
      "title": "ImageNet Large Scale Visual Recognition Challenge",
      "year": 2015,
      "citationCount": 31647,
      "fieldCitationRatio": 7802.6,
      "abstract": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.",
      "reference_ids": [
        "pub.1061743490",
        "pub.1093519792",
        "pub.1061744704",
        "pub.1005662680",
        "pub.1094016389",
        "pub.1019562355",
        "pub.1093603006",
        "pub.1095432752",
        "pub.1061697776",
        "pub.1095612626",
        "pub.1093328144",
        "pub.1095828189",
        "pub.1024892064",
        "pub.1061744813",
        "pub.1093347727",
        "pub.1094938111",
        "pub.1094273178",
        "pub.1014796149",
        "pub.1018357603",
        "pub.1049381146",
        "pub.1093883984",
        "pub.1095244523",
        "pub.1052777670",
        "pub.1030406568",
        "pub.1061743879",
        "pub.1079142101",
        "pub.1023854910",
        "pub.1028413381",
        "pub.1037871789",
        "pub.1017073734",
        "pub.1032233097",
        "pub.1052687286",
        "pub.1061743736",
        "pub.1044213993",
        "pub.1036601217",
        "pub.1061743745",
        "pub.1061744374",
        "pub.1045344996",
        "pub.1094033212",
        "pub.1045321436",
        "pub.1094251884",
        "pub.1095180230",
        "pub.1018453641",
        "pub.1095122440",
        "pub.1061743071",
        "pub.1095506116",
        "pub.1099426737",
        "pub.1094136360",
        "pub.1095578081",
        "pub.1110923470",
        "pub.1027534025",
        "pub.1061744034",
        "pub.1025918724",
        "pub.1094246303",
        "pub.1094727707",
        "pub.1095559903",
        "pub.1093296270",
        "pub.1094492451",
        "pub.1094646180",
        "pub.1094512911",
        "pub.1094855815",
        "pub.1099341327",
        "pub.1093355304",
        "pub.1094291017",
        "pub.1095689025",
        "pub.1093557144",
        "pub.1093992926",
        "pub.1033900312",
        "pub.1027572846"
      ],
      "concepts_scores": [
        {
          "concept": "ImageNet Large Scale Visual Recognition Challenge",
          "relevance": 0.691
        },
        {
          "concept": "object recognition",
          "relevance": 0.683
        },
        {
          "concept": "large-scale image classification",
          "relevance": 0.68
        },
        {
          "concept": "object category classification",
          "relevance": 0.666
        },
        {
          "concept": "Millions of images",
          "relevance": 0.666
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.66
        },
        {
          "concept": "ground-truth annotations",
          "relevance": 0.656
        },
        {
          "concept": "Recognition Challenge",
          "relevance": 0.613
        },
        {
          "concept": "object detection",
          "relevance": 0.612
        },
        {
          "concept": "image classification",
          "relevance": 0.608
        },
        {
          "concept": "human accuracy",
          "relevance": 0.598
        },
        {
          "concept": "object categories",
          "relevance": 0.596
        },
        {
          "concept": "category classification",
          "relevance": 0.581
        },
        {
          "concept": "classification",
          "relevance": 0.497
        },
        {
          "concept": "ImageNet",
          "relevance": 0.483
        },
        {
          "concept": "recognition",
          "relevance": 0.481
        },
        {
          "concept": "accuracy",
          "relevance": 0.478
        },
        {
          "concept": "objective",
          "relevance": 0.451
        },
        {
          "concept": "dataset",
          "relevance": 0.451
        },
        {
          "concept": "detection",
          "relevance": 0.442
        },
        {
          "concept": "annotation",
          "relevance": 0.441
        },
        {
          "concept": "challenges",
          "relevance": 0.394
        },
        {
          "concept": "images",
          "relevance": 0.394
        },
        {
          "concept": "creation",
          "relevance": 0.341
        },
        {
          "concept": "millions",
          "relevance": 0.339
        },
        {
          "concept": "improvement",
          "relevance": 0.318
        },
        {
          "concept": "categories",
          "relevance": 0.305
        },
        {
          "concept": "results",
          "relevance": 0.304
        },
        {
          "concept": "direction",
          "relevance": 0.295
        },
        {
          "concept": "field",
          "relevance": 0.286
        },
        {
          "concept": "analysis",
          "relevance": 0.25
        },
        {
          "concept": "institutions",
          "relevance": 0.236
        },
        {
          "concept": "years",
          "relevance": 0.223
        },
        {
          "concept": "participants",
          "relevance": 0.211
        },
        {
          "concept": "paper",
          "relevance": 0.137
        }
      ]
    }
  ],
  "evolution_links": [
    {
      "source": "pub.1169214707",
      "target": "pub.1163453096",
      "source_title": "A Comprehensive Survey of Continual Learning: Theory, Method and Application",
      "target_title": "CODA-Prompt: COntinual Decomposed Attention-Based Prompting for Rehearsal-Free Continual Learning"
    },
    {
      "source": "pub.1163453096",
      "target": "pub.1125160666",
      "source_title": "CODA-Prompt: COntinual Decomposed Attention-Based Prompting for Rehearsal-Free Continual Learning",
      "target_title": "Moment Matching for Multi-Source Domain Adaptation"
    },
    {
      "source": "pub.1125160666",
      "target": "pub.1093359587",
      "source_title": "Moment Matching for Multi-Source Domain Adaptation",
      "target_title": "Deep Residual Learning for Image Recognition"
    },
    {
      "source": "pub.1125160666",
      "target": "pub.1061179979",
      "source_title": "Moment Matching for Multi-Source Domain Adaptation",
      "target_title": "Gradient-based learning applied to document recognition"
    },
    {
      "source": "pub.1163453096",
      "target": "pub.1123987570",
      "source_title": "CODA-Prompt: COntinual Decomposed Attention-Based Prompting for Rehearsal-Free Continual Learning",
      "target_title": "Learning a Unified Classifier Incrementally via Rebalancing"
    },
    {
      "source": "pub.1123987570",
      "target": "pub.1095689025",
      "source_title": "Learning a Unified Classifier Incrementally via Rebalancing",
      "target_title": "ImageNet: A large-scale hierarchical image database"
    },
    {
      "source": "pub.1123987570",
      "target": "pub.1094727707",
      "source_title": "Learning a Unified Classifier Incrementally via Rebalancing",
      "target_title": "Rich feature hierarchies for accurate object detection and semantic segmentation"
    },
    {
      "source": "pub.1169214707",
      "target": "pub.1155160450",
      "source_title": "A Comprehensive Survey of Continual Learning: Theory, Method and Application",
      "target_title": "FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning"
    },
    {
      "source": "pub.1155160450",
      "target": "pub.1123987524",
      "source_title": "FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning",
      "target_title": "Large Scale Incremental Learning"
    },
    {
      "source": "pub.1123987524",
      "target": "pub.1093359587",
      "source_title": "Large Scale Incremental Learning",
      "target_title": "Deep Residual Learning for Image Recognition"
    },
    {
      "source": "pub.1123987524",
      "target": "pub.1009767488",
      "source_title": "Large Scale Incremental Learning",
      "target_title": "ImageNet Large Scale Visual Recognition Challenge"
    }
  ]
}