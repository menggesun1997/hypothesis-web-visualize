[
  {
    "paperId": "pub.1184137747",
    "doi": "10.1186/s13040-024-00414-9",
    "title": "Open challenges and opportunities in federated foundation models towards biomedical healthcare",
    "year": 2025,
    "citationCount": 8,
    "fieldCitationRatio": 0.0,
    "abstract": "This survey explores the transformative impact of foundation models (FMs) in artificial intelligence, focusing on their integration with federated learning (FL) in biomedical research. Foundation models such as ChatGPT, LLaMa, and CLIP, which are trained on vast datasets through methods including unsupervised pretraining, self-supervised learning, instructed fine-tuning, and reinforcement learning from human feedback, represent significant advancements in machine learning. These models, with their ability to generate coherent text and realistic images, are crucial for biomedical applications that require processing diverse data forms such as clinical reports, diagnostic images, and multimodal patient interactions. The incorporation of FL with these sophisticated models presents a promising strategy to harness their analytical power while safeguarding the privacy of sensitive medical data. This approach not only enhances the capabilities of FMs in medical diagnostics and personalized treatment but also addresses critical concerns about data privacy and security in healthcare. This survey reviews the current applications of FMs in federated settings, underscores the challenges, and identifies future research directions including scaling FMs, managing data diversity, and enhancing communication efficiency within FL frameworks. The objective is to encourage further research into the combined potential of FMs and FL, laying the groundwork for healthcare innovations.",
    "reference_ids": [
      "pub.1135323740",
      "pub.1130018712",
      "pub.1139532533",
      "pub.1157432180",
      "pub.1139947425",
      "pub.1163541083",
      "pub.1093359587",
      "pub.1133177015",
      "pub.1166578747",
      "pub.1092344414",
      "pub.1175161444",
      "pub.1167960714",
      "pub.1122413940",
      "pub.1034603392",
      "pub.1092625279",
      "pub.1152292454",
      "pub.1090693624",
      "pub.1126146801",
      "pub.1036922127",
      "pub.1128739468",
      "pub.1033404373",
      "pub.1061179648",
      "pub.1084206837",
      "pub.1099110523",
      "pub.1123832275",
      "pub.1137821262",
      "pub.1141942664",
      "pub.1144291158",
      "pub.1146291216",
      "pub.1154256880",
      "pub.1160103012",
      "pub.1175343991",
      "pub.1142378799",
      "pub.1157546912",
      "pub.1124048252",
      "pub.1125130599",
      "pub.1151003027",
      "pub.1164941443",
      "pub.1129757375",
      "pub.1149821101",
      "pub.1101063896",
      "pub.1131002266",
      "pub.1149741257",
      "pub.1145901384",
      "pub.1151380649",
      "pub.1100864805",
      "pub.1025343689",
      "pub.1125666719",
      "pub.1170135630",
      "pub.1163454104",
      "pub.1061529099",
      "pub.1142373075",
      "pub.1151748536",
      "pub.1164705743",
      "pub.1144759884",
      "pub.1135852635",
      "pub.1146618129",
      "pub.1127797754",
      "pub.1129734072",
      "pub.1130212635",
      "pub.1167754582",
      "pub.1148815137",
      "pub.1125158595",
      "pub.1143048846",
      "pub.1163031047",
      "pub.1170135221",
      "pub.1039633073",
      "pub.1143901258",
      "pub.1159417616",
      "pub.1029626466",
      "pub.1111372013",
      "pub.1139522820",
      "pub.1150639879",
      "pub.1154887103",
      "pub.1171202309",
      "pub.1151380550",
      "pub.1157837589",
      "pub.1163098166",
      "pub.1118043258",
      "pub.1153407056",
      "pub.1046498955",
      "pub.1111636890",
      "pub.1114205975",
      "pub.1123988552",
      "pub.1142367136",
      "pub.1123988226",
      "pub.1143948984",
      "pub.1152354889",
      "pub.1010020120",
      "pub.1038140272",
      "pub.1137419593",
      "pub.1156044010",
      "pub.1163042336",
      "pub.1120882528",
      "pub.1169254210",
      "pub.1020839961",
      "pub.1167394273",
      "pub.1170136669",
      "pub.1111868225",
      "pub.1048813546",
      "pub.1129913470",
      "pub.1136507728",
      "pub.1152010294",
      "pub.1061179979",
      "pub.1151026129",
      "pub.1129552656",
      "pub.1140288629",
      "pub.1091860759",
      "pub.1133177200",
      "pub.1095689025",
      "pub.1157336399",
      "pub.1077189435",
      "pub.1125865822",
      "pub.1133573121",
      "pub.1175056064",
      "pub.1156181518",
      "pub.1121025784",
      "pub.1166572453",
      "pub.1132927396",
      "pub.1091403846",
      "pub.1120396052",
      "pub.1011243329",
      "pub.1165341300",
      "pub.1165461252",
      "pub.1126983463",
      "pub.1163041778",
      "pub.1133252928",
      "pub.1143879065",
      "pub.1107669637",
      "pub.1122290267",
      "pub.1151673153",
      "pub.1007329839",
      "pub.1113355033",
      "pub.1059413204",
      "pub.1147209869",
      "pub.1160332642",
      "pub.1166268573",
      "pub.1169869424",
      "pub.1121827328",
      "pub.1135112882",
      "pub.1112093901",
      "pub.1120329849",
      "pub.1122290388",
      "pub.1170135648",
      "pub.1133341454",
      "pub.1140596439",
      "pub.1127318696",
      "pub.1131074864",
      "pub.1155987964",
      "pub.1154996652",
      "pub.1150208760",
      "pub.1132293252",
      "pub.1138202955",
      "pub.1003651104",
      "pub.1126763033",
      "pub.1151037535",
      "pub.1104321292",
      "pub.1138859332",
      "pub.1136994017",
      "pub.1133175157",
      "pub.1108733798",
      "pub.1135350235",
      "pub.1031120478",
      "pub.1149514017",
      "pub.1121622947",
      "pub.1139853407",
      "pub.1092698424",
      "pub.1148089991",
      "pub.1142575409",
      "pub.1149215169",
      "pub.1025595401",
      "pub.1061528581",
      "pub.1107455905",
      "pub.1133175050",
      "pub.1151381159",
      "pub.1014928761",
      "pub.1170136541",
      "pub.1167738420",
      "pub.1123309938",
      "pub.1092105548",
      "pub.1092357659",
      "pub.1124302904",
      "pub.1090904008",
      "pub.1163453498",
      "pub.1138572951",
      "pub.1151130044",
      "pub.1136588700",
      "pub.1155888342",
      "pub.1160635088",
      "pub.1135710434",
      "pub.1137810593"
    ],
    "concepts_scores": [
      {
        "concept": "federated learning",
        "relevance": 0.753
      },
      {
        "concept": "sensitive medical data",
        "relevance": 0.667
      },
      {
        "concept": "self-supervised learning",
        "relevance": 0.666
      },
      {
        "concept": "enhanced communication efficiency",
        "relevance": 0.648
      },
      {
        "concept": "FL framework",
        "relevance": 0.619
      },
      {
        "concept": "unsupervised pretraining",
        "relevance": 0.616
      },
      {
        "concept": "data privacy",
        "relevance": 0.615
      },
      {
        "concept": "reinforcement learning",
        "relevance": 0.613
      },
      {
        "concept": "human feedback",
        "relevance": 0.61
      },
      {
        "concept": "federated setting",
        "relevance": 0.608
      },
      {
        "concept": "data diversity",
        "relevance": 0.602
      },
      {
        "concept": "communication efficiency",
        "relevance": 0.595
      },
      {
        "concept": "machine learning",
        "relevance": 0.594
      },
      {
        "concept": "artificial intelligence",
        "relevance": 0.592
      },
      {
        "concept": "open challenges",
        "relevance": 0.591
      },
      {
        "concept": "medical data",
        "relevance": 0.583
      },
      {
        "concept": "fine-tuning",
        "relevance": 0.568
      },
      {
        "concept": "privacy",
        "relevance": 0.55
      },
      {
        "concept": "research directions",
        "relevance": 0.536
      },
      {
        "concept": "learning",
        "relevance": 0.529
      },
      {
        "concept": "foundation model",
        "relevance": 0.526
      },
      {
        "concept": "coherent text",
        "relevance": 0.514
      },
      {
        "concept": "medical diagnostics",
        "relevance": 0.51
      },
      {
        "concept": "ChatGPT",
        "relevance": 0.48
      },
      {
        "concept": "healthcare innovation",
        "relevance": 0.475
      },
      {
        "concept": "images",
        "relevance": 0.458
      },
      {
        "concept": "pretraining",
        "relevance": 0.455
      },
      {
        "concept": "security",
        "relevance": 0.455
      },
      {
        "concept": "dataset",
        "relevance": 0.453
      },
      {
        "concept": "intelligence",
        "relevance": 0.447
      },
      {
        "concept": "sophisticated models",
        "relevance": 0.446
      },
      {
        "concept": "biomedical healthcare",
        "relevance": 0.442
      },
      {
        "concept": "data form",
        "relevance": 0.439
      },
      {
        "concept": "machine",
        "relevance": 0.437
      },
      {
        "concept": "applications",
        "relevance": 0.435
      },
      {
        "concept": "healthcare",
        "relevance": 0.418
      },
      {
        "concept": "model",
        "relevance": 0.413
      },
      {
        "concept": "analytical power",
        "relevance": 0.413
      },
      {
        "concept": "transformative impact",
        "relevance": 0.406
      },
      {
        "concept": "capability",
        "relevance": 0.402
      },
      {
        "concept": "framework",
        "relevance": 0.4
      },
      {
        "concept": "text",
        "relevance": 0.399
      },
      {
        "concept": "challenges",
        "relevance": 0.395
      },
      {
        "concept": "research",
        "relevance": 0.393
      },
      {
        "concept": "data",
        "relevance": 0.385
      },
      {
        "concept": "feedback",
        "relevance": 0.382
      },
      {
        "concept": "biomedical research",
        "relevance": 0.381
      },
      {
        "concept": "clips",
        "relevance": 0.381
      },
      {
        "concept": "objective",
        "relevance": 0.366
      },
      {
        "concept": "sets",
        "relevance": 0.361
      },
      {
        "concept": "reinforcement",
        "relevance": 0.353
      },
      {
        "concept": "patient interactions",
        "relevance": 0.353
      },
      {
        "concept": "method",
        "relevance": 0.351
      },
      {
        "concept": "integration",
        "relevance": 0.348
      },
      {
        "concept": "efficiency",
        "relevance": 0.347
      },
      {
        "concept": "innovation",
        "relevance": 0.337
      },
      {
        "concept": "power",
        "relevance": 0.334
      },
      {
        "concept": "advances",
        "relevance": 0.326
      },
      {
        "concept": "clinical reports",
        "relevance": 0.324
      },
      {
        "concept": "personalized treatment",
        "relevance": 0.32
      },
      {
        "concept": "diagnostic imaging",
        "relevance": 0.318
      },
      {
        "concept": "direction",
        "relevance": 0.296
      },
      {
        "concept": "opportunities",
        "relevance": 0.292
      },
      {
        "concept": "foundations",
        "relevance": 0.289
      },
      {
        "concept": "diversity",
        "relevance": 0.286
      },
      {
        "concept": "survey",
        "relevance": 0.276
      },
      {
        "concept": "concerns",
        "relevance": 0.272
      },
      {
        "concept": "diagnostics",
        "relevance": 0.253
      },
      {
        "concept": "biomedical applications",
        "relevance": 0.248
      },
      {
        "concept": "interaction",
        "relevance": 0.245
      },
      {
        "concept": "treatment",
        "relevance": 0.239
      },
      {
        "concept": "reports",
        "relevance": 0.219
      },
      {
        "concept": "potential",
        "relevance": 0.213
      },
      {
        "concept": "form",
        "relevance": 0.197
      },
      {
        "concept": "llamas",
        "relevance": 0.178
      },
      {
        "concept": "incorporation",
        "relevance": 0.15
      }
    ]
  },
  {
    "paperId": "pub.1182793755",
    "doi": "10.3389/fdata.2024.1501154",
    "title": "Enhancing sentiment and intent analysis in public health via fine-tuned Large Language Models on tobacco and e-cigarette-related tweets",
    "year": 2024,
    "citationCount": 4,
    "fieldCitationRatio": 0.0,
    "abstract": "Background: Accurate sentiment analysis and intent categorization of tobacco and e-cigarette-related social media content are critical for public health research, yet they necessitate specialized natural language processing approaches.\nObjective: To compare pre-trained and fine-tuned Flan-T5 models for intent classification and sentiment analysis of tobacco and e-cigarette tweets, demonstrating the effectiveness of pre-training a lightweight large language model for domain specific tasks.\nMethods: Three Flan-T5 classification models were developed: (1) tobacco intent, (2) e-cigarette intent, and (3) sentiment analysis. Domain-specific datasets with tobacco and e-cigarette tweets were created using GPT-4 and validated by tobacco control specialists using a rigorous evaluation process. A standardized rubric and consensus mechanism involving domain specialists ensured high-quality datasets. The Flan-T5 Large Language Models were fine-tuned using Low-Rank Adaptation and evaluated against pre-trained baselines on the datasets using accuracy performance metrics. To further assess model generalizability and robustness, the fine-tuned models were evaluated on real-world tweets collected around the COP9 event.\nResults: In every task, fine-tuned models performed much better than pre-trained models. Compared to the pre-trained model's accuracy of 0.33, the fine-tuned model achieved an overall accuracy of 0.91 for tobacco intent classification. The fine-tuned model achieved an accuracy of 0.93 for e-cigarette intent, which is higher than the accuracy of 0.36 for the pre-trained model. The fine-tuned model significantly outperformed the pre-trained model's accuracy of 0.65 in sentiment analysis, achieving an accuracy of 0.94 for sentiments.\nConclusion: The effectiveness of lightweight Flan-T5 models in analyzing tweets associated with tobacco and e-cigarette is significantly improved by domain-specific fine-tuning, providing highly accurate instruments for tracking public conversation on tobacco and e-cigarette. The involvement of domain specialists in dataset validation ensured that the generated content accurately represented real-world discussions, thereby enhancing the quality and reliability of the results. Research on tobacco control and the formulation of public policy could be informed by these findings.",
    "reference_ids": [
      "pub.1119353072",
      "pub.1168747782",
      "pub.1172700507",
      "pub.1156343937",
      "pub.1154570942",
      "pub.1163045919",
      "pub.1164680305",
      "pub.1169907965",
      "pub.1171392854",
      "pub.1173032543",
      "pub.1173754387",
      "pub.1160511105",
      "pub.1173418028",
      "pub.1168869793",
      "pub.1158836991",
      "pub.1158022269",
      "pub.1169217126",
      "pub.1158600650",
      "pub.1160653203",
      "pub.1156151267",
      "pub.1152022267",
      "pub.1165019852",
      "pub.1173580736",
      "pub.1159831801",
      "pub.1123935425",
      "pub.1166120973",
      "pub.1173452950",
      "pub.1168812009",
      "pub.1169173113",
      "pub.1163493542",
      "pub.1155888342",
      "pub.1173710928",
      "pub.1124217439"
    ],
    "concepts_scores": [
      {
        "concept": "pre-trained models",
        "relevance": 0.737
      },
      {
        "concept": "sentiment analysis",
        "relevance": 0.727
      },
      {
        "concept": "language model",
        "relevance": 0.716
      },
      {
        "concept": "intent classification",
        "relevance": 0.688
      },
      {
        "concept": "domain specialists",
        "relevance": 0.681
      },
      {
        "concept": "e-cigarettes",
        "relevance": 0.671
      },
      {
        "concept": "domain-specific fine-tuning",
        "relevance": 0.662
      },
      {
        "concept": "accurate sentiment analysis",
        "relevance": 0.642
      },
      {
        "concept": "domain-specific datasets",
        "relevance": 0.642
      },
      {
        "concept": "natural language processing approach",
        "relevance": 0.641
      },
      {
        "concept": "domain-specific tasks",
        "relevance": 0.626
      },
      {
        "concept": "public health research",
        "relevance": 0.612
      },
      {
        "concept": "accuracy performance metrics",
        "relevance": 0.611
      },
      {
        "concept": "e-cigarette-related tweets",
        "relevance": 0.606
      },
      {
        "concept": "e-cigarette tweets",
        "relevance": 0.605
      },
      {
        "concept": "high-quality datasets",
        "relevance": 0.598
      },
      {
        "concept": "compare pre-trained",
        "relevance": 0.597
      },
      {
        "concept": "pre-training baselines",
        "relevance": 0.597
      },
      {
        "concept": "consensus mechanism",
        "relevance": 0.59
      },
      {
        "concept": "model accuracy",
        "relevance": 0.588
      },
      {
        "concept": "social media content",
        "relevance": 0.583
      },
      {
        "concept": "effect of pre-training",
        "relevance": 0.583
      },
      {
        "concept": "low-rank",
        "relevance": 0.577
      },
      {
        "concept": "pre-training",
        "relevance": 0.576
      },
      {
        "concept": "tobacco control",
        "relevance": 0.576
      },
      {
        "concept": "classification model",
        "relevance": 0.572
      },
      {
        "concept": "performance metrics",
        "relevance": 0.566
      },
      {
        "concept": "health research",
        "relevance": 0.563
      },
      {
        "concept": "analysis of tobacco",
        "relevance": 0.562
      },
      {
        "concept": "model generalizability",
        "relevance": 0.561
      },
      {
        "concept": "tweets",
        "relevance": 0.556
      },
      {
        "concept": "fine-tuning",
        "relevance": 0.548
      },
      {
        "concept": "dataset",
        "relevance": 0.541
      },
      {
        "concept": "specific tasks",
        "relevance": 0.539
      },
      {
        "concept": "intent analysis",
        "relevance": 0.537
      },
      {
        "concept": "dataset validation",
        "relevance": 0.537
      },
      {
        "concept": "public health",
        "relevance": 0.527
      },
      {
        "concept": "overall accuracy",
        "relevance": 0.524
      },
      {
        "concept": "sentiment",
        "relevance": 0.523
      },
      {
        "concept": "tobacco",
        "relevance": 0.52
      },
      {
        "concept": "processing approach",
        "relevance": 0.516
      },
      {
        "concept": "media content",
        "relevance": 0.51
      },
      {
        "concept": "evaluation process",
        "relevance": 0.5
      },
      {
        "concept": "accuracy",
        "relevance": 0.499
      },
      {
        "concept": "specialists",
        "relevance": 0.488
      },
      {
        "concept": "task",
        "relevance": 0.485
      },
      {
        "concept": "classification",
        "relevance": 0.481
      },
      {
        "concept": "accurate instrument",
        "relevance": 0.459
      },
      {
        "concept": "control specialists",
        "relevance": 0.448
      },
      {
        "concept": "language",
        "relevance": 0.445
      },
      {
        "concept": "health",
        "relevance": 0.426
      },
      {
        "concept": "metrics",
        "relevance": 0.424
      },
      {
        "concept": "domain",
        "relevance": 0.422
      },
      {
        "concept": "robustness",
        "relevance": 0.415
      },
      {
        "concept": "public policy",
        "relevance": 0.407
      },
      {
        "concept": "intention",
        "relevance": 0.401
      },
      {
        "concept": "model",
        "relevance": 0.4
      },
      {
        "concept": "formulation of public policies",
        "relevance": 0.397
      },
      {
        "concept": "baseline",
        "relevance": 0.386
      },
      {
        "concept": "generalizability",
        "relevance": 0.384
      },
      {
        "concept": "research",
        "relevance": 0.361
      },
      {
        "concept": "consensus",
        "relevance": 0.352
      },
      {
        "concept": "quality",
        "relevance": 0.351
      },
      {
        "concept": "reliability",
        "relevance": 0.347
      },
      {
        "concept": "analysis",
        "relevance": 0.344
      },
      {
        "concept": "adaptation",
        "relevance": 0.34
      },
      {
        "concept": "evaluation",
        "relevance": 0.339
      },
      {
        "concept": "instrument",
        "relevance": 0.339
      },
      {
        "concept": "validity",
        "relevance": 0.325
      },
      {
        "concept": "policy",
        "relevance": 0.324
      },
      {
        "concept": "findings",
        "relevance": 0.32
      },
      {
        "concept": "involvement",
        "relevance": 0.309
      },
      {
        "concept": "discussion",
        "relevance": 0.308
      },
      {
        "concept": "process",
        "relevance": 0.303
      },
      {
        "concept": "effect",
        "relevance": 0.294
      },
      {
        "concept": "results",
        "relevance": 0.294
      },
      {
        "concept": "control",
        "relevance": 0.283
      },
      {
        "concept": "content",
        "relevance": 0.278
      },
      {
        "concept": "events",
        "relevance": 0.276
      },
      {
        "concept": "public conversation",
        "relevance": 0.274
      },
      {
        "concept": "formulation",
        "relevance": 0.264
      },
      {
        "concept": "approach",
        "relevance": 0.256
      },
      {
        "concept": "mechanism",
        "relevance": 0.224
      },
      {
        "concept": "conversion",
        "relevance": 0.197
      },
      {
        "concept": "COP9",
        "relevance": 0.163
      }
    ]
  },
  {
    "paperId": "pub.1186593116",
    "doi": "10.1038/s41598-025-91940-x",
    "title": "A large language model for advanced power dispatch",
    "year": 2025,
    "citationCount": 1,
    "fieldCitationRatio": 0.0,
    "abstract": "Power dispatch is essential for providing society with stable, cost-effective, and eco-friendly electricity. However, traditional methods falter as power systems grow in scale and complexity, struggling with multitasking, swift problem-solving, and human-machine collaboration. This paper introduces Grid Artificial Intelligent Assistant (GAIA), a pioneering Large Language Model (LLM) designed to assist with a variety of power system operational tasks, including operation adjustment, operation monitoring, and black start scenarios. We have developed a novel dataset construction technique that harnesses various data sources to fine-tune GAIA for optimal performance in this domain. This approach streamlines LLM training, allowing for the seamless integration of multidimensional data in power system management. Additionally, we have crafted specialized prompt strategies to boost GAIA’s input-output efficiency in dispatch scenarios. When evaluated on the ElecBench benchmark, GAIA surpasses the baseline model Large Language Model Meta AI-2 (LLaMA2) on multiple metrics. In practical applications, GAIA has demonstrated its ability to enhance decision-making processes, improve operational efficiency, and facilitate better human-machine interactions in power dispatch operations. This paper expands the application of LLMs to power dispatch and validates their practical utility, paving the way for future innovations in this field.",
    "reference_ids": [
      "pub.1092293893",
      "pub.1166872595",
      "pub.1107025245",
      "pub.1061751339",
      "pub.1166542851",
      "pub.1061780233",
      "pub.1111434459",
      "pub.1151003027",
      "pub.1061627232",
      "pub.1166289808",
      "pub.1059417905",
      "pub.1160635088",
      "pub.1104219292",
      "pub.1061195248",
      "pub.1182710967",
      "pub.1163044197",
      "pub.1061632147",
      "pub.1172994394",
      "pub.1167777328",
      "pub.1158696456",
      "pub.1176268042",
      "pub.1175873969",
      "pub.1093882119"
    ],
    "concepts_scores": [
      {
        "concept": "human-machine collaboration",
        "relevance": 0.597
      },
      {
        "concept": "human-machine interaction",
        "relevance": 0.594
      },
      {
        "concept": "power dispatch",
        "relevance": 0.579
      },
      {
        "concept": "artificial intelligence assistance",
        "relevance": 0.577
      },
      {
        "concept": "integration of multidimensional data",
        "relevance": 0.571
      },
      {
        "concept": "language model",
        "relevance": 0.558
      },
      {
        "concept": "intelligent assistant",
        "relevance": 0.558
      },
      {
        "concept": "multidimensional data",
        "relevance": 0.545
      },
      {
        "concept": "seamless integration",
        "relevance": 0.536
      },
      {
        "concept": "multiple metrics",
        "relevance": 0.526
      },
      {
        "concept": "power system management",
        "relevance": 0.509
      },
      {
        "concept": "dispatch scenarios",
        "relevance": 0.502
      },
      {
        "concept": "power system",
        "relevance": 0.499
      },
      {
        "concept": "system management",
        "relevance": 0.499
      },
      {
        "concept": "optimal performance",
        "relevance": 0.498
      },
      {
        "concept": "eco-friendly electricity",
        "relevance": 0.493
      },
      {
        "concept": "operational tasks",
        "relevance": 0.483
      },
      {
        "concept": "traditional methods",
        "relevance": 0.477
      },
      {
        "concept": "dispatching operation",
        "relevance": 0.464
      },
      {
        "concept": "data sources",
        "relevance": 0.457
      },
      {
        "concept": "dispatch",
        "relevance": 0.455
      },
      {
        "concept": "operational efficiency",
        "relevance": 0.454
      },
      {
        "concept": "operation adjustment",
        "relevance": 0.453
      },
      {
        "concept": "operational monitoring",
        "relevance": 0.443
      },
      {
        "concept": "scenarios",
        "relevance": 0.439
      },
      {
        "concept": "construction techniques",
        "relevance": 0.439
      },
      {
        "concept": "decision-making process",
        "relevance": 0.439
      },
      {
        "concept": "power",
        "relevance": 0.432
      },
      {
        "concept": "dataset",
        "relevance": 0.414
      },
      {
        "concept": "operation",
        "relevance": 0.405
      },
      {
        "concept": "benchmarks",
        "relevance": 0.405
      },
      {
        "concept": "metrics",
        "relevance": 0.402
      },
      {
        "concept": "task",
        "relevance": 0.397
      },
      {
        "concept": "problem-solving",
        "relevance": 0.394
      },
      {
        "concept": "LLM",
        "relevance": 0.394
      },
      {
        "concept": "efficiency",
        "relevance": 0.389
      },
      {
        "concept": "input-output efficiency",
        "relevance": 0.366
      },
      {
        "concept": "performance",
        "relevance": 0.365
      },
      {
        "concept": "language",
        "relevance": 0.364
      },
      {
        "concept": "grid",
        "relevance": 0.362
      },
      {
        "concept": "training",
        "relevance": 0.362
      },
      {
        "concept": "electricity",
        "relevance": 0.347
      },
      {
        "concept": "collaboration",
        "relevance": 0.346
      },
      {
        "concept": "domain",
        "relevance": 0.345
      },
      {
        "concept": "applications",
        "relevance": 0.344
      },
      {
        "concept": "system",
        "relevance": 0.332
      },
      {
        "concept": "cost-effective",
        "relevance": 0.327
      },
      {
        "concept": "technique",
        "relevance": 0.326
      },
      {
        "concept": "monitoring",
        "relevance": 0.324
      },
      {
        "concept": "method",
        "relevance": 0.321
      },
      {
        "concept": "assistance",
        "relevance": 0.318
      },
      {
        "concept": "innovation",
        "relevance": 0.308
      },
      {
        "concept": "complex",
        "relevance": 0.304
      },
      {
        "concept": "model",
        "relevance": 0.303
      },
      {
        "concept": "process",
        "relevance": 0.292
      },
      {
        "concept": "data",
        "relevance": 0.29
      },
      {
        "concept": "management",
        "relevance": 0.279
      },
      {
        "concept": "Swift",
        "relevance": 0.261
      },
      {
        "concept": "source",
        "relevance": 0.26
      },
      {
        "concept": "scale",
        "relevance": 0.231
      },
      {
        "concept": "baseline",
        "relevance": 0.225
      },
      {
        "concept": "interaction",
        "relevance": 0.224
      },
      {
        "concept": "society",
        "relevance": 0.202
      },
      {
        "concept": "adjustment",
        "relevance": 0.197
      },
      {
        "concept": "AI-2",
        "relevance": 0.177
      }
    ]
  },
  {
    "paperId": "pub.1183729306",
    "doi": "10.3390/e26121114",
    "title": "Contextual Fine-Tuning of Language Models with Classifier-Driven Content Moderation for Text Generation",
    "year": 2024,
    "citationCount": 3,
    "fieldCitationRatio": 0.0,
    "abstract": "In today's digital age, ensuring the appropriateness of content for children is crucial for their cognitive and emotional development. The rise of automated text generation technologies, such as Large Language Models like LLaMA, Mistral, and Zephyr, has created a pressing need for effective tools to filter and classify suitable content. However, the existing methods often fail to effectively address the intricate details and unique characteristics of children's literature. This study aims to bridge this gap by developing a robust framework that utilizes fine-tuned language models, classification techniques, and contextual story generation to generate and classify children's stories based on their suitability. Employing a combination of fine-tuning techniques on models such as LLaMA, Mistral, and Zephyr, alongside a BERT-based classifier, we evaluated the generated stories against established metrics like ROUGE, METEOR, and BERT Scores. The fine-tuned Mistral-7B model achieved a ROUGE-1 score of 0.4785, significantly higher than the base model's 0.3185, while Zephyr-7B-Beta achieved a METEOR score of 0.4154 compared to its base counterpart's score of 0.3602. The results indicated that the fine-tuned models outperformed base models, generating content more aligned with human standards. Moreover, the BERT Classifier exhibited high precision (0.95) and recall (0.97) for identifying unsuitable content, further enhancing the reliability of content classification. These findings highlight the potential of advanced language models in generating age-appropriate stories and enhancing content moderation strategies. This research has broader implications for educational technology, content curation, and parental control systems, offering a scalable approach to ensuring children's exposure to safe and enriching narratives.",
    "reference_ids": [
      "pub.1148340412",
      "pub.1141029630",
      "pub.1164815360",
      "pub.1117660148",
      "pub.1181805505",
      "pub.1182811420",
      "pub.1099110523",
      "pub.1171848782",
      "pub.1182344327",
      "pub.1158712234",
      "pub.1181714610",
      "pub.1172827052",
      "pub.1139853640",
      "pub.1169799356",
      "pub.1099239594",
      "pub.1148061673",
      "pub.1171319371",
      "pub.1156054443",
      "pub.1164274438"
    ],
    "concepts_scores": [
      {
        "concept": "language model",
        "relevance": 0.66
      },
      {
        "concept": "text generation technology",
        "relevance": 0.584
      },
      {
        "concept": "advanced language models",
        "relevance": 0.584
      },
      {
        "concept": "ROUGE-1 score",
        "relevance": 0.583
      },
      {
        "concept": "BERT-based classifier",
        "relevance": 0.574
      },
      {
        "concept": "fine-tuned models",
        "relevance": 0.573
      },
      {
        "concept": "parental control systems",
        "relevance": 0.557
      },
      {
        "concept": "characteristics of children’s literature",
        "relevance": 0.551
      },
      {
        "concept": "base model",
        "relevance": 0.541
      },
      {
        "concept": "BERT classifier",
        "relevance": 0.539
      },
      {
        "concept": "METEOR scores",
        "relevance": 0.538
      },
      {
        "concept": "content moderation strategy",
        "relevance": 0.535
      },
      {
        "concept": "content classification",
        "relevance": 0.532
      },
      {
        "concept": "text generation",
        "relevance": 0.53
      },
      {
        "concept": "today's digital age",
        "relevance": 0.53
      },
      {
        "concept": "classification techniques",
        "relevance": 0.522
      },
      {
        "concept": "story generation",
        "relevance": 0.514
      },
      {
        "concept": "content curation",
        "relevance": 0.499
      },
      {
        "concept": "children’s literature",
        "relevance": 0.497
      },
      {
        "concept": "children's stories",
        "relevance": 0.491
      },
      {
        "concept": "content moderation",
        "relevance": 0.487
      },
      {
        "concept": "BERT",
        "relevance": 0.485
      },
      {
        "concept": "classifier",
        "relevance": 0.481
      },
      {
        "concept": "appropriateness of content",
        "relevance": 0.477
      },
      {
        "concept": "digital age",
        "relevance": 0.476
      },
      {
        "concept": "story",
        "relevance": 0.46
      },
      {
        "concept": "moderation strategies",
        "relevance": 0.455
      },
      {
        "concept": "language",
        "relevance": 0.445
      },
      {
        "concept": "classification",
        "relevance": 0.436
      },
      {
        "concept": "intricate details",
        "relevance": 0.425
      },
      {
        "concept": "control system",
        "relevance": 0.42
      },
      {
        "concept": "children's exposure",
        "relevance": 0.419
      },
      {
        "concept": "educational technology",
        "relevance": 0.407
      },
      {
        "concept": "technology",
        "relevance": 0.401
      },
      {
        "concept": "Mistral",
        "relevance": 0.395
      },
      {
        "concept": "unique characteristics",
        "relevance": 0.393
      },
      {
        "concept": "human standards",
        "relevance": 0.391
      },
      {
        "concept": "metrics",
        "relevance": 0.384
      },
      {
        "concept": "text",
        "relevance": 0.381
      },
      {
        "concept": "narratives",
        "relevance": 0.381
      },
      {
        "concept": "emotional development",
        "relevance": 0.369
      },
      {
        "concept": "Zephyr",
        "relevance": 0.367
      },
      {
        "concept": "effective tool",
        "relevance": 0.363
      },
      {
        "concept": "model",
        "relevance": 0.362
      },
      {
        "concept": "generation technologies",
        "relevance": 0.362
      },
      {
        "concept": "technique",
        "relevance": 0.36
      },
      {
        "concept": "children",
        "relevance": 0.356
      },
      {
        "concept": "base",
        "relevance": 0.356
      },
      {
        "concept": "framework",
        "relevance": 0.35
      },
      {
        "concept": "contextual",
        "relevance": 0.347
      },
      {
        "concept": "curation",
        "relevance": 0.346
      },
      {
        "concept": "appropriateness",
        "relevance": 0.344
      },
      {
        "concept": "content",
        "relevance": 0.33
      },
      {
        "concept": "pressing need",
        "relevance": 0.33
      },
      {
        "concept": "details",
        "relevance": 0.33
      },
      {
        "concept": "precision",
        "relevance": 0.33
      },
      {
        "concept": "today",
        "relevance": 0.32
      },
      {
        "concept": "tools",
        "relevance": 0.317
      },
      {
        "concept": "system",
        "relevance": 0.317
      },
      {
        "concept": "generation",
        "relevance": 0.314
      },
      {
        "concept": "reliability",
        "relevance": 0.314
      },
      {
        "concept": "method",
        "relevance": 0.306
      },
      {
        "concept": "llamas",
        "relevance": 0.297
      },
      {
        "concept": "Rouge",
        "relevance": 0.296
      },
      {
        "concept": "literature",
        "relevance": 0.282
      },
      {
        "concept": "research",
        "relevance": 0.282
      },
      {
        "concept": "standards",
        "relevance": 0.281
      },
      {
        "concept": "needs",
        "relevance": 0.277
      },
      {
        "concept": "results",
        "relevance": 0.267
      },
      {
        "concept": "strategies",
        "relevance": 0.266
      },
      {
        "concept": "suitability",
        "relevance": 0.26
      },
      {
        "concept": "meteor",
        "relevance": 0.258
      },
      {
        "concept": "development",
        "relevance": 0.238
      },
      {
        "concept": "findings",
        "relevance": 0.235
      },
      {
        "concept": "combination",
        "relevance": 0.234
      },
      {
        "concept": "scores",
        "relevance": 0.233
      },
      {
        "concept": "moderately",
        "relevance": 0.217
      },
      {
        "concept": "study",
        "relevance": 0.216
      },
      {
        "concept": "potential",
        "relevance": 0.186
      },
      {
        "concept": "age",
        "relevance": 0.185
      },
      {
        "concept": "exposure",
        "relevance": 0.166
      }
    ]
  },
  {
    "paperId": "pub.1171029525",
    "doi": "10.1093/jamia/ocae074",
    "title": "Large language models for biomedicine: foundations, opportunities, challenges, and best practices",
    "year": 2024,
    "citationCount": 27,
    "fieldCitationRatio": 0.0,
    "abstract": "OBJECTIVES: Generative large language models (LLMs) are a subset of transformers-based neural network architecture models. LLMs have successfully leveraged a combination of an increased number of parameters, improvements in computational efficiency, and large pre-training datasets to perform a wide spectrum of natural language processing (NLP) tasks. Using a few examples (few-shot) or no examples (zero-shot) for prompt-tuning has enabled LLMs to achieve state-of-the-art performance in a broad range of NLP applications. This article by the American Medical Informatics Association (AMIA) NLP Working Group characterizes the opportunities, challenges, and best practices for our community to leverage and advance the integration of LLMs in downstream NLP applications effectively. This can be accomplished through a variety of approaches, including augmented prompting, instruction prompt tuning, and reinforcement learning from human feedback (RLHF).\nTARGET AUDIENCE: Our focus is on making LLMs accessible to the broader biomedical informatics community, including clinicians and researchers who may be unfamiliar with NLP. Additionally, NLP practitioners may gain insight from the described best practices.\nSCOPE: We focus on 3 broad categories of NLP tasks, namely natural language understanding, natural language inferencing, and natural language generation. We review the emerging trends in prompt tuning, instruction fine-tuning, and evaluation metrics used for LLMs while drawing attention to several issues that impact biomedical NLP applications, including falsehoods in generated text (confabulation/hallucinations), toxicity, and dataset contamination leading to overfitting. We also review potential approaches to address some of these current challenges in LLMs, such as chain of thought prompting, and the phenomena of emergent capabilities observed in LLMs that can be leveraged to address complex NLP challenge in biomedical applications.",
    "reference_ids": [
      "pub.1140714420",
      "pub.1139948286",
      "pub.1099113580",
      "pub.1120882528",
      "pub.1160759555",
      "pub.1117659708",
      "pub.1166058806",
      "pub.1163029334",
      "pub.1132921735",
      "pub.1160635088",
      "pub.1096025530",
      "pub.1129757043",
      "pub.1160103012",
      "pub.1099151203",
      "pub.1144112989",
      "pub.1115977877",
      "pub.1143948984",
      "pub.1122290388",
      "pub.1141942664",
      "pub.1160026137",
      "pub.1117658906",
      "pub.1160155964"
    ],
    "concepts_scores": [
      {
        "concept": "natural language processing",
        "relevance": 0.803
      },
      {
        "concept": "prompt tuning",
        "relevance": 0.699
      },
      {
        "concept": "NLP applications",
        "relevance": 0.693
      },
      {
        "concept": "language model",
        "relevance": 0.692
      },
      {
        "concept": "state-of-the-art performance",
        "relevance": 0.673
      },
      {
        "concept": "NLP practitioners",
        "relevance": 0.672
      },
      {
        "concept": "natural language processing applications",
        "relevance": 0.666
      },
      {
        "concept": "biomedical NLP applications",
        "relevance": 0.655
      },
      {
        "concept": "pre-training dataset",
        "relevance": 0.651
      },
      {
        "concept": "neural network architecture model",
        "relevance": 0.649
      },
      {
        "concept": "natural language understanding",
        "relevance": 0.649
      },
      {
        "concept": "natural language generation",
        "relevance": 0.646
      },
      {
        "concept": "biomedical informatics community",
        "relevance": 0.638
      },
      {
        "concept": "network architecture model",
        "relevance": 0.628
      },
      {
        "concept": "American Medical Informatics Association (AMIA",
        "relevance": 0.608
      },
      {
        "concept": "prompt-tuning",
        "relevance": 0.607
      },
      {
        "concept": "few-shot",
        "relevance": 0.605
      },
      {
        "concept": "Zero-Shot",
        "relevance": 0.605
      },
      {
        "concept": "NLP tasks",
        "relevance": 0.604
      },
      {
        "concept": "NLP challenge",
        "relevance": 0.604
      },
      {
        "concept": "reinforcement learning",
        "relevance": 0.601
      },
      {
        "concept": "human feedback",
        "relevance": 0.597
      },
      {
        "concept": "language understanding",
        "relevance": 0.594
      },
      {
        "concept": "language generation",
        "relevance": 0.594
      },
      {
        "concept": "evaluation metrics",
        "relevance": 0.593
      },
      {
        "concept": "informatics community",
        "relevance": 0.588
      },
      {
        "concept": "language processing",
        "relevance": 0.585
      },
      {
        "concept": "architecture model",
        "relevance": 0.583
      },
      {
        "concept": "fine-tuning",
        "relevance": 0.556
      },
      {
        "concept": "computational efficiency",
        "relevance": 0.544
      },
      {
        "concept": "dataset",
        "relevance": 0.514
      },
      {
        "concept": "emergency capability",
        "relevance": 0.514
      },
      {
        "concept": "overfitting",
        "relevance": 0.464
      },
      {
        "concept": "applications",
        "relevance": 0.455
      },
      {
        "concept": "inferencing",
        "relevance": 0.449
      },
      {
        "concept": "metrics",
        "relevance": 0.43
      },
      {
        "concept": "instruction",
        "relevance": 0.427
      },
      {
        "concept": "tuning",
        "relevance": 0.426
      },
      {
        "concept": "task",
        "relevance": 0.425
      },
      {
        "concept": "No examples",
        "relevance": 0.42
      },
      {
        "concept": "learning",
        "relevance": 0.419
      },
      {
        "concept": "examples",
        "relevance": 0.418
      },
      {
        "concept": "challenges",
        "relevance": 0.407
      },
      {
        "concept": "language",
        "relevance": 0.405
      },
      {
        "concept": "model",
        "relevance": 0.395
      },
      {
        "concept": "falsehood",
        "relevance": 0.394
      },
      {
        "concept": "capability",
        "relevance": 0.394
      },
      {
        "concept": "performance",
        "relevance": 0.39
      },
      {
        "concept": "Working Group",
        "relevance": 0.377
      },
      {
        "concept": "practice",
        "relevance": 0.375
      },
      {
        "concept": "feedback",
        "relevance": 0.374
      },
      {
        "concept": "increasing number",
        "relevance": 0.361
      },
      {
        "concept": "community",
        "relevance": 0.353
      },
      {
        "concept": "issues",
        "relevance": 0.351
      },
      {
        "concept": "reinforcement",
        "relevance": 0.345
      },
      {
        "concept": "evaluation",
        "relevance": 0.344
      },
      {
        "concept": "integration",
        "relevance": 0.341
      },
      {
        "concept": "efficiency",
        "relevance": 0.34
      },
      {
        "concept": "opportunities",
        "relevance": 0.331
      },
      {
        "concept": "categories",
        "relevance": 0.324
      },
      {
        "concept": "understanding",
        "relevance": 0.323
      },
      {
        "concept": "American",
        "relevance": 0.321
      },
      {
        "concept": "research",
        "relevance": 0.317
      },
      {
        "concept": "improvement",
        "relevance": 0.313
      },
      {
        "concept": "process",
        "relevance": 0.308
      },
      {
        "concept": "generation",
        "relevance": 0.304
      },
      {
        "concept": "phenomenon",
        "relevance": 0.299
      },
      {
        "concept": "potential approach",
        "relevance": 0.298
      },
      {
        "concept": "Amia",
        "relevance": 0.294
      },
      {
        "concept": "foundations",
        "relevance": 0.291
      },
      {
        "concept": "practitioners",
        "relevance": 0.291
      },
      {
        "concept": "parameters",
        "relevance": 0.283
      },
      {
        "concept": "approach",
        "relevance": 0.268
      },
      {
        "concept": "combination",
        "relevance": 0.262
      },
      {
        "concept": "chain",
        "relevance": 0.258
      },
      {
        "concept": "biomedicine",
        "relevance": 0.256
      },
      {
        "concept": "number",
        "relevance": 0.253
      },
      {
        "concept": "trends",
        "relevance": 0.244
      },
      {
        "concept": "biomedical applications",
        "relevance": 0.243
      },
      {
        "concept": "group",
        "relevance": 0.209
      },
      {
        "concept": "clinicians",
        "relevance": 0.186
      },
      {
        "concept": "review potential approaches",
        "relevance": 0.168
      },
      {
        "concept": "contamination",
        "relevance": 0.159
      },
      {
        "concept": "toxicity",
        "relevance": 0.143
      }
    ]
  },
  {
    "paperId": "pub.1183921142",
    "doi": "10.1038/s41598-024-75599-4",
    "title": "Parameter-efficient fine-tuning of large language models using semantic knowledge tuning",
    "year": 2024,
    "citationCount": 4,
    "fieldCitationRatio": 0.0,
    "abstract": "Large Language Models (LLMs) are gaining significant popularity in recent years for specialized tasks using prompts due to their low computational cost. Standard methods like prefix tuning utilize special, modifiable tokens that lack semantic meaning and require extensive training for best performance, often falling short. In this context, we propose a novel method called Semantic Knowledge Tuning (SK-Tuning) for prompt and prefix tuning that employs meaningful words instead of random tokens. This method involves using a fixed LLM to understand and process the semantic content of the prompt through zero-shot capabilities. Following this, it integrates the processed prompt with the input text to improve the model’s performance on particular tasks. Our experimental results show that SK-Tuning exhibits faster training times, fewer parameters, and superior performance on tasks such as text classification and understanding compared to other tuning methods. This approach offers a promising method for optimizing the efficiency and effectiveness of LLMs in processing language tasks.",
    "reference_ids": [
      "pub.1174225639",
      "pub.1148391209",
      "pub.1099240332",
      "pub.1148391132",
      "pub.1148390815",
      "pub.1171402976",
      "pub.1170632230",
      "pub.1163045216",
      "pub.1031120478",
      "pub.1139947391",
      "pub.1143948984",
      "pub.1163590882",
      "pub.1166186050",
      "pub.1117660148",
      "pub.1027395904",
      "pub.1183208145",
      "pub.1163043756",
      "pub.1099106053",
      "pub.1163041570",
      "pub.1096025559",
      "pub.1150867162",
      "pub.1117659358",
      "pub.1164438122",
      "pub.1182813830",
      "pub.1138308113",
      "pub.1117659050",
      "pub.1121398611",
      "pub.1164112886",
      "pub.1167961947",
      "pub.1163045451"
    ],
    "concepts_scores": [
      {
        "concept": "language model",
        "relevance": 0.647
      },
      {
        "concept": "zero-shot capability",
        "relevance": 0.612
      },
      {
        "concept": "input text",
        "relevance": 0.561
      },
      {
        "concept": "random tokens",
        "relevance": 0.555
      },
      {
        "concept": "training time",
        "relevance": 0.554
      },
      {
        "concept": "modifier tokens",
        "relevance": 0.55
      },
      {
        "concept": "semantic meaning",
        "relevance": 0.539
      },
      {
        "concept": "computational cost",
        "relevance": 0.533
      },
      {
        "concept": "fine-tuning",
        "relevance": 0.52
      },
      {
        "concept": "superior performance",
        "relevance": 0.518
      },
      {
        "concept": "semantic content",
        "relevance": 0.515
      },
      {
        "concept": "novel method",
        "relevance": 0.505
      },
      {
        "concept": "experimental results",
        "relevance": 0.499
      },
      {
        "concept": "specialized tasks",
        "relevance": 0.496
      },
      {
        "concept": "language tasks",
        "relevance": 0.494
      },
      {
        "concept": "task",
        "relevance": 0.492
      },
      {
        "concept": "tokens",
        "relevance": 0.478
      },
      {
        "concept": "model performance",
        "relevance": 0.459
      },
      {
        "concept": "language",
        "relevance": 0.447
      },
      {
        "concept": "performance",
        "relevance": 0.444
      },
      {
        "concept": "tuning method",
        "relevance": 0.439
      },
      {
        "concept": "extensive training",
        "relevance": 0.433
      },
      {
        "concept": "semantics",
        "relevance": 0.43
      },
      {
        "concept": "tuning",
        "relevance": 0.428
      },
      {
        "concept": "training",
        "relevance": 0.419
      },
      {
        "concept": "prefix",
        "relevance": 0.41
      },
      {
        "concept": "method",
        "relevance": 0.4
      },
      {
        "concept": "prompts",
        "relevance": 0.396
      },
      {
        "concept": "LLM",
        "relevance": 0.394
      },
      {
        "concept": "classification",
        "relevance": 0.394
      },
      {
        "concept": "text",
        "relevance": 0.382
      },
      {
        "concept": "words",
        "relevance": 0.378
      },
      {
        "concept": "input",
        "relevance": 0.37
      },
      {
        "concept": "model",
        "relevance": 0.369
      },
      {
        "concept": "capability",
        "relevance": 0.368
      },
      {
        "concept": "mean",
        "relevance": 0.337
      },
      {
        "concept": "cost",
        "relevance": 0.332
      },
      {
        "concept": "context",
        "relevance": 0.328
      },
      {
        "concept": "efficiency",
        "relevance": 0.318
      },
      {
        "concept": "standard methods",
        "relevance": 0.28
      },
      {
        "concept": "results",
        "relevance": 0.279
      },
      {
        "concept": "time",
        "relevance": 0.277
      },
      {
        "concept": "content",
        "relevance": 0.266
      },
      {
        "concept": "parameters",
        "relevance": 0.265
      },
      {
        "concept": "effect",
        "relevance": 0.242
      },
      {
        "concept": "years",
        "relevance": 0.208
      }
    ]
  },
  {
    "paperId": "pub.1170211509",
    "doi": "10.1088/1361-6560/ad387d",
    "title": "Advancing medical imaging with language models: featuring a spotlight on ChatGPT",
    "year": 2024,
    "citationCount": 31,
    "fieldCitationRatio": 0.0,
    "abstract": "This review paper aims to serve as a comprehensive guide and instructional resource for researchers seeking to effectively implement language models in medical imaging research. First, we presented the fundamental principles and evolution of language models, dedicating particular attention to large language models. We then reviewed the current literature on how language models are being used to improve medical imaging, emphasizing a range of applications such as image captioning, report generation, report classification, findings extraction, visual question response systems, interpretable diagnosis and so on. Notably, the capabilities of ChatGPT were spotlighted for researchers to explore its further applications. Furthermore, we covered the advantageous impacts of accurate and efficient language models in medical imaging analysis, such as the enhancement of clinical workflow efficiency, reduction of diagnostic errors, and assistance of clinicians in providing timely and accurate diagnoses. Overall, our goal is to have better integration of language models with medical imaging, thereby inspiring new ideas and innovations. It is our aspiration that this review can serve as a useful resource for researchers in this field, stimulating continued investigative and innovative pursuits of the application of language models in medical imaging.",
    "reference_ids": [
      "pub.1110399669",
      "pub.1129757334",
      "pub.1134139819",
      "pub.1031388101",
      "pub.1165125771",
      "pub.1122290393",
      "pub.1165876932",
      "pub.1114995901",
      "pub.1166189430",
      "pub.1163453847",
      "pub.1139947810",
      "pub.1150187654",
      "pub.1164939438",
      "pub.1166130148",
      "pub.1165647708",
      "pub.1160000503",
      "pub.1148390520",
      "pub.1157273035",
      "pub.1158635650",
      "pub.1166268573",
      "pub.1160506723",
      "pub.1133175894",
      "pub.1129479873",
      "pub.1163678978",
      "pub.1164113528",
      "pub.1156359853",
      "pub.1155196311",
      "pub.1166193492",
      "pub.1169868057",
      "pub.1112536714",
      "pub.1151130044",
      "pub.1157053699",
      "pub.1139828544",
      "pub.1159867915",
      "pub.1140106935",
      "pub.1164576157",
      "pub.1145901384",
      "pub.1146815576",
      "pub.1166405420",
      "pub.1160505148",
      "pub.1100767582",
      "pub.1149214644",
      "pub.1164705743",
      "pub.1175773771",
      "pub.1159737511",
      "pub.1157362983",
      "pub.1131343503",
      "pub.1158133161",
      "pub.1164452784",
      "pub.1138337559",
      "pub.1144682962",
      "pub.1151033044",
      "pub.1128582016",
      "pub.1012802956",
      "pub.1139861295",
      "pub.1164575541",
      "pub.1169767395",
      "pub.1135528973",
      "pub.1146436225",
      "pub.1038140272",
      "pub.1150163629",
      "pub.1162835902",
      "pub.1163636742",
      "pub.1095839635",
      "pub.1151033040",
      "pub.1158836329",
      "pub.1131464992",
      "pub.1162720855",
      "pub.1151033100",
      "pub.1163452669",
      "pub.1170726180",
      "pub.1160332642",
      "pub.1160172437",
      "pub.1155254261",
      "pub.1153631876",
      "pub.1061178979"
    ],
    "concepts_scores": [
      {
        "concept": "language model",
        "relevance": 0.564
      },
      {
        "concept": "medical images",
        "relevance": 0.542
      },
      {
        "concept": "application of language models",
        "relevance": 0.49
      },
      {
        "concept": "efficient language model",
        "relevance": 0.487
      },
      {
        "concept": "medical image analysis",
        "relevance": 0.486
      },
      {
        "concept": "medical imaging research",
        "relevance": 0.475
      },
      {
        "concept": "image captions",
        "relevance": 0.457
      },
      {
        "concept": "improve medical imaging",
        "relevance": 0.448
      },
      {
        "concept": "report classification",
        "relevance": 0.433
      },
      {
        "concept": "report generation",
        "relevance": 0.432
      },
      {
        "concept": "assistance of clinicians",
        "relevance": 0.426
      },
      {
        "concept": "clinical workflow efficiency",
        "relevance": 0.42
      },
      {
        "concept": "ChatGPT",
        "relevance": 0.411
      },
      {
        "concept": "interpretable diagnosis",
        "relevance": 0.403
      },
      {
        "concept": "reduction of diagnostic errors",
        "relevance": 0.4
      },
      {
        "concept": "question–response system",
        "relevance": 0.396
      },
      {
        "concept": "innovative pursuits",
        "relevance": 0.387
      },
      {
        "concept": "workflow efficiency",
        "relevance": 0.386
      },
      {
        "concept": "advanced medical imaging",
        "relevance": 0.369
      },
      {
        "concept": "findings extraction",
        "relevance": 0.369
      },
      {
        "concept": "images",
        "relevance": 0.364
      },
      {
        "concept": "image analysis",
        "relevance": 0.361
      },
      {
        "concept": "language",
        "relevance": 0.358
      },
      {
        "concept": "imaging research",
        "relevance": 0.354
      },
      {
        "concept": "captions",
        "relevance": 0.346
      },
      {
        "concept": "diagnostic errors",
        "relevance": 0.331
      },
      {
        "concept": "response system",
        "relevance": 0.329
      },
      {
        "concept": "applications",
        "relevance": 0.322
      },
      {
        "concept": "resources",
        "relevance": 0.32
      },
      {
        "concept": "instructional resources",
        "relevance": 0.319
      },
      {
        "concept": "classification",
        "relevance": 0.319
      },
      {
        "concept": "model",
        "relevance": 0.306
      },
      {
        "concept": "capability",
        "relevance": 0.297
      },
      {
        "concept": "review paper",
        "relevance": 0.296
      },
      {
        "concept": "research",
        "relevance": 0.296
      },
      {
        "concept": "error",
        "relevance": 0.294
      },
      {
        "concept": "comprehensive guide",
        "relevance": 0.274
      },
      {
        "concept": "system",
        "relevance": 0.268
      },
      {
        "concept": "diagnosis",
        "relevance": 0.268
      },
      {
        "concept": "clinicians",
        "relevance": 0.268
      },
      {
        "concept": "goal",
        "relevance": 0.263
      },
      {
        "concept": "review",
        "relevance": 0.261
      },
      {
        "concept": "integration",
        "relevance": 0.258
      },
      {
        "concept": "efficiency",
        "relevance": 0.257
      },
      {
        "concept": "assistance",
        "relevance": 0.257
      },
      {
        "concept": "ideas",
        "relevance": 0.251
      },
      {
        "concept": "accurate diagnosis",
        "relevance": 0.25
      },
      {
        "concept": "innovation",
        "relevance": 0.249
      },
      {
        "concept": "pursuit",
        "relevance": 0.245
      },
      {
        "concept": "guide",
        "relevance": 0.234
      },
      {
        "concept": "extraction",
        "relevance": 0.231
      },
      {
        "concept": "generation",
        "relevance": 0.23
      },
      {
        "concept": "enhancement",
        "relevance": 0.223
      },
      {
        "concept": "reports",
        "relevance": 0.214
      },
      {
        "concept": "literature",
        "relevance": 0.208
      },
      {
        "concept": "evolution",
        "relevance": 0.204
      },
      {
        "concept": "impact",
        "relevance": 0.203
      },
      {
        "concept": "aspiration",
        "relevance": 0.203
      },
      {
        "concept": "reduction",
        "relevance": 0.199
      },
      {
        "concept": "paper",
        "relevance": 0.187
      },
      {
        "concept": "analysis",
        "relevance": 0.186
      }
    ]
  },
  {
    "paperId": "pub.1188587713",
    "doi": "10.1016/j.xinn.2025.100948",
    "title": "Foundation models and intelligent decision-making: Progress, challenges, and perspectives",
    "year": 2025,
    "citationCount": 2,
    "fieldCitationRatio": 0.0,
    "abstract": "Intelligent decision-making (IDM) is a cornerstone of artificial intelligence (AI) designed to automate or augment decision processes. Modern IDM paradigms integrate advanced frameworks to enable intelligent agents to make effective and adaptive choices and decompose complex tasks into manageable steps, such as AI agents and high-level reinforcement learning. Recent advances in multimodal foundation-based approaches unify diverse input modalities-such as vision, language, and sensory data-into a cohesive decision-making process. Foundation models (FMs) have become pivotal in science and industry, transforming decision-making and research capabilities. Their large-scale, multimodal data-processing abilities foster adaptability and interdisciplinary breakthroughs across fields such as healthcare, life sciences, and education. This survey examines IDM's evolution, advanced paradigms with FMs and their transformative impact on decision-making across diverse scientific and industrial domains, highlighting the challenges and opportunities in building efficient, adaptive, and ethical decision systems.",
    "reference_ids": [
      "pub.1045294089",
      "pub.1158239540",
      "pub.1153010528",
      "pub.1175491354",
      "pub.1170430537",
      "pub.1165126258",
      "pub.1155915898",
      "pub.1181549151",
      "pub.1168796577",
      "pub.1181354605",
      "pub.1106125921",
      "pub.1166873105",
      "pub.1167961056",
      "pub.1173300783",
      "pub.1186974053",
      "pub.1134324518",
      "pub.1146562592",
      "pub.1107377144",
      "pub.1052711422",
      "pub.1176209402",
      "pub.1184153402",
      "pub.1145531397",
      "pub.1038140272",
      "pub.1129078103",
      "pub.1130209625",
      "pub.1183555107",
      "pub.1052170058",
      "pub.1129905568",
      "pub.1174940618",
      "pub.1132160929",
      "pub.1147814073",
      "pub.1140363597",
      "pub.1174453085",
      "pub.1171950459",
      "pub.1175839995",
      "pub.1168234816",
      "pub.1168706613",
      "pub.1117831857",
      "pub.1183992906",
      "pub.1105579492",
      "pub.1170766779",
      "pub.1109722339",
      "pub.1181270842",
      "pub.1181449630",
      "pub.1173555512",
      "pub.1046726295",
      "pub.1160172764",
      "pub.1158455565",
      "pub.1113787091",
      "pub.1139752527",
      "pub.1123642846",
      "pub.1144456084",
      "pub.1162884271",
      "pub.1149214651",
      "pub.1184202369",
      "pub.1163020468",
      "pub.1187540812",
      "pub.1163454216",
      "pub.1039427823",
      "pub.1172961873",
      "pub.1165837679",
      "pub.1140757977",
      "pub.1134390852",
      "pub.1164112521",
      "pub.1168589269",
      "pub.1168297520",
      "pub.1118944138",
      "pub.1119360854",
      "pub.1175053729",
      "pub.1139351332",
      "pub.1157581229",
      "pub.1085204298",
      "pub.1143948984",
      "pub.1186383719",
      "pub.1127553900",
      "pub.1169771957",
      "pub.1153960790",
      "pub.1183877297",
      "pub.1181362571",
      "pub.1171563469",
      "pub.1174225295",
      "pub.1175997856",
      "pub.1164347677",
      "pub.1182811613",
      "pub.1136908616",
      "pub.1129832558",
      "pub.1022009683",
      "pub.1038436955",
      "pub.1148391555",
      "pub.1013456524",
      "pub.1142739075",
      "pub.1171641295",
      "pub.1170136079",
      "pub.1025596604",
      "pub.1183885263",
      "pub.1128747176",
      "pub.1151380807",
      "pub.1053100403",
      "pub.1100659839",
      "pub.1167361299",
      "pub.1060006530",
      "pub.1151461341",
      "pub.1174019494",
      "pub.1176235742",
      "pub.1165265572",
      "pub.1110428240",
      "pub.1165529859",
      "pub.1154281696",
      "pub.1164903118",
      "pub.1185755644",
      "pub.1125709668",
      "pub.1126152118",
      "pub.1170747606",
      "pub.1175657158",
      "pub.1142245816",
      "pub.1129757334",
      "pub.1168042514",
      "pub.1021899069",
      "pub.1183857227",
      "pub.1104321292",
      "pub.1160112082",
      "pub.1157693686",
      "pub.1129757159",
      "pub.1159738465",
      "pub.1139515134",
      "pub.1118998891",
      "pub.1183279296",
      "pub.1155101431",
      "pub.1101382661",
      "pub.1151380648",
      "pub.1146883946",
      "pub.1162912604",
      "pub.1176225602",
      "pub.1050223513",
      "pub.1170516634",
      "pub.1168120349",
      "pub.1030517994",
      "pub.1176313283",
      "pub.1144481194",
      "pub.1171990077",
      "pub.1045385618",
      "pub.1144816193",
      "pub.1181409419",
      "pub.1061406472",
      "pub.1053183408",
      "pub.1164828095",
      "pub.1186384222",
      "pub.1151817599",
      "pub.1182277194",
      "pub.1146257012",
      "pub.1151927953",
      "pub.1128665679",
      "pub.1174625542",
      "pub.1169182094",
      "pub.1175055338",
      "pub.1152674724",
      "pub.1188652202",
      "pub.1186384343",
      "pub.1160816344",
      "pub.1148379430",
      "pub.1112918929",
      "pub.1163452986",
      "pub.1188610201",
      "pub.1147384892",
      "pub.1147385495",
      "pub.1118769417",
      "pub.1170811451",
      "pub.1038970481",
      "pub.1122205721",
      "pub.1135720228",
      "pub.1144323154",
      "pub.1129415908",
      "pub.1119960248",
      "pub.1160011750",
      "pub.1175052830",
      "pub.1127990889",
      "pub.1168673766",
      "pub.1135419899",
      "pub.1129885869",
      "pub.1174211627",
      "pub.1147113881",
      "pub.1175491380",
      "pub.1118771071",
      "pub.1141057329",
      "pub.1154516302",
      "pub.1175838890",
      "pub.1169658270",
      "pub.1143627783",
      "pub.1168286792",
      "pub.1175977683",
      "pub.1073275007",
      "pub.1131971348",
      "pub.1160000503",
      "pub.1099674591",
      "pub.1174225389",
      "pub.1175614279",
      "pub.1121892749",
      "pub.1174471612",
      "pub.1149415887",
      "pub.1037255795",
      "pub.1117164368",
      "pub.1110192280",
      "pub.1174583294",
      "pub.1144113229",
      "pub.1157955066",
      "pub.1172849494",
      "pub.1155539854",
      "pub.1170333824",
      "pub.1158690893",
      "pub.1105591840",
      "pub.1164577563",
      "pub.1152357671",
      "pub.1166429957",
      "pub.1006867054",
      "pub.1155051130",
      "pub.1165376019",
      "pub.1166673297",
      "pub.1153199090",
      "pub.1093359587",
      "pub.1063347217",
      "pub.1183111556",
      "pub.1125320737",
      "pub.1169623215",
      "pub.1176040909",
      "pub.1121024877",
      "pub.1153500306",
      "pub.1163045546",
      "pub.1182672004",
      "pub.1138646437",
      "pub.1166982073",
      "pub.1164403320",
      "pub.1181544881",
      "pub.1047038492",
      "pub.1061744945",
      "pub.1153604590",
      "pub.1127538834",
      "pub.1037868559",
      "pub.1169984921",
      "pub.1139690962",
      "pub.1127498144",
      "pub.1184456147",
      "pub.1181547455",
      "pub.1158566633",
      "pub.1159837515",
      "pub.1151381158",
      "pub.1174625064",
      "pub.1143936192",
      "pub.1175053596",
      "pub.1118643186",
      "pub.1164675687",
      "pub.1175373448",
      "pub.1173036812",
      "pub.1181129207",
      "pub.1171904680",
      "pub.1156266261",
      "pub.1181627963",
      "pub.1151421401",
      "pub.1108732895",
      "pub.1174302117",
      "pub.1174082551",
      "pub.1183706031",
      "pub.1181393874",
      "pub.1105446658",
      "pub.1143941454",
      "pub.1069641248",
      "pub.1119620502",
      "pub.1118777989",
      "pub.1032039307",
      "pub.1092459617",
      "pub.1170136150",
      "pub.1107079800",
      "pub.1121024948",
      "pub.1166623280",
      "pub.1155196311",
      "pub.1156284911",
      "pub.1133875707",
      "pub.1137047731",
      "pub.1166062577",
      "pub.1147856961",
      "pub.1151491867",
      "pub.1185043099",
      "pub.1074125415",
      "pub.1093129770",
      "pub.1030416171",
      "pub.1164381944",
      "pub.1155882787",
      "pub.1160635088",
      "pub.1061662879",
      "pub.1142230135",
      "pub.1058596909",
      "pub.1184205709",
      "pub.1172981932",
      "pub.1125969140",
      "pub.1152370887",
      "pub.1182671822",
      "pub.1182689183",
      "pub.1164180747",
      "pub.1155808762",
      "pub.1151444220",
      "pub.1112358766",
      "pub.1157451525",
      "pub.1151380794",
      "pub.1173955440",
      "pub.1184202091",
      "pub.1170558130",
      "pub.1145901979",
      "pub.1010905201",
      "pub.1099110523",
      "pub.1172767781",
      "pub.1095757637",
      "pub.1140466886",
      "pub.1174263983",
      "pub.1175385026",
      "pub.1146149224",
      "pub.1122913724",
      "pub.1184047564",
      "pub.1164676962",
      "pub.1170776656",
      "pub.1173158602",
      "pub.1149215321",
      "pub.1144520708",
      "pub.1129913612",
      "pub.1160210849",
      "pub.1128857117",
      "pub.1148909552",
      "pub.1153982932",
      "pub.1169895796",
      "pub.1151381125",
      "pub.1169105905",
      "pub.1170854972",
      "pub.1183623629",
      "pub.1163045360",
      "pub.1184458463",
      "pub.1037432371",
      "pub.1163452592",
      "pub.1169867324",
      "pub.1183674482",
      "pub.1123028413",
      "pub.1184340117",
      "pub.1096025161",
      "pub.1147741726",
      "pub.1160759046",
      "pub.1165903178",
      "pub.1164751543",
      "pub.1153603506",
      "pub.1181669204",
      "pub.1061298064",
      "pub.1155845485",
      "pub.1017082610",
      "pub.1138298309",
      "pub.1175378130",
      "pub.1150209056",
      "pub.1164724045",
      "pub.1175125081",
      "pub.1143668042",
      "pub.1146718347",
      "pub.1173291184",
      "pub.1135880863",
      "pub.1005251492",
      "pub.1162787956",
      "pub.1169210248",
      "pub.1183272457",
      "pub.1160172707",
      "pub.1160626291",
      "pub.1165126318",
      "pub.1151748680",
      "pub.1168640452",
      "pub.1186915735",
      "pub.1167960721",
      "pub.1169205610",
      "pub.1166166707",
      "pub.1047090011",
      "pub.1137649959",
      "pub.1164406002",
      "pub.1163045403",
      "pub.1140015988",
      "pub.1155595564",
      "pub.1140077900",
      "pub.1173419920",
      "pub.1163044316",
      "pub.1182792210",
      "pub.1158819277",
      "pub.1172185681",
      "pub.1183404489",
      "pub.1170135934",
      "pub.1150988109",
      "pub.1164984854",
      "pub.1176046417",
      "pub.1152843639",
      "pub.1044270720",
      "pub.1011777538",
      "pub.1169237566",
      "pub.1169460668",
      "pub.1188868098",
      "pub.1132796582",
      "pub.1156115470",
      "pub.1157184122",
      "pub.1158239294",
      "pub.1168913159",
      "pub.1175816008",
      "pub.1148390672",
      "pub.1148728946",
      "pub.1168232639",
      "pub.1181548059",
      "pub.1183462993",
      "pub.1181844363",
      "pub.1184212775",
      "pub.1124833026",
      "pub.1168131198",
      "pub.1127381301",
      "pub.1106814751",
      "pub.1187551182",
      "pub.1186384302",
      "pub.1186041741",
      "pub.1157672384",
      "pub.1181447777",
      "pub.1061406477",
      "pub.1174230961",
      "pub.1158455659",
      "pub.1163972832",
      "pub.1172443466",
      "pub.1181761201",
      "pub.1091500476",
      "pub.1170367723",
      "pub.1165903196",
      "pub.1141619715",
      "pub.1157329986",
      "pub.1183050023",
      "pub.1164700936",
      "pub.1167962316",
      "pub.1155759307",
      "pub.1166479013",
      "pub.1171949910",
      "pub.1157391414",
      "pub.1150294918",
      "pub.1163678297",
      "pub.1127353445",
      "pub.1181226590",
      "pub.1181544558",
      "pub.1157939610",
      "pub.1130435351",
      "pub.1182811808",
      "pub.1181199985",
      "pub.1175068404",
      "pub.1167918611",
      "pub.1135848443",
      "pub.1158657697",
      "pub.1149242753",
      "pub.1182285923",
      "pub.1124868484",
      "pub.1183475571",
      "pub.1164475509",
      "pub.1154304223",
      "pub.1170987053",
      "pub.1167325724",
      "pub.1172045263",
      "pub.1105447467",
      "pub.1160759555",
      "pub.1175050923",
      "pub.1126868538",
      "pub.1111749023",
      "pub.1165105979",
      "pub.1136502807",
      "pub.1069666680",
      "pub.1159923622",
      "pub.1165285334",
      "pub.1136696364",
      "pub.1022683539",
      "pub.1175123440",
      "pub.1125954350",
      "pub.1145871773",
      "pub.1171403727",
      "pub.1160816154",
      "pub.1165376043",
      "pub.1061806130",
      "pub.1169358480",
      "pub.1166873535",
      "pub.1070708200",
      "pub.1158510648",
      "pub.1175026787",
      "pub.1175520189"
    ],
    "concepts_scores": [
      {
        "concept": "intelligent decision-making",
        "relevance": 0.751
      },
      {
        "concept": "artificial intelligence",
        "relevance": 0.65
      },
      {
        "concept": "reinforcement learning",
        "relevance": 0.582
      },
      {
        "concept": "intelligent agents",
        "relevance": 0.581
      },
      {
        "concept": "AI agents",
        "relevance": 0.58
      },
      {
        "concept": "decision system",
        "relevance": 0.563
      },
      {
        "concept": "industrial domains",
        "relevance": 0.558
      },
      {
        "concept": "advanced framework",
        "relevance": 0.55
      },
      {
        "concept": "advanced paradigm",
        "relevance": 0.548
      },
      {
        "concept": "complex task",
        "relevance": 0.544
      },
      {
        "concept": "decision process",
        "relevance": 0.542
      },
      {
        "concept": "transforming decision-making",
        "relevance": 0.528
      },
      {
        "concept": "decision-making",
        "relevance": 0.517
      },
      {
        "concept": "intelligence",
        "relevance": 0.491
      },
      {
        "concept": "foundation model",
        "relevance": 0.485
      },
      {
        "concept": "decision-making process",
        "relevance": 0.455
      },
      {
        "concept": "adaptive choice",
        "relevance": 0.449
      },
      {
        "concept": "large-scale",
        "relevance": 0.448
      },
      {
        "concept": "research capabilities",
        "relevance": 0.438
      },
      {
        "concept": "paradigm",
        "relevance": 0.434
      },
      {
        "concept": "task",
        "relevance": 0.412
      },
      {
        "concept": "learning",
        "relevance": 0.406
      },
      {
        "concept": "vision",
        "relevance": 0.389
      },
      {
        "concept": "life sciences",
        "relevance": 0.386
      },
      {
        "concept": "transformative impact",
        "relevance": 0.385
      },
      {
        "concept": "capability",
        "relevance": 0.381
      },
      {
        "concept": "framework",
        "relevance": 0.38
      },
      {
        "concept": "language",
        "relevance": 0.378
      },
      {
        "concept": "fostering adaptation",
        "relevance": 0.358
      },
      {
        "concept": "domain",
        "relevance": 0.358
      },
      {
        "concept": "science",
        "relevance": 0.346
      },
      {
        "concept": "process",
        "relevance": 0.345
      },
      {
        "concept": "system",
        "relevance": 0.344
      },
      {
        "concept": "adaptation",
        "relevance": 0.334
      },
      {
        "concept": "healthcare",
        "relevance": 0.326
      },
      {
        "concept": "challenges",
        "relevance": 0.324
      },
      {
        "concept": "steps",
        "relevance": 0.316
      },
      {
        "concept": "model",
        "relevance": 0.314
      },
      {
        "concept": "research",
        "relevance": 0.307
      },
      {
        "concept": "industry",
        "relevance": 0.298
      },
      {
        "concept": "opportunities",
        "relevance": 0.277
      },
      {
        "concept": "foundations",
        "relevance": 0.274
      },
      {
        "concept": "field",
        "relevance": 0.272
      },
      {
        "concept": "agents",
        "relevance": 0.262
      },
      {
        "concept": "breakthrough",
        "relevance": 0.259
      },
      {
        "concept": "choice",
        "relevance": 0.257
      },
      {
        "concept": "evolution",
        "relevance": 0.246
      },
      {
        "concept": "impact",
        "relevance": 0.23
      },
      {
        "concept": "survey",
        "relevance": 0.226
      },
      {
        "concept": "education",
        "relevance": 0.218
      },
      {
        "concept": "life",
        "relevance": 0.197
      },
      {
        "concept": "approach",
        "relevance": 0.152
      }
    ]
  },
  {
    "paperId": "pub.1174963238",
    "doi": "10.1093/bib/bbae354",
    "title": "Harnessing large language models’ zero-shot and few-shot learning capabilities for regulatory research",
    "year": 2024,
    "citationCount": 6,
    "fieldCitationRatio": 0.0,
    "abstract": "Large language models (LLMs) are sophisticated AI-driven models trained on vast sources of natural language data. They are adept at generating responses that closely mimic human conversational patterns. One of the most notable examples is OpenAI's ChatGPT, which has been extensively used across diverse sectors. Despite their flexibility, a significant challenge arises as most users must transmit their data to the servers of companies operating these models. Utilizing ChatGPT or similar models online may inadvertently expose sensitive information to the risk of data breaches. Therefore, implementing LLMs that are open source and smaller in scale within a secure local network becomes a crucial step for organizations where ensuring data privacy and protection has the highest priority, such as regulatory agencies. As a feasibility evaluation, we implemented a series of open-source LLMs within a regulatory agency's local network and assessed their performance on specific tasks involving extracting relevant clinical pharmacology information from regulatory drug labels. Our research shows that some models work well in the context of few- or zero-shot learning, achieving performance comparable, or even better than, neural network models that needed thousands of training samples. One of the models was selected to address a real-world issue of finding intrinsic factors that affect drugs' clinical exposure without any training or fine-tuning. In a dataset of over 700 000 sentences, the model showed a 78.5% accuracy rate. Our work pointed to the possibility of implementing open-source LLMs within a secure local network and using these models to perform various natural language processing tasks when large numbers of training examples are unavailable.",
    "reference_ids": [
      "pub.1121016091",
      "pub.1105931110",
      "pub.1163041872",
      "pub.1168164361",
      "pub.1158268258",
      "pub.1131095623",
      "pub.1154223979",
      "pub.1092117371",
      "pub.1110890640",
      "pub.1156069812",
      "pub.1163044255",
      "pub.1138962421",
      "pub.1128255850",
      "pub.1085308297",
      "pub.1163042336",
      "pub.1125814840",
      "pub.1163043853",
      "pub.1152045540",
      "pub.1128641167",
      "pub.1143948984",
      "pub.1170036051",
      "pub.1133174687",
      "pub.1120882528",
      "pub.1106381564",
      "pub.1165448184",
      "pub.1007197624",
      "pub.1011392015"
    ],
    "concepts_scores": [
      {
        "concept": "language model",
        "relevance": 0.725
      },
      {
        "concept": "few-shot learning capability",
        "relevance": 0.705
      },
      {
        "concept": "risk of data breaches",
        "relevance": 0.702
      },
      {
        "concept": "local network",
        "relevance": 0.702
      },
      {
        "concept": "natural language processing tasks",
        "relevance": 0.702
      },
      {
        "concept": "zero-shot learning",
        "relevance": 0.685
      },
      {
        "concept": "language processing tasks",
        "relevance": 0.681
      },
      {
        "concept": "natural language data",
        "relevance": 0.658
      },
      {
        "concept": "neural network model",
        "relevance": 0.658
      },
      {
        "concept": "Zero-Shot",
        "relevance": 0.634
      },
      {
        "concept": "training examples",
        "relevance": 0.633
      },
      {
        "concept": "data privacy",
        "relevance": 0.631
      },
      {
        "concept": "AI-driven models",
        "relevance": 0.628
      },
      {
        "concept": "sensitive information",
        "relevance": 0.625
      },
      {
        "concept": "data breaches",
        "relevance": 0.625
      },
      {
        "concept": "training samples",
        "relevance": 0.622
      },
      {
        "concept": "learning capability",
        "relevance": 0.614
      },
      {
        "concept": "processing tasks",
        "relevance": 0.611
      },
      {
        "concept": "accuracy rate",
        "relevance": 0.595
      },
      {
        "concept": "network model",
        "relevance": 0.592
      },
      {
        "concept": "ChatGPT",
        "relevance": 0.571
      },
      {
        "concept": "network",
        "relevance": 0.558
      },
      {
        "concept": "language data",
        "relevance": 0.545
      },
      {
        "concept": "task",
        "relevance": 0.517
      },
      {
        "concept": "OpenAI",
        "relevance": 0.498
      },
      {
        "concept": "training",
        "relevance": 0.494
      },
      {
        "concept": "conversational patterns",
        "relevance": 0.49
      },
      {
        "concept": "privacy",
        "relevance": 0.488
      },
      {
        "concept": "server",
        "relevance": 0.487
      },
      {
        "concept": "users",
        "relevance": 0.478
      },
      {
        "concept": "information",
        "relevance": 0.477
      },
      {
        "concept": "language",
        "relevance": 0.474
      },
      {
        "concept": "performance",
        "relevance": 0.474
      },
      {
        "concept": "feasibility evaluation",
        "relevance": 0.47
      },
      {
        "concept": "dataset",
        "relevance": 0.465
      },
      {
        "concept": "LLM",
        "relevance": 0.45
      },
      {
        "concept": "learning",
        "relevance": 0.439
      },
      {
        "concept": "examples",
        "relevance": 0.438
      },
      {
        "concept": "model",
        "relevance": 0.425
      },
      {
        "concept": "accuracy",
        "relevance": 0.425
      },
      {
        "concept": "breach",
        "relevance": 0.423
      },
      {
        "concept": "capability",
        "relevance": 0.413
      },
      {
        "concept": "sentences",
        "relevance": 0.412
      },
      {
        "concept": "diverse sectors",
        "relevance": 0.41
      },
      {
        "concept": "regulatory research",
        "relevance": 0.395
      },
      {
        "concept": "data",
        "relevance": 0.395
      },
      {
        "concept": "flexibility",
        "relevance": 0.394
      },
      {
        "concept": "labeling",
        "relevance": 0.394
      },
      {
        "concept": "research",
        "relevance": 0.385
      },
      {
        "concept": "companies",
        "relevance": 0.37
      },
      {
        "concept": "issues",
        "relevance": 0.368
      },
      {
        "concept": "evaluation",
        "relevance": 0.361
      },
      {
        "concept": "feasibility",
        "relevance": 0.358
      },
      {
        "concept": "pharmacological information",
        "relevance": 0.346
      },
      {
        "concept": "source",
        "relevance": 0.338
      },
      {
        "concept": "context",
        "relevance": 0.338
      },
      {
        "concept": "drug labels",
        "relevance": 0.327
      },
      {
        "concept": "priority",
        "relevance": 0.326
      },
      {
        "concept": "clinical pharmacology information",
        "relevance": 0.325
      },
      {
        "concept": "regulatory agencies",
        "relevance": 0.303
      },
      {
        "concept": "patterns",
        "relevance": 0.28
      },
      {
        "concept": "protection",
        "relevance": 0.275
      },
      {
        "concept": "clinical exposure",
        "relevance": 0.271
      },
      {
        "concept": "organization",
        "relevance": 0.257
      },
      {
        "concept": "sector",
        "relevance": 0.256
      },
      {
        "concept": "agencies",
        "relevance": 0.255
      },
      {
        "concept": "drug",
        "relevance": 0.245
      },
      {
        "concept": "rate",
        "relevance": 0.238
      },
      {
        "concept": "FEW",
        "relevance": 0.23
      },
      {
        "concept": "intrinsic factors",
        "relevance": 0.229
      },
      {
        "concept": "exposure",
        "relevance": 0.227
      },
      {
        "concept": "response",
        "relevance": 0.223
      },
      {
        "concept": "samples",
        "relevance": 0.209
      },
      {
        "concept": "risk",
        "relevance": 0.202
      },
      {
        "concept": "factors",
        "relevance": 0.199
      }
    ]
  },
  {
    "paperId": "pub.1183445208",
    "doi": "10.1016/j.patter.2024.101098",
    "title": "Integration of large language models and federated learning",
    "year": 2024,
    "citationCount": 11,
    "fieldCitationRatio": 0.0,
    "abstract": "As the parameter size of large language models (LLMs) continues to expand, there is an urgent need to address the scarcity of high-quality data. In response, existing research has attempted to make a breakthrough by incorporating federated learning (FL) into LLMs. Conversely, considering the outstanding performance of LLMs in task generalization, researchers have also tried applying LLMs within FL to tackle challenges in relevant domains. The complementarity between LLMs and FL has already ignited widespread research interest. In this review, we aim to deeply explore the integration of LLMs and FL. We propose a research framework dividing the fusion of LLMs and FL into three parts: the combination of LLM sub-technologies with FL, the integration of FL sub-technologies with LLMs, and the overall merger of LLMs and FL. We first provide a comprehensive review of the current state of research in the domain of LLMs combined with FL, including their typical applications, integration advantages, challenges faced, and future directions for resolution. Subsequently, we discuss the practical applications of the combination of LLMs and FL in critical scenarios such as healthcare, finance, and education and provide new perspectives and insights into future research directions for LLMs and FL.",
    "reference_ids": [
      "pub.1156284911",
      "pub.1148728946",
      "pub.1141495141",
      "pub.1138899689",
      "pub.1151029220",
      "pub.1111749023",
      "pub.1149214030",
      "pub.1163041966",
      "pub.1163316962",
      "pub.1165227637",
      "pub.1170172874",
      "pub.1163045260",
      "pub.1164748294",
      "pub.1129756829",
      "pub.1163044322",
      "pub.1152602671",
      "pub.1163447919",
      "pub.1166873581",
      "pub.1163042747",
      "pub.1129812113",
      "pub.1129798348",
      "pub.1143749058",
      "pub.1163324251",
      "pub.1166483990",
      "pub.1152860639",
      "pub.1152818783",
      "pub.1164705743",
      "pub.1163026895",
      "pub.1169868623",
      "pub.1139947461",
      "pub.1130792870",
      "pub.1140363891",
      "pub.1158341595",
      "pub.1160194269",
      "pub.1079257201",
      "pub.1157546742",
      "pub.1146726542",
      "pub.1095757637",
      "pub.1083988539",
      "pub.1157124553",
      "pub.1163045634",
      "pub.1138840287",
      "pub.1157939659",
      "pub.1126708197",
      "pub.1155808762",
      "pub.1175056064",
      "pub.1170135955",
      "pub.1159713539",
      "pub.1156069812",
      "pub.1100154986",
      "pub.1157838462",
      "pub.1126708106",
      "pub.1145824517",
      "pub.1124465200",
      "pub.1156061261",
      "pub.1156251619",
      "pub.1159714053",
      "pub.1166873114",
      "pub.1142760247",
      "pub.1154828381",
      "pub.1157939382",
      "pub.1143336464",
      "pub.1158076546",
      "pub.1113523340",
      "pub.1113303694",
      "pub.1166582966",
      "pub.1163044859",
      "pub.1163676362",
      "pub.1175821967",
      "pub.1124561570",
      "pub.1135920673",
      "pub.1121159568",
      "pub.1163991366",
      "pub.1124244220",
      "pub.1133252928",
      "pub.1068000405",
      "pub.1138840354",
      "pub.1137337590",
      "pub.1095588117",
      "pub.1156079736",
      "pub.1151600477",
      "pub.1170135509",
      "pub.1160625986",
      "pub.1163453515",
      "pub.1168981859",
      "pub.1120654710",
      "pub.1157939610",
      "pub.1163045663",
      "pub.1123260833",
      "pub.1141190595",
      "pub.1152622128",
      "pub.1163043960",
      "pub.1156895083",
      "pub.1157850866",
      "pub.1148391290",
      "pub.1157728377",
      "pub.1094237891",
      "pub.1132298352",
      "pub.1160336928",
      "pub.1163045546",
      "pub.1122836218",
      "pub.1164952384",
      "pub.1130314084",
      "pub.1160635088",
      "pub.1020384618",
      "pub.1169867896",
      "pub.1128280227",
      "pub.1143042802",
      "pub.1158455201",
      "pub.1019052401",
      "pub.1121887722",
      "pub.1160799298",
      "pub.1166157937",
      "pub.1170612936",
      "pub.1139939023",
      "pub.1163905365",
      "pub.1159862053",
      "pub.1170136121",
      "pub.1138569680",
      "pub.1152716262",
      "pub.1085045796",
      "pub.1135710434",
      "pub.1132252232",
      "pub.1157282807",
      "pub.1084152728",
      "pub.1124301819",
      "pub.1167566703",
      "pub.1169306136",
      "pub.1141651242",
      "pub.1154826561",
      "pub.1126481185",
      "pub.1158116221",
      "pub.1163938169",
      "pub.1139515134",
      "pub.1149956952",
      "pub.1105538429",
      "pub.1158487181",
      "pub.1167962483",
      "pub.1167962098",
      "pub.1158410437",
      "pub.1156695998",
      "pub.1155381517",
      "pub.1164950658",
      "pub.1164953222",
      "pub.1175055376",
      "pub.1163098166",
      "pub.1167861333"
    ],
    "concepts_scores": [
      {
        "concept": "federated learning",
        "relevance": 0.697
      },
      {
        "concept": "language model",
        "relevance": 0.636
      },
      {
        "concept": "parameter size",
        "relevance": 0.546
      },
      {
        "concept": "sub-technologies",
        "relevance": 0.544
      },
      {
        "concept": "task generalization",
        "relevance": 0.542
      },
      {
        "concept": "widespread research interest",
        "relevance": 0.536
      },
      {
        "concept": "research directions",
        "relevance": 0.483
      },
      {
        "concept": "learning",
        "relevance": 0.446
      },
      {
        "concept": "high-quality data",
        "relevance": 0.442
      },
      {
        "concept": "research framework",
        "relevance": 0.439
      },
      {
        "concept": "research interest",
        "relevance": 0.426
      },
      {
        "concept": "integration advantages",
        "relevance": 0.419
      },
      {
        "concept": "language",
        "relevance": 0.416
      },
      {
        "concept": "relevant domains",
        "relevance": 0.4
      },
      {
        "concept": "LLM",
        "relevance": 0.398
      },
      {
        "concept": "domain",
        "relevance": 0.394
      },
      {
        "concept": "applications",
        "relevance": 0.392
      },
      {
        "concept": "task",
        "relevance": 0.391
      },
      {
        "concept": "integration",
        "relevance": 0.388
      },
      {
        "concept": "scenarios",
        "relevance": 0.374
      },
      {
        "concept": "research",
        "relevance": 0.363
      },
      {
        "concept": "framework",
        "relevance": 0.36
      },
      {
        "concept": "performance",
        "relevance": 0.359
      },
      {
        "concept": "generalization",
        "relevance": 0.35
      },
      {
        "concept": "model",
        "relevance": 0.346
      },
      {
        "concept": "fusion",
        "relevance": 0.334
      },
      {
        "concept": "comprehensive review",
        "relevance": 0.327
      },
      {
        "concept": "healthcare",
        "relevance": 0.309
      },
      {
        "concept": "direction",
        "relevance": 0.308
      },
      {
        "concept": "finance",
        "relevance": 0.305
      },
      {
        "concept": "merger",
        "relevance": 0.297
      },
      {
        "concept": "advantage",
        "relevance": 0.296
      },
      {
        "concept": "education",
        "relevance": 0.286
      },
      {
        "concept": "data",
        "relevance": 0.285
      },
      {
        "concept": "combination",
        "relevance": 0.279
      },
      {
        "concept": "resolution",
        "relevance": 0.277
      },
      {
        "concept": "perspective",
        "relevance": 0.268
      },
      {
        "concept": "scarcity",
        "relevance": 0.264
      },
      {
        "concept": "interest",
        "relevance": 0.262
      },
      {
        "concept": "parameters",
        "relevance": 0.26
      },
      {
        "concept": "complementarity",
        "relevance": 0.26
      },
      {
        "concept": "parts",
        "relevance": 0.259
      },
      {
        "concept": "scarcity of high-quality data",
        "relevance": 0.248
      },
      {
        "concept": "size",
        "relevance": 0.233
      },
      {
        "concept": "response",
        "relevance": 0.21
      },
      {
        "concept": "review",
        "relevance": 0.208
      }
    ]
  }
]