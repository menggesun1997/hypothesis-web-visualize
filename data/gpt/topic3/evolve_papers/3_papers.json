{
  "papers": [
    {
      "paperId": "pub.1172790398",
      "doi": "10.1162/coli_a_00524",
      "title": "Bias and Fairness in Large Language Models: A Survey",
      "year": 2024,
      "citationCount": 203,
      "fieldCitationRatio": NaN,
      "abstract": "Abstract Rapid advancements of large language models (LLMs) have enabled the processing, understanding, and generation of human-like text, with increasing integration into systems that touch our social sphere. Despite this success, these models can learn, perpetuate, and amplify harmful social biases. In this article, we present a comprehensive survey of bias evaluation and mitigation techniques for LLMs. We first consolidate, formalize, and expand notions of social bias and fairness in natural language processing, defining distinct facets of harm and introducing several desiderata to operationalize fairness for LLMs. We then unify the literature by proposing three intuitive taxonomies, two for bias evaluation, namely, metrics and datasets, and one for mitigation. Our first taxonomy of metrics for bias evaluation disambiguates the relationship between metrics and evaluation datasets, and organizes metrics by the different levels at which they operate in a model: embeddings, probabilities, and generated text. Our second taxonomy of datasets for bias evaluation categorizes datasets by their structure as counterfactual inputs or prompts, and identifies the targeted harms and social groups; we also release a consolidation of publicly available datasets for improved access. Our third taxonomy of techniques for bias mitigation classifies methods by their intervention during pre-processing, in-training, intra-processing, and post-processing, with granular subcategories that elucidate research trends. Finally, we identify open problems and challenges for future work. Synthesizing a wide range of recent research, we aim to provide a clear guide of the existing literature that empowers researchers and practitioners to better understand and prevent the propagation of bias in LLMs.",
      "reference_ids": [
        "pub.1163043737",
        "pub.1140080916",
        "pub.1148815224",
        "pub.1133175302",
        "pub.1163045121",
        "pub.1151958631",
        "pub.1163045176",
        "pub.1139947567",
        "pub.1139948267",
        "pub.1143949669",
        "pub.1089226715",
        "pub.1139947167",
        "pub.1133177374",
        "pub.1139948397",
        "pub.1117925618",
        "pub.1148392024",
        "pub.1129757334",
        "pub.1156259642",
        "pub.1163042752",
        "pub.1163043618",
        "pub.1118169431",
        "pub.1139947579",
        "pub.1166872789",
        "pub.1129025153",
        "pub.1133175322",
        "pub.1163043741",
        "pub.1121025485",
        "pub.1166872726",
        "pub.1133176915",
        "pub.1144118532",
        "pub.1149214162",
        "pub.1129757091",
        "pub.1112472554",
        "pub.1165317422",
        "pub.1140080841",
        "pub.1139947166",
        "pub.1010926018",
        "pub.1163043633",
        "pub.1138840354",
        "pub.1163991075",
        "pub.1174225473",
        "pub.1104321297",
        "pub.1084825219",
        "pub.1159720440",
        "pub.1139947391",
        "pub.1098653837",
        "pub.1139621749",
        "pub.1148391190",
        "pub.1129757382",
        "pub.1084152728",
        "pub.1025096580",
        "pub.1149741157",
        "pub.1166381427",
        "pub.1149741670",
        "pub.1149741163",
        "pub.1163991062",
        "pub.1128856573",
        "pub.1149741710",
        "pub.1038436955",
        "pub.1139948409",
        "pub.1049741652",
        "pub.1138840355",
        "pub.1135710434",
        "pub.1113351566",
        "pub.1139947364",
        "pub.1144245243",
        "pub.1150866134",
        "pub.1050059401",
        "pub.1118169430",
        "pub.1163044456",
        "pub.1100517007",
        "pub.1121024755",
        "pub.1168149665",
        "pub.1118169432",
        "pub.1133176809",
        "pub.1100731697",
        "pub.1142776348",
        "pub.1148391832",
        "pub.1140081924",
        "pub.1142678683",
        "pub.1145362413",
        "pub.1133174773",
        "pub.1139947366",
        "pub.1148390692",
        "pub.1163042358",
        "pub.1134455594",
        "pub.1163043541",
        "pub.1127963283",
        "pub.1138840471",
        "pub.1163043497",
        "pub.1166872918",
        "pub.1163042223",
        "pub.1111607515",
        "pub.1163044403",
        "pub.1148815234",
        "pub.1130391394",
        "pub.1163044470",
        "pub.1046053779",
        "pub.1129756820",
        "pub.1163045157",
        "pub.1163043612",
        "pub.1107482550",
        "pub.1163042211",
        "pub.1149741688",
        "pub.1149741166",
        "pub.1160174346",
        "pub.1142776598",
        "pub.1129670455",
        "pub.1111334730",
        "pub.1148391796",
        "pub.1149741162",
        "pub.1174226142",
        "pub.1086115539",
        "pub.1143073374",
        "pub.1133175312",
        "pub.1121024753",
        "pub.1138840468",
        "pub.1149741352",
        "pub.1103189946",
        "pub.1148815082",
        "pub.1139947461",
        "pub.1163044334",
        "pub.1163991186",
        "pub.1128235047",
        "pub.1051392379",
        "pub.1163042217",
        "pub.1148390565",
        "pub.1135707334",
        "pub.1133174312",
        "pub.1149741168",
        "pub.1122021003",
        "pub.1144245257",
        "pub.1155645585",
        "pub.1149741280",
        "pub.1138840352",
        "pub.1163991031",
        "pub.1166874216",
        "pub.1139947660",
        "pub.1160155964",
        "pub.1129756846",
        "pub.1136564546",
        "pub.1156350610",
        "pub.1148391739",
        "pub.1158361897",
        "pub.1138840519",
        "pub.1163042818",
        "pub.1121025284",
        "pub.1143949496",
        "pub.1149741169",
        "pub.1139948282",
        "pub.1129757094",
        "pub.1133177362",
        "pub.1157275035",
        "pub.1163043904",
        "pub.1163045060",
        "pub.1146504828",
        "pub.1138840503",
        "pub.1135331525",
        "pub.1143949180",
        "pub.1129757271",
        "pub.1151003027",
        "pub.1122290547",
        "pub.1140080890",
        "pub.1129757093",
        "pub.1149741167",
        "pub.1149741175",
        "pub.1139669196",
        "pub.1135712544",
        "pub.1165991660",
        "pub.1163044460",
        "pub.1118169824",
        "pub.1148391101",
        "pub.1148390704",
        "pub.1104321692",
        "pub.1104321298",
        "pub.1139947418",
        "pub.1144245021",
        "pub.1133361999",
        "pub.1149741156",
        "pub.1149741172",
        "pub.1105229811",
        "pub.1150208896",
        "pub.1160813211",
        "pub.1156708291",
        "pub.1129757072",
        "pub.1163045164",
        "pub.1111349442",
        "pub.1142776494",
        "pub.1163041790",
        "pub.1143336252",
        "pub.1160172908",
        "pub.1143948984",
        "pub.1148390914",
        "pub.1118169433",
        "pub.1132139207",
        "pub.1111349489",
        "pub.1157837797",
        "pub.1143949171",
        "pub.1163045469",
        "pub.1159715598",
        "pub.1163043923",
        "pub.1163044392",
        "pub.1163044244",
        "pub.1122290356",
        "pub.1138840686",
        "pub.1148391587",
        "pub.1163044292",
        "pub.1144245177",
        "pub.1163042188"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.622
        },
        {
          "concept": "taxonomy of metrics",
          "relevance": 0.584
        },
        {
          "concept": "natural language processing",
          "relevance": 0.578
        },
        {
          "concept": "human-like text",
          "relevance": 0.573
        },
        {
          "concept": "taxonomy of techniques",
          "relevance": 0.556
        },
        {
          "concept": "counterfactual inputs",
          "relevance": 0.532
        },
        {
          "concept": "evaluation dataset",
          "relevance": 0.53
        },
        {
          "concept": "language processing",
          "relevance": 0.526
        },
        {
          "concept": "intra-process",
          "relevance": 0.526
        },
        {
          "concept": "pre-processing",
          "relevance": 0.517
        },
        {
          "concept": "bias mitigation",
          "relevance": 0.501
        },
        {
          "concept": "dataset",
          "relevance": 0.497
        },
        {
          "concept": "mitigation techniques",
          "relevance": 0.483
        },
        {
          "concept": "research trends",
          "relevance": 0.482
        },
        {
          "concept": "metrics",
          "relevance": 0.479
        },
        {
          "concept": "post-processing",
          "relevance": 0.478
        },
        {
          "concept": "comprehensive survey",
          "relevance": 0.476
        },
        {
          "concept": "open problems",
          "relevance": 0.472
        },
        {
          "concept": "fairness",
          "relevance": 0.462
        },
        {
          "concept": "Rapid advancement",
          "relevance": 0.44
        },
        {
          "concept": "social biases",
          "relevance": 0.431
        },
        {
          "concept": "Abstract Rapid advances",
          "relevance": 0.43
        },
        {
          "concept": "taxonomy",
          "relevance": 0.424
        },
        {
          "concept": "language",
          "relevance": 0.406
        },
        {
          "concept": "embedding",
          "relevance": 0.402
        },
        {
          "concept": "social sphere",
          "relevance": 0.387
        },
        {
          "concept": "social groups",
          "relevance": 0.387
        },
        {
          "concept": "LLM",
          "relevance": 0.386
        },
        {
          "concept": "evaluation",
          "relevance": 0.385
        },
        {
          "concept": "increasing integration",
          "relevance": 0.366
        },
        {
          "concept": "technique",
          "relevance": 0.363
        },
        {
          "concept": "model",
          "relevance": 0.361
        },
        {
          "concept": "improve access",
          "relevance": 0.36
        },
        {
          "concept": "input",
          "relevance": 0.356
        },
        {
          "concept": "text",
          "relevance": 0.352
        },
        {
          "concept": "access",
          "relevance": 0.348
        },
        {
          "concept": "research",
          "relevance": 0.346
        },
        {
          "concept": "probability",
          "relevance": 0.334
        },
        {
          "concept": "desiderata",
          "relevance": 0.331
        },
        {
          "concept": "bias evaluation",
          "relevance": 0.33
        },
        {
          "concept": "harm",
          "relevance": 0.322
        },
        {
          "concept": "process",
          "relevance": 0.32
        },
        {
          "concept": "system",
          "relevance": 0.319
        },
        {
          "concept": "mitigation",
          "relevance": 0.314
        },
        {
          "concept": "method",
          "relevance": 0.309
        },
        {
          "concept": "integration",
          "relevance": 0.307
        },
        {
          "concept": "notions",
          "relevance": 0.293
        },
        {
          "concept": "advances",
          "relevance": 0.287
        },
        {
          "concept": "propagation",
          "relevance": 0.283
        },
        {
          "concept": "literature",
          "relevance": 0.282
        },
        {
          "concept": "propagation of bias",
          "relevance": 0.281
        },
        {
          "concept": "bias",
          "relevance": 0.275
        },
        {
          "concept": "generation",
          "relevance": 0.274
        },
        {
          "concept": "sphere",
          "relevance": 0.269
        },
        {
          "concept": "success",
          "relevance": 0.269
        },
        {
          "concept": "prompts",
          "relevance": 0.265
        },
        {
          "concept": "practitioners",
          "relevance": 0.261
        },
        {
          "concept": "survey",
          "relevance": 0.26
        },
        {
          "concept": "Abstract",
          "relevance": 0.254
        },
        {
          "concept": "understanding",
          "relevance": 0.251
        },
        {
          "concept": "consolidation",
          "relevance": 0.247
        },
        {
          "concept": "subcategories",
          "relevance": 0.245
        },
        {
          "concept": "intervention",
          "relevance": 0.239
        },
        {
          "concept": "trends",
          "relevance": 0.235
        },
        {
          "concept": "relationship",
          "relevance": 0.234
        },
        {
          "concept": "in-training",
          "relevance": 0.23
        },
        {
          "concept": "structure",
          "relevance": 0.224
        },
        {
          "concept": "problem",
          "relevance": 0.21
        },
        {
          "concept": "group",
          "relevance": 0.198
        },
        {
          "concept": "levels",
          "relevance": 0.179
        }
      ]
    },
    {
      "paperId": "pub.1165317422",
      "doi": "10.1145/3617694.3623259",
      "title": "Toward Operationalizing Pipeline-aware ML Fairness: A Research Agenda for Developing Practical Guidelines and Tools",
      "year": 2023,
      "citationCount": 14,
      "fieldCitationRatio": 9.24,
      "abstract": "While algorithmic fairness is a thriving area of research, in practice, mitigating issues of bias often gets reduced to enforcing an arbitrarily chosen fairness metric, either by enforcing fairness constraints during the optimization step, post-processing model outputs, or by manipulating the training data. Recent work has called on the ML community to take a more holistic approach to tackle fairness issues by systematically investigating the many design choices made through the ML pipeline, and identifying interventions that target the issue’s root cause, as opposed to its symptoms. While we share the conviction that this pipeline-based approach is the most appropriate for combating algorithmic unfairness on the ground, we believe there are currently very few methods of operationalizing this approach in practice. Drawing on our experience as educators and practitioners, we first demonstrate that without clear guidelines and toolkits, even individuals with specialized ML knowledge find it challenging to hypothesize how various design choices influence model behavior. We then consult the fair-ML literature to understand the progress to date toward operationalizing the pipeline-aware approach: we systematically collect and organize the prior work that attempts to detect, measure, and mitigate various sources of unfairness through the ML pipeline. We utilize this extensive categorization of previous contributions to sketch a research agenda for the community. We hope this work serves as the stepping stone toward a more comprehensive set of resources for ML researchers, practitioners, and students interested in exploring, designing, and testing pipeline-oriented approaches to algorithmic fairness.",
      "reference_ids": [
        "pub.1113814587",
        "pub.1122420370",
        "pub.1135716228",
        "pub.1140412617",
        "pub.1142000789",
        "pub.1124267285",
        "pub.1050817771",
        "pub.1142760082",
        "pub.1148815181",
        "pub.1145241879",
        "pub.1159717157",
        "pub.1140080888",
        "pub.1140080915",
        "pub.1111334722",
        "pub.1117925616",
        "pub.1111334730",
        "pub.1135718200",
        "pub.1135715156",
        "pub.1143073374",
        "pub.1004545697",
        "pub.1149798707",
        "pub.1122068379",
        "pub.1124267283",
        "pub.1032230412",
        "pub.1124608045",
        "pub.1140080821",
        "pub.1154196504",
        "pub.1133362571",
        "pub.1135715626",
        "pub.1147478084",
        "pub.1149798637",
        "pub.1111334697",
        "pub.1135707334",
        "pub.1127963241",
        "pub.1127963431",
        "pub.1149798627",
        "pub.1158548476",
        "pub.1142532386",
        "pub.1135714397",
        "pub.1148955940",
        "pub.1025096580",
        "pub.1148815077",
        "pub.1140503168",
        "pub.1148815195",
        "pub.1135707953",
        "pub.1117913860",
        "pub.1152010293",
        "pub.1140080877",
        "pub.1131824674",
        "pub.1148815182",
        "pub.1140080906",
        "pub.1111334701",
        "pub.1129913389",
        "pub.1140838533",
        "pub.1137840049",
        "pub.1125798987",
        "pub.1148815141",
        "pub.1140080921"
      ],
      "concepts_scores": [
        {
          "concept": "ML pipeline",
          "relevance": 0.683
        },
        {
          "concept": "algorithmic fairness",
          "relevance": 0.668
        },
        {
          "concept": "pipeline-based approach",
          "relevance": 0.641
        },
        {
          "concept": "sources of unfairness",
          "relevance": 0.602
        },
        {
          "concept": "fairness constraints",
          "relevance": 0.595
        },
        {
          "concept": "fairness metrics",
          "relevance": 0.591
        },
        {
          "concept": "training data",
          "relevance": 0.59
        },
        {
          "concept": "ML community",
          "relevance": 0.587
        },
        {
          "concept": "ML research",
          "relevance": 0.583
        },
        {
          "concept": "fairness issues",
          "relevance": 0.582
        },
        {
          "concept": "ML knowledge",
          "relevance": 0.582
        },
        {
          "concept": "algorithmic unfairness",
          "relevance": 0.573
        },
        {
          "concept": "design choices",
          "relevance": 0.555
        },
        {
          "concept": "ML fairness",
          "relevance": 0.532
        },
        {
          "concept": "fairness",
          "relevance": 0.524
        },
        {
          "concept": "optimization step",
          "relevance": 0.513
        },
        {
          "concept": "post‐process model outputs",
          "relevance": 0.506
        },
        {
          "concept": "model behavior",
          "relevance": 0.476
        },
        {
          "concept": "unfairness",
          "relevance": 0.475
        },
        {
          "concept": "comprehensive set",
          "relevance": 0.468
        },
        {
          "concept": "research agenda",
          "relevance": 0.455
        },
        {
          "concept": "pipeline",
          "relevance": 0.453
        },
        {
          "concept": "issues of bias",
          "relevance": 0.452
        },
        {
          "concept": "stepping stone",
          "relevance": 0.437
        },
        {
          "concept": "metrics",
          "relevance": 0.427
        },
        {
          "concept": "issues",
          "relevance": 0.424
        },
        {
          "concept": "root cause",
          "relevance": 0.424
        },
        {
          "concept": "toolkit",
          "relevance": 0.418
        },
        {
          "concept": "optimization",
          "relevance": 0.402
        },
        {
          "concept": "design",
          "relevance": 0.395
        },
        {
          "concept": "categorization",
          "relevance": 0.393
        },
        {
          "concept": "research",
          "relevance": 0.389
        },
        {
          "concept": "model output",
          "relevance": 0.389
        },
        {
          "concept": "constraints",
          "relevance": 0.387
        },
        {
          "concept": "holistic approach",
          "relevance": 0.386
        },
        {
          "concept": "training",
          "relevance": 0.385
        },
        {
          "concept": "various sources",
          "relevance": 0.378
        },
        {
          "concept": "steps",
          "relevance": 0.375
        },
        {
          "concept": "output",
          "relevance": 0.369
        },
        {
          "concept": "resources",
          "relevance": 0.364
        },
        {
          "concept": "tools",
          "relevance": 0.353
        },
        {
          "concept": "sets",
          "relevance": 0.352
        },
        {
          "concept": "method",
          "relevance": 0.341
        },
        {
          "concept": "knowledge",
          "relevance": 0.339
        },
        {
          "concept": "practitioners",
          "relevance": 0.334
        },
        {
          "concept": "source",
          "relevance": 0.321
        },
        {
          "concept": "data",
          "relevance": 0.308
        },
        {
          "concept": "practice guidelines",
          "relevance": 0.306
        },
        {
          "concept": "practice",
          "relevance": 0.304
        },
        {
          "concept": "agenda",
          "relevance": 0.299
        },
        {
          "concept": "approach",
          "relevance": 0.292
        },
        {
          "concept": "community",
          "relevance": 0.289
        },
        {
          "concept": "contribution",
          "relevance": 0.276
        },
        {
          "concept": "stone",
          "relevance": 0.276
        },
        {
          "concept": "guidelines",
          "relevance": 0.272
        },
        {
          "concept": "choice",
          "relevance": 0.269
        },
        {
          "concept": "literature",
          "relevance": 0.269
        },
        {
          "concept": "conviction",
          "relevance": 0.252
        },
        {
          "concept": "behavior",
          "relevance": 0.252
        },
        {
          "concept": "students",
          "relevance": 0.249
        },
        {
          "concept": "ground",
          "relevance": 0.244
        },
        {
          "concept": "measurements",
          "relevance": 0.237
        },
        {
          "concept": "intervention",
          "relevance": 0.236
        },
        {
          "concept": "education",
          "relevance": 0.219
        },
        {
          "concept": "bias",
          "relevance": 0.217
        },
        {
          "concept": "symptoms",
          "relevance": 0.215
        },
        {
          "concept": "individuals",
          "relevance": 0.209
        },
        {
          "concept": "cause",
          "relevance": 0.196
        },
        {
          "concept": "progression",
          "relevance": 0.192
        }
      ]
    },
    {
      "paperId": "pub.1143073374",
      "doi": "10.1145/3465416.3483305",
      "title": "A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle",
      "year": 2021,
      "citationCount": 398,
      "fieldCitationRatio": 124.04,
      "abstract": "As machine learning (ML) increasingly affects people and society, awareness of its potential unwanted consequences has also grown. To anticipate, prevent, and mitigate undesirable downstream consequences, it is critical that we understand when and how harm might be introduced throughout the ML life cycle. In this paper, we provide a framework that identifies seven distinct potential sources of downstream harm in machine learning, spanning data collection, development, and deployment. In doing so, we aim to facilitate more productive and precise communication around these issues, as well as more direct, application-grounded ways to mitigate them.",
      "reference_ids": [
        "pub.1137024208",
        "pub.1111334730",
        "pub.1107190906",
        "pub.1006441695",
        "pub.1135718527",
        "pub.1138871274",
        "pub.1101733512",
        "pub.1105579550",
        "pub.1103176690",
        "pub.1135714309",
        "pub.1103189946",
        "pub.1006825520",
        "pub.1041320087",
        "pub.1105723580",
        "pub.1095689025",
        "pub.1124547018",
        "pub.1111334706",
        "pub.1011011892",
        "pub.1133361998",
        "pub.1105687947",
        "pub.1124608021",
        "pub.1139669196",
        "pub.1104220462",
        "pub.1099810478",
        "pub.1111334732"
      ],
      "concepts_scores": [
        {
          "concept": "machine learning",
          "relevance": 0.564
        },
        {
          "concept": "machine learning life cycle",
          "relevance": 0.536
        },
        {
          "concept": "learning life cycle",
          "relevance": 0.52
        },
        {
          "concept": "ML life-cycle",
          "relevance": 0.492
        },
        {
          "concept": "life cycle",
          "relevance": 0.484
        },
        {
          "concept": "machine",
          "relevance": 0.415
        },
        {
          "concept": "learning",
          "relevance": 0.387
        },
        {
          "concept": "source of harm",
          "relevance": 0.374
        },
        {
          "concept": "data collection",
          "relevance": 0.364
        },
        {
          "concept": "framework",
          "relevance": 0.362
        },
        {
          "concept": "deployment",
          "relevance": 0.353
        },
        {
          "concept": "potential unwanted consequences",
          "relevance": 0.334
        },
        {
          "concept": "communication",
          "relevance": 0.333
        },
        {
          "concept": "unwanted consequences",
          "relevance": 0.329
        },
        {
          "concept": "harm",
          "relevance": 0.301
        },
        {
          "concept": "downstream harm",
          "relevance": 0.298
        },
        {
          "concept": "potential sources",
          "relevance": 0.281
        },
        {
          "concept": "issues",
          "relevance": 0.28
        },
        {
          "concept": "collection",
          "relevance": 0.276
        },
        {
          "concept": "society",
          "relevance": 0.272
        },
        {
          "concept": "downstream consequences",
          "relevance": 0.263
        },
        {
          "concept": "consequences",
          "relevance": 0.261
        },
        {
          "concept": "cycle",
          "relevance": 0.26
        },
        {
          "concept": "people",
          "relevance": 0.259
        },
        {
          "concept": "data",
          "relevance": 0.247
        },
        {
          "concept": "development",
          "relevance": 0.244
        },
        {
          "concept": "awareness",
          "relevance": 0.229
        },
        {
          "concept": "understanding",
          "relevance": 0.226
        }
      ]
    },
    {
      "paperId": "pub.1105579550",
      "doi": "10.1613/jair.953",
      "title": "SMOTE: Synthetic Minority Over-sampling Technique",
      "year": 2002,
      "citationCount": 23684,
      "fieldCitationRatio": 4741.53,
      "abstract": "An approach to the construction of classifiers from    imbalanced datasets is described. A dataset is imbalanced if the    classification categories are not approximately equally    represented. Often real-world data sets are predominately composed of    ``normal'' examples with only a small percentage of ``abnormal'' or    ``interesting'' examples. It is also the case that the cost of    misclassifying an abnormal (interesting) example as a normal example    is often much higher than the cost of the reverse    error. Under-sampling of the majority (normal) class has been proposed    as a good means of increasing the sensitivity of a classifier to the    minority class. This paper shows that a combination of our method of    over-sampling the minority (abnormal) class and under-sampling the    majority (normal) class can achieve better classifier performance (in    ROC space) than only under-sampling the majority class.  This paper    also shows that a combination of our method of over-sampling the    minority class and under-sampling the majority class can achieve    better classifier performance (in ROC space) than varying the loss    ratios in Ripper or class priors in Naive Bayes. Our method of    over-sampling the minority class involves creating synthetic minority    class examples.  Experiments are performed using C4.5, Ripper and a    Naive Bayes classifier. The method is evaluated using the area under    the Receiver Operating Characteristic curve (AUC) and the ROC convex    hull strategy.",
      "reference_ids": NaN,
      "concepts_scores": [
        {
          "concept": "minority class",
          "relevance": 0.719
        },
        {
          "concept": "under-sampling",
          "relevance": 0.676
        },
        {
          "concept": "method of over-sampling",
          "relevance": 0.654
        },
        {
          "concept": "construction of classifiers",
          "relevance": 0.633
        },
        {
          "concept": "imbalanced datasets",
          "relevance": 0.592
        },
        {
          "concept": "class priors",
          "relevance": 0.591
        },
        {
          "concept": "Naive Bayes",
          "relevance": 0.587
        },
        {
          "concept": "classifier performance",
          "relevance": 0.585
        },
        {
          "concept": "synthetic minority",
          "relevance": 0.582
        },
        {
          "concept": "over-sampling",
          "relevance": 0.568
        },
        {
          "concept": "classifier",
          "relevance": 0.56
        },
        {
          "concept": "data sets",
          "relevance": 0.517
        },
        {
          "concept": "dataset",
          "relevance": 0.508
        },
        {
          "concept": "Ripper",
          "relevance": 0.491
        },
        {
          "concept": "classification categories",
          "relevance": 0.485
        },
        {
          "concept": "C4.5",
          "relevance": 0.462
        },
        {
          "concept": "performance",
          "relevance": 0.447
        },
        {
          "concept": "error",
          "relevance": 0.445
        },
        {
          "concept": "examples",
          "relevance": 0.434
        },
        {
          "concept": "priors",
          "relevance": 0.424
        },
        {
          "concept": "method",
          "relevance": 0.42
        },
        {
          "concept": "classification",
          "relevance": 0.417
        },
        {
          "concept": "class",
          "relevance": 0.408
        },
        {
          "concept": "cost",
          "relevance": 0.406
        },
        {
          "concept": "sets",
          "relevance": 0.35
        },
        {
          "concept": "experiments",
          "relevance": 0.322
        },
        {
          "concept": "construction",
          "relevance": 0.311
        },
        {
          "concept": "data",
          "relevance": 0.306
        },
        {
          "concept": "Bay",
          "relevance": 0.304
        },
        {
          "concept": "combination",
          "relevance": 0.3
        },
        {
          "concept": "reversal errors",
          "relevance": 0.298
        },
        {
          "concept": "categories",
          "relevance": 0.297
        },
        {
          "concept": "ROC",
          "relevance": 0.295
        },
        {
          "concept": "AUC",
          "relevance": 0.288
        },
        {
          "concept": "area",
          "relevance": 0.245
        },
        {
          "concept": "cases",
          "relevance": 0.244
        },
        {
          "concept": "loss",
          "relevance": 0.222
        },
        {
          "concept": "sensitivity",
          "relevance": 0.211
        },
        {
          "concept": "ratio",
          "relevance": 0.202
        },
        {
          "concept": "percentage",
          "relevance": 0.198
        },
        {
          "concept": "minority",
          "relevance": 0.181
        },
        {
          "concept": "reversal",
          "relevance": 0.159
        }
      ]
    },
    {
      "paperId": "pub.1101733512",
      "doi": "10.2139/ssrn.2477899",
      "title": "Big Data's Disparate Impact",
      "year": 2016,
      "citationCount": 2146,
      "fieldCitationRatio": 1600.94,
      "abstract": "Advocates of algorithmic techniques like data mining argue that these techniques eliminate human biases from the decision-making process. But an algorithm is only as good as the data it works with. Data is frequently imperfect in ways that allow these algorithms to inherit the prejudices of prior decision makers. In other cases, data may simply reflect the widespread biases that persist in society at large. In still others, data mining can discover surprisingly useful regularities that are really just preexisting patterns of exclusion and inequality. Unthinking reliance on data mining can deny historically disadvantaged and vulnerable groups full participation in society. Worse still, because the resulting discrimination is almost always an unintentional emergent property of the algorithm’s use rather than a conscious choice by its programmers, it can be unusually hard to identify the source of the problem or to explain it to a court. This Essay examines these concerns through the lens of American antidiscrimination law — more particularly, through Title VII’s prohibition of discrimination in employment. In the absence of a demonstrable intent to discriminate, the best doctrinal hope for data mining’s victims would seem to lie in disparate impact doctrine. Case law and the Equal Employment Opportunity Commission’s Uniform Guidelines, though, hold that a practice can be justified as a business necessity when its outcomes are predictive of future employment outcomes, and data mining is specifically designed to find such statistical correlations. Unless there is a reasonably practical way to demonstrate that these discoveries are spurious, Title VII would appear to bless its use, even though the correlations it discovers will often reflect historic patterns of prejudice, others’ discrimination against members of protected groups, or flaws in the underlying data Addressing the sources of this unintentional discrimination and remedying the corresponding deficiencies in the law will be difficult technically, difficult legally, and difficult politically. There are a number of practical limits to what can be accomplished computationally. For example, when discrimination occurs because the data being mined is itself a result of past intentional discrimination, there is frequently no obvious method to adjust historical data to rid it of this taint. Corrective measures that alter the results of the data mining after it is complete would tread on legally and politically disputed terrain. These challenges for reform throw into stark relief the tension between the two major theories underlying antidiscrimination law: anticlassification and antisubordination. Finding a solution to big data’s disparate impact will require more than best efforts to stamp out prejudice and bias; it will require a wholesale reexamination of the meanings of “discrimination” and “fairness.”",
      "reference_ids": [
        "pub.1048617383",
        "pub.1044838020",
        "pub.1014929502",
        "pub.1004117218",
        "pub.1020990278",
        "pub.1102128484",
        "pub.1042265166",
        "pub.1011612816",
        "pub.1101926620",
        "pub.1089418660",
        "pub.1074941088",
        "pub.1051538115",
        "pub.1088307444",
        "pub.1030910923"
      ],
      "concepts_scores": [
        {
          "concept": "antidiscrimination laws",
          "relevance": 0.779
        },
        {
          "concept": "prohibition of discrimination",
          "relevance": 0.727
        },
        {
          "concept": "patterns of prejudice",
          "relevance": 0.687
        },
        {
          "concept": "case law",
          "relevance": 0.675
        },
        {
          "concept": "mine victims",
          "relevance": 0.664
        },
        {
          "concept": "intentional discrimination",
          "relevance": 0.663
        },
        {
          "concept": "unintentional discrimination",
          "relevance": 0.649
        },
        {
          "concept": "law",
          "relevance": 0.645
        },
        {
          "concept": "business necessity",
          "relevance": 0.642
        },
        {
          "concept": "decision-making process",
          "relevance": 0.597
        },
        {
          "concept": "uniform guidelines",
          "relevance": 0.595
        },
        {
          "concept": "widespread bias",
          "relevance": 0.591
        },
        {
          "concept": "patterns of exclusion",
          "relevance": 0.581
        },
        {
          "concept": "preexisting pattern",
          "relevance": 0.576
        },
        {
          "concept": "full participation",
          "relevance": 0.567
        },
        {
          "concept": "prejudice",
          "relevance": 0.563
        },
        {
          "concept": "conscious choice",
          "relevance": 0.562
        },
        {
          "concept": "corrective measures",
          "relevance": 0.538
        },
        {
          "concept": "discrimination",
          "relevance": 0.534
        },
        {
          "concept": "historical patterns",
          "relevance": 0.534
        },
        {
          "concept": "society",
          "relevance": 0.531
        },
        {
          "concept": "court",
          "relevance": 0.53
        },
        {
          "concept": "antidiscrimination",
          "relevance": 0.526
        },
        {
          "concept": "victims",
          "relevance": 0.52
        },
        {
          "concept": "doctrine",
          "relevance": 0.52
        },
        {
          "concept": "human bias",
          "relevance": 0.502
        },
        {
          "concept": "advocates",
          "relevance": 0.498
        },
        {
          "concept": "employment outcomes",
          "relevance": 0.496
        },
        {
          "concept": "reform",
          "relevance": 0.493
        },
        {
          "concept": "equality",
          "relevance": 0.476
        },
        {
          "concept": "fairness",
          "relevance": 0.476
        },
        {
          "concept": "necessity",
          "relevance": 0.46
        },
        {
          "concept": "decision makers",
          "relevance": 0.452
        },
        {
          "concept": "employment",
          "relevance": 0.451
        },
        {
          "concept": "decision",
          "relevance": 0.448
        },
        {
          "concept": "reliance",
          "relevance": 0.448
        },
        {
          "concept": "essay",
          "relevance": 0.435
        },
        {
          "concept": "data mining",
          "relevance": 0.433
        },
        {
          "concept": "business",
          "relevance": 0.43
        },
        {
          "concept": "members",
          "relevance": 0.424
        },
        {
          "concept": "concerns",
          "relevance": 0.423
        },
        {
          "concept": "practice",
          "relevance": 0.416
        },
        {
          "concept": "unthinking",
          "relevance": 0.412
        },
        {
          "concept": "taint",
          "relevance": 0.412
        },
        {
          "concept": "intention",
          "relevance": 0.41
        },
        {
          "concept": "cases",
          "relevance": 0.409
        },
        {
          "concept": "makers",
          "relevance": 0.405
        },
        {
          "concept": "algorithm use",
          "relevance": 0.4
        },
        {
          "concept": "exclusion",
          "relevance": 0.398
        },
        {
          "concept": "impact",
          "relevance": 0.396
        },
        {
          "concept": "reexamination",
          "relevance": 0.382
        },
        {
          "concept": "tension",
          "relevance": 0.372
        },
        {
          "concept": "emergent properties",
          "relevance": 0.371
        },
        {
          "concept": "inequality",
          "relevance": 0.367
        },
        {
          "concept": "hope",
          "relevance": 0.367
        },
        {
          "concept": "lens",
          "relevance": 0.365
        },
        {
          "concept": "title",
          "relevance": 0.364
        },
        {
          "concept": "guidelines",
          "relevance": 0.361
        },
        {
          "concept": "participants",
          "relevance": 0.35
        },
        {
          "concept": "programme",
          "relevance": 0.35
        },
        {
          "concept": "mining",
          "relevance": 0.348
        },
        {
          "concept": "data mining",
          "relevance": 0.348
        },
        {
          "concept": "relief",
          "relevance": 0.338
        },
        {
          "concept": "problem",
          "relevance": 0.336
        },
        {
          "concept": "algorithmic techniques",
          "relevance": 0.335
        },
        {
          "concept": "theory",
          "relevance": 0.33
        },
        {
          "concept": "choice",
          "relevance": 0.326
        },
        {
          "concept": "source",
          "relevance": 0.326
        },
        {
          "concept": "use",
          "relevance": 0.325
        },
        {
          "concept": "algorithm",
          "relevance": 0.323
        },
        {
          "concept": "bias",
          "relevance": 0.32
        },
        {
          "concept": "data",
          "relevance": 0.313
        },
        {
          "concept": "limitations",
          "relevance": 0.313
        },
        {
          "concept": "outcomes",
          "relevance": 0.312
        },
        {
          "concept": "data",
          "relevance": 0.291
        },
        {
          "concept": "historical data",
          "relevance": 0.279
        },
        {
          "concept": "absence",
          "relevance": 0.275
        },
        {
          "concept": "process",
          "relevance": 0.271
        },
        {
          "concept": "measurements",
          "relevance": 0.263
        },
        {
          "concept": "technique",
          "relevance": 0.241
        },
        {
          "concept": "discovery",
          "relevance": 0.24
        },
        {
          "concept": "regularization",
          "relevance": 0.237
        },
        {
          "concept": "terrain",
          "relevance": 0.232
        },
        {
          "concept": "group",
          "relevance": 0.226
        },
        {
          "concept": "deficiency",
          "relevance": 0.223
        },
        {
          "concept": "solution",
          "relevance": 0.2
        },
        {
          "concept": "properties",
          "relevance": 0.184
        },
        {
          "concept": "results",
          "relevance": 0.178
        },
        {
          "concept": "statistical correlation",
          "relevance": 0.177
        },
        {
          "concept": "correlation",
          "relevance": 0.143
        }
      ]
    },
    {
      "paperId": "pub.1148815077",
      "doi": "10.1145/3531146.3533083",
      "title": "The Values Encoded in Machine Learning Research",
      "year": 2022,
      "citationCount": 221,
      "fieldCitationRatio": 124.22,
      "abstract": "Machine learning currently exerts an outsized influence on the world, increasingly affecting institutional practices and impacted communities. It is therefore critical that we question vague conceptions of the field as value-neutral or universally beneficial, and investigate what specific values the field is advancing. In this paper, we first introduce a method and annotation scheme for studying the values encoded in documents such as research papers. Applying the scheme, we analyze 100 highly cited machine learning papers published at premier machine learning conferences, ICML and NeurIPS. We annotate key features of papers which reveal their values: their justification for their choice of project, which attributes of their project they uplift, their consideration of potential negative consequences, and their institutional affiliations and funding sources. We find that few of the papers justify how their project connects to a societal need (15%) and far fewer discuss negative potential (1%). Through line-by-line content analysis, we identify 59 values that are uplifted in ML research, and, of these, we find that the papers most frequently justify and assess themselves based on Performance, Generalization, Quantitative evidence, Efficiency, Building on past work, and Novelty. We present extensive textual evidence and identify key themes in the definitions and operationalization of these values. Notably, we find systematic textual evidence that these top values are being defined and applied with assumptions and implications generally supporting the centralization of power. Finally, we find increasingly close ties between these highly cited papers and tech companies and elite universities.",
      "reference_ids": [
        "pub.1129757091",
        "pub.1058932064",
        "pub.1135186391",
        "pub.1137670835",
        "pub.1014185598",
        "pub.1140080856",
        "pub.1140080900",
        "pub.1052330588",
        "pub.1105842441",
        "pub.1072555568",
        "pub.1062504873",
        "pub.1011865198",
        "pub.1135710434",
        "pub.1113967314",
        "pub.1113814587",
        "pub.1000293583",
        "pub.1049959021",
        "pub.1129310197",
        "pub.1074560454",
        "pub.1029467010",
        "pub.1130539145",
        "pub.1017418969",
        "pub.1133177154",
        "pub.1123567258"
      ],
      "concepts_scores": [
        {
          "concept": "machine learning conferences",
          "relevance": 0.64
        },
        {
          "concept": "machine learning research",
          "relevance": 0.636
        },
        {
          "concept": "machine learning papers",
          "relevance": 0.629
        },
        {
          "concept": "annotation scheme",
          "relevance": 0.583
        },
        {
          "concept": "ML research",
          "relevance": 0.579
        },
        {
          "concept": "machine learning",
          "relevance": 0.574
        },
        {
          "concept": "learning papers",
          "relevance": 0.564
        },
        {
          "concept": "learning research",
          "relevance": 0.56
        },
        {
          "concept": "learning conference",
          "relevance": 0.54
        },
        {
          "concept": "machine",
          "relevance": 0.522
        },
        {
          "concept": "tech companies",
          "relevance": 0.519
        },
        {
          "concept": "institutional affiliation",
          "relevance": 0.51
        },
        {
          "concept": "research paper",
          "relevance": 0.509
        },
        {
          "concept": "scheme",
          "relevance": 0.486
        },
        {
          "concept": "key features",
          "relevance": 0.481
        },
        {
          "concept": "NeurIPS",
          "relevance": 0.464
        },
        {
          "concept": "project",
          "relevance": 0.463
        },
        {
          "concept": "ICML",
          "relevance": 0.444
        },
        {
          "concept": "annotation",
          "relevance": 0.428
        },
        {
          "concept": "potential negative consequences",
          "relevance": 0.424
        },
        {
          "concept": "societal needs",
          "relevance": 0.421
        },
        {
          "concept": "textual evidence",
          "relevance": 0.417
        },
        {
          "concept": "learning",
          "relevance": 0.413
        },
        {
          "concept": "funding sources",
          "relevance": 0.406
        },
        {
          "concept": "line-by-line content analysis",
          "relevance": 0.4
        },
        {
          "concept": "content analysis",
          "relevance": 0.392
        },
        {
          "concept": "impacted communities",
          "relevance": 0.39
        },
        {
          "concept": "value-neutral",
          "relevance": 0.388
        },
        {
          "concept": "documents",
          "relevance": 0.388
        },
        {
          "concept": "paper",
          "relevance": 0.388
        },
        {
          "concept": "elite universities",
          "relevance": 0.387
        },
        {
          "concept": "performance",
          "relevance": 0.385
        },
        {
          "concept": "research",
          "relevance": 0.38
        },
        {
          "concept": "tech",
          "relevance": 0.38
        },
        {
          "concept": "generalization",
          "relevance": 0.376
        },
        {
          "concept": "novelty",
          "relevance": 0.372
        },
        {
          "concept": "features",
          "relevance": 0.371
        },
        {
          "concept": "negative consequences",
          "relevance": 0.37
        },
        {
          "concept": "institutional practices",
          "relevance": 0.368
        },
        {
          "concept": "outsized influence",
          "relevance": 0.357
        },
        {
          "concept": "companies",
          "relevance": 0.354
        },
        {
          "concept": "quantitative evidence",
          "relevance": 0.348
        },
        {
          "concept": "centralization of power",
          "relevance": 0.345
        },
        {
          "concept": "method",
          "relevance": 0.339
        },
        {
          "concept": "concept",
          "relevance": 0.337
        },
        {
          "concept": "funding",
          "relevance": 0.336
        },
        {
          "concept": "efficiency",
          "relevance": 0.336
        },
        {
          "concept": "definition",
          "relevance": 0.328
        },
        {
          "concept": "power",
          "relevance": 0.323
        },
        {
          "concept": "operationalization",
          "relevance": 0.322
        },
        {
          "concept": "needs",
          "relevance": 0.316
        },
        {
          "concept": "assumptions",
          "relevance": 0.314
        },
        {
          "concept": "top value",
          "relevance": 0.313
        },
        {
          "concept": "ties",
          "relevance": 0.306
        },
        {
          "concept": "conference",
          "relevance": 0.304
        },
        {
          "concept": "affiliation",
          "relevance": 0.298
        },
        {
          "concept": "University",
          "relevance": 0.286
        },
        {
          "concept": "practice",
          "relevance": 0.282
        },
        {
          "concept": "evidence",
          "relevance": 0.282
        },
        {
          "concept": "world",
          "relevance": 0.281
        },
        {
          "concept": "values",
          "relevance": 0.278
        },
        {
          "concept": "field",
          "relevance": 0.277
        },
        {
          "concept": "source",
          "relevance": 0.275
        },
        {
          "concept": "themes",
          "relevance": 0.269
        },
        {
          "concept": "influence",
          "relevance": 0.266
        },
        {
          "concept": "justification",
          "relevance": 0.265
        },
        {
          "concept": "community",
          "relevance": 0.248
        },
        {
          "concept": "analysis",
          "relevance": 0.243
        },
        {
          "concept": "Central",
          "relevance": 0.242
        },
        {
          "concept": "consequences",
          "relevance": 0.238
        },
        {
          "concept": "potential",
          "relevance": 0.233
        },
        {
          "concept": "negative potentials",
          "relevance": 0.167
        }
      ]
    },
    {
      "paperId": "pub.1135710434",
      "doi": "10.1145/3442188.3445922",
      "title": "On the Dangers of Stochastic Parrots",
      "year": 2021,
      "citationCount": 3504,
      "fieldCitationRatio": 3455.33,
      "abstract": "The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.",
      "reference_ids": [
        "pub.1125041917",
        "pub.1130315096",
        "pub.1132673693",
        "pub.1123773517",
        "pub.1125798967",
        "pub.1017035478",
        "pub.1032202015",
        "pub.1121025467",
        "pub.1121025485",
        "pub.1123778584",
        "pub.1128856734",
        "pub.1129926886",
        "pub.1000120992",
        "pub.1099113809",
        "pub.1121024947",
        "pub.1123132008",
        "pub.1031732216",
        "pub.1139255870",
        "pub.1111334730",
        "pub.1152417508",
        "pub.1061180209",
        "pub.1051758447",
        "pub.1021080654",
        "pub.1003268395",
        "pub.1023730237",
        "pub.1102821228",
        "pub.1053126851",
        "pub.1040632585",
        "pub.1005452468",
        "pub.1032338077",
        "pub.1113128256",
        "pub.1122290356",
        "pub.1044943146",
        "pub.1030531895",
        "pub.1023091413",
        "pub.1036017766",
        "pub.1092025836",
        "pub.1128856715",
        "pub.1103729151",
        "pub.1083902442",
        "pub.1117660148",
        "pub.1111607515",
        "pub.1133361901",
        "pub.1134315451",
        "pub.1083882403",
        "pub.1138871273",
        "pub.1010680957"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.646
        },
        {
          "concept": "English",
          "relevance": 0.522
        },
        {
          "concept": "language",
          "relevance": 0.517
        },
        {
          "concept": "pretrained models",
          "relevance": 0.474
        },
        {
          "concept": "NLP",
          "relevance": 0.433
        },
        {
          "concept": "research directions",
          "relevance": 0.415
        },
        {
          "concept": "BERT",
          "relevance": 0.403
        },
        {
          "concept": "architectural innovation",
          "relevance": 0.401
        },
        {
          "concept": "planning approach",
          "relevance": 0.398
        },
        {
          "concept": "research",
          "relevance": 0.396
        },
        {
          "concept": "leaderboard",
          "relevance": 0.368
        },
        {
          "concept": "dataset",
          "relevance": 0.351
        },
        {
          "concept": "deployment",
          "relevance": 0.35
        },
        {
          "concept": "danger",
          "relevance": 0.349
        },
        {
          "concept": "Web",
          "relevance": 0.344
        },
        {
          "concept": "benchmarks",
          "relevance": 0.342
        },
        {
          "concept": "task",
          "relevance": 0.336
        },
        {
          "concept": "model",
          "relevance": 0.312
        },
        {
          "concept": "boundaries",
          "relevance": 0.312
        },
        {
          "concept": "innovation",
          "relevance": 0.311
        },
        {
          "concept": "technology",
          "relevance": 0.307
        },
        {
          "concept": "parrots",
          "relevance": 0.303
        },
        {
          "concept": "development",
          "relevance": 0.3
        },
        {
          "concept": "path",
          "relevance": 0.298
        },
        {
          "concept": "investment resources",
          "relevance": 0.297
        },
        {
          "concept": "stakeholder values",
          "relevance": 0.295
        },
        {
          "concept": "resources",
          "relevance": 0.289
        },
        {
          "concept": "goal",
          "relevance": 0.284
        },
        {
          "concept": "cost",
          "relevance": 0.28
        },
        {
          "concept": "methodology",
          "relevance": 0.268
        },
        {
          "concept": "Development Goals",
          "relevance": 0.268
        },
        {
          "concept": "financial costs",
          "relevance": 0.261
        },
        {
          "concept": "approach",
          "relevance": 0.255
        },
        {
          "concept": "exercise",
          "relevance": 0.241
        },
        {
          "concept": "recommendations",
          "relevance": 0.239
        },
        {
          "concept": "stakeholders",
          "relevance": 0.236
        },
        {
          "concept": "state",
          "relevance": 0.234
        },
        {
          "concept": "years",
          "relevance": 0.23
        },
        {
          "concept": "direction",
          "relevance": 0.229
        },
        {
          "concept": "variants",
          "relevance": 0.227
        },
        {
          "concept": "risk",
          "relevance": 0.203
        },
        {
          "concept": "size",
          "relevance": 0.2
        },
        {
          "concept": "values",
          "relevance": 0.178
        }
      ]
    },
    {
      "paperId": "pub.1029467010",
      "doi": "10.1016/j.npls.2016.01.001",
      "title": "How to plan and perform a qualitative study using content analysis",
      "year": 2016,
      "citationCount": 3241,
      "fieldCitationRatio": 1126.0,
      "abstract": "This paper describes the research process – from planning to presentation, with the emphasis on credibility throughout the whole process – when the methodology of qualitative content analysis is chosen in a qualitative study. The groundwork for the credibility initiates when the planning of the study begins. External and internal resources have to be identified, and the researcher must consider his or her experience of the phenomenon to be studied in order to minimize any bias of his/her own influence. The purpose of content analysis is to organize and elicit meaning from the data collected and to draw realistic conclusions from it. The researcher must choose whether the analysis should be of a broad surface structure (a manifest analysis) or of a deep structure (a latent analysis). Four distinct main stages are described in this paper: the decontextualisation, the recontextualisation, the categorization, and the compilation. This description of qualitative content analysis offers one approach that shows how the general principles of the method can be used.",
      "reference_ids": [
        "pub.1032850168",
        "pub.1069438345",
        "pub.1047104385",
        "pub.1027861291",
        "pub.1013649404",
        "pub.1001435815",
        "pub.1040706967",
        "pub.1020078769",
        "pub.1008935133",
        "pub.1047754685",
        "pub.1051887340",
        "pub.1073924538",
        "pub.1049695373",
        "pub.1037712631",
        "pub.1017531294",
        "pub.1037105113",
        "pub.1007806339"
      ],
      "concepts_scores": [
        {
          "concept": "content analysis",
          "relevance": 0.543
        },
        {
          "concept": "qualitative content analysis",
          "relevance": 0.52
        },
        {
          "concept": "internal resources",
          "relevance": 0.495
        },
        {
          "concept": "qualitative study",
          "relevance": 0.48
        },
        {
          "concept": "credibility",
          "relevance": 0.416
        },
        {
          "concept": "research process",
          "relevance": 0.402
        },
        {
          "concept": "research",
          "relevance": 0.391
        },
        {
          "concept": "planning",
          "relevance": 0.329
        },
        {
          "concept": "recontextualisation",
          "relevance": 0.318
        },
        {
          "concept": "decontextualisation",
          "relevance": 0.311
        },
        {
          "concept": "resources",
          "relevance": 0.3
        },
        {
          "concept": "methodology",
          "relevance": 0.299
        },
        {
          "concept": "analysis",
          "relevance": 0.296
        },
        {
          "concept": "paper",
          "relevance": 0.295
        },
        {
          "concept": "study",
          "relevance": 0.29
        },
        {
          "concept": "conclusions",
          "relevance": 0.282
        },
        {
          "concept": "deep structure",
          "relevance": 0.277
        },
        {
          "concept": "influence",
          "relevance": 0.275
        },
        {
          "concept": "process",
          "relevance": 0.272
        },
        {
          "concept": "categorization",
          "relevance": 0.269
        },
        {
          "concept": "content",
          "relevance": 0.26
        },
        {
          "concept": "bias",
          "relevance": 0.249
        },
        {
          "concept": "data",
          "relevance": 0.247
        },
        {
          "concept": "presentation",
          "relevance": 0.24
        },
        {
          "concept": "compilation",
          "relevance": 0.229
        },
        {
          "concept": "phenomenon",
          "relevance": 0.227
        },
        {
          "concept": "experiments",
          "relevance": 0.219
        },
        {
          "concept": "surface structure",
          "relevance": 0.209
        },
        {
          "concept": "description",
          "relevance": 0.207
        },
        {
          "concept": "structure",
          "relevance": 0.206
        },
        {
          "concept": "stage",
          "relevance": 0.194
        },
        {
          "concept": "method",
          "relevance": 0.187
        },
        {
          "concept": "surface",
          "relevance": 0.161
        }
      ]
    }
  ],
  "evolution_links": [
    {
      "source": "pub.1172790398",
      "target": "pub.1165317422",
      "source_title": "Bias and Fairness in Large Language Models: A Survey",
      "target_title": "Toward Operationalizing Pipeline-aware ML Fairness: A Research Agenda for Developing Practical Guidelines and Tools"
    },
    {
      "source": "pub.1165317422",
      "target": "pub.1143073374",
      "source_title": "Toward Operationalizing Pipeline-aware ML Fairness: A Research Agenda for Developing Practical Guidelines and Tools",
      "target_title": "A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle"
    },
    {
      "source": "pub.1143073374",
      "target": "pub.1105579550",
      "source_title": "A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle",
      "target_title": "SMOTE: Synthetic Minority Over-sampling Technique"
    },
    {
      "source": "pub.1143073374",
      "target": "pub.1101733512",
      "source_title": "A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle",
      "target_title": "Big Data's Disparate Impact"
    },
    {
      "source": "pub.1165317422",
      "target": "pub.1148815077",
      "source_title": "Toward Operationalizing Pipeline-aware ML Fairness: A Research Agenda for Developing Practical Guidelines and Tools",
      "target_title": "The Values Encoded in Machine Learning Research"
    },
    {
      "source": "pub.1148815077",
      "target": "pub.1135710434",
      "source_title": "The Values Encoded in Machine Learning Research",
      "target_title": "On the Dangers of Stochastic Parrots"
    },
    {
      "source": "pub.1148815077",
      "target": "pub.1029467010",
      "source_title": "The Values Encoded in Machine Learning Research",
      "target_title": "How to plan and perform a qualitative study using content analysis"
    }
  ]
}