{
  "papers": [
    {
      "paperId": "pub.1154205505",
      "doi": "10.1080/10447318.2022.2153320",
      "title": "Six Human-Centered Artificial Intelligence Grand Challenges",
      "year": 2023,
      "citationCount": 277,
      "fieldCitationRatio": 182.78,
      "abstract": "Widespread adoption of artificial intelligence (AI) technologies is substantially affecting the human condition in ways that are not yet well understood. Negative unintended consequences abound including the perpetuation and exacerbation of societal inequalities and divisions via algorithmic decision making. We present six grand challenges for the scientific community to create AI technologies that are human-centered, that is, ethical, fair, and enhance the human condition. These grand challenges are the result of an international collaboration across academia, industry and government and represent the consensus views of a group of 26 experts in the field of human-centered artificial intelligence (HCAI). In essence, these challenges advocate for a human-centered approach to AI that (1) is centered in human well-being, (2) is designed responsibly, (3) respects privacy, (4) follows human-centered design principles, (5) is subject to appropriate governance and oversight, and (6) interacts with individuals while respecting human’s cognitive capacities. We hope that these challenges and their associated research directions serve as a call for action to conduct research and development in AI that serves as a force multiplier towards more fair, equitable and sustainable societies.",
      "reference_ids": [
        "pub.1136963960",
        "pub.1111408293",
        "pub.1104571182",
        "pub.1045604768",
        "pub.1111977993",
        "pub.1132000000",
        "pub.1142504502",
        "pub.1105934270",
        "pub.1113500190",
        "pub.1124049496",
        "pub.1104220463",
        "pub.1131351103",
        "pub.1111334719",
        "pub.1117352078",
        "pub.1130381612",
        "pub.1113813993",
        "pub.1092625899",
        "pub.1071058552",
        "pub.1126123451",
        "pub.1140404632",
        "pub.1119406219",
        "pub.1102562809",
        "pub.1172300505",
        "pub.1111935925",
        "pub.1120392099",
        "pub.1144366739",
        "pub.1119919019",
        "pub.1122001853",
        "pub.1125822736",
        "pub.1146592024",
        "pub.1145433247",
        "pub.1139794355",
        "pub.1128739423",
        "pub.1131876062",
        "pub.1103067323",
        "pub.1104016351",
        "pub.1117603627",
        "pub.1129793532",
        "pub.1140080911",
        "pub.1111606153",
        "pub.1124308275",
        "pub.1128879308",
        "pub.1129798296",
        "pub.1137362952",
        "pub.1091106954",
        "pub.1004117218",
        "pub.1122819943",
        "pub.1111334730",
        "pub.1134079529",
        "pub.1110192280",
        "pub.1005840804",
        "pub.1100223798",
        "pub.1128491824",
        "pub.1129127055",
        "pub.1001715712",
        "pub.1146537520",
        "pub.1105951163",
        "pub.1123608337",
        "pub.1105551943",
        "pub.1064529936",
        "pub.1132190966",
        "pub.1107873621",
        "pub.1048475499",
        "pub.1128428448",
        "pub.1131116463",
        "pub.1120234735",
        "pub.1124547018",
        "pub.1117674836",
        "pub.1138786376",
        "pub.1138572193",
        "pub.1020254845",
        "pub.1040196774",
        "pub.1092230544",
        "pub.1101056956",
        "pub.1125119160",
        "pub.1131843056",
        "pub.1140404415",
        "pub.1113142551",
        "pub.1045019116",
        "pub.1150423488",
        "pub.1002167655",
        "pub.1136835184",
        "pub.1139800731",
        "pub.1083900003",
        "pub.1030389413",
        "pub.1142451389",
        "pub.1046457413",
        "pub.1127963098",
        "pub.1122909219",
        "pub.1138532624",
        "pub.1128112462",
        "pub.1123772692",
        "pub.1046045849",
        "pub.1130082439",
        "pub.1125058520",
        "pub.1113274309",
        "pub.1025096580",
        "pub.1109727167",
        "pub.1128712207",
        "pub.1136531386",
        "pub.1112615572",
        "pub.1104589443",
        "pub.1006867054",
        "pub.1110063291",
        "pub.1104259524",
        "pub.1110916238",
        "pub.1093514997",
        "pub.1150696243",
        "pub.1107865769",
        "pub.1130210457",
        "pub.1138170180",
        "pub.1139289818",
        "pub.1086115539",
        "pub.1130936978",
        "pub.1139350879",
        "pub.1070194700",
        "pub.1127963241",
        "pub.1009385637",
        "pub.1101336285",
        "pub.1131076164",
        "pub.1117127623",
        "pub.1112521379",
        "pub.1024768567",
        "pub.1124889240",
        "pub.1101380916",
        "pub.1103067078",
        "pub.1149768158",
        "pub.1023622326",
        "pub.1138334945",
        "pub.1141986916",
        "pub.1091994926",
        "pub.1103565605",
        "pub.1145294424",
        "pub.1136395298",
        "pub.1131850089",
        "pub.1144655421",
        "pub.1141037898",
        "pub.1024038464",
        "pub.1110205751",
        "pub.1139669196",
        "pub.1146918243",
        "pub.1063168741",
        "pub.1138352376",
        "pub.1140404184",
        "pub.1017350263",
        "pub.1030786196",
        "pub.1114066598",
        "pub.1110521585",
        "pub.1112945304",
        "pub.1045385618",
        "pub.1127354656",
        "pub.1142161007",
        "pub.1135787714",
        "pub.1052782730",
        "pub.1039678909",
        "pub.1039127451",
        "pub.1112250129",
        "pub.1012556579",
        "pub.1138894740",
        "pub.1142508001",
        "pub.1118611712",
        "pub.1087306110",
        "pub.1113813992",
        "pub.1105577960",
        "pub.1092202694",
        "pub.1141007788",
        "pub.1138741065",
        "pub.1145635007",
        "pub.1109816564",
        "pub.1133586968",
        "pub.1120387381",
        "pub.1140080897",
        "pub.1083775034",
        "pub.1004941227",
        "pub.1141307261",
        "pub.1003604553",
        "pub.1118781833",
        "pub.1009879584",
        "pub.1135036155",
        "pub.1000730567",
        "pub.1083575120",
        "pub.1142507789",
        "pub.1146575648",
        "pub.1106225457",
        "pub.1007740722",
        "pub.1091439401",
        "pub.1096024200",
        "pub.1129364191",
        "pub.1123961805",
        "pub.1135969248",
        "pub.1025213114",
        "pub.1009296542",
        "pub.1035328812",
        "pub.1102338042",
        "pub.1146073018",
        "pub.1113364030",
        "pub.1072710245",
        "pub.1033726592",
        "pub.1008527002",
        "pub.1141231211",
        "pub.1119343863",
        "pub.1140401873",
        "pub.1020199651",
        "pub.1092079377",
        "pub.1120633235",
        "pub.1139806003",
        "pub.1146004856",
        "pub.1140531641",
        "pub.1061789059",
        "pub.1109931394",
        "pub.1102128484",
        "pub.1101232548",
        "pub.1134141081",
        "pub.1077754966",
        "pub.1059247989"
      ],
      "concepts_scores": [
        {
          "concept": "adoption of artificial intelligence",
          "relevance": 0.781
        },
        {
          "concept": "human-centered artificial intelligence",
          "relevance": 0.762
        },
        {
          "concept": "widespread adoption of artificial intelligence",
          "relevance": 0.67
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.663
        },
        {
          "concept": "approach to AI",
          "relevance": 0.624
        },
        {
          "concept": "algorithmic decision making",
          "relevance": 0.607
        },
        {
          "concept": "human-centered design principles",
          "relevance": 0.603
        },
        {
          "concept": "AI technology",
          "relevance": 0.572
        },
        {
          "concept": "human condition",
          "relevance": 0.541
        },
        {
          "concept": "research directions",
          "relevance": 0.519
        },
        {
          "concept": "human cognitive capacities",
          "relevance": 0.505
        },
        {
          "concept": "intelligence",
          "relevance": 0.5
        },
        {
          "concept": "design principles",
          "relevance": 0.498
        },
        {
          "concept": "cognitive capacity",
          "relevance": 0.491
        },
        {
          "concept": "widespread adoption",
          "relevance": 0.484
        },
        {
          "concept": "decision making",
          "relevance": 0.481
        },
        {
          "concept": "force multiplier",
          "relevance": 0.475
        },
        {
          "concept": "privacy",
          "relevance": 0.459
        },
        {
          "concept": "technology",
          "relevance": 0.444
        },
        {
          "concept": "international collaboration",
          "relevance": 0.438
        },
        {
          "concept": "human well-being",
          "relevance": 0.436
        },
        {
          "concept": "consensus view",
          "relevance": 0.427
        },
        {
          "concept": "scientific community",
          "relevance": 0.408
        },
        {
          "concept": "societal inequalities",
          "relevance": 0.407
        },
        {
          "concept": "challenges",
          "relevance": 0.402
        },
        {
          "concept": "academia",
          "relevance": 0.386
        },
        {
          "concept": "experts",
          "relevance": 0.384
        },
        {
          "concept": "sustainable society",
          "relevance": 0.38
        },
        {
          "concept": "multipliers",
          "relevance": 0.379
        },
        {
          "concept": "collaboration",
          "relevance": 0.366
        },
        {
          "concept": "negative unintended consequences",
          "relevance": 0.362
        },
        {
          "concept": "research",
          "relevance": 0.362
        },
        {
          "concept": "making",
          "relevance": 0.361
        },
        {
          "concept": "unintended consequences",
          "relevance": 0.358
        },
        {
          "concept": "well-being",
          "relevance": 0.351
        },
        {
          "concept": "views",
          "relevance": 0.347
        },
        {
          "concept": "society",
          "relevance": 0.347
        },
        {
          "concept": "government",
          "relevance": 0.326
        },
        {
          "concept": "principles",
          "relevance": 0.321
        },
        {
          "concept": "oversight",
          "relevance": 0.308
        },
        {
          "concept": "industry",
          "relevance": 0.303
        },
        {
          "concept": "perpetuation",
          "relevance": 0.294
        },
        {
          "concept": "direction",
          "relevance": 0.286
        },
        {
          "concept": "consensus",
          "relevance": 0.282
        },
        {
          "concept": "community",
          "relevance": 0.281
        },
        {
          "concept": "division",
          "relevance": 0.274
        },
        {
          "concept": "action",
          "relevance": 0.27
        },
        {
          "concept": "consequences",
          "relevance": 0.269
        },
        {
          "concept": "development",
          "relevance": 0.264
        },
        {
          "concept": "individuals",
          "relevance": 0.247
        },
        {
          "concept": "capacity",
          "relevance": 0.245
        },
        {
          "concept": "inequality",
          "relevance": 0.24
        },
        {
          "concept": "conditions",
          "relevance": 0.225
        },
        {
          "concept": "force",
          "relevance": 0.212
        },
        {
          "concept": "exacerbation",
          "relevance": 0.198
        },
        {
          "concept": "group",
          "relevance": 0.167
        }
      ]
    },
    {
      "paperId": "pub.1142161007",
      "doi": "10.1016/s2589-7500(21)00208-9",
      "title": "The false hope of current approaches to explainable artificial intelligence in health care",
      "year": 2021,
      "citationCount": 849,
      "fieldCitationRatio": 283.97,
      "abstract": "The black-box nature of current artificial intelligence (AI) has caused some to question whether AI must be explainable to be used in high-stakes scenarios such as medicine. It has been argued that explainable AI will engender trust with the health-care workforce, provide transparency into the AI decision making process, and potentially mitigate various kinds of bias. In this Viewpoint, we argue that this argument represents a false hope for explainable AI and that current explainability methods are unlikely to achieve these goals for patient-level decision support. We provide an overview of current explainability techniques and highlight how various failure cases can cause problems for decision making for individual patients. In the absence of suitable explainability methods, we advocate for rigorous internal and external validation of AI models as a more direct means of achieving the goals often associated with explainability, and we caution against having explainability be a requirement for clinically deployed models.",
      "reference_ids": [
        "pub.1123462168",
        "pub.1059744121",
        "pub.1101511782",
        "pub.1122068379",
        "pub.1127954048",
        "pub.1137855749",
        "pub.1120315979",
        "pub.1101456014",
        "pub.1111918634",
        "pub.1100060663",
        "pub.1101594069",
        "pub.1117944489",
        "pub.1131837639",
        "pub.1121116962",
        "pub.1122595188",
        "pub.1107264104",
        "pub.1128104531",
        "pub.1127963016",
        "pub.1121037081",
        "pub.1125461433",
        "pub.1114160691",
        "pub.1107455905",
        "pub.1110955659",
        "pub.1122290388",
        "pub.1125898572",
        "pub.1004090829",
        "pub.1020017350",
        "pub.1113842568",
        "pub.1134389326",
        "pub.1127953097",
        "pub.1124308279",
        "pub.1099151330",
        "pub.1124608013",
        "pub.1134518780",
        "pub.1027341916"
      ],
      "concepts_scores": [
        {
          "concept": "artificial intelligence",
          "relevance": 0.638
        },
        {
          "concept": "explainability methods",
          "relevance": 0.606
        },
        {
          "concept": "Explainable Artificial Intelligence",
          "relevance": 0.569
        },
        {
          "concept": "black-box nature",
          "relevance": 0.566
        },
        {
          "concept": "current artificial intelligence",
          "relevance": 0.558
        },
        {
          "concept": "high-stakes scenarios",
          "relevance": 0.551
        },
        {
          "concept": "validation of AI models",
          "relevance": 0.549
        },
        {
          "concept": "health-care workforce",
          "relevance": 0.539
        },
        {
          "concept": "explainability techniques",
          "relevance": 0.522
        },
        {
          "concept": "AI models",
          "relevance": 0.509
        },
        {
          "concept": "decision support",
          "relevance": 0.504
        },
        {
          "concept": "explainability",
          "relevance": 0.499
        },
        {
          "concept": "decision making process",
          "relevance": 0.493
        },
        {
          "concept": "health care",
          "relevance": 0.491
        },
        {
          "concept": "mitigate various kinds",
          "relevance": 0.481
        },
        {
          "concept": "intelligence",
          "relevance": 0.447
        },
        {
          "concept": "failure cases",
          "relevance": 0.417
        },
        {
          "concept": "individual patients",
          "relevance": 0.414
        },
        {
          "concept": "care",
          "relevance": 0.38
        },
        {
          "concept": "health",
          "relevance": 0.372
        },
        {
          "concept": "workforce",
          "relevance": 0.364
        },
        {
          "concept": "scenarios",
          "relevance": 0.359
        },
        {
          "concept": "goal",
          "relevance": 0.356
        },
        {
          "concept": "method",
          "relevance": 0.351
        },
        {
          "concept": "clinic",
          "relevance": 0.348
        },
        {
          "concept": "requirements",
          "relevance": 0.342
        },
        {
          "concept": "medicine",
          "relevance": 0.333
        },
        {
          "concept": "model",
          "relevance": 0.332
        },
        {
          "concept": "decision",
          "relevance": 0.331
        },
        {
          "concept": "support",
          "relevance": 0.327
        },
        {
          "concept": "patients",
          "relevance": 0.313
        },
        {
          "concept": "technique",
          "relevance": 0.308
        },
        {
          "concept": "kinds",
          "relevance": 0.306
        },
        {
          "concept": "transparency",
          "relevance": 0.298
        },
        {
          "concept": "bias",
          "relevance": 0.288
        },
        {
          "concept": "validity",
          "relevance": 0.283
        },
        {
          "concept": "overview",
          "relevance": 0.278
        },
        {
          "concept": "process",
          "relevance": 0.271
        },
        {
          "concept": "approach",
          "relevance": 0.223
        },
        {
          "concept": "cases",
          "relevance": 0.222
        },
        {
          "concept": "failure",
          "relevance": 0.207
        },
        {
          "concept": "problem",
          "relevance": 0.207
        },
        {
          "concept": "absence",
          "relevance": 0.2
        }
      ]
    },
    {
      "paperId": "pub.1122068379",
      "doi": "10.1126/science.aax2342",
      "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
      "year": 2019,
      "citationCount": 4039,
      "fieldCitationRatio": 858.59,
      "abstract": "Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. We show that a widely used algorithm, typical of this industry-wide approach and affecting millions of patients, exhibits significant racial bias: At a given risk score, Black patients are considerably sicker than White patients, as evidenced by signs of uncontrolled illnesses. Remedying this disparity would increase the percentage of Black patients receiving additional help from 17.7 to 46.5%. The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for White patients. Thus, despite health care cost appearing to be an effective proxy for health by some measures of predictive accuracy, large racial biases arise. We suggest that the choice of convenient, seemingly effective proxies for ground truth can be an important source of algorithmic bias in many contexts.",
      "reference_ids": [
        "pub.1111334701",
        "pub.1013108695",
        "pub.1011011892",
        "pub.1024670161",
        "pub.1044203179",
        "pub.1064528116",
        "pub.1053451067",
        "pub.1061630049",
        "pub.1101733512",
        "pub.1017968193",
        "pub.1009495412",
        "pub.1113452706",
        "pub.1078954492",
        "pub.1018520788",
        "pub.1084825219",
        "pub.1015838411",
        "pub.1091026367",
        "pub.1085108555",
        "pub.1021186690",
        "pub.1091346623",
        "pub.1019556988",
        "pub.1068673126",
        "pub.1052872047",
        "pub.1025206623",
        "pub.1050266154",
        "pub.1020760380",
        "pub.1086115539",
        "pub.1085512126",
        "pub.1004545697",
        "pub.1112607861",
        "pub.1050180888",
        "pub.1046495222",
        "pub.1111334706",
        "pub.1068843237"
      ],
      "concepts_scores": [
        {
          "concept": "health care costs",
          "relevance": 0.654
        },
        {
          "concept": "care costs",
          "relevance": 0.607
        },
        {
          "concept": "black patients",
          "relevance": 0.605
        },
        {
          "concept": "complex health needs",
          "relevance": 0.586
        },
        {
          "concept": "white patients",
          "relevance": 0.581
        },
        {
          "concept": "health of populations",
          "relevance": 0.574
        },
        {
          "concept": "percentage of black patients",
          "relevance": 0.571
        },
        {
          "concept": "health needs",
          "relevance": 0.534
        },
        {
          "concept": "health system",
          "relevance": 0.532
        },
        {
          "concept": "uncontrolled illness",
          "relevance": 0.522
        },
        {
          "concept": "racial bias",
          "relevance": 0.516
        },
        {
          "concept": "risk score",
          "relevance": 0.506
        },
        {
          "concept": "health",
          "relevance": 0.5
        },
        {
          "concept": "industry-wide approach",
          "relevance": 0.47
        },
        {
          "concept": "sources of algorithmic bias",
          "relevance": 0.467
        },
        {
          "concept": "illness",
          "relevance": 0.456
        },
        {
          "concept": "measures of predictive accuracy",
          "relevance": 0.45
        },
        {
          "concept": "racial bias",
          "relevance": 0.438
        },
        {
          "concept": "patients",
          "relevance": 0.423
        },
        {
          "concept": "care",
          "relevance": 0.411
        },
        {
          "concept": "disparities",
          "relevance": 0.396
        },
        {
          "concept": "bias",
          "relevance": 0.386
        },
        {
          "concept": "scores",
          "relevance": 0.375
        },
        {
          "concept": "affecting millions",
          "relevance": 0.372
        },
        {
          "concept": "needs",
          "relevance": 0.365
        },
        {
          "concept": "risk",
          "relevance": 0.364
        },
        {
          "concept": "population",
          "relevance": 0.349
        },
        {
          "concept": "effective proxy",
          "relevance": 0.349
        },
        {
          "concept": "bias",
          "relevance": 0.337
        },
        {
          "concept": "algorithmic bias",
          "relevance": 0.334
        },
        {
          "concept": "money",
          "relevance": 0.32
        },
        {
          "concept": "truth",
          "relevance": 0.312
        },
        {
          "concept": "cost",
          "relevance": 0.309
        },
        {
          "concept": "proxies",
          "relevance": 0.305
        },
        {
          "concept": "percentage",
          "relevance": 0.3
        },
        {
          "concept": "millions",
          "relevance": 0.297
        },
        {
          "concept": "measurements",
          "relevance": 0.291
        },
        {
          "concept": "context",
          "relevance": 0.28
        },
        {
          "concept": "prediction algorithm",
          "relevance": 0.265
        },
        {
          "concept": "approach",
          "relevance": 0.241
        },
        {
          "concept": "ground",
          "relevance": 0.232
        },
        {
          "concept": "ground truth",
          "relevance": 0.221
        },
        {
          "concept": "prediction accuracy",
          "relevance": 0.214
        },
        {
          "concept": "algorithm",
          "relevance": 0.213
        },
        {
          "concept": "system",
          "relevance": 0.194
        },
        {
          "concept": "source",
          "relevance": 0.194
        },
        {
          "concept": "accuracy",
          "relevance": 0.164
        }
      ]
    },
    {
      "paperId": "pub.1101733512",
      "doi": "10.2139/ssrn.2477899",
      "title": "Big Data's Disparate Impact",
      "year": 2016,
      "citationCount": 2146,
      "fieldCitationRatio": 1600.94,
      "abstract": "Advocates of algorithmic techniques like data mining argue that these techniques eliminate human biases from the decision-making process. But an algorithm is only as good as the data it works with. Data is frequently imperfect in ways that allow these algorithms to inherit the prejudices of prior decision makers. In other cases, data may simply reflect the widespread biases that persist in society at large. In still others, data mining can discover surprisingly useful regularities that are really just preexisting patterns of exclusion and inequality. Unthinking reliance on data mining can deny historically disadvantaged and vulnerable groups full participation in society. Worse still, because the resulting discrimination is almost always an unintentional emergent property of the algorithm’s use rather than a conscious choice by its programmers, it can be unusually hard to identify the source of the problem or to explain it to a court. This Essay examines these concerns through the lens of American antidiscrimination law — more particularly, through Title VII’s prohibition of discrimination in employment. In the absence of a demonstrable intent to discriminate, the best doctrinal hope for data mining’s victims would seem to lie in disparate impact doctrine. Case law and the Equal Employment Opportunity Commission’s Uniform Guidelines, though, hold that a practice can be justified as a business necessity when its outcomes are predictive of future employment outcomes, and data mining is specifically designed to find such statistical correlations. Unless there is a reasonably practical way to demonstrate that these discoveries are spurious, Title VII would appear to bless its use, even though the correlations it discovers will often reflect historic patterns of prejudice, others’ discrimination against members of protected groups, or flaws in the underlying data Addressing the sources of this unintentional discrimination and remedying the corresponding deficiencies in the law will be difficult technically, difficult legally, and difficult politically. There are a number of practical limits to what can be accomplished computationally. For example, when discrimination occurs because the data being mined is itself a result of past intentional discrimination, there is frequently no obvious method to adjust historical data to rid it of this taint. Corrective measures that alter the results of the data mining after it is complete would tread on legally and politically disputed terrain. These challenges for reform throw into stark relief the tension between the two major theories underlying antidiscrimination law: anticlassification and antisubordination. Finding a solution to big data’s disparate impact will require more than best efforts to stamp out prejudice and bias; it will require a wholesale reexamination of the meanings of “discrimination” and “fairness.”",
      "reference_ids": [
        "pub.1048617383",
        "pub.1044838020",
        "pub.1014929502",
        "pub.1004117218",
        "pub.1020990278",
        "pub.1102128484",
        "pub.1042265166",
        "pub.1011612816",
        "pub.1101926620",
        "pub.1089418660",
        "pub.1074941088",
        "pub.1051538115",
        "pub.1088307444",
        "pub.1030910923"
      ],
      "concepts_scores": [
        {
          "concept": "antidiscrimination laws",
          "relevance": 0.779
        },
        {
          "concept": "prohibition of discrimination",
          "relevance": 0.727
        },
        {
          "concept": "patterns of prejudice",
          "relevance": 0.687
        },
        {
          "concept": "case law",
          "relevance": 0.675
        },
        {
          "concept": "mine victims",
          "relevance": 0.664
        },
        {
          "concept": "intentional discrimination",
          "relevance": 0.663
        },
        {
          "concept": "unintentional discrimination",
          "relevance": 0.649
        },
        {
          "concept": "law",
          "relevance": 0.645
        },
        {
          "concept": "business necessity",
          "relevance": 0.642
        },
        {
          "concept": "decision-making process",
          "relevance": 0.597
        },
        {
          "concept": "uniform guidelines",
          "relevance": 0.595
        },
        {
          "concept": "widespread bias",
          "relevance": 0.591
        },
        {
          "concept": "patterns of exclusion",
          "relevance": 0.581
        },
        {
          "concept": "preexisting pattern",
          "relevance": 0.576
        },
        {
          "concept": "full participation",
          "relevance": 0.567
        },
        {
          "concept": "prejudice",
          "relevance": 0.563
        },
        {
          "concept": "conscious choice",
          "relevance": 0.562
        },
        {
          "concept": "corrective measures",
          "relevance": 0.538
        },
        {
          "concept": "discrimination",
          "relevance": 0.534
        },
        {
          "concept": "historical patterns",
          "relevance": 0.534
        },
        {
          "concept": "society",
          "relevance": 0.531
        },
        {
          "concept": "court",
          "relevance": 0.53
        },
        {
          "concept": "antidiscrimination",
          "relevance": 0.526
        },
        {
          "concept": "victims",
          "relevance": 0.52
        },
        {
          "concept": "doctrine",
          "relevance": 0.52
        },
        {
          "concept": "human bias",
          "relevance": 0.502
        },
        {
          "concept": "advocates",
          "relevance": 0.498
        },
        {
          "concept": "employment outcomes",
          "relevance": 0.496
        },
        {
          "concept": "reform",
          "relevance": 0.493
        },
        {
          "concept": "equality",
          "relevance": 0.476
        },
        {
          "concept": "fairness",
          "relevance": 0.476
        },
        {
          "concept": "necessity",
          "relevance": 0.46
        },
        {
          "concept": "decision makers",
          "relevance": 0.452
        },
        {
          "concept": "employment",
          "relevance": 0.451
        },
        {
          "concept": "decision",
          "relevance": 0.448
        },
        {
          "concept": "reliance",
          "relevance": 0.448
        },
        {
          "concept": "essay",
          "relevance": 0.435
        },
        {
          "concept": "data mining",
          "relevance": 0.433
        },
        {
          "concept": "business",
          "relevance": 0.43
        },
        {
          "concept": "members",
          "relevance": 0.424
        },
        {
          "concept": "concerns",
          "relevance": 0.423
        },
        {
          "concept": "practice",
          "relevance": 0.416
        },
        {
          "concept": "unthinking",
          "relevance": 0.412
        },
        {
          "concept": "taint",
          "relevance": 0.412
        },
        {
          "concept": "intention",
          "relevance": 0.41
        },
        {
          "concept": "cases",
          "relevance": 0.409
        },
        {
          "concept": "makers",
          "relevance": 0.405
        },
        {
          "concept": "algorithm use",
          "relevance": 0.4
        },
        {
          "concept": "exclusion",
          "relevance": 0.398
        },
        {
          "concept": "impact",
          "relevance": 0.396
        },
        {
          "concept": "reexamination",
          "relevance": 0.382
        },
        {
          "concept": "tension",
          "relevance": 0.372
        },
        {
          "concept": "emergent properties",
          "relevance": 0.371
        },
        {
          "concept": "inequality",
          "relevance": 0.367
        },
        {
          "concept": "hope",
          "relevance": 0.367
        },
        {
          "concept": "lens",
          "relevance": 0.365
        },
        {
          "concept": "title",
          "relevance": 0.364
        },
        {
          "concept": "guidelines",
          "relevance": 0.361
        },
        {
          "concept": "participants",
          "relevance": 0.35
        },
        {
          "concept": "programme",
          "relevance": 0.35
        },
        {
          "concept": "mining",
          "relevance": 0.348
        },
        {
          "concept": "data mining",
          "relevance": 0.348
        },
        {
          "concept": "relief",
          "relevance": 0.338
        },
        {
          "concept": "problem",
          "relevance": 0.336
        },
        {
          "concept": "algorithmic techniques",
          "relevance": 0.335
        },
        {
          "concept": "theory",
          "relevance": 0.33
        },
        {
          "concept": "choice",
          "relevance": 0.326
        },
        {
          "concept": "source",
          "relevance": 0.326
        },
        {
          "concept": "use",
          "relevance": 0.325
        },
        {
          "concept": "algorithm",
          "relevance": 0.323
        },
        {
          "concept": "bias",
          "relevance": 0.32
        },
        {
          "concept": "data",
          "relevance": 0.313
        },
        {
          "concept": "limitations",
          "relevance": 0.313
        },
        {
          "concept": "outcomes",
          "relevance": 0.312
        },
        {
          "concept": "data",
          "relevance": 0.291
        },
        {
          "concept": "historical data",
          "relevance": 0.279
        },
        {
          "concept": "absence",
          "relevance": 0.275
        },
        {
          "concept": "process",
          "relevance": 0.271
        },
        {
          "concept": "measurements",
          "relevance": 0.263
        },
        {
          "concept": "technique",
          "relevance": 0.241
        },
        {
          "concept": "discovery",
          "relevance": 0.24
        },
        {
          "concept": "regularization",
          "relevance": 0.237
        },
        {
          "concept": "terrain",
          "relevance": 0.232
        },
        {
          "concept": "group",
          "relevance": 0.226
        },
        {
          "concept": "deficiency",
          "relevance": 0.223
        },
        {
          "concept": "solution",
          "relevance": 0.2
        },
        {
          "concept": "properties",
          "relevance": 0.184
        },
        {
          "concept": "results",
          "relevance": 0.178
        },
        {
          "concept": "statistical correlation",
          "relevance": 0.177
        },
        {
          "concept": "correlation",
          "relevance": 0.143
        }
      ]
    },
    {
      "paperId": "pub.1084825219",
      "doi": "10.1126/science.aal4230",
      "title": "Semantics derived automatically from language corpora contain human-like biases",
      "year": 2017,
      "citationCount": 1776,
      "fieldCitationRatio": 949.85,
      "abstract": "Machine learning is a means to derive artificial intelligence by discovering patterns in existing data. Here, we show that applying machine learning to ordinary human language results in human-like semantic biases. We replicated a spectrum of known biases, as measured by the Implicit Association Test, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the World Wide Web. Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as toward insects or flowers, problematic as toward race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names. Our methods hold promise for identifying and addressing sources of bias in culture, including technology.",
      "reference_ids": [
        "pub.1050059401",
        "pub.1067630577",
        "pub.1064524350",
        "pub.1105674405",
        "pub.1010926018",
        "pub.1064524570",
        "pub.1034791051",
        "pub.1024894225",
        "pub.1048940580",
        "pub.1028227738",
        "pub.1101733512",
        "pub.1019465812",
        "pub.1099110523",
        "pub.1018124040",
        "pub.1029146593",
        "pub.1046457413"
      ],
      "concepts_scores": [
        {
          "concept": "machine learning",
          "relevance": 0.626
        },
        {
          "concept": "World Wide Web",
          "relevance": 0.58
        },
        {
          "concept": "language corpora",
          "relevance": 0.562
        },
        {
          "concept": "language results",
          "relevance": 0.556
        },
        {
          "concept": "standard corpus",
          "relevance": 0.555
        },
        {
          "concept": "text corpus",
          "relevance": 0.55
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.538
        },
        {
          "concept": "semantic bias",
          "relevance": 0.537
        },
        {
          "concept": "Wide Web",
          "relevance": 0.537
        },
        {
          "concept": "corpus",
          "relevance": 0.522
        },
        {
          "concept": "accurate imprints",
          "relevance": 0.486
        },
        {
          "concept": "historical bias",
          "relevance": 0.47
        },
        {
          "concept": "machine",
          "relevance": 0.46
        },
        {
          "concept": "learning",
          "relevance": 0.45
        },
        {
          "concept": "language",
          "relevance": 0.434
        },
        {
          "concept": "text",
          "relevance": 0.429
        },
        {
          "concept": "semantics",
          "relevance": 0.427
        },
        {
          "concept": "Implicit Association Test",
          "relevance": 0.422
        },
        {
          "concept": "intelligence",
          "relevance": 0.406
        },
        {
          "concept": "Web",
          "relevance": 0.404
        },
        {
          "concept": "gender",
          "relevance": 0.396
        },
        {
          "concept": "Association Test",
          "relevance": 0.383
        },
        {
          "concept": "culture",
          "relevance": 0.382
        },
        {
          "concept": "race",
          "relevance": 0.37
        },
        {
          "concept": "implicit",
          "relevance": 0.361
        },
        {
          "concept": "world",
          "relevance": 0.361
        },
        {
          "concept": "career",
          "relevance": 0.36
        },
        {
          "concept": "technology",
          "relevance": 0.36
        },
        {
          "concept": "results",
          "relevance": 0.321
        },
        {
          "concept": "method",
          "relevance": 0.319
        },
        {
          "concept": "status quo distribution",
          "relevance": 0.301
        },
        {
          "concept": "data",
          "relevance": 0.288
        },
        {
          "concept": "flowers",
          "relevance": 0.284
        },
        {
          "concept": "insects",
          "relevance": 0.281
        },
        {
          "concept": "sources of bias",
          "relevance": 0.278
        },
        {
          "concept": "bias",
          "relevance": 0.271
        },
        {
          "concept": "source",
          "relevance": 0.263
        },
        {
          "concept": "status",
          "relevance": 0.262
        },
        {
          "concept": "imprinting",
          "relevance": 0.259
        },
        {
          "concept": "patterns",
          "relevance": 0.248
        },
        {
          "concept": "distribution",
          "relevance": 0.231
        },
        {
          "concept": "test",
          "relevance": 0.226
        },
        {
          "concept": "spectra",
          "relevance": 0.193
        }
      ]
    },
    {
      "paperId": "pub.1124308279",
      "doi": "10.1145/3351095.3372873",
      "title": "Closing the AI accountability gap",
      "year": 2020,
      "citationCount": 666,
      "fieldCitationRatio": 143.84,
      "abstract": "Rising concern for the societal implications of artificial intelligence systems has inspired a wave of academic and journalistic literature in which deployed systems are audited for harm by investigators from outside the organizations deploying the algorithms. However, it remains challenging for practitioners to identify the harmful repercussions of their own systems prior to deployment, and, once deployed, emergent issues can become difficult or impossible to trace back to their source. In this paper, we introduce a framework for algorithmic auditing that supports artificial intelligence system development end-to-end, to be applied throughout the internal organization development life-cycle. Each stage of the audit yields a set of documents that together form an overall audit report, drawing on an organization's values or principles to assess the fit of decisions made throughout the process. The proposed auditing framework is intended to contribute to closing the accountability gap in the development and deployment of large-scale artificial intelligence systems by embedding a robust process to ensure audit integrity.",
      "reference_ids": [
        "pub.1023685415",
        "pub.1121582629",
        "pub.1106011386",
        "pub.1092227895",
        "pub.1002596470",
        "pub.1027565129",
        "pub.1079002399",
        "pub.1036631098",
        "pub.1079083959",
        "pub.1027063024",
        "pub.1117925571",
        "pub.1111334732",
        "pub.1091354647",
        "pub.1098713377",
        "pub.1117920726",
        "pub.1111334730",
        "pub.1002463699",
        "pub.1113132533",
        "pub.1035213833",
        "pub.1086043945",
        "pub.1036075909",
        "pub.1090841929",
        "pub.1091510492",
        "pub.1100409917",
        "pub.1036098465",
        "pub.1035603447",
        "pub.1047933561",
        "pub.1051180149",
        "pub.1101594069",
        "pub.1095764490",
        "pub.1100449028",
        "pub.1037658177",
        "pub.1111334697"
      ],
      "concepts_scores": [
        {
          "concept": "artificial intelligence systems",
          "relevance": 0.757
        },
        {
          "concept": "intelligent systems",
          "relevance": 0.717
        },
        {
          "concept": "development life cycle",
          "relevance": 0.676
        },
        {
          "concept": "end-to-end",
          "relevance": 0.667
        },
        {
          "concept": "audit integrity",
          "relevance": 0.623
        },
        {
          "concept": "deployed system",
          "relevance": 0.601
        },
        {
          "concept": "audit framework",
          "relevance": 0.595
        },
        {
          "concept": "accountability gap",
          "relevance": 0.555
        },
        {
          "concept": "audit report",
          "relevance": 0.547
        },
        {
          "concept": "organization's values",
          "relevance": 0.541
        },
        {
          "concept": "deployment",
          "relevance": 0.537
        },
        {
          "concept": "audit",
          "relevance": 0.507
        },
        {
          "concept": "framework",
          "relevance": 0.475
        },
        {
          "concept": "emergent issues",
          "relevance": 0.468
        },
        {
          "concept": "algorithm",
          "relevance": 0.467
        },
        {
          "concept": "system",
          "relevance": 0.46
        },
        {
          "concept": "societal implications",
          "relevance": 0.458
        },
        {
          "concept": "robust process",
          "relevance": 0.419
        },
        {
          "concept": "rising concerns",
          "relevance": 0.415
        },
        {
          "concept": "documents",
          "relevance": 0.412
        },
        {
          "concept": "life cycle",
          "relevance": 0.41
        },
        {
          "concept": "organization",
          "relevance": 0.404
        },
        {
          "concept": "decision",
          "relevance": 0.393
        },
        {
          "concept": "implications",
          "relevance": 0.386
        },
        {
          "concept": "accounts",
          "relevance": 0.376
        },
        {
          "concept": "practitioners",
          "relevance": 0.374
        },
        {
          "concept": "process",
          "relevance": 0.373
        },
        {
          "concept": "issues",
          "relevance": 0.368
        },
        {
          "concept": "gap",
          "relevance": 0.365
        },
        {
          "concept": "journalistic literature",
          "relevance": 0.36
        },
        {
          "concept": "integration",
          "relevance": 0.357
        },
        {
          "concept": "literature",
          "relevance": 0.34
        },
        {
          "concept": "repercussions",
          "relevance": 0.309
        },
        {
          "concept": "concerns",
          "relevance": 0.305
        },
        {
          "concept": "fitness",
          "relevance": 0.303
        },
        {
          "concept": "source",
          "relevance": 0.292
        },
        {
          "concept": "development",
          "relevance": 0.28
        },
        {
          "concept": "reports",
          "relevance": 0.262
        },
        {
          "concept": "stage",
          "relevance": 0.24
        },
        {
          "concept": "values",
          "relevance": 0.24
        },
        {
          "concept": "wave",
          "relevance": 0.204
        },
        {
          "concept": "investigation",
          "relevance": 0.181
        }
      ]
    },
    {
      "paperId": "pub.1095764490",
      "doi": "10.1109/iccv.2015.425",
      "title": "Deep Learning Face Attributes in the Wild**http://personal.ie.cuhk.edu.hk/~lz013/projects/FaceAttributes.html",
      "year": 2015,
      "citationCount": 5957,
      "fieldCitationRatio": 1309.89,
      "abstract": "Predicting face attributes in the wild is challenging due to complex face variations. We propose a novel deep learning framework for attribute prediction in the wild. It cascades two CNNs, LNet and ANet, which are fine-tuned jointly with attribute tags, but pre-trained differently. LNet is pre-trained by massive general object categories for face localization, while ANet is pre-trained by massive face identities for attribute prediction. This framework not only outperforms the state-of-the-art with a large margin, but also reveals valuable facts on learning face representation. (1) It shows how the performances of face localization (LNet) and attribute prediction (ANet) can be improved by different pre-training strategies. (2) It reveals that although the filters of LNet are fine-tuned only with image-level attribute tags, their response maps over entire images have strong indication of face locations. This fact enables training LNet for face localization with only image-level annotations, but without face bounding boxes or landmarks, which are required by all attribute recognition works. (3) It also demonstrates that the high-level hidden neurons of ANet automatically discover semantic concepts after pretraining with massive face identities, and such concepts are significantly enriched after fine-tuning with attribute tags. Each attribute can be well explained with a sparse linear combination of these concepts.",
      "reference_ids": [
        "pub.1033244218",
        "pub.1095648011",
        "pub.1095174197",
        "pub.1095689025",
        "pub.1011079920",
        "pub.1030406568",
        "pub.1093324540",
        "pub.1094053279",
        "pub.1093810850",
        "pub.1093492902",
        "pub.1093645378",
        "pub.1093301256",
        "pub.1094211775",
        "pub.1093704497",
        "pub.1093602754",
        "pub.1093603006",
        "pub.1015397249",
        "pub.1049590036",
        "pub.1013130399",
        "pub.1093337962",
        "pub.1093767478",
        "pub.1052782426",
        "pub.1095791039",
        "pub.1095774085"
      ],
      "concepts_scores": [
        {
          "concept": "face localization",
          "relevance": 0.715
        },
        {
          "concept": "face attributes",
          "relevance": 0.714
        },
        {
          "concept": "Predicting face attributes",
          "relevance": 0.672
        },
        {
          "concept": "complex face variations",
          "relevance": 0.672
        },
        {
          "concept": "learning face representations",
          "relevance": 0.672
        },
        {
          "concept": "face bounding boxes",
          "relevance": 0.671
        },
        {
          "concept": "image-level annotations",
          "relevance": 0.67
        },
        {
          "concept": "pre-training strategy",
          "relevance": 0.668
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.666
        },
        {
          "concept": "deep learning framework",
          "relevance": 0.659
        },
        {
          "concept": "face identity",
          "relevance": 0.641
        },
        {
          "concept": "bounding boxes",
          "relevance": 0.618
        },
        {
          "concept": "face variations",
          "relevance": 0.612
        },
        {
          "concept": "learning framework",
          "relevance": 0.611
        },
        {
          "concept": "semantic concepts",
          "relevance": 0.611
        },
        {
          "concept": "attribute tags",
          "relevance": 0.609
        },
        {
          "concept": "recognition work",
          "relevance": 0.609
        },
        {
          "concept": "face representation",
          "relevance": 0.605
        },
        {
          "concept": "face location",
          "relevance": 0.603
        },
        {
          "concept": "object categories",
          "relevance": 0.602
        },
        {
          "concept": "response map",
          "relevance": 0.565
        },
        {
          "concept": "LNET",
          "relevance": 0.55
        },
        {
          "concept": "tags",
          "relevance": 0.505
        },
        {
          "concept": "Anet",
          "relevance": 0.496
        },
        {
          "concept": "CNNs",
          "relevance": 0.483
        },
        {
          "concept": "framework",
          "relevance": 0.466
        },
        {
          "concept": "Deep",
          "relevance": 0.464
        },
        {
          "concept": "attributes",
          "relevance": 0.449
        },
        {
          "concept": "annotation",
          "relevance": 0.445
        },
        {
          "concept": "face",
          "relevance": 0.431
        },
        {
          "concept": "representation",
          "relevance": 0.426
        },
        {
          "concept": "concept",
          "relevance": 0.426
        },
        {
          "concept": "recognition",
          "relevance": 0.419
        },
        {
          "concept": "prediction",
          "relevance": 0.417
        },
        {
          "concept": "localization",
          "relevance": 0.408
        },
        {
          "concept": "filter",
          "relevance": 0.407
        },
        {
          "concept": "performance",
          "relevance": 0.401
        },
        {
          "concept": "images",
          "relevance": 0.398
        },
        {
          "concept": "training",
          "relevance": 0.398
        },
        {
          "concept": "maps",
          "relevance": 0.387
        },
        {
          "concept": "landmarks",
          "relevance": 0.379
        },
        {
          "concept": "wild",
          "relevance": 0.371
        },
        {
          "concept": "box",
          "relevance": 0.364
        },
        {
          "concept": "identity",
          "relevance": 0.323
        },
        {
          "concept": "location",
          "relevance": 0.323
        },
        {
          "concept": "categories",
          "relevance": 0.308
        },
        {
          "concept": "strategies",
          "relevance": 0.306
        },
        {
          "concept": "work",
          "relevance": 0.302
        },
        {
          "concept": "combination",
          "relevance": 0.269
        },
        {
          "concept": "variation",
          "relevance": 0.22
        },
        {
          "concept": "margin",
          "relevance": 0.218
        },
        {
          "concept": "indicators",
          "relevance": 0.212
        },
        {
          "concept": "response",
          "relevance": 0.204
        }
      ]
    },
    {
      "paperId": "pub.1111334730",
      "doi": "10.1145/3287560.3287596",
      "title": "Model Cards for Model Reporting",
      "year": 2019,
      "citationCount": 1456,
      "fieldCitationRatio": 356.64,
      "abstract": "Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.",
      "reference_ids": [
        "pub.1061630049",
        "pub.1117659503",
        "pub.1099239594",
        "pub.1095764490",
        "pub.1105229811",
        "pub.1111349442",
        "pub.1090992200",
        "pub.1011627113",
        "pub.1073742341"
      ],
      "concepts_scores": [
        {
          "concept": "train machine learning models",
          "relevance": 0.787
        },
        {
          "concept": "machine learning models",
          "relevance": 0.754
        },
        {
          "concept": "artificial intelligence technology",
          "relevance": 0.709
        },
        {
          "concept": "learning models",
          "relevance": 0.702
        },
        {
          "concept": "field of computer vision",
          "relevance": 0.658
        },
        {
          "concept": "intelligence technology",
          "relevance": 0.658
        },
        {
          "concept": "detect smiling faces",
          "relevance": 0.644
        },
        {
          "concept": "detect toxic comments",
          "relevance": 0.644
        },
        {
          "concept": "democratization of machine learning",
          "relevance": 0.644
        },
        {
          "concept": "natural language processing",
          "relevance": 0.632
        },
        {
          "concept": "model card",
          "relevance": 0.623
        },
        {
          "concept": "computer vision",
          "relevance": 0.591
        },
        {
          "concept": "toxic comments",
          "relevance": 0.59
        },
        {
          "concept": "application domains",
          "relevance": 0.586
        },
        {
          "concept": "short documents",
          "relevance": 0.583
        },
        {
          "concept": "language processing",
          "relevance": 0.575
        },
        {
          "concept": "machine learning",
          "relevance": 0.572
        },
        {
          "concept": "relevant documents",
          "relevance": 0.563
        },
        {
          "concept": "supervised models",
          "relevance": 0.558
        },
        {
          "concept": "application fields",
          "relevance": 0.521
        },
        {
          "concept": "high-impact tasks",
          "relevance": 0.518
        },
        {
          "concept": "performance evaluation procedure",
          "relevance": 0.517
        },
        {
          "concept": "relevant information",
          "relevance": 0.503
        },
        {
          "concept": "card",
          "relevance": 0.491
        },
        {
          "concept": "documents",
          "relevance": 0.47
        },
        {
          "concept": "evaluate number",
          "relevance": 0.462
        },
        {
          "concept": "framework",
          "relevance": 0.446
        },
        {
          "concept": "performance",
          "relevance": 0.444
        },
        {
          "concept": "evaluation procedure",
          "relevance": 0.443
        },
        {
          "concept": "increase transparency",
          "relevance": 0.443
        },
        {
          "concept": "technology",
          "relevance": 0.442
        },
        {
          "concept": "model reporting",
          "relevance": 0.44
        },
        {
          "concept": "applications",
          "relevance": 0.419
        },
        {
          "concept": "task",
          "relevance": 0.418
        },
        {
          "concept": "learning",
          "relevance": 0.411
        },
        {
          "concept": "model",
          "relevance": 0.399
        },
        {
          "concept": "vision",
          "relevance": 0.394
        },
        {
          "concept": "evaluation",
          "relevance": 0.391
        },
        {
          "concept": "usage",
          "relevance": 0.389
        },
        {
          "concept": "information",
          "relevance": 0.386
        },
        {
          "concept": "text",
          "relevance": 0.384
        },
        {
          "concept": "images",
          "relevance": 0.381
        },
        {
          "concept": "performance characteristics",
          "relevance": 0.372
        },
        {
          "concept": "context",
          "relevance": 0.367
        },
        {
          "concept": "domain",
          "relevance": 0.363
        },
        {
          "concept": "face",
          "relevance": 0.356
        },
        {
          "concept": "law enforcement",
          "relevance": 0.354
        },
        {
          "concept": "intersectional groups",
          "relevance": 0.344
        },
        {
          "concept": "concept",
          "relevance": 0.335
        },
        {
          "concept": "transparency",
          "relevance": 0.331
        },
        {
          "concept": "process",
          "relevance": 0.302
        },
        {
          "concept": "comments",
          "relevance": 0.302
        },
        {
          "concept": "enforcement",
          "relevance": 0.279
        },
        {
          "concept": "number",
          "relevance": 0.249
        },
        {
          "concept": "area",
          "relevance": 0.244
        },
        {
          "concept": "characteristics",
          "relevance": 0.244
        },
        {
          "concept": "cases",
          "relevance": 0.243
        },
        {
          "concept": "procedure",
          "relevance": 0.238
        },
        {
          "concept": "democratization",
          "relevance": 0.22
        },
        {
          "concept": "education",
          "relevance": 0.208
        },
        {
          "concept": "law",
          "relevance": 0.206
        },
        {
          "concept": "release model",
          "relevance": 0.196
        },
        {
          "concept": "conditions",
          "relevance": 0.194
        },
        {
          "concept": "medicine",
          "relevance": 0.184
        },
        {
          "concept": "phenotypic groups",
          "relevance": 0.183
        },
        {
          "concept": "employment",
          "relevance": 0.178
        },
        {
          "concept": "group",
          "relevance": 0.172
        },
        {
          "concept": "reports",
          "relevance": 0.166
        }
      ]
    },
    {
      "paperId": "pub.1145635007",
      "doi": "10.1093/oso/9780192845290.001.0001",
      "title": "Human-Centered AI",
      "year": 2022,
      "citationCount": 400,
      "fieldCitationRatio": 172.73,
      "abstract": "Abstract Researchers, developers, business leaders, policy makers, and others are expanding the technology-centered scope of artificial intelligence (AI) to include human-centered AI (HCAI) ways of thinking. This expansion from an algorithm-focused view to embrace a human-centered perspective can shape the future of technology so as to better serve human needs. Educators, designers, software engineers, product managers, evaluators, and government agency staffers can build on AI-driven technologies to design products and services that make life better for people and enable people to care for each other. Humans have always been tool builders, and now they are supertool builders, whose inventions can improve our health, family life, education, business, the environment, and much more. The remarkable progress in algorithms for machine and deep learning have opened the doors to new opportunities, and some dark possibilities. However, a bright future awaits AI researchers, developers, business leaders, policy makers, and others who build on their working methods by including HCAI strategies of design and testing. This enlarged vision can shape the future of technology so as to better serve human needs. As many technology companies and thought leaders have said, the goal is not to replace people, but to empower them by making design choices that give humans control over technology.",
      "reference_ids": [
        "pub.1085775000",
        "pub.1131344354",
        "pub.1112253333",
        "pub.1061429731",
        "pub.1073454197",
        "pub.1064395048",
        "pub.1114160691",
        "pub.1115028521",
        "pub.1123007193",
        "pub.1131824735",
        "pub.1061614792",
        "pub.1110192280",
        "pub.1095217374",
        "pub.1105383002",
        "pub.1124770667",
        "pub.1132317176",
        "pub.1113814546",
        "pub.1137857482",
        "pub.1108386892",
        "pub.1120984877",
        "pub.1084035154",
        "pub.1131824692",
        "pub.1120682811",
        "pub.1018569007",
        "pub.1043784543",
        "pub.1104202417",
        "pub.1128046116",
        "pub.1129025153",
        "pub.1122817391",
        "pub.1134080694",
        "pub.1015839466",
        "pub.1005319597",
        "pub.1111914793",
        "pub.1130238137",
        "pub.1073469105",
        "pub.1110383569",
        "pub.1101140581",
        "pub.1123555678",
        "pub.1134702644",
        "pub.1061814554",
        "pub.1079405891",
        "pub.1048183025",
        "pub.1107307488",
        "pub.1016529976",
        "pub.1112315759",
        "pub.1110510908",
        "pub.1122312117",
        "pub.1113814587",
        "pub.1113814698",
        "pub.1006825520",
        "pub.1064039882",
        "pub.1135357963",
        "pub.1125504169",
        "pub.1099677497",
        "pub.1111334730",
        "pub.1120316165",
        "pub.1061406450",
        "pub.1135555448",
        "pub.1091274422",
        "pub.1125043835",
        "pub.1129690716",
        "pub.1105857474",
        "pub.1061185299",
        "pub.1129334203",
        "pub.1122988592",
        "pub.1006066692",
        "pub.1101396435",
        "pub.1008175277",
        "pub.1003655048",
        "pub.1121233604",
        "pub.1032162237",
        "pub.1120375577",
        "pub.1037740260",
        "pub.1127963207",
        "pub.1127963385",
        "pub.1109653374",
        "pub.1117603627",
        "pub.1014682843",
        "pub.1120198075",
        "pub.1000700641",
        "pub.1113309559",
        "pub.1134770155",
        "pub.1057897337",
        "pub.1091274319",
        "pub.1032397665",
        "pub.1090774763",
        "pub.1120252609",
        "pub.1033794754",
        "pub.1111372013",
        "pub.1124115663",
        "pub.1090572055",
        "pub.1125113158",
        "pub.1127963378",
        "pub.1061405775",
        "pub.1095414430",
        "pub.1111938179",
        "pub.1110645643",
        "pub.1122068379",
        "pub.1111334708",
        "pub.1125017478",
        "pub.1061385976",
        "pub.1113814620",
        "pub.1125206405",
        "pub.1111334723",
        "pub.1129092388",
        "pub.1127360705",
        "pub.1105241309",
        "pub.1009278427",
        "pub.1091347095",
        "pub.1073281377",
        "pub.1120106028",
        "pub.1104571224",
        "pub.1003107234",
        "pub.1058230770",
        "pub.1092393324",
        "pub.1117626339",
        "pub.1050891747",
        "pub.1127379614",
        "pub.1128046093",
        "pub.1131824722",
        "pub.1115961743",
        "pub.1092050424",
        "pub.1120249897",
        "pub.1125652438",
        "pub.1086041350",
        "pub.1092081310",
        "pub.1107633480",
        "pub.1117678692",
        "pub.1035838871",
        "pub.1101475942",
        "pub.1129157560",
        "pub.1040568508",
        "pub.1113813993",
        "pub.1061185331",
        "pub.1104384297",
        "pub.1093392818",
        "pub.1162717568",
        "pub.1130210457",
        "pub.1127963198",
        "pub.1113814566",
        "pub.1099971369",
        "pub.1103067401",
        "pub.1009497615",
        "pub.1113814588",
        "pub.1150866207",
        "pub.1124308279",
        "pub.1123272682",
        "pub.1122784938",
        "pub.1112875972",
        "pub.1128667983",
        "pub.1061797749",
        "pub.1092723101",
        "pub.1061657665",
        "pub.1127166807",
        "pub.1131360260",
        "pub.1061157752",
        "pub.1130302389",
        "pub.1035689290",
        "pub.1020852032",
        "pub.1003357096",
        "pub.1101627203",
        "pub.1106346583",
        "pub.1122460182",
        "pub.1085232439",
        "pub.1121176811",
        "pub.1043698876",
        "pub.1040311004",
        "pub.1046458977",
        "pub.1112250107",
        "pub.1131656020",
        "pub.1048355292",
        "pub.1073283444",
        "pub.1120411188",
        "pub.1122385335",
        "pub.1037103192",
        "pub.1032334987",
        "pub.1101395499",
        "pub.1108128499",
        "pub.1095661696",
        "pub.1117296273",
        "pub.1124608048",
        "pub.1127263869",
        "pub.1093490478",
        "pub.1104597912",
        "pub.1127907771",
        "pub.1061405983",
        "pub.1085641906",
        "pub.1113363075",
        "pub.1006998069",
        "pub.1073601756",
        "pub.1091510492",
        "pub.1120522246",
        "pub.1113813992",
        "pub.1121691323",
        "pub.1105537014",
        "pub.1094991807",
        "pub.1025185982",
        "pub.1125828477",
        "pub.1107865769",
        "pub.1127963210",
        "pub.1139800731",
        "pub.1110724076",
        "pub.1092243991"
      ],
      "concepts_scores": [
        {
          "concept": "human-centered AI",
          "relevance": 0.778
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.667
        },
        {
          "concept": "future of technology",
          "relevance": 0.637
        },
        {
          "concept": "human-centered perspective",
          "relevance": 0.612
        },
        {
          "concept": "software engineering",
          "relevance": 0.601
        },
        {
          "concept": "deep learning",
          "relevance": 0.589
        },
        {
          "concept": "AI research",
          "relevance": 0.586
        },
        {
          "concept": "tool builders",
          "relevance": 0.572
        },
        {
          "concept": "replace people",
          "relevance": 0.565
        },
        {
          "concept": "design choices",
          "relevance": 0.555
        },
        {
          "concept": "technology companies",
          "relevance": 0.525
        },
        {
          "concept": "human control",
          "relevance": 0.509
        },
        {
          "concept": "business",
          "relevance": 0.481
        },
        {
          "concept": "technology",
          "relevance": 0.48
        },
        {
          "concept": "design products",
          "relevance": 0.479
        },
        {
          "concept": "production management",
          "relevance": 0.475
        },
        {
          "concept": "algorithm",
          "relevance": 0.443
        },
        {
          "concept": "intelligence",
          "relevance": 0.435
        },
        {
          "concept": "software",
          "relevance": 0.431
        },
        {
          "concept": "business leaders",
          "relevance": 0.425
        },
        {
          "concept": "machine",
          "relevance": 0.425
        },
        {
          "concept": "learning",
          "relevance": 0.416
        },
        {
          "concept": "design",
          "relevance": 0.415
        },
        {
          "concept": "builders",
          "relevance": 0.405
        },
        {
          "concept": "darker possibilities",
          "relevance": 0.404
        },
        {
          "concept": "vision",
          "relevance": 0.399
        },
        {
          "concept": "services",
          "relevance": 0.388
        },
        {
          "concept": "human needs",
          "relevance": 0.382
        },
        {
          "concept": "working methods",
          "relevance": 0.378
        },
        {
          "concept": "research",
          "relevance": 0.364
        },
        {
          "concept": "environment",
          "relevance": 0.363
        },
        {
          "concept": "makers",
          "relevance": 0.362
        },
        {
          "concept": "needs",
          "relevance": 0.358
        },
        {
          "concept": "engineering",
          "relevance": 0.353
        },
        {
          "concept": "tools",
          "relevance": 0.353
        },
        {
          "concept": "people",
          "relevance": 0.35
        },
        {
          "concept": "companies",
          "relevance": 0.35
        },
        {
          "concept": "strategies of design",
          "relevance": 0.346
        },
        {
          "concept": "goal",
          "relevance": 0.346
        },
        {
          "concept": "evaluation",
          "relevance": 0.342
        },
        {
          "concept": "method",
          "relevance": 0.341
        },
        {
          "concept": "doors",
          "relevance": 0.339
        },
        {
          "concept": "views",
          "relevance": 0.337
        },
        {
          "concept": "Abstract Research",
          "relevance": 0.322
        },
        {
          "concept": "future",
          "relevance": 0.311
        },
        {
          "concept": "family life",
          "relevance": 0.31
        },
        {
          "concept": "development",
          "relevance": 0.307
        },
        {
          "concept": "humans",
          "relevance": 0.305
        },
        {
          "concept": "staffers",
          "relevance": 0.304
        },
        {
          "concept": "SuperTools",
          "relevance": 0.304
        },
        {
          "concept": "invention",
          "relevance": 0.304
        },
        {
          "concept": "policy makers",
          "relevance": 0.303
        },
        {
          "concept": "leaders",
          "relevance": 0.299
        },
        {
          "concept": "education",
          "relevance": 0.297
        },
        {
          "concept": "management",
          "relevance": 0.297
        },
        {
          "concept": "work",
          "relevance": 0.292
        },
        {
          "concept": "life",
          "relevance": 0.291
        },
        {
          "concept": "thinking",
          "relevance": 0.29
        },
        {
          "concept": "perspective",
          "relevance": 0.29
        },
        {
          "concept": "policy",
          "relevance": 0.286
        },
        {
          "concept": "opportunities",
          "relevance": 0.284
        },
        {
          "concept": "possibilities",
          "relevance": 0.282
        },
        {
          "concept": "Abstract",
          "relevance": 0.281
        },
        {
          "concept": "choice",
          "relevance": 0.264
        },
        {
          "concept": "enlarged vision",
          "relevance": 0.254
        },
        {
          "concept": "control",
          "relevance": 0.244
        },
        {
          "concept": "test",
          "relevance": 0.242
        },
        {
          "concept": "government",
          "relevance": 0.221
        },
        {
          "concept": "production",
          "relevance": 0.211
        },
        {
          "concept": "expansion",
          "relevance": 0.203
        },
        {
          "concept": "progression",
          "relevance": 0.192
        },
        {
          "concept": "health",
          "relevance": 0.183
        },
        {
          "concept": "family",
          "relevance": 0.157
        }
      ]
    },
    {
      "paperId": "pub.1131360260",
      "doi": "10.1007/s12525-020-00441-4",
      "title": "Trustworthy artificial intelligence",
      "year": 2020,
      "citationCount": 418,
      "fieldCitationRatio": 111.29,
      "abstract": "Artificial intelligence (AI) brings forth many opportunities to contribute to the wellbeing of individuals and the advancement of economies and societies, but also a variety of novel ethical, legal, social, and technological challenges. Trustworthy AI (TAI) bases on the idea that trust builds the foundation of societies, economies, and sustainable development, and that individuals, organizations, and societies will therefore only ever be able to realize the full potential of AI, if trust can be established in its development, deployment, and use. With this article we aim to introduce the concept of TAI and its five foundational principles (1) beneficence, (2) non-maleficence, (3) autonomy, (4) justice, and (5) explicability. We further draw on these five principles to develop a data-driven research framework for TAI and demonstrate its utility by delineating fruitful avenues for future research, particularly with regard to the distributed ledger technology-based realization of TAI.",
      "reference_ids": [
        "pub.1125324085",
        "pub.1002940167",
        "pub.1064711672",
        "pub.1120999688",
        "pub.1084526515",
        "pub.1112265786",
        "pub.1125721088",
        "pub.1024547281",
        "pub.1117984215",
        "pub.1046591658",
        "pub.1107064439",
        "pub.1044032450",
        "pub.1128105278",
        "pub.1107416904",
        "pub.1123980249",
        "pub.1121050328",
        "pub.1123119283",
        "pub.1110751760",
        "pub.1113670299",
        "pub.1085745659",
        "pub.1102515265",
        "pub.1105796481",
        "pub.1073126321",
        "pub.1120993537",
        "pub.1104996018",
        "pub.1001146272",
        "pub.1120701607",
        "pub.1124666384",
        "pub.1107416898",
        "pub.1100093825",
        "pub.1020852032",
        "pub.1110767090",
        "pub.1123468592",
        "pub.1118105134",
        "pub.1095757637",
        "pub.1067597755",
        "pub.1112117401",
        "pub.1100731524",
        "pub.1125715868",
        "pub.1122068379",
        "pub.1123669031",
        "pub.1120763348",
        "pub.1070818406",
        "pub.1121012557",
        "pub.1124845491",
        "pub.1114160691",
        "pub.1100850538",
        "pub.1099317522",
        "pub.1109827414",
        "pub.1117678679",
        "pub.1109867218",
        "pub.1102515207",
        "pub.1110098979",
        "pub.1100818062",
        "pub.1021796137",
        "pub.1120396052",
        "pub.1092016470",
        "pub.1103975456",
        "pub.1072898521",
        "pub.1042616083",
        "pub.1117307665",
        "pub.1110192280",
        "pub.1083643339",
        "pub.1061600426",
        "pub.1061157752",
        "pub.1068001166",
        "pub.1018068907",
        "pub.1121879794",
        "pub.1124484286",
        "pub.1110997632",
        "pub.1051894738",
        "pub.1105975661",
        "pub.1121096073",
        "pub.1061423981",
        "pub.1005525522",
        "pub.1113866248",
        "pub.1111760702",
        "pub.1113957228",
        "pub.1064711171"
      ],
      "concepts_scores": [
        {
          "concept": "trustworthy AI",
          "relevance": 0.614
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.56
        },
        {
          "concept": "concept of trustworthy AI",
          "relevance": 0.519
        },
        {
          "concept": "potential of AI",
          "relevance": 0.512
        },
        {
          "concept": "non-maleficence",
          "relevance": 0.508
        },
        {
          "concept": "foundational principles",
          "relevance": 0.505
        },
        {
          "concept": "sustainable development",
          "relevance": 0.451
        },
        {
          "concept": "society",
          "relevance": 0.443
        },
        {
          "concept": "wellbeing of individuals",
          "relevance": 0.424
        },
        {
          "concept": "advancement of economy",
          "relevance": 0.422
        },
        {
          "concept": "justice",
          "relevance": 0.415
        },
        {
          "concept": "trust",
          "relevance": 0.408
        },
        {
          "concept": "beneficence",
          "relevance": 0.399
        },
        {
          "concept": "data-driven research framework",
          "relevance": 0.398
        },
        {
          "concept": "research framework",
          "relevance": 0.398
        },
        {
          "concept": "technological challenges",
          "relevance": 0.393
        },
        {
          "concept": "economy",
          "relevance": 0.386
        },
        {
          "concept": "autonomy",
          "relevance": 0.381
        },
        {
          "concept": "ethics",
          "relevance": 0.371
        },
        {
          "concept": "deployment",
          "relevance": 0.369
        },
        {
          "concept": "intelligence",
          "relevance": 0.365
        },
        {
          "concept": "explication",
          "relevance": 0.362
        },
        {
          "concept": "trustworthiness",
          "relevance": 0.36
        },
        {
          "concept": "principles",
          "relevance": 0.353
        },
        {
          "concept": "individuals",
          "relevance": 0.342
        },
        {
          "concept": "framework",
          "relevance": 0.327
        },
        {
          "concept": "concept",
          "relevance": 0.313
        },
        {
          "concept": "opportunities",
          "relevance": 0.297
        },
        {
          "concept": "challenges",
          "relevance": 0.296
        },
        {
          "concept": "development",
          "relevance": 0.296
        },
        {
          "concept": "wellbeing",
          "relevance": 0.292
        },
        {
          "concept": "basis",
          "relevance": 0.286
        },
        {
          "concept": "research",
          "relevance": 0.285
        },
        {
          "concept": "organization",
          "relevance": 0.278
        },
        {
          "concept": "advances",
          "relevance": 0.266
        },
        {
          "concept": "potential",
          "relevance": 0.174
        }
      ]
    },
    {
      "paperId": "pub.1123669031",
      "doi": "10.1016/j.inffus.2019.12.012",
      "title": "Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI",
      "year": 2020,
      "citationCount": 6325,
      "fieldCitationRatio": 1771.33,
      "abstract": "In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.",
      "reference_ids": [
        "pub.1042615414",
        "pub.1061219401",
        "pub.1096023874",
        "pub.1101733512",
        "pub.1021170941",
        "pub.1028400209",
        "pub.1035528476",
        "pub.1094742232",
        "pub.1035358834",
        "pub.1123987987",
        "pub.1095158054",
        "pub.1005513000",
        "pub.1019836050",
        "pub.1050689977",
        "pub.1093967349",
        "pub.1107085681",
        "pub.1064395048",
        "pub.1098961911",
        "pub.1045871111",
        "pub.1011966477",
        "pub.1085411942",
        "pub.1094183945",
        "pub.1096024397",
        "pub.1034724024",
        "pub.1021865543",
        "pub.1061542200",
        "pub.1105267403",
        "pub.1107990161",
        "pub.1092587583",
        "pub.1102440210",
        "pub.1061121888",
        "pub.1100517402",
        "pub.1148881484",
        "pub.1098652939",
        "pub.1093687173",
        "pub.1028574329",
        "pub.1112109249",
        "pub.1018631941",
        "pub.1019158257",
        "pub.1085775000",
        "pub.1098665577",
        "pub.1111517565",
        "pub.1111154371",
        "pub.1020955997",
        "pub.1064025762",
        "pub.1095432752",
        "pub.1091495976",
        "pub.1049316471",
        "pub.1039556427",
        "pub.1091931489",
        "pub.1100060361",
        "pub.1111349438",
        "pub.1047909927",
        "pub.1051180149",
        "pub.1024210546",
        "pub.1107454647",
        "pub.1058368938",
        "pub.1090432178",
        "pub.1095849131",
        "pub.1111918634",
        "pub.1106333613",
        "pub.1061814814",
        "pub.1027649710",
        "pub.1000549865",
        "pub.1112776877",
        "pub.1014825862",
        "pub.1049258745",
        "pub.1061716988",
        "pub.1083871624",
        "pub.1099502981",
        "pub.1095147768",
        "pub.1120935870",
        "pub.1004370089",
        "pub.1130542975",
        "pub.1148956109",
        "pub.1011249939",
        "pub.1001242466",
        "pub.1001327449",
        "pub.1038436955",
        "pub.1002371134",
        "pub.1095620157",
        "pub.1084847747",
        "pub.1041537446",
        "pub.1011106895",
        "pub.1002229238",
        "pub.1032944518",
        "pub.1042422861",
        "pub.1061219349",
        "pub.1084499265",
        "pub.1100465649",
        "pub.1124427266",
        "pub.1061661777",
        "pub.1061213767",
        "pub.1086112618",
        "pub.1042839861",
        "pub.1000169726",
        "pub.1049363904",
        "pub.1092081310",
        "pub.1111888884",
        "pub.1092353421",
        "pub.1110721054",
        "pub.1007845652",
        "pub.1104321291",
        "pub.1054490623",
        "pub.1102379781",
        "pub.1061218950",
        "pub.1093827000",
        "pub.1018424047",
        "pub.1123988581",
        "pub.1046196687",
        "pub.1107019541",
        "pub.1098652906",
        "pub.1094486642",
        "pub.1099928651",
        "pub.1039257850",
        "pub.1009182784",
        "pub.1022738538",
        "pub.1037368667",
        "pub.1100060663",
        "pub.1110458978",
        "pub.1127315100",
        "pub.1041744898",
        "pub.1020867876",
        "pub.1006790092",
        "pub.1042480730",
        "pub.1046964746",
        "pub.1008011122",
        "pub.1107635307",
        "pub.1093623258",
        "pub.1033292604",
        "pub.1047492925",
        "pub.1101456014",
        "pub.1111334730",
        "pub.1120413212",
        "pub.1107463234",
        "pub.1095379032",
        "pub.1124770667",
        "pub.1033755585",
        "pub.1024247269",
        "pub.1041355599",
        "pub.1094870718",
        "pub.1061219090",
        "pub.1092345755",
        "pub.1123988409",
        "pub.1110721049",
        "pub.1090427213",
        "pub.1095085510",
        "pub.1105109777",
        "pub.1025096580",
        "pub.1058305389",
        "pub.1092684559",
        "pub.1110300503",
        "pub.1092182412",
        "pub.1032233097",
        "pub.1040632585",
        "pub.1045055595",
        "pub.1106005146",
        "pub.1124428668",
        "pub.1026373856",
        "pub.1055413683",
        "pub.1106289667",
        "pub.1025388351",
        "pub.1058285916",
        "pub.1051509580",
        "pub.1000480902",
        "pub.1091100372",
        "pub.1086115539",
        "pub.1029222403",
        "pub.1094986107",
        "pub.1095367828",
        "pub.1034441287",
        "pub.1093727695",
        "pub.1094587181",
        "pub.1107064439",
        "pub.1093730551",
        "pub.1093645378",
        "pub.1107865769",
        "pub.1016388523",
        "pub.1132261472",
        "pub.1047400580",
        "pub.1086116230",
        "pub.1019445570",
        "pub.1018972392",
        "pub.1034925587",
        "pub.1109815019",
        "pub.1110300502",
        "pub.1036446674",
        "pub.1114160691",
        "pub.1017737903",
        "pub.1032525280",
        "pub.1094413522",
        "pub.1061656512",
        "pub.1107591702",
        "pub.1114223398",
        "pub.1094589663",
        "pub.1098653311",
        "pub.1110300507",
        "pub.1095602201",
        "pub.1044216575",
        "pub.1049022804",
        "pub.1049901803",
        "pub.1093270996",
        "pub.1111349489",
        "pub.1111399924",
        "pub.1094697112",
        "pub.1021464684",
        "pub.1071056988",
        "pub.1005068793",
        "pub.1084786277",
        "pub.1094679398",
        "pub.1119942183",
        "pub.1098668582",
        "pub.1110721001",
        "pub.1110269462",
        "pub.1019422208",
        "pub.1110720309",
        "pub.1052693282",
        "pub.1130877123",
        "pub.1028872103",
        "pub.1093861070",
        "pub.1122065554",
        "pub.1061742933",
        "pub.1091931494",
        "pub.1031639131",
        "pub.1049302469",
        "pub.1110374450",
        "pub.1115422863",
        "pub.1105723696",
        "pub.1111376308",
        "pub.1091454711",
        "pub.1107651665",
        "pub.1053201614",
        "pub.1061193342",
        "pub.1100481780",
        "pub.1148956119",
        "pub.1148955576",
        "pub.1001658848",
        "pub.1012542794",
        "pub.1104315667",
        "pub.1042123527",
        "pub.1108236251",
        "pub.1105386282",
        "pub.1023195388",
        "pub.1051425387",
        "pub.1043059560",
        "pub.1099151187",
        "pub.1044718751",
        "pub.1106875674",
        "pub.1086114628",
        "pub.1061661685",
        "pub.1003144799",
        "pub.1020311129",
        "pub.1122290267",
        "pub.1046812635",
        "pub.1101491119",
        "pub.1033024038"
      ],
      "concepts_scores": [
        {
          "concept": "field of XAI",
          "relevance": 0.774
        },
        {
          "concept": "artificial intelligence",
          "relevance": 0.761
        },
        {
          "concept": "machine learning",
          "relevance": 0.746
        },
        {
          "concept": "implementation of AI methods",
          "relevance": 0.709
        },
        {
          "concept": "barrier of explainability",
          "relevance": 0.69
        },
        {
          "concept": "Explainable Artificial Intelligence",
          "relevance": 0.68
        },
        {
          "concept": "hype of AI",
          "relevance": 0.677
        },
        {
          "concept": "Responsible Artificial Intelligence",
          "relevance": 0.677
        },
        {
          "concept": "deep learning methods",
          "relevance": 0.673
        },
        {
          "concept": "machine learning models",
          "relevance": 0.648
        },
        {
          "concept": "benefits of AI",
          "relevance": 0.631
        },
        {
          "concept": "sub-symbols",
          "relevance": 0.628
        },
        {
          "concept": "practical deployment",
          "relevance": 0.625
        },
        {
          "concept": "model explainability",
          "relevance": 0.62
        },
        {
          "concept": "learning methods",
          "relevance": 0.613
        },
        {
          "concept": "data fusion",
          "relevance": 0.613
        },
        {
          "concept": "AI methods",
          "relevance": 0.613
        },
        {
          "concept": "XAI",
          "relevance": 0.612
        },
        {
          "concept": "AI models",
          "relevance": 0.608
        },
        {
          "concept": "learning models",
          "relevance": 0.603
        },
        {
          "concept": "explainability",
          "relevance": 0.601
        },
        {
          "concept": "problem fall",
          "relevance": 0.575
        },
        {
          "concept": "intelligence",
          "relevance": 0.561
        },
        {
          "concept": "machine",
          "relevance": 0.558
        },
        {
          "concept": "learning",
          "relevance": 0.537
        },
        {
          "concept": "taxonomy",
          "relevance": 0.497
        },
        {
          "concept": "Deep",
          "relevance": 0.476
        },
        {
          "concept": "literature analysis",
          "relevance": 0.462
        },
        {
          "concept": "Artificial",
          "relevance": 0.449
        },
        {
          "concept": "data",
          "relevance": 0.447
        },
        {
          "concept": "fairness",
          "relevance": 0.445
        },
        {
          "concept": "hype",
          "relevance": 0.429
        },
        {
          "concept": "implementation",
          "relevance": 0.425
        },
        {
          "concept": "method",
          "relevance": 0.419
        },
        {
          "concept": "concept",
          "relevance": 0.417
        },
        {
          "concept": "model",
          "relevance": 0.416
        },
        {
          "concept": "experts",
          "relevance": 0.41
        },
        {
          "concept": "paradigm",
          "relevance": 0.407
        },
        {
          "concept": "definition",
          "relevance": 0.406
        },
        {
          "concept": "research advances",
          "relevance": 0.398
        },
        {
          "concept": "fusion",
          "relevance": 0.383
        },
        {
          "concept": "technique",
          "relevance": 0.368
        },
        {
          "concept": "goal",
          "relevance": 0.367
        },
        {
          "concept": "field",
          "relevance": 0.36
        },
        {
          "concept": "motivational background",
          "relevance": 0.358
        },
        {
          "concept": "methodology",
          "relevance": 0.358
        },
        {
          "concept": "challenges",
          "relevance": 0.352
        },
        {
          "concept": "conceptual propositions",
          "relevance": 0.345
        },
        {
          "concept": "activity sectors",
          "relevance": 0.345
        },
        {
          "concept": "contribution",
          "relevance": 0.339
        },
        {
          "concept": "advances",
          "relevance": 0.336
        },
        {
          "concept": "proposition",
          "relevance": 0.335
        },
        {
          "concept": "disciplines",
          "relevance": 0.335
        },
        {
          "concept": "overview",
          "relevance": 0.332
        },
        {
          "concept": "literature",
          "relevance": 0.331
        },
        {
          "concept": "newcomers",
          "relevance": 0.325
        },
        {
          "concept": "benefits",
          "relevance": 0.309
        },
        {
          "concept": "background",
          "relevance": 0.303
        },
        {
          "concept": "opportunities",
          "relevance": 0.301
        },
        {
          "concept": "core",
          "relevance": 0.301
        },
        {
          "concept": "audience",
          "relevance": 0.299
        },
        {
          "concept": "sector",
          "relevance": 0.298
        },
        {
          "concept": "interpretation",
          "relevance": 0.28
        },
        {
          "concept": "professionals",
          "relevance": 0.269
        },
        {
          "concept": "expectations",
          "relevance": 0.265
        },
        {
          "concept": "community",
          "relevance": 0.265
        },
        {
          "concept": "analysis",
          "relevance": 0.259
        },
        {
          "concept": "organization",
          "relevance": 0.259
        },
        {
          "concept": "momentum",
          "relevance": 0.237
        },
        {
          "concept": "accounts",
          "relevance": 0.236
        },
        {
          "concept": "bias",
          "relevance": 0.23
        },
        {
          "concept": "years",
          "relevance": 0.195
        },
        {
          "concept": "barriers",
          "relevance": 0.173
        },
        {
          "concept": "fall",
          "relevance": 0.169
        },
        {
          "concept": "activity",
          "relevance": 0.169
        },
        {
          "concept": "materials",
          "relevance": 0.155
        },
        {
          "concept": "problem",
          "relevance": 0.136
        }
      ]
    },
    {
      "paperId": "pub.1137857482",
      "doi": "10.1145/3411764.3445188",
      "title": "Expanding Explainability: Towards Social Transparency in AI systems",
      "year": 2021,
      "citationCount": 365,
      "fieldCitationRatio": 115.59,
      "abstract": "As AI-powered systems increasingly mediate consequential decision-making, their explainability is critical for end-users to take informed and accountable actions. Explanations in human-human interactions are socially-situated. AI systems are often socio-organizationally embedded. However, Explainable AI (XAI) approaches have been predominantly algorithm-centered. We take a developmental step towards socially-situated XAI by introducing and exploring Social Transparency (ST), a sociotechnically informed perspective that incorporates the socio-organizational context into explaining AI-mediated decision-making. To explore ST conceptually, we conducted interviews with 29 AI users and practitioners grounded in a speculative design scenario. We suggested constitutive design elements of ST and developed a conceptual framework to unpack ST’s effect and implications at the technical, decision-making, and organizational level. The framework showcases how ST can potentially calibrate trust in AI, improve decision-making, facilitate organizational collective actions, and cultivate holistic explainability. Our work contributes to the discourse of Human-Centered XAI by expanding the design space of XAI.",
      "reference_ids": [
        "pub.1041917065",
        "pub.1130542975",
        "pub.1027709117",
        "pub.1085641906",
        "pub.1052019283",
        "pub.1122420462",
        "pub.1122420499",
        "pub.1127963385",
        "pub.1125414336",
        "pub.1034769792",
        "pub.1111334708",
        "pub.1029399728",
        "pub.1124267278",
        "pub.1127963419",
        "pub.1008214926",
        "pub.1035330195",
        "pub.1107865769",
        "pub.1069908683",
        "pub.1030083846",
        "pub.1042154811",
        "pub.1124308276",
        "pub.1125828477",
        "pub.1119901816",
        "pub.1117925590",
        "pub.1009456115",
        "pub.1020529936",
        "pub.1127963666",
        "pub.1007448100",
        "pub.1103568851",
        "pub.1112250105",
        "pub.1091265606",
        "pub.1042389336",
        "pub.1111334732",
        "pub.1017062356",
        "pub.1113814546",
        "pub.1020754614",
        "pub.1034508394",
        "pub.1120513163",
        "pub.1125414318",
        "pub.1040848892",
        "pub.1127963410",
        "pub.1107972253",
        "pub.1023444419",
        "pub.1124267275",
        "pub.1019320865",
        "pub.1123669031",
        "pub.1094066088",
        "pub.1102411000",
        "pub.1043347890",
        "pub.1113814225",
        "pub.1103568374",
        "pub.1124308280",
        "pub.1128046116",
        "pub.1111918634",
        "pub.1115028521",
        "pub.1112250111",
        "pub.1130334241",
        "pub.1112250084",
        "pub.1127963016",
        "pub.1123285712",
        "pub.1150206963",
        "pub.1043744400",
        "pub.1113814588",
        "pub.1101482506",
        "pub.1125414357",
        "pub.1129021568",
        "pub.1011785128",
        "pub.1109721220",
        "pub.1029614420",
        "pub.1050259071",
        "pub.1044097311",
        "pub.1039779306"
      ],
      "concepts_scores": [
        {
          "concept": "social transparency",
          "relevance": 0.674
        },
        {
          "concept": "AI systems",
          "relevance": 0.668
        },
        {
          "concept": "human-human interaction",
          "relevance": 0.638
        },
        {
          "concept": "AI-powered systems",
          "relevance": 0.629
        },
        {
          "concept": "Explainable AI",
          "relevance": 0.594
        },
        {
          "concept": "calibrate trust",
          "relevance": 0.589
        },
        {
          "concept": "socio-organizational context",
          "relevance": 0.577
        },
        {
          "concept": "XAI",
          "relevance": 0.573
        },
        {
          "concept": "end-users",
          "relevance": 0.565
        },
        {
          "concept": "explainability",
          "relevance": 0.549
        },
        {
          "concept": "decision-making",
          "relevance": 0.536
        },
        {
          "concept": "improve decision-making",
          "relevance": 0.522
        },
        {
          "concept": "socio-organizational",
          "relevance": 0.512
        },
        {
          "concept": "AI users",
          "relevance": 0.511
        },
        {
          "concept": "design space",
          "relevance": 0.507
        },
        {
          "concept": "design elements",
          "relevance": 0.49
        },
        {
          "concept": "collective action",
          "relevance": 0.471
        },
        {
          "concept": "information perspective",
          "relevance": 0.456
        },
        {
          "concept": "users",
          "relevance": 0.45
        },
        {
          "concept": "design scenarios",
          "relevance": 0.448
        },
        {
          "concept": "framework",
          "relevance": 0.448
        },
        {
          "concept": "Sociotechnical",
          "relevance": 0.429
        },
        {
          "concept": "discourse",
          "relevance": 0.428
        },
        {
          "concept": "system",
          "relevance": 0.426
        },
        {
          "concept": "organizational level",
          "relevance": 0.423
        },
        {
          "concept": "AI",
          "relevance": 0.416
        },
        {
          "concept": "conceptual framework",
          "relevance": 0.402
        },
        {
          "concept": "scenarios",
          "relevance": 0.401
        },
        {
          "concept": "design",
          "relevance": 0.392
        },
        {
          "concept": "Towards",
          "relevance": 0.39
        },
        {
          "concept": "transparency",
          "relevance": 0.385
        },
        {
          "concept": "trust",
          "relevance": 0.384
        },
        {
          "concept": "Social",
          "relevance": 0.367
        },
        {
          "concept": "context",
          "relevance": 0.36
        },
        {
          "concept": "perspective",
          "relevance": 0.358
        },
        {
          "concept": "interviews",
          "relevance": 0.358
        },
        {
          "concept": "practitioners",
          "relevance": 0.33
        },
        {
          "concept": "steps",
          "relevance": 0.322
        },
        {
          "concept": "action",
          "relevance": 0.319
        },
        {
          "concept": "elements",
          "relevance": 0.302
        },
        {
          "concept": "implications",
          "relevance": 0.281
        },
        {
          "concept": "developmental steps",
          "relevance": 0.265
        },
        {
          "concept": "explanation",
          "relevance": 0.263
        },
        {
          "concept": "ST effects",
          "relevance": 0.243
        },
        {
          "concept": "interaction",
          "relevance": 0.237
        },
        {
          "concept": "effect",
          "relevance": 0.223
        },
        {
          "concept": "levels",
          "relevance": 0.195
        }
      ]
    },
    {
      "paperId": "pub.1130542975",
      "doi": "10.1145/3236386.3241340",
      "title": "The Mythos of Model Interpretability",
      "year": 2018,
      "citationCount": 2137,
      "fieldCitationRatio": 475.53,
      "abstract": "Supervised machine-learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world?",
      "reference_ids": [
        "pub.1095620157",
        "pub.1033755585",
        "pub.1061542200",
        "pub.1000169726",
        "pub.1038436955",
        "pub.1006536353",
        "pub.1110458978",
        "pub.1098665577",
        "pub.1018972392",
        "pub.1000480902",
        "pub.1002229238",
        "pub.1033292604"
      ],
      "concepts_scores": [
        {
          "concept": "supervised machine-learning model",
          "relevance": 0.528
        },
        {
          "concept": "machine-learning models",
          "relevance": 0.51
        },
        {
          "concept": "deployment",
          "relevance": 0.389
        },
        {
          "concept": "predictive capability",
          "relevance": 0.371
        },
        {
          "concept": "capability",
          "relevance": 0.346
        },
        {
          "concept": "model",
          "relevance": 0.285
        },
        {
          "concept": "mythos",
          "relevance": 0.26
        },
        {
          "concept": "world",
          "relevance": 0.25
        }
      ]
    }
  ],
  "evolution_links": [
    {
      "source": "pub.1154205505",
      "target": "pub.1142161007",
      "source_title": "Six Human-Centered Artificial Intelligence Grand Challenges",
      "target_title": "The false hope of current approaches to explainable artificial intelligence in health care"
    },
    {
      "source": "pub.1142161007",
      "target": "pub.1122068379",
      "source_title": "The false hope of current approaches to explainable artificial intelligence in health care",
      "target_title": "Dissecting racial bias in an algorithm used to manage the health of populations"
    },
    {
      "source": "pub.1122068379",
      "target": "pub.1101733512",
      "source_title": "Dissecting racial bias in an algorithm used to manage the health of populations",
      "target_title": "Big Data's Disparate Impact"
    },
    {
      "source": "pub.1122068379",
      "target": "pub.1084825219",
      "source_title": "Dissecting racial bias in an algorithm used to manage the health of populations",
      "target_title": "Semantics derived automatically from language corpora contain human-like biases"
    },
    {
      "source": "pub.1142161007",
      "target": "pub.1124308279",
      "source_title": "The false hope of current approaches to explainable artificial intelligence in health care",
      "target_title": "Closing the AI accountability gap"
    },
    {
      "source": "pub.1124308279",
      "target": "pub.1095764490",
      "source_title": "Closing the AI accountability gap",
      "target_title": "Deep Learning Face Attributes in the Wild**http://personal.ie.cuhk.edu.hk/~lz013/projects/FaceAttributes.html"
    },
    {
      "source": "pub.1124308279",
      "target": "pub.1111334730",
      "source_title": "Closing the AI accountability gap",
      "target_title": "Model Cards for Model Reporting"
    },
    {
      "source": "pub.1154205505",
      "target": "pub.1145635007",
      "source_title": "Six Human-Centered Artificial Intelligence Grand Challenges",
      "target_title": "Human-Centered AI"
    },
    {
      "source": "pub.1145635007",
      "target": "pub.1131360260",
      "source_title": "Human-Centered AI",
      "target_title": "Trustworthy artificial intelligence"
    },
    {
      "source": "pub.1131360260",
      "target": "pub.1123669031",
      "source_title": "Trustworthy artificial intelligence",
      "target_title": "Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI"
    },
    {
      "source": "pub.1145635007",
      "target": "pub.1137857482",
      "source_title": "Human-Centered AI",
      "target_title": "Expanding Explainability: Towards Social Transparency in AI systems"
    },
    {
      "source": "pub.1137857482",
      "target": "pub.1123669031",
      "source_title": "Expanding Explainability: Towards Social Transparency in AI systems",
      "target_title": "Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI"
    },
    {
      "source": "pub.1137857482",
      "target": "pub.1130542975",
      "source_title": "Expanding Explainability: Towards Social Transparency in AI systems",
      "target_title": "The Mythos of Model Interpretability"
    }
  ]
}