{
  "papers": [
    {
      "paperId": "pub.1151003027",
      "doi": "10.1145/3560815",
      "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",
      "year": 2023,
      "citationCount": 2772,
      "fieldCitationRatio": 1685.67,
      "abstract": " This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input  x  and predict an output  y  as P (  y|x  ), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input  x  is modified using a template into a textual string prompt  x′  that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string  x̂  , from which the final output  y  can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g., the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website NLPedia–Pretrain including constantly updated survey and paperlist. ",
      "reference_ids": [
        "pub.1098666552",
        "pub.1095157363",
        "pub.1122290551",
        "pub.1129120160",
        "pub.1148391398",
        "pub.1141073631",
        "pub.1138840569",
        "pub.1099110523",
        "pub.1121025051",
        "pub.1148391651",
        "pub.1129757244",
        "pub.1137805304",
        "pub.1117659836",
        "pub.1138840374",
        "pub.1096025766",
        "pub.1099110546",
        "pub.1122290126",
        "pub.1096025548",
        "pub.1100516767",
        "pub.1128474475",
        "pub.1098653543",
        "pub.1100516746",
        "pub.1124455948",
        "pub.1143949330",
        "pub.1143949340",
        "pub.1096025868",
        "pub.1134455702",
        "pub.1148955841",
        "pub.1147477782",
        "pub.1106022887",
        "pub.1099113537",
        "pub.1138840348",
        "pub.1138840683",
        "pub.1146971006",
        "pub.1100516703",
        "pub.1129757129",
        "pub.1139947326",
        "pub.1148391035",
        "pub.1133175780",
        "pub.1122290238",
        "pub.1100060173",
        "pub.1139947422",
        "pub.1099110648",
        "pub.1142776580",
        "pub.1099201585",
        "pub.1139947618",
        "pub.1099110721",
        "pub.1129483373",
        "pub.1142776451",
        "pub.1121024921",
        "pub.1133176946",
        "pub.1133177107",
        "pub.1139947391",
        "pub.1144244999",
        "pub.1143949069",
        "pub.1133177239",
        "pub.1104321292",
        "pub.1051082970",
        "pub.1122290267",
        "pub.1104321115",
        "pub.1138840269",
        "pub.1106019786",
        "pub.1048573168",
        "pub.1117659358",
        "pub.1069420947",
        "pub.1148956715",
        "pub.1121025079",
        "pub.1099150699",
        "pub.1061744581",
        "pub.1138840584",
        "pub.1099113445",
        "pub.1138840599",
        "pub.1139948265",
        "pub.1133175114",
        "pub.1122290260",
        "pub.1143949389",
        "pub.1098653837",
        "pub.1038140272",
        "pub.1095195739",
        "pub.1129757334",
        "pub.1121025568",
        "pub.1117659342",
        "pub.1122290421",
        "pub.1015894360",
        "pub.1143948984",
        "pub.1133175102",
        "pub.1146568372"
      ],
      "concepts_scores": [
        {
          "concept": "natural language processing",
          "relevance": 0.762
        },
        {
          "concept": "language model",
          "relevance": 0.757
        },
        {
          "concept": "language processing",
          "relevance": 0.693
        },
        {
          "concept": "pre-trained language models",
          "relevance": 0.681
        },
        {
          "concept": "prompt-based learning",
          "relevance": 0.67
        },
        {
          "concept": "probability of text",
          "relevance": 0.67
        },
        {
          "concept": "zero-shot learning",
          "relevance": 0.669
        },
        {
          "concept": "no labeled data",
          "relevance": 0.668
        },
        {
          "concept": "few-shot",
          "relevance": 0.619
        },
        {
          "concept": "supervised learning",
          "relevance": 0.614
        },
        {
          "concept": "raw text",
          "relevance": 0.611
        },
        {
          "concept": "prediction task",
          "relevance": 0.605
        },
        {
          "concept": "original input",
          "relevance": 0.604
        },
        {
          "concept": "textual strings",
          "relevance": 0.602
        },
        {
          "concept": "pre-training",
          "relevance": 0.599
        },
        {
          "concept": "massive amounts",
          "relevance": 0.584
        },
        {
          "concept": "mathematical notation",
          "relevance": 0.579
        },
        {
          "concept": "learning",
          "relevance": 0.521
        },
        {
          "concept": "research work",
          "relevance": 0.518
        },
        {
          "concept": "unfilled slot",
          "relevance": 0.517
        },
        {
          "concept": "tuning strategy",
          "relevance": 0.514
        },
        {
          "concept": "language",
          "relevance": 0.486
        },
        {
          "concept": "input",
          "relevance": 0.469
        },
        {
          "concept": "text",
          "relevance": 0.464
        },
        {
          "concept": "paradigm",
          "relevance": 0.458
        },
        {
          "concept": "notation",
          "relevance": 0.443
        },
        {
          "concept": "output",
          "relevance": 0.441
        },
        {
          "concept": "task",
          "relevance": 0.435
        },
        {
          "concept": "websites",
          "relevance": 0.42
        },
        {
          "concept": "scenarios",
          "relevance": 0.416
        },
        {
          "concept": "model",
          "relevance": 0.415
        },
        {
          "concept": "information",
          "relevance": 0.402
        },
        {
          "concept": "slot",
          "relevance": 0.401
        },
        {
          "concept": "framework",
          "relevance": 0.401
        },
        {
          "concept": "prompt method",
          "relevance": 0.398
        },
        {
          "concept": "prediction",
          "relevance": 0.396
        },
        {
          "concept": "systematic survey",
          "relevance": 0.393
        },
        {
          "concept": "beginners",
          "relevance": 0.391
        },
        {
          "concept": "probability",
          "relevance": 0.38
        },
        {
          "concept": "resources",
          "relevance": 0.375
        },
        {
          "concept": "string",
          "relevance": 0.369
        },
        {
          "concept": "process",
          "relevance": 0.365
        },
        {
          "concept": "method",
          "relevance": 0.351
        },
        {
          "concept": "concept",
          "relevance": 0.349
        },
        {
          "concept": "work",
          "relevance": 0.348
        },
        {
          "concept": "reasons",
          "relevance": 0.342
        },
        {
          "concept": "template",
          "relevance": 0.33
        },
        {
          "concept": "research",
          "relevance": 0.324
        },
        {
          "concept": "data",
          "relevance": 0.317
        },
        {
          "concept": "basics",
          "relevance": 0.312
        },
        {
          "concept": "dimensions",
          "relevance": 0.31
        },
        {
          "concept": "strategies",
          "relevance": 0.305
        },
        {
          "concept": "prompts",
          "relevance": 0.299
        },
        {
          "concept": "function",
          "relevance": 0.291
        },
        {
          "concept": "field",
          "relevance": 0.287
        },
        {
          "concept": "typology",
          "relevance": 0.281
        },
        {
          "concept": "survey",
          "relevance": 0.277
        },
        {
          "concept": "nature",
          "relevance": 0.259
        },
        {
          "concept": "amount",
          "relevance": 0.253
        },
        {
          "concept": "systematic review",
          "relevance": 0.196
        },
        {
          "concept": "review",
          "relevance": 0.19
        }
      ]
    },
    {
      "paperId": "pub.1147477782",
      "doi": "10.1145/3485447.3511998",
      "title": "KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction",
      "year": 2022,
      "citationCount": 262,
      "fieldCitationRatio": 102.72,
      "abstract": "Recently, prompt-tuning has achieved promising results for specific few-shot classification tasks. The core idea of prompt-tuning is to insert text pieces (i.e., templates) into the input and transform a classification task into a masked language modeling problem. However, for relation extraction, determining an appropriate prompt template requires domain expertise, and it is cumbersome and time-consuming to obtain a suitable label word. Furthermore, there exists abundant semantic and prior knowledge among the relation labels that cannot be ignored. To this end, we focus on incorporating knowledge among relation labels into prompt-tuning for relation extraction and propose a Knowledge-aware Prompt-tuning approach with synergistic optimization (KnowPrompt). Specifically, we inject latent knowledge contained in relation labels into prompt construction with learnable virtual type words and answer words. Then, we synergistically optimize their representation with structured constraints. Extensive experimental results on five datasets with standard and low-resource settings demonstrate the effectiveness of our approach. Our code and datasets are available in GitHub1 for reproducibility.",
      "reference_ids": [
        "pub.1138840374",
        "pub.1122315743",
        "pub.1122290022",
        "pub.1139947538",
        "pub.1134455317",
        "pub.1127360386",
        "pub.1137805304",
        "pub.1138569947",
        "pub.1148391035",
        "pub.1099106181",
        "pub.1117658890",
        "pub.1134455702",
        "pub.1140364023",
        "pub.1122290039",
        "pub.1134455455",
        "pub.1120647268",
        "pub.1128856587",
        "pub.1129756711",
        "pub.1127360416",
        "pub.1100516689",
        "pub.1125558196",
        "pub.1138571099",
        "pub.1117658766",
        "pub.1139947422",
        "pub.1139947326",
        "pub.1118169675",
        "pub.1129119957",
        "pub.1133177107",
        "pub.1139947391",
        "pub.1142776451",
        "pub.1134455786",
        "pub.1163042908",
        "pub.1139947379",
        "pub.1140412574",
        "pub.1133177283",
        "pub.1121024616",
        "pub.1150866060",
        "pub.1035437891",
        "pub.1121024871",
        "pub.1099113707",
        "pub.1129757046",
        "pub.1150866067",
        "pub.1117659160",
        "pub.1143948984"
      ],
      "concepts_scores": [
        {
          "concept": "prompt-tuning",
          "relevance": 0.756
        },
        {
          "concept": "classification task",
          "relevance": 0.712
        },
        {
          "concept": "few-shot classification tasks",
          "relevance": 0.688
        },
        {
          "concept": "language modeling problem",
          "relevance": 0.67
        },
        {
          "concept": "relation extraction",
          "relevance": 0.618
        },
        {
          "concept": "prompt template",
          "relevance": 0.617
        },
        {
          "concept": "domain expertise",
          "relevance": 0.604
        },
        {
          "concept": "text pieces",
          "relevance": 0.601
        },
        {
          "concept": "label words",
          "relevance": 0.599
        },
        {
          "concept": "latent knowledge",
          "relevance": 0.595
        },
        {
          "concept": "core idea",
          "relevance": 0.577
        },
        {
          "concept": "typed words",
          "relevance": 0.575
        },
        {
          "concept": "experimental results",
          "relevance": 0.547
        },
        {
          "concept": "dataset",
          "relevance": 0.526
        },
        {
          "concept": "model problem",
          "relevance": 0.506
        },
        {
          "concept": "task",
          "relevance": 0.504
        },
        {
          "concept": "GitHub1",
          "relevance": 0.486
        },
        {
          "concept": "optimization",
          "relevance": 0.479
        },
        {
          "concept": "labeling",
          "relevance": 0.476
        },
        {
          "concept": "words",
          "relevance": 0.453
        },
        {
          "concept": "code",
          "relevance": 0.442
        },
        {
          "concept": "structural constraints",
          "relevance": 0.438
        },
        {
          "concept": "classification",
          "relevance": 0.432
        },
        {
          "concept": "representation",
          "relevance": 0.425
        },
        {
          "concept": "knowledge",
          "relevance": 0.424
        },
        {
          "concept": "input",
          "relevance": 0.405
        },
        {
          "concept": "language",
          "relevance": 0.399
        },
        {
          "concept": "constraints",
          "relevance": 0.399
        },
        {
          "concept": "extraction",
          "relevance": 0.38
        },
        {
          "concept": "domain",
          "relevance": 0.378
        },
        {
          "concept": "sets",
          "relevance": 0.362
        },
        {
          "concept": "results",
          "relevance": 0.354
        },
        {
          "concept": "expertise",
          "relevance": 0.35
        },
        {
          "concept": "synergistic optimization",
          "relevance": 0.336
        },
        {
          "concept": "template",
          "relevance": 0.33
        },
        {
          "concept": "ideas",
          "relevance": 0.319
        },
        {
          "concept": "construction",
          "relevance": 0.307
        },
        {
          "concept": "low-resource settings",
          "relevance": 0.302
        },
        {
          "concept": "core",
          "relevance": 0.292
        },
        {
          "concept": "pieces",
          "relevance": 0.292
        },
        {
          "concept": "relations",
          "relevance": 0.271
        },
        {
          "concept": "reproducibility",
          "relevance": 0.215
        },
        {
          "concept": "effect",
          "relevance": 0.199
        },
        {
          "concept": "problem",
          "relevance": 0.172
        },
        {
          "concept": "approach",
          "relevance": 0.153
        }
      ]
    },
    {
      "paperId": "pub.1137805304",
      "doi": "10.1145/3411763.3451760",
      "title": "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm",
      "year": 2021,
      "citationCount": 568,
      "fieldCitationRatio": 177.02,
      "abstract": "Prevailing methods for mapping large generative language models to supervised tasks may fail to sufficiently probe models’ novel capabilities. Using GPT-3 as a case study, we show that 0-shot prompts can significantly outperform few-shot prompts. We suggest that the function of few-shot examples in these cases is better described as locating an already learned task rather than meta-learning. This analysis motivates rethinking the role of prompts in controlling and evaluating powerful language models. We discuss methods of prompt programming, emphasizing the usefulness of considering prompts through the lens of natural language. We explore techniques for exploiting the capacity of narratives and cultural anchors to encode nuanced intentions and techniques for encouraging deconstruction of a problem into components before producing a verdict. Informed by this more encompassing theory of prompt programming, we also introduce the idea of a metaprompt that seeds the model to generate its own natural language prompts for a range of tasks. Finally, we discuss how these more general methods of interacting with language models can be incorporated into existing and future benchmarks and practical applications.",
      "reference_ids": [
        "pub.1117660390",
        "pub.1129757221",
        "pub.1144245257",
        "pub.1121025240",
        "pub.1099117445",
        "pub.1117659358"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.749
        },
        {
          "concept": "few-shot examples",
          "relevance": 0.664
        },
        {
          "concept": "generative language models",
          "relevance": 0.655
        },
        {
          "concept": "natural language prompts",
          "relevance": 0.652
        },
        {
          "concept": "few-shot",
          "relevance": 0.613
        },
        {
          "concept": "meta-learning",
          "relevance": 0.61
        },
        {
          "concept": "supervised tasks",
          "relevance": 0.597
        },
        {
          "concept": "natural language",
          "relevance": 0.595
        },
        {
          "concept": "language prompts",
          "relevance": 0.591
        },
        {
          "concept": "GPT-3",
          "relevance": 0.586
        },
        {
          "concept": "learning tasks",
          "relevance": 0.565
        },
        {
          "concept": "capacity of narratives",
          "relevance": 0.561
        },
        {
          "concept": "cultural anchors",
          "relevance": 0.531
        },
        {
          "concept": "probe model",
          "relevance": 0.519
        },
        {
          "concept": "language",
          "relevance": 0.513
        },
        {
          "concept": "task",
          "relevance": 0.499
        },
        {
          "concept": "case study",
          "relevance": 0.457
        },
        {
          "concept": "prompts",
          "relevance": 0.444
        },
        {
          "concept": "benchmarks",
          "relevance": 0.439
        },
        {
          "concept": "general method",
          "relevance": 0.424
        },
        {
          "concept": "narratives",
          "relevance": 0.417
        },
        {
          "concept": "program",
          "relevance": 0.413
        },
        {
          "concept": "model",
          "relevance": 0.41
        },
        {
          "concept": "technique",
          "relevance": 0.409
        },
        {
          "concept": "method",
          "relevance": 0.403
        },
        {
          "concept": "deconstruction",
          "relevance": 0.401
        },
        {
          "concept": "capability",
          "relevance": 0.399
        },
        {
          "concept": "paradigm",
          "relevance": 0.392
        },
        {
          "concept": "examples",
          "relevance": 0.366
        },
        {
          "concept": "lens",
          "relevance": 0.338
        },
        {
          "concept": "verdict",
          "relevance": 0.338
        },
        {
          "concept": "intention",
          "relevance": 0.329
        },
        {
          "concept": "anchor",
          "relevance": 0.309
        },
        {
          "concept": "theory",
          "relevance": 0.302
        },
        {
          "concept": "cases",
          "relevance": 0.29
        },
        {
          "concept": "function",
          "relevance": 0.288
        },
        {
          "concept": "use",
          "relevance": 0.281
        },
        {
          "concept": "components",
          "relevance": 0.279
        },
        {
          "concept": "capacity",
          "relevance": 0.252
        },
        {
          "concept": "analysis",
          "relevance": 0.249
        },
        {
          "concept": "study",
          "relevance": 0.237
        },
        {
          "concept": "problem",
          "relevance": 0.204
        },
        {
          "concept": "probe",
          "relevance": 0.16
        }
      ]
    },
    {
      "paperId": "pub.1140364023",
      "doi": "10.24963/ijcai.2021/551",
      "title": "Document-level Relation Extraction as Semantic Segmentation",
      "year": 2021,
      "citationCount": 132,
      "fieldCitationRatio": 37.8,
      "abstract": "Document-level relation extraction aims to extract relations among multiple entity pairs from a document. Previously proposed graph-based or transformer-based models utilize the entities independently, regardless of global information among relational triples. This paper approaches the problem by predicting an entity-level relation matrix to capture local and global information, parallel to the semantic segmentation task in computer vision. Herein, we propose a Document U-shaped Network for document-level relation extraction. Specifically, we leverage an encoder module to capture the context information of entities and a U-shaped segmentation module over the image-style feature map to capture global interdependency among triples. Experimental results show that our approach can obtain state-of-the-art performance on three benchmark datasets DocRED, CDR, and GDA.",
      "reference_ids": NaN,
      "concepts_scores": [
        {
          "concept": "Document-level relation extraction",
          "relevance": 0.82
        },
        {
          "concept": "relation extraction",
          "relevance": 0.737
        },
        {
          "concept": "global information",
          "relevance": 0.716
        },
        {
          "concept": "state-of-the-art performance",
          "relevance": 0.709
        },
        {
          "concept": "semantic segmentation task",
          "relevance": 0.688
        },
        {
          "concept": "information of entities",
          "relevance": 0.686
        },
        {
          "concept": "state-of-the-art",
          "relevance": 0.684
        },
        {
          "concept": "transformer-based models",
          "relevance": 0.683
        },
        {
          "concept": "U-shaped network",
          "relevance": 0.681
        },
        {
          "concept": "entity pairs",
          "relevance": 0.639
        },
        {
          "concept": "relational triples",
          "relevance": 0.639
        },
        {
          "concept": "feature maps",
          "relevance": 0.635
        },
        {
          "concept": "semantic segmentation",
          "relevance": 0.634
        },
        {
          "concept": "computer vision",
          "relevance": 0.634
        },
        {
          "concept": "context information",
          "relevance": 0.633
        },
        {
          "concept": "segmentation task",
          "relevance": 0.631
        },
        {
          "concept": "encoder module",
          "relevance": 0.631
        },
        {
          "concept": "graph-based",
          "relevance": 0.628
        },
        {
          "concept": "extract relations",
          "relevance": 0.627
        },
        {
          "concept": "segmentation module",
          "relevance": 0.623
        },
        {
          "concept": "experimental results",
          "relevance": 0.563
        },
        {
          "concept": "semantics",
          "relevance": 0.484
        },
        {
          "concept": "information",
          "relevance": 0.479
        },
        {
          "concept": "encoding",
          "relevance": 0.477
        },
        {
          "concept": "DOCR",
          "relevance": 0.467
        },
        {
          "concept": "network",
          "relevance": 0.461
        },
        {
          "concept": "computer",
          "relevance": 0.46
        },
        {
          "concept": "triples",
          "relevance": 0.449
        },
        {
          "concept": "task",
          "relevance": 0.448
        },
        {
          "concept": "modulation",
          "relevance": 0.447
        },
        {
          "concept": "entities",
          "relevance": 0.432
        },
        {
          "concept": "vision",
          "relevance": 0.423
        },
        {
          "concept": "documents",
          "relevance": 0.414
        },
        {
          "concept": "performance",
          "relevance": 0.411
        },
        {
          "concept": "maps",
          "relevance": 0.397
        },
        {
          "concept": "extraction",
          "relevance": 0.391
        },
        {
          "concept": "segments",
          "relevance": 0.388
        },
        {
          "concept": "GDA",
          "relevance": 0.388
        },
        {
          "concept": "CDR",
          "relevance": 0.352
        },
        {
          "concept": "model",
          "relevance": 0.342
        },
        {
          "concept": "context",
          "relevance": 0.339
        },
        {
          "concept": "interdependence",
          "relevance": 0.331
        },
        {
          "concept": "matrix",
          "relevance": 0.328
        },
        {
          "concept": "global interdependence",
          "relevance": 0.319
        },
        {
          "concept": "pairs",
          "relevance": 0.318
        },
        {
          "concept": "results",
          "relevance": 0.315
        },
        {
          "concept": "relations",
          "relevance": 0.279
        },
        {
          "concept": "problem",
          "relevance": 0.158
        }
      ]
    },
    {
      "paperId": "pub.1141073631",
      "doi": "10.1162/tacl_a_00407",
      "title": "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering",
      "year": 2021,
      "citationCount": 132,
      "fieldCitationRatio": 42.19,
      "abstract": "Abstract\n                  Recent works have shown that language models (LM) capture different types of knowledge regarding facts or common sense. However, because no model is perfect, they still fail to provide appropriate answers in many cases. In this paper, we ask the question, “How can we know when language models know, with confidence, the answer to a particular query?” We examine this question from the point of view of calibration, the property of a probabilistic model’s predicted probabilities actually being well correlated with the probabilities of correctness. We examine three strong generative models—T5, BART, and GPT-2—and study whether their probabilities on QA tasks are well calibrated, finding the answer is a relatively emphatic no. We then examine methods to calibrate such models to make their confidence scores correlate better with the likelihood of correctness through fine-tuning, post-hoc probability modification, or adjustment of the predicted outputs or inputs. Experiments on a diverse range of datasets demonstrate the effectiveness of our methods. We also perform analysis to study the strengths and limitations of these methods, shedding light on further improvements that may be made in methods for calibrating LMs. We have released the code at https://github.com/jzbjyb/lm-calibration.",
      "reference_ids": [
        "pub.1104321297",
        "pub.1129756761",
        "pub.1138840366",
        "pub.1133176782",
        "pub.1096025508",
        "pub.1121025906",
        "pub.1121025070",
        "pub.1122290267",
        "pub.1129483373",
        "pub.1129757334",
        "pub.1128856545",
        "pub.1128856548",
        "pub.1133176863",
        "pub.1117660393",
        "pub.1124267278",
        "pub.1129757429",
        "pub.1133177239",
        "pub.1128856705",
        "pub.1041315606",
        "pub.1133177197",
        "pub.1100516767",
        "pub.1013350270",
        "pub.1133174898",
        "pub.1121025062",
        "pub.1117659396",
        "pub.1117659708",
        "pub.1096025331",
        "pub.1061179979",
        "pub.1121025044",
        "pub.1129757112",
        "pub.1117660372",
        "pub.1122290982",
        "pub.1128856625",
        "pub.1117658906",
        "pub.1093359587",
        "pub.1098653837",
        "pub.1122290471",
        "pub.1133175114",
        "pub.1122290623",
        "pub.1021899069",
        "pub.1122290551"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.653
        },
        {
          "concept": "question answering",
          "relevance": 0.53
        },
        {
          "concept": "probability of correctness",
          "relevance": 0.53
        },
        {
          "concept": "QA task",
          "relevance": 0.522
        },
        {
          "concept": "fine-tuning",
          "relevance": 0.487
        },
        {
          "concept": "probabilistic model",
          "relevance": 0.486
        },
        {
          "concept": "confidence scores",
          "relevance": 0.483
        },
        {
          "concept": "predicted output",
          "relevance": 0.476
        },
        {
          "concept": "recent work",
          "relevance": 0.466
        },
        {
          "concept": "emphatic no.",
          "relevance": 0.459
        },
        {
          "concept": "Abstract Recent work",
          "relevance": 0.43
        },
        {
          "concept": "likelihood of correctness",
          "relevance": 0.421
        },
        {
          "concept": "language",
          "relevance": 0.416
        },
        {
          "concept": "query",
          "relevance": 0.411
        },
        {
          "concept": "probability",
          "relevance": 0.395
        },
        {
          "concept": "dataset",
          "relevance": 0.389
        },
        {
          "concept": "code",
          "relevance": 0.378
        },
        {
          "concept": "answers",
          "relevance": 0.375
        },
        {
          "concept": "task",
          "relevance": 0.372
        },
        {
          "concept": "method",
          "relevance": 0.372
        },
        {
          "concept": "questions",
          "relevance": 0.363
        },
        {
          "concept": "model",
          "relevance": 0.355
        },
        {
          "concept": "calibrating such models",
          "relevance": 0.353
        },
        {
          "concept": "input",
          "relevance": 0.347
        },
        {
          "concept": "shed light",
          "relevance": 0.334
        },
        {
          "concept": "correction",
          "relevance": 0.332
        },
        {
          "concept": "no model",
          "relevance": 0.329
        },
        {
          "concept": "output",
          "relevance": 0.326
        },
        {
          "concept": "Bart",
          "relevance": 0.307
        },
        {
          "concept": "knowledge",
          "relevance": 0.298
        },
        {
          "concept": "post-hoc",
          "relevance": 0.292
        },
        {
          "concept": "calibration",
          "relevance": 0.285
        },
        {
          "concept": "experiments",
          "relevance": 0.285
        },
        {
          "concept": "Abstract",
          "relevance": 0.282
        },
        {
          "concept": "work",
          "relevance": 0.282
        },
        {
          "concept": "improvement",
          "relevance": 0.274
        },
        {
          "concept": "generation",
          "relevance": 0.267
        },
        {
          "concept": "confidence",
          "relevance": 0.261
        },
        {
          "concept": "limitations",
          "relevance": 0.245
        },
        {
          "concept": "likelihood",
          "relevance": 0.235
        },
        {
          "concept": "adjustment",
          "relevance": 0.229
        },
        {
          "concept": "No.",
          "relevance": 0.227
        },
        {
          "concept": "scores",
          "relevance": 0.222
        },
        {
          "concept": "cases",
          "relevance": 0.216
        },
        {
          "concept": "analysis",
          "relevance": 0.215
        },
        {
          "concept": "light",
          "relevance": 0.209
        },
        {
          "concept": "modification",
          "relevance": 0.206
        },
        {
          "concept": "properties",
          "relevance": 0.195
        },
        {
          "concept": "study",
          "relevance": 0.172
        },
        {
          "concept": "effect",
          "relevance": 0.171
        },
        {
          "concept": "strength",
          "relevance": 0.17
        }
      ]
    },
    {
      "paperId": "pub.1124267278",
      "doi": "10.1145/3351095.3372852",
      "title": "Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making",
      "year": 2020,
      "citationCount": 595,
      "fieldCitationRatio": 158.42,
      "abstract": "Today, AI is being increasingly used to help human experts make decisions in high-stakes scenarios. In these scenarios, full automation is often undesirable, not only due to the significance of the outcome, but also because human experts can draw on their domain knowledge complementary to the model's to ensure task success. We refer to these scenarios as AI-assisted decision making, where the individual strengths of the human and the AI come together to optimize the joint decision outcome. A key to their success is to appropriately calibrate human trust in the AI on a case-by-case basis; knowing when to trust or distrust the AI allows the human expert to appropriately apply their knowledge, improving decision outcomes in cases where the model is likely to perform poorly. This research conducts a case study of AI-assisted decision making in which humans and AI have comparable performance alone, and explores whether features that reveal case-specific model information can calibrate trust and improve the joint performance of the human and AI. Specifically, we study the effect of showing confidence score and local explanation for a particular prediction. Through two human experiments, we show that confidence score can help calibrate people's trust in an AI model, but trust calibration alone is not sufficient to improve AI-assisted decision making, which may also depend on whether the human can bring in enough unique knowledge to complement the AI's errors. We also highlight the problems in using local explanation for AI-assisted decision making scenarios and invite the research community to explore new approaches to explainability for calibrating human trust in AI.",
      "reference_ids": [
        "pub.1112250084",
        "pub.1113814474",
        "pub.1027295960",
        "pub.1111334724",
        "pub.1064711672",
        "pub.1067597755",
        "pub.1046837285",
        "pub.1094486642",
        "pub.1029645980",
        "pub.1031137001",
        "pub.1119901816",
        "pub.1113814266",
        "pub.1044732832",
        "pub.1107064439",
        "pub.1113814546",
        "pub.1126983320",
        "pub.1112250103",
        "pub.1051639050",
        "pub.1112250105",
        "pub.1106289667",
        "pub.1038436955",
        "pub.1064048670",
        "pub.1112250072",
        "pub.1011210362",
        "pub.1067596678"
      ],
      "concepts_scores": [
        {
          "concept": "AI-assisted decision making",
          "relevance": 0.831
        },
        {
          "concept": "human experts",
          "relevance": 0.742
        },
        {
          "concept": "human trust",
          "relevance": 0.705
        },
        {
          "concept": "local explanations",
          "relevance": 0.679
        },
        {
          "concept": "approaches to explainability",
          "relevance": 0.672
        },
        {
          "concept": "AI-assisted decision",
          "relevance": 0.664
        },
        {
          "concept": "confidence scores",
          "relevance": 0.655
        },
        {
          "concept": "high-stakes scenarios",
          "relevance": 0.64
        },
        {
          "concept": "decision making scenarios",
          "relevance": 0.638
        },
        {
          "concept": "domain knowledge",
          "relevance": 0.613
        },
        {
          "concept": "calibrate trust",
          "relevance": 0.612
        },
        {
          "concept": "trust calibration",
          "relevance": 0.608
        },
        {
          "concept": "decision making",
          "relevance": 0.608
        },
        {
          "concept": "AI errors",
          "relevance": 0.595
        },
        {
          "concept": "AI models",
          "relevance": 0.592
        },
        {
          "concept": "task success",
          "relevance": 0.577
        },
        {
          "concept": "model information",
          "relevance": 0.563
        },
        {
          "concept": "research community",
          "relevance": 0.563
        },
        {
          "concept": "decision outcomes",
          "relevance": 0.561
        },
        {
          "concept": "improve decision outcomes",
          "relevance": 0.559
        },
        {
          "concept": "AI",
          "relevance": 0.541
        },
        {
          "concept": "scenarios",
          "relevance": 0.516
        },
        {
          "concept": "people’s trust",
          "relevance": 0.512
        },
        {
          "concept": "trust",
          "relevance": 0.497
        },
        {
          "concept": "experts",
          "relevance": 0.485
        },
        {
          "concept": "explainability",
          "relevance": 0.469
        },
        {
          "concept": "performance",
          "relevance": 0.464
        },
        {
          "concept": "case study",
          "relevance": 0.463
        },
        {
          "concept": "making",
          "relevance": 0.457
        },
        {
          "concept": "automation",
          "relevance": 0.447
        },
        {
          "concept": "decision",
          "relevance": 0.445
        },
        {
          "concept": "effect of confidence",
          "relevance": 0.443
        },
        {
          "concept": "task",
          "relevance": 0.436
        },
        {
          "concept": "unique knowledge",
          "relevance": 0.429
        },
        {
          "concept": "knowledge",
          "relevance": 0.425
        },
        {
          "concept": "model's",
          "relevance": 0.423
        },
        {
          "concept": "individual strengths",
          "relevance": 0.417
        },
        {
          "concept": "accuracy",
          "relevance": 0.416
        },
        {
          "concept": "model",
          "relevance": 0.405
        },
        {
          "concept": "information",
          "relevance": 0.403
        },
        {
          "concept": "error",
          "relevance": 0.399
        },
        {
          "concept": "human experience",
          "relevance": 0.389
        },
        {
          "concept": "features",
          "relevance": 0.386
        },
        {
          "concept": "domain",
          "relevance": 0.379
        },
        {
          "concept": "research",
          "relevance": 0.376
        },
        {
          "concept": "joint performance",
          "relevance": 0.375
        },
        {
          "concept": "today",
          "relevance": 0.369
        },
        {
          "concept": "success",
          "relevance": 0.355
        },
        {
          "concept": "prediction",
          "relevance": 0.343
        },
        {
          "concept": "distrust",
          "relevance": 0.341
        },
        {
          "concept": "calibration",
          "relevance": 0.334
        },
        {
          "concept": "experiments",
          "relevance": 0.334
        },
        {
          "concept": "explanation",
          "relevance": 0.327
        },
        {
          "concept": "confidence",
          "relevance": 0.322
        },
        {
          "concept": "humans",
          "relevance": 0.314
        },
        {
          "concept": "community",
          "relevance": 0.304
        },
        {
          "concept": "cases",
          "relevance": 0.298
        },
        {
          "concept": "scores",
          "relevance": 0.249
        },
        {
          "concept": "problem",
          "relevance": 0.245
        },
        {
          "concept": "outcomes",
          "relevance": 0.239
        },
        {
          "concept": "effect",
          "relevance": 0.231
        },
        {
          "concept": "approach",
          "relevance": 0.229
        },
        {
          "concept": "significance",
          "relevance": 0.211
        },
        {
          "concept": "strength",
          "relevance": 0.184
        }
      ]
    },
    {
      "paperId": "pub.1064711672",
      "doi": "10.1287/isre.13.3.334.81",
      "title": "Developing and Validating Trust Measures for e-Commerce: An Integrative Typology",
      "year": 2002,
      "citationCount": 3426,
      "fieldCitationRatio": 483.18,
      "abstract": "Evidence suggests that consumers often hesitate to transact with Web-based vendors because of uncertainty about vendor behavior or the perceived risk of having personal information stolen by hackers. Trust plays a central role in helping consumers overcome perceptions of risk and insecurity. Trust makes consumers comfortable sharing personal information, making purchases, and acting on Web vendor advice—behaviors essential to widespread adoption of e-commerce. Therefore, trust is critical to both researchers and practitioners. Prior research on e-commerce trust has used diverse, incomplete, and inconsistent definitions of trust, making it difficult to compare results across studies. This paper contributes by proposing and validating measures for a multidisciplinary, multidimensional model of trust in e-commerce. The model includes four high-level constructs—disposition to trust, institution-based trust, trusting beliefs, and trusting intentions—which are further delineated into 16 measurable, literature-grounded subconstructs. The psychometric properties of the measures are demonstrated through use of a hypothetical, legal advice Web site. The results show that trust is indeed a multidimensional concept. Proposed relationships among the trust constructs are tested (for internal nomological validity), as are relationships between the trust constructs and three other e-commerce constructs (for external nomological validity), as Web experience, personal innovativeness, and Web site quality. Suggestions for future research as well as implications for practice are discussed.",
      "reference_ids": [
        "pub.1110266394",
        "pub.1035597750",
        "pub.1004095598",
        "pub.1023220121",
        "pub.1069908562",
        "pub.1064711433",
        "pub.1002853180",
        "pub.1026597602",
        "pub.1025911243",
        "pub.1102515141",
        "pub.1072898728",
        "pub.1022495625",
        "pub.1070014184",
        "pub.1064733481",
        "pub.1029898262",
        "pub.1015379641",
        "pub.1028253900",
        "pub.1091223707",
        "pub.1019669971",
        "pub.1018368129",
        "pub.1102514812",
        "pub.1070004370",
        "pub.1036450961",
        "pub.1050224227",
        "pub.1007572520",
        "pub.1058602772",
        "pub.1001143442",
        "pub.1069909113",
        "pub.1036961059",
        "pub.1016202922",
        "pub.1053459304",
        "pub.1064712050",
        "pub.1032115841",
        "pub.1048904045",
        "pub.1072898429",
        "pub.1073171344",
        "pub.1102514978",
        "pub.1063547209",
        "pub.1069417734",
        "pub.1069538222",
        "pub.1037103353",
        "pub.1013931547",
        "pub.1102515060",
        "pub.1064721971",
        "pub.1069993517",
        "pub.1099317522",
        "pub.1058548289",
        "pub.1053691264",
        "pub.1092016470",
        "pub.1047551017",
        "pub.1070093751",
        "pub.1047684349",
        "pub.1063626000",
        "pub.1063722712",
        "pub.1090926042",
        "pub.1010482605",
        "pub.1064720609",
        "pub.1063732198",
        "pub.1072898717",
        "pub.1102515180",
        "pub.1102514932",
        "pub.1048923521",
        "pub.1051123431",
        "pub.1018227688",
        "pub.1051481559",
        "pub.1070014206",
        "pub.1025232299",
        "pub.1058528757"
      ],
      "concepts_scores": [
        {
          "concept": "e-commerce",
          "relevance": 0.818
        },
        {
          "concept": "trust construct",
          "relevance": 0.764
        },
        {
          "concept": "adoption of e-commerce",
          "relevance": 0.748
        },
        {
          "concept": "e-commerce trust",
          "relevance": 0.73
        },
        {
          "concept": "institution-based trust",
          "relevance": 0.727
        },
        {
          "concept": "e-commerce constructs",
          "relevance": 0.727
        },
        {
          "concept": "web-based vendors",
          "relevance": 0.724
        },
        {
          "concept": "web site quality",
          "relevance": 0.715
        },
        {
          "concept": "personal information",
          "relevance": 0.677
        },
        {
          "concept": "personal innovativeness",
          "relevance": 0.673
        },
        {
          "concept": "trusting beliefs",
          "relevance": 0.667
        },
        {
          "concept": "definition of trust",
          "relevance": 0.657
        },
        {
          "concept": "perception of risk",
          "relevance": 0.651
        },
        {
          "concept": "vendor behavior",
          "relevance": 0.648
        },
        {
          "concept": "perceived risk",
          "relevance": 0.645
        },
        {
          "concept": "integrated typology",
          "relevance": 0.639
        },
        {
          "concept": "trust",
          "relevance": 0.612
        },
        {
          "concept": "consumers",
          "relevance": 0.602
        },
        {
          "concept": "web experience",
          "relevance": 0.591
        },
        {
          "concept": "trust measures",
          "relevance": 0.588
        },
        {
          "concept": "multidimensional concept",
          "relevance": 0.586
        },
        {
          "concept": "Web sites",
          "relevance": 0.573
        },
        {
          "concept": "vendors",
          "relevance": 0.55
        },
        {
          "concept": "multidimensional model",
          "relevance": 0.54
        },
        {
          "concept": "Web",
          "relevance": 0.537
        },
        {
          "concept": "purchase",
          "relevance": 0.516
        },
        {
          "concept": "research",
          "relevance": 0.508
        },
        {
          "concept": "site quality",
          "relevance": 0.506
        },
        {
          "concept": "innovation",
          "relevance": 0.494
        },
        {
          "concept": "hackers",
          "relevance": 0.477
        },
        {
          "concept": "adoption",
          "relevance": 0.471
        },
        {
          "concept": "inconsistent definitions",
          "relevance": 0.468
        },
        {
          "concept": "relationship",
          "relevance": 0.465
        },
        {
          "concept": "information",
          "relevance": 0.462
        },
        {
          "concept": "subconstructs",
          "relevance": 0.462
        },
        {
          "concept": "typology",
          "relevance": 0.458
        },
        {
          "concept": "practitioners",
          "relevance": 0.458
        },
        {
          "concept": "construction",
          "relevance": 0.458
        },
        {
          "concept": "compare results",
          "relevance": 0.448
        },
        {
          "concept": "suggestions",
          "relevance": 0.435
        },
        {
          "concept": "risk",
          "relevance": 0.43
        },
        {
          "concept": "model",
          "relevance": 0.405
        },
        {
          "concept": "practice",
          "relevance": 0.403
        },
        {
          "concept": "uncertainty",
          "relevance": 0.4
        },
        {
          "concept": "insecurity",
          "relevance": 0.391
        },
        {
          "concept": "beliefs",
          "relevance": 0.386
        },
        {
          "concept": "psychometric properties",
          "relevance": 0.376
        },
        {
          "concept": "concept",
          "relevance": 0.372
        },
        {
          "concept": "behavior",
          "relevance": 0.356
        },
        {
          "concept": "quality",
          "relevance": 0.353
        },
        {
          "concept": "results",
          "relevance": 0.351
        },
        {
          "concept": "integration",
          "relevance": 0.346
        },
        {
          "concept": "evidence",
          "relevance": 0.338
        },
        {
          "concept": "measurements",
          "relevance": 0.336
        },
        {
          "concept": "experiments",
          "relevance": 0.331
        },
        {
          "concept": "validity",
          "relevance": 0.321
        },
        {
          "concept": "study",
          "relevance": 0.31
        },
        {
          "concept": "properties",
          "relevance": 0.226
        },
        {
          "concept": "sites",
          "relevance": 0.163
        }
      ]
    },
    {
      "paperId": "pub.1067597755",
      "doi": "10.1518/hfes.46.1.50_30392",
      "title": "Trust in Automation: Designing for Appropriate Reliance",
      "year": 2004,
      "citationCount": 2831,
      "fieldCitationRatio": NaN,
      "abstract": "Automation is often problematic because people fail to rely upon it appropriately. Because people respond to technology socially, trust influences reliance on automation. In particular, trust guides reliance when complexity and unanticipated situations make a complete understanding of the automation impractical. This review considers trust from the organizational, sociological, interpersonal, psychological, and neurological perspectives. It considers how the context, automation characteristics, and cognitive processes affect the appropriateness of trust. The context in which the automation is used influences automation performance and provides a goal-oriented perspective to assess automation characteristics along a dimension of attributional abstraction. These characteristics can influence trust through analytic, analogical, and affective processes. The challenges of extrapolating the concept of trust in people to trust in automation are discussed. A conceptual model integrates research regarding trust in automation and describes the dynamics of trust, the role of context, and the influence of display characteristics. Actual or potential applications of this research include improved designs of systems that require people to manage imperfect automation.",
      "reference_ids": [
        "pub.1048747142",
        "pub.1050361502",
        "pub.1074651072",
        "pub.1092016462",
        "pub.1005873047",
        "pub.1013485356",
        "pub.1071037231",
        "pub.1070093982",
        "pub.1046792567",
        "pub.1026597602",
        "pub.1031722369",
        "pub.1018666072",
        "pub.1019261304",
        "pub.1037291764",
        "pub.1025512486",
        "pub.1064733481",
        "pub.1044827000",
        "pub.1063736077",
        "pub.1035698089",
        "pub.1048888695",
        "pub.1008490656",
        "pub.1058751934",
        "pub.1070818406",
        "pub.1000122699",
        "pub.1067596917",
        "pub.1042120873",
        "pub.1092921012",
        "pub.1050665807",
        "pub.1067596905",
        "pub.1023001151",
        "pub.1008750687",
        "pub.1067596514",
        "pub.1050539316",
        "pub.1018368129",
        "pub.1011842240",
        "pub.1038100359",
        "pub.1061781156",
        "pub.1061793528",
        "pub.1099317522",
        "pub.1049302919",
        "pub.1062555920",
        "pub.1024046591",
        "pub.1039690768",
        "pub.1009208227",
        "pub.1032835545",
        "pub.1015970063",
        "pub.1070195986",
        "pub.1014903551",
        "pub.1070014237",
        "pub.1063625683",
        "pub.1003181900",
        "pub.1054058142",
        "pub.1002770745",
        "pub.1012241745",
        "pub.1023220121",
        "pub.1063626000",
        "pub.1046403377",
        "pub.1082769005",
        "pub.1047735361",
        "pub.1016262558",
        "pub.1029903284",
        "pub.1061157752",
        "pub.1046406597",
        "pub.1024502183",
        "pub.1032115841",
        "pub.1063184750",
        "pub.1067596464",
        "pub.1036054092",
        "pub.1036562988",
        "pub.1001224822",
        "pub.1033572613",
        "pub.1028183777",
        "pub.1054018847",
        "pub.1009497615",
        "pub.1003735850",
        "pub.1016372949",
        "pub.1039937706",
        "pub.1067596955",
        "pub.1029555975",
        "pub.1006393123",
        "pub.1069417843",
        "pub.1049451990",
        "pub.1053691264",
        "pub.1070814257",
        "pub.1006009888",
        "pub.1079343232",
        "pub.1064449322",
        "pub.1043179109",
        "pub.1070798539",
        "pub.1025131634",
        "pub.1061157751",
        "pub.1002183506",
        "pub.1020071665",
        "pub.1013355258",
        "pub.1020965522",
        "pub.1115073265",
        "pub.1033518062",
        "pub.1022785583",
        "pub.1030131857",
        "pub.1008259727",
        "pub.1001767742",
        "pub.1051650404",
        "pub.1067596476",
        "pub.1026186318",
        "pub.1067596517",
        "pub.1045820553",
        "pub.1024699067",
        "pub.1011702326",
        "pub.1083286478",
        "pub.1069417638",
        "pub.1083190479",
        "pub.1007990190",
        "pub.1067596960",
        "pub.1061121465",
        "pub.1063655993",
        "pub.1022104605",
        "pub.1006945988",
        "pub.1003444238",
        "pub.1030596024",
        "pub.1043437484",
        "pub.1015652190"
      ],
      "concepts_scores": [
        {
          "concept": "automation characteristics",
          "relevance": 0.648
        },
        {
          "concept": "goal-oriented perspective",
          "relevance": 0.613
        },
        {
          "concept": "concept of trust",
          "relevance": 0.573
        },
        {
          "concept": "imperfect automation",
          "relevance": 0.568
        },
        {
          "concept": "dynamics of trust",
          "relevance": 0.564
        },
        {
          "concept": "automation",
          "relevance": 0.542
        },
        {
          "concept": "influence trust",
          "relevance": 0.53
        },
        {
          "concept": "affective processes",
          "relevance": 0.512
        },
        {
          "concept": "cognitive processes",
          "relevance": 0.507
        },
        {
          "concept": "automated performance",
          "relevance": 0.505
        },
        {
          "concept": "neurological perspective",
          "relevance": 0.491
        },
        {
          "concept": "trust",
          "relevance": 0.484
        },
        {
          "concept": "display characteristics",
          "relevance": 0.483
        },
        {
          "concept": "conceptual model",
          "relevance": 0.472
        },
        {
          "concept": "context",
          "relevance": 0.39
        },
        {
          "concept": "performance",
          "relevance": 0.388
        },
        {
          "concept": "technology",
          "relevance": 0.386
        },
        {
          "concept": "perspective",
          "relevance": 0.384
        },
        {
          "concept": "improved design",
          "relevance": 0.381
        },
        {
          "concept": "people",
          "relevance": 0.377
        },
        {
          "concept": "reliance",
          "relevance": 0.37
        },
        {
          "concept": "research",
          "relevance": 0.369
        },
        {
          "concept": "applications",
          "relevance": 0.366
        },
        {
          "concept": "process",
          "relevance": 0.354
        },
        {
          "concept": "system",
          "relevance": 0.354
        },
        {
          "concept": "design",
          "relevance": 0.341
        },
        {
          "concept": "appropriateness",
          "relevance": 0.34
        },
        {
          "concept": "concept",
          "relevance": 0.34
        },
        {
          "concept": "complex",
          "relevance": 0.324
        },
        {
          "concept": "model",
          "relevance": 0.323
        },
        {
          "concept": "situation",
          "relevance": 0.316
        },
        {
          "concept": "influence",
          "relevance": 0.315
        },
        {
          "concept": "characteristics",
          "relevance": 0.306
        },
        {
          "concept": "dimensions",
          "relevance": 0.302
        },
        {
          "concept": "Abstract",
          "relevance": 0.281
        },
        {
          "concept": "dynamics",
          "relevance": 0.263
        },
        {
          "concept": "review",
          "relevance": 0.239
        }
      ]
    },
    {
      "paperId": "pub.1129483373",
      "doi": "10.1162/tacl_a_00324",
      "title": "How Can We Know What Language Models Know?",
      "year": 2020,
      "citationCount": 569,
      "fieldCitationRatio": 129.69,
      "abstract": "Recent work has presented intriguing results examining the knowledge contained in language models (LMs) by having the LM fill in the blanks of prompts such as “ Obama is a __ by profession”. These prompts are usually manually created, and quite possibly sub-optimal; another prompt such as “ Obama worked as a __ ” may result in more accurately predicting the correct profession. Because of this, given an inappropriate prompt, we might fail to retrieve facts that the LM does know, and thus any given prompt only provides a lower bound estimate of the knowledge contained in an LM. In this paper, we attempt to more accurately estimate the knowledge contained in LMs by automatically discovering better prompts to use in this querying process. Specifically, we propose mining-based and paraphrasing-based methods to automatically generate high-quality and diverse prompts, as well as ensemble methods to combine answers from different prompts. Extensive experiments on the LAMA benchmark for extracting relational knowledge from LMs demonstrate that our methods can improve accuracy from 31.1% to 39.6%, providing a tighter lower bound on what LMs know. We have released the code and the resulting LM Prompt And Query Archive (LPAQA) at https://github.com/jzbjyb/LPAQA .",
      "reference_ids": [
        "pub.1122290267",
        "pub.1098653562",
        "pub.1122290022",
        "pub.1121025906",
        "pub.1099106152",
        "pub.1100516882",
        "pub.1113176961",
        "pub.1121024871",
        "pub.1039788842",
        "pub.1104321292",
        "pub.1122290238",
        "pub.1128856548",
        "pub.1099150709",
        "pub.1100516699",
        "pub.1096025501",
        "pub.1096026321",
        "pub.1009004428",
        "pub.1110957755",
        "pub.1128856604",
        "pub.1121024948",
        "pub.1121025079",
        "pub.1096024929",
        "pub.1121025190",
        "pub.1121025044",
        "pub.1094864123",
        "pub.1117659590",
        "pub.1120932880",
        "pub.1122290650",
        "pub.1099113809",
        "pub.1099113445",
        "pub.1121024731",
        "pub.1099239596"
      ],
      "concepts_scores": [
        {
          "concept": "language model",
          "relevance": 0.707
        },
        {
          "concept": "query processing",
          "relevance": 0.574
        },
        {
          "concept": "ensemble methods",
          "relevance": 0.553
        },
        {
          "concept": "mining-based",
          "relevance": 0.552
        },
        {
          "concept": "query",
          "relevance": 0.514
        },
        {
          "concept": "improved accuracy",
          "relevance": 0.498
        },
        {
          "concept": "sub-optimal",
          "relevance": 0.478
        },
        {
          "concept": "related knowledge",
          "relevance": 0.455
        },
        {
          "concept": "corrections profession",
          "relevance": 0.435
        },
        {
          "concept": "language",
          "relevance": 0.428
        },
        {
          "concept": "automatically",
          "relevance": 0.422
        },
        {
          "concept": "benchmarks",
          "relevance": 0.41
        },
        {
          "concept": "code",
          "relevance": 0.409
        },
        {
          "concept": "high-quality",
          "relevance": 0.404
        },
        {
          "concept": "knowledge",
          "relevance": 0.399
        },
        {
          "concept": "method",
          "relevance": 0.395
        },
        {
          "concept": "accuracy",
          "relevance": 0.384
        },
        {
          "concept": "model",
          "relevance": 0.356
        },
        {
          "concept": "prompts",
          "relevance": 0.345
        },
        {
          "concept": "answers",
          "relevance": 0.345
        },
        {
          "concept": "archival",
          "relevance": 0.338
        },
        {
          "concept": "Obama",
          "relevance": 0.326
        },
        {
          "concept": "estimation",
          "relevance": 0.316
        },
        {
          "concept": "experiments",
          "relevance": 0.308
        },
        {
          "concept": "process",
          "relevance": 0.291
        },
        {
          "concept": "results",
          "relevance": 0.283
        },
        {
          "concept": "profession",
          "relevance": 0.257
        },
        {
          "concept": "Lama",
          "relevance": 0.247
        },
        {
          "concept": "blank",
          "relevance": 0.165
        }
      ]
    },
    {
      "paperId": "pub.1110957755",
      "doi": "10.1162/tacl_a_00115",
      "title": "Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies",
      "year": 2016,
      "citationCount": 462,
      "fieldCitationRatio": 237.23,
      "abstract": "The success of long short-term memory (LSTM) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. Linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by LSTMs, which do not have explicit structural representations? We begin addressing this question using number agreement in English subject-verb dependencies. We probe the architecture’s grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. In the strongly supervised settings, the LSTM achieved very high overall accuracy (less than 1% errors), but errors increased when sequential and structural information conflicted. The frequency of such errors rose sharply in the language-modeling setting. We conclude that LSTMs can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufficient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured.",
      "reference_ids": [
        "pub.1061219644",
        "pub.1003380474",
        "pub.1036546465",
        "pub.1004588643",
        "pub.1046119997",
        "pub.1046144752",
        "pub.1040170772",
        "pub.1091667777",
        "pub.1043706368",
        "pub.1009671161",
        "pub.1004203654",
        "pub.1110957742",
        "pub.1038140272",
        "pub.1037432371",
        "pub.1011297337",
        "pub.1041236743",
        "pub.1035080444",
        "pub.1010052958"
      ],
      "concepts_scores": [
        {
          "concept": "sensitive to syntactic structure",
          "relevance": 0.72
        },
        {
          "concept": "subject-verb dependencies",
          "relevance": 0.713
        },
        {
          "concept": "success of long short-term memory",
          "relevance": 0.679
        },
        {
          "concept": "grammatical targets",
          "relevance": 0.653
        },
        {
          "concept": "short-term memory",
          "relevance": 0.645
        },
        {
          "concept": "grammatical competence",
          "relevance": 0.645
        },
        {
          "concept": "grammatical structure",
          "relevance": 0.643
        },
        {
          "concept": "linguistic regularities",
          "relevance": 0.642
        },
        {
          "concept": "syntactic structure",
          "relevance": 0.641
        },
        {
          "concept": "statistical regularities",
          "relevance": 0.624
        },
        {
          "concept": "language model",
          "relevance": 0.62
        },
        {
          "concept": "language processing",
          "relevance": 0.617
        },
        {
          "concept": "long short-term memory",
          "relevance": 0.605
        },
        {
          "concept": "language",
          "relevance": 0.604
        },
        {
          "concept": "targeted supervision",
          "relevance": 0.538
        },
        {
          "concept": "structural representation",
          "relevance": 0.525
        },
        {
          "concept": "memory",
          "relevance": 0.48
        },
        {
          "concept": "supervision",
          "relevance": 0.468
        },
        {
          "concept": "training objectives",
          "relevance": 0.453
        },
        {
          "concept": "competence",
          "relevance": 0.44
        },
        {
          "concept": "neural network",
          "relevance": 0.437
        },
        {
          "concept": "representation",
          "relevance": 0.415
        },
        {
          "concept": "ability",
          "relevance": 0.411
        },
        {
          "concept": "training",
          "relevance": 0.386
        },
        {
          "concept": "dependence",
          "relevance": 0.384
        },
        {
          "concept": "architecture",
          "relevance": 0.379
        },
        {
          "concept": "model signals",
          "relevance": 0.374
        },
        {
          "concept": "reduce errors",
          "relevance": 0.373
        },
        {
          "concept": "structural information",
          "relevance": 0.369
        },
        {
          "concept": "error",
          "relevance": 0.352
        },
        {
          "concept": "regularization",
          "relevance": 0.351
        },
        {
          "concept": "network",
          "relevance": 0.325
        },
        {
          "concept": "sets",
          "relevance": 0.316
        },
        {
          "concept": "target",
          "relevance": 0.313
        },
        {
          "concept": "objective",
          "relevance": 0.306
        },
        {
          "concept": "success",
          "relevance": 0.304
        },
        {
          "concept": "accuracy",
          "relevance": 0.302
        },
        {
          "concept": "information",
          "relevance": 0.294
        },
        {
          "concept": "process",
          "relevance": 0.293
        },
        {
          "concept": "structure",
          "relevance": 0.266
        },
        {
          "concept": "frequency",
          "relevance": 0.257
        },
        {
          "concept": "signal",
          "relevance": 0.256
        },
        {
          "concept": "model",
          "relevance": 0.251
        }
      ]
    },
    {
      "paperId": "pub.1120932880",
      "doi": "10.1609/aaai.v33i01.33013027",
      "title": "ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning",
      "year": 2019,
      "citationCount": 358,
      "fieldCitationRatio": 92.08,
      "abstract": "We present ATOMIC, an atlas of everyday commonsense reasoning, organized through 877k textual descriptions of inferential knowledge. Compared to existing resources that center around taxonomic knowledge, ATOMIC focuses on inferential knowledge organized as typed if-then relations with variables (e.g., “if X pays Y a compliment, then Y will likely return the compliment”). We propose nine if-then relation types to distinguish causes vs. effects, agents vs. themes, voluntary vs. involuntary events, and actions vs. mental states. By generatively training on the rich inferential knowledge described in ATOMIC, we show that neural models can acquire simple commonsense capabilities and reason about previously unseen events. Experimental results demonstrate that multitask models that incorporate the hierarchical structure of if-then relation types lead to more accurate inference compared to models trained in isolation, as measured by both automatic and human evaluation.",
      "reference_ids": [
        "pub.1096014157",
        "pub.1117659809",
        "pub.1070573500",
        "pub.1041816037",
        "pub.1037995984",
        "pub.1026547604",
        "pub.1099117498",
        "pub.1152418030"
      ],
      "concepts_scores": [
        {
          "concept": "commonsense reasoning",
          "relevance": 0.6
        },
        {
          "concept": "human evaluation",
          "relevance": 0.598
        },
        {
          "concept": "textual descriptions",
          "relevance": 0.595
        },
        {
          "concept": "inferential knowledge",
          "relevance": 0.591
        },
        {
          "concept": "neural model",
          "relevance": 0.59
        },
        {
          "concept": "if-then relations",
          "relevance": 0.585
        },
        {
          "concept": "multitask model",
          "relevance": 0.585
        },
        {
          "concept": "if-then",
          "relevance": 0.582
        },
        {
          "concept": "generator training",
          "relevance": 0.58
        },
        {
          "concept": "relation types",
          "relevance": 0.547
        },
        {
          "concept": "experimental results",
          "relevance": 0.535
        },
        {
          "concept": "hierarchical structure",
          "relevance": 0.502
        },
        {
          "concept": "accurate inference",
          "relevance": 0.496
        },
        {
          "concept": "commonsense",
          "relevance": 0.491
        },
        {
          "concept": "multitasking",
          "relevance": 0.447
        },
        {
          "concept": "knowledge",
          "relevance": 0.415
        },
        {
          "concept": "inference",
          "relevance": 0.405
        },
        {
          "concept": "model",
          "relevance": 0.395
        },
        {
          "concept": "capability",
          "relevance": 0.394
        },
        {
          "concept": "taxonomic knowledge",
          "relevance": 0.389
        },
        {
          "concept": "training",
          "relevance": 0.388
        },
        {
          "concept": "atoms",
          "relevance": 0.376
        },
        {
          "concept": "resources",
          "relevance": 0.367
        },
        {
          "concept": "evaluation",
          "relevance": 0.345
        },
        {
          "concept": "reasons",
          "relevance": 0.335
        },
        {
          "concept": "generation",
          "relevance": 0.305
        },
        {
          "concept": "results",
          "relevance": 0.299
        },
        {
          "concept": "Atlas",
          "relevance": 0.296
        },
        {
          "concept": "relations",
          "relevance": 0.266
        },
        {
          "concept": "isolates",
          "relevance": 0.25
        },
        {
          "concept": "structure",
          "relevance": 0.249
        },
        {
          "concept": "center",
          "relevance": 0.242
        },
        {
          "concept": "events",
          "relevance": 0.222
        },
        {
          "concept": "variables",
          "relevance": 0.221
        },
        {
          "concept": "type",
          "relevance": 0.205
        }
      ]
    }
  ],
  "evolution_links": [
    {
      "source": "pub.1151003027",
      "target": "pub.1147477782",
      "source_title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",
      "target_title": "KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction"
    },
    {
      "source": "pub.1147477782",
      "target": "pub.1137805304",
      "source_title": "KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction",
      "target_title": "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm"
    },
    {
      "source": "pub.1147477782",
      "target": "pub.1140364023",
      "source_title": "KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction",
      "target_title": "Document-level Relation Extraction as Semantic Segmentation"
    },
    {
      "source": "pub.1151003027",
      "target": "pub.1141073631",
      "source_title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",
      "target_title": "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering"
    },
    {
      "source": "pub.1141073631",
      "target": "pub.1124267278",
      "source_title": "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering",
      "target_title": "Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making"
    },
    {
      "source": "pub.1124267278",
      "target": "pub.1064711672",
      "source_title": "Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making",
      "target_title": "Developing and Validating Trust Measures for e-Commerce: An Integrative Typology"
    },
    {
      "source": "pub.1124267278",
      "target": "pub.1067597755",
      "source_title": "Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making",
      "target_title": "Trust in Automation: Designing for Appropriate Reliance"
    },
    {
      "source": "pub.1141073631",
      "target": "pub.1129483373",
      "source_title": "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering",
      "target_title": "How Can We Know What Language Models Know?"
    },
    {
      "source": "pub.1129483373",
      "target": "pub.1110957755",
      "source_title": "How Can We Know What Language Models Know?",
      "target_title": "Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies"
    },
    {
      "source": "pub.1129483373",
      "target": "pub.1120932880",
      "source_title": "How Can We Know What Language Models Know?",
      "target_title": "ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning"
    }
  ]
}