[
  {
    "paperId": "pub.1181644616",
    "doi": "10.1016/j.neunet.2024.106833",
    "title": "Retrieval In Decoder benefits generative models for explainable complex question answering",
    "year": 2024,
    "citationCount": 2,
    "fieldCitationRatio": NaN,
    "abstract": "Large-scale Language Models (LLMs) utilizing the Chain-of-Thought prompting demonstrate exceptional performance in a variety of tasks. However, the persistence of factual hallucinations remains a significant challenge in practical applications. Prevailing retrieval-augmented methods treat the retriever and generator as separate components, which inadvertently restricts the generator's capabilities to those of the retriever through intensive supervised training. In this work, we propose an unsupervised Retrieval In Decoder framework for multi-granularity decoding called RID, which integrates retrieval directly into the decoding process of generative models. It dynamically adjusts decoding granularity based on retrieval outcomes, and duly corrects the decoding direction through its direct impact on the next token. Moreover, we introduce a reinforcement learning-driven knowledge distillation method for adaptive explanation generation to better apply to Small-scale Language Models (SLMs). The experimental results across six public benchmarks surpass popular LLMs and existing retrieval-augmented methods, which demonstrates the effectiveness of RID in models of different scales and verifies its applicability and scalability.",
    "reference_ids": [
      "pub.1129757327",
      "pub.1117658906",
      "pub.1125046979",
      "pub.1155376414",
      "pub.1153822671",
      "pub.1152377244",
      "pub.1141964557",
      "pub.1152637982",
      "pub.1118819380",
      "pub.1137228675",
      "pub.1145122135",
      "pub.1148187413",
      "pub.1151884563",
      "pub.1163180832",
      "pub.1153313333",
      "pub.1156629939",
      "pub.1127990889",
      "pub.1148390796",
      "pub.1148032748",
      "pub.1163043527",
      "pub.1163042760",
      "pub.1163044282",
      "pub.1154196985",
      "pub.1152843639",
      "pub.1128856545",
      "pub.1143749122",
      "pub.1152020866",
      "pub.1119019253",
      "pub.1163043978",
      "pub.1151655652",
      "pub.1151717253",
      "pub.1155808762",
      "pub.1155251750",
      "pub.1154955687",
      "pub.1150095974",
      "pub.1158142191",
      "pub.1128948524",
      "pub.1133177310",
      "pub.1163041820",
      "pub.1160816154",
      "pub.1160754602",
      "pub.1157098329"
    ],
    "concepts_scores": [
      {
        "concept": "large-scale language models",
        "relevance": 0.856
      },
      {
        "concept": "language model",
        "relevance": 0.735
      },
      {
        "concept": "generative model",
        "relevance": 0.707
      },
      {
        "concept": "complex question answering",
        "relevance": 0.696
      },
      {
        "concept": "next token",
        "relevance": 0.645
      },
      {
        "concept": "question answering",
        "relevance": 0.643
      },
      {
        "concept": "decoding framework",
        "relevance": 0.641
      },
      {
        "concept": "public benchmarks",
        "relevance": 0.641
      },
      {
        "concept": "decoding direction",
        "relevance": 0.637
      },
      {
        "concept": "decoding process",
        "relevance": 0.635
      },
      {
        "concept": "decoding",
        "relevance": 0.619
      },
      {
        "concept": "supervised training",
        "relevance": 0.614
      },
      {
        "concept": "retrieval",
        "relevance": 0.58
      },
      {
        "concept": "experimental results",
        "relevance": 0.568
      },
      {
        "concept": "generation capability",
        "relevance": 0.53
      },
      {
        "concept": "retrieval outcomes",
        "relevance": 0.515
      },
      {
        "concept": "scalability",
        "relevance": 0.491
      },
      {
        "concept": "Unsupervised",
        "relevance": 0.488
      },
      {
        "concept": "granularity",
        "relevance": 0.477
      },
      {
        "concept": "tokens",
        "relevance": 0.47
      },
      {
        "concept": "benchmarks",
        "relevance": 0.46
      },
      {
        "concept": "applications",
        "relevance": 0.453
      },
      {
        "concept": "task",
        "relevance": 0.452
      },
      {
        "concept": "model",
        "relevance": 0.429
      },
      {
        "concept": "capability",
        "relevance": 0.418
      },
      {
        "concept": "framework",
        "relevance": 0.417
      },
      {
        "concept": "performance",
        "relevance": 0.415
      },
      {
        "concept": "training",
        "relevance": 0.412
      },
      {
        "concept": "separate components",
        "relevance": 0.401
      },
      {
        "concept": "answers",
        "relevance": 0.388
      },
      {
        "concept": "method",
        "relevance": 0.365
      },
      {
        "concept": "RID",
        "relevance": 0.33
      },
      {
        "concept": "generation",
        "relevance": 0.324
      },
      {
        "concept": "results",
        "relevance": 0.318
      },
      {
        "concept": "direction",
        "relevance": 0.308
      },
      {
        "concept": "components",
        "relevance": 0.292
      },
      {
        "concept": "impact",
        "relevance": 0.252
      },
      {
        "concept": "hallucinations",
        "relevance": 0.241
      },
      {
        "concept": "scale",
        "relevance": 0.241
      },
      {
        "concept": "effect",
        "relevance": 0.207
      },
      {
        "concept": "persistence",
        "relevance": 0.192
      },
      {
        "concept": "outcomes",
        "relevance": 0.176
      },
      {
        "concept": "intensive supervised training",
        "relevance": 0.086
      }
    ]
  },
  {
    "paperId": "pub.1158191617",
    "doi": "10.1016/j.jbi.2023.104392",
    "title": "KEBLM: Knowledge-Enhanced Biomedical Language Models",
    "year": 2023,
    "citationCount": 22,
    "fieldCitationRatio": 13.37,
    "abstract": "Pretrained language models (PLMs) have demonstrated strong performance on many natural language processing (NLP) tasks. Despite their great success, these PLMs are typically pretrained only on unstructured free texts without leveraging existing structured knowledge bases that are readily available for many domains, especially scientific domains. As a result, these PLMs may not achieve satisfactory performance on knowledge-intensive tasks such as biomedical NLP. Comprehending a complex biomedical document without domain-specific knowledge is challenging, even for humans. Inspired by this observation, we propose a general framework for incorporating various types of domain knowledge from multiple sources into biomedical PLMs. We encode domain knowledge using lightweight adapter modules, bottleneck feed-forward networks that are inserted into different locations of a backbone PLM. For each knowledge source of interest, we pretrain an adapter module to capture the knowledge in a self-supervised way. We design a wide range of self-supervised objectives to accommodate diverse types of knowledge, ranging from entity relations to description sentences. Once a set of pretrained adapters is available, we employ fusion layers to combine the knowledge encoded within these adapters for downstream tasks. Each fusion layer is a parameterized mixer of the available trained adapters that can identify and activate the most useful adapters for a given input. Our method diverges from prior work by including a knowledge consolidation phase, during which we teach the fusion layers to effectively combine knowledge from both the original PLM and newly-acquired external knowledge using a large collection of unannotated texts. After the consolidation phase, the complete knowledge-enhanced model can be fine-tuned for any downstream task of interest to achieve optimal performance. Extensive experiments on many biomedical NLP datasets show that our proposed framework consistently improves the performance of the underlying PLMs on various downstream tasks such as natural language inference, question answering, and entity linking. These results demonstrate the benefits of using multiple sources of external knowledge to enhance PLMs and the effectiveness of the framework for incorporating knowledge into PLMs. While primarily focused on the biomedical domain in this work, our framework is highly adaptable and can be easily applied to other domains, such as the bioenergy sector.",
    "reference_ids": [
      "pub.1139947541",
      "pub.1149582867",
      "pub.1122290388",
      "pub.1121025776",
      "pub.1149741100",
      "pub.1144245147",
      "pub.1122290022",
      "pub.1123987994",
      "pub.1143949144",
      "pub.1138840514",
      "pub.1144244942",
      "pub.1133177015",
      "pub.1133174582",
      "pub.1138840047",
      "pub.1143949139",
      "pub.1133177365",
      "pub.1007671778",
      "pub.1133177133",
      "pub.1138840297",
      "pub.1129756925",
      "pub.1025423384",
      "pub.1120882528",
      "pub.1121025797",
      "pub.1134315451",
      "pub.1117659358",
      "pub.1122290276",
      "pub.1143949235",
      "pub.1104321431",
      "pub.1117658833",
      "pub.1042802800",
      "pub.1018642423",
      "pub.1125558196",
      "pub.1133174689",
      "pub.1131699569",
      "pub.1143223923",
      "pub.1149741472",
      "pub.1121024731",
      "pub.1157699005",
      "pub.1141942664",
      "pub.1053001192",
      "pub.1032444382",
      "pub.1138840366",
      "pub.1163042455",
      "pub.1126568697",
      "pub.1142776637",
      "pub.1024359916",
      "pub.1122291182",
      "pub.1133177310",
      "pub.1133177161",
      "pub.1138840451",
      "pub.1139947540",
      "pub.1136507728",
      "pub.1142776598",
      "pub.1122290648"
    ],
    "concepts_scores": [
      {
        "concept": "Pretrained language models",
        "relevance": 0.846
      },
      {
        "concept": "natural language processing",
        "relevance": 0.817
      },
      {
        "concept": "downstream tasks",
        "relevance": 0.767
      },
      {
        "concept": "fusion layer",
        "relevance": 0.762
      },
      {
        "concept": "adaptive modulation",
        "relevance": 0.728
      },
      {
        "concept": "domain knowledge",
        "relevance": 0.722
      },
      {
        "concept": "biomedical NLP",
        "relevance": 0.699
      },
      {
        "concept": "external knowledge",
        "relevance": 0.69
      },
      {
        "concept": "encode domain knowledge",
        "relevance": 0.683
      },
      {
        "concept": "natural language inference",
        "relevance": 0.681
      },
      {
        "concept": "self-supervised objective",
        "relevance": 0.68
      },
      {
        "concept": "self-supervised way",
        "relevance": 0.679
      },
      {
        "concept": "knowledge-intensive tasks",
        "relevance": 0.674
      },
      {
        "concept": "feed-forward network",
        "relevance": 0.666
      },
      {
        "concept": "domain-specific knowledge",
        "relevance": 0.66
      },
      {
        "concept": "sources of external knowledge",
        "relevance": 0.639
      },
      {
        "concept": "language inference",
        "relevance": 0.631
      },
      {
        "concept": "biomedical documents",
        "relevance": 0.63
      },
      {
        "concept": "NLP datasets",
        "relevance": 0.629
      },
      {
        "concept": "unannotated text",
        "relevance": 0.628
      },
      {
        "concept": "entity relations",
        "relevance": 0.627
      },
      {
        "concept": "language model",
        "relevance": 0.624
      },
      {
        "concept": "description sentences",
        "relevance": 0.619
      },
      {
        "concept": "multiple sources",
        "relevance": 0.616
      },
      {
        "concept": "biomedical domain",
        "relevance": 0.613
      },
      {
        "concept": "language processing",
        "relevance": 0.61
      },
      {
        "concept": "knowledge sources",
        "relevance": 0.604
      },
      {
        "concept": "scientific domains",
        "relevance": 0.59
      },
      {
        "concept": "incorporating knowledge",
        "relevance": 0.564
      },
      {
        "concept": "optimal performance",
        "relevance": 0.557
      },
      {
        "concept": "satisfactory performance",
        "relevance": 0.553
      },
      {
        "concept": "task",
        "relevance": 0.55
      },
      {
        "concept": "performance",
        "relevance": 0.505
      },
      {
        "concept": "framework",
        "relevance": 0.498
      },
      {
        "concept": "domain",
        "relevance": 0.481
      },
      {
        "concept": "text",
        "relevance": 0.473
      },
      {
        "concept": "dataset",
        "relevance": 0.463
      },
      {
        "concept": "fusion",
        "relevance": 0.462
      },
      {
        "concept": "diverse types",
        "relevance": 0.459
      },
      {
        "concept": "network",
        "relevance": 0.457
      },
      {
        "concept": "adaptation",
        "relevance": 0.449
      },
      {
        "concept": "knowledge",
        "relevance": 0.445
      },
      {
        "concept": "modulation",
        "relevance": 0.443
      },
      {
        "concept": "bottleneck",
        "relevance": 0.43
      },
      {
        "concept": "entities",
        "relevance": 0.428
      },
      {
        "concept": "inference",
        "relevance": 0.422
      },
      {
        "concept": "input",
        "relevance": 0.414
      },
      {
        "concept": "documents",
        "relevance": 0.411
      },
      {
        "concept": "sentences",
        "relevance": 0.41
      },
      {
        "concept": "answers",
        "relevance": 0.381
      },
      {
        "concept": "objective",
        "relevance": 0.374
      },
      {
        "concept": "way",
        "relevance": 0.371
      },
      {
        "concept": "collection",
        "relevance": 0.362
      },
      {
        "concept": "results",
        "relevance": 0.361
      },
      {
        "concept": "method",
        "relevance": 0.359
      },
      {
        "concept": "layer",
        "relevance": 0.34
      },
      {
        "concept": "experiments",
        "relevance": 0.34
      },
      {
        "concept": "model",
        "relevance": 0.339
      },
      {
        "concept": "source",
        "relevance": 0.337
      },
      {
        "concept": "backbone",
        "relevance": 0.337
      },
      {
        "concept": "location",
        "relevance": 0.329
      },
      {
        "concept": "process",
        "relevance": 0.321
      },
      {
        "concept": "success",
        "relevance": 0.312
      },
      {
        "concept": "consolidation phase",
        "relevance": 0.31
      },
      {
        "concept": "relations",
        "relevance": 0.309
      },
      {
        "concept": "benefits",
        "relevance": 0.306
      },
      {
        "concept": "bioenergy sector",
        "relevance": 0.297
      },
      {
        "concept": "humans",
        "relevance": 0.276
      },
      {
        "concept": "sector",
        "relevance": 0.255
      },
      {
        "concept": "phase",
        "relevance": 0.244
      },
      {
        "concept": "consolidation",
        "relevance": 0.242
      },
      {
        "concept": "bioenergy",
        "relevance": 0.241
      },
      {
        "concept": "type",
        "relevance": 0.213
      },
      {
        "concept": "observations",
        "relevance": 0.211
      },
      {
        "concept": "effect",
        "relevance": 0.203
      },
      {
        "concept": "training adaptations",
        "relevance": 0.129
      }
    ]
  },
  {
    "paperId": "pub.1188503821",
    "doi": "10.1016/j.patter.2025.101260",
    "title": "Unleashing the potential of prompt engineering for large language models",
    "year": 2025,
    "citationCount": 34,
    "fieldCitationRatio": NaN,
    "abstract": "This review explores the role of prompt engineering in unleashing the capabilities of large language models (LLMs). Prompt engineering is the process of structuring inputs, and it has emerged as a crucial technique for maximizing the utility and accuracy of these models. Both foundational and advanced prompt engineering methodologies-including techniques such as self-consistency, chain of thought, and generated knowledge, which can significantly enhance the performance of models-are explored in this paper. Additionally, the prompt methods for vision language models (VLMs) are examined in detail. Prompt methods are evaluated with subjective and objective metrics, ensuring a robust analysis of their efficacy. Critical to this discussion is the role of prompt engineering in artificial intelligence (AI) security, particularly in terms of defending against adversarial attacks that exploit vulnerabilities in LLMs. Strategies for minimizing these risks and improving the robustness of models are thoroughly reviewed. Finally, we provide a perspective for future research and applications.",
    "reference_ids": [
      "pub.1173611067",
      "pub.1138840449",
      "pub.1163453782",
      "pub.1138840329",
      "pub.1184547889",
      "pub.1129756760",
      "pub.1163042759",
      "pub.1148391035",
      "pub.1163043523",
      "pub.1099239594",
      "pub.1164953222",
      "pub.1122290238",
      "pub.1091745067",
      "pub.1155707017",
      "pub.1159923121",
      "pub.1167704269",
      "pub.1119011509",
      "pub.1110957800",
      "pub.1169012331",
      "pub.1151003027",
      "pub.1166873105",
      "pub.1141488106",
      "pub.1186383719",
      "pub.1129756745",
      "pub.1158341488",
      "pub.1163041741",
      "pub.1158361897",
      "pub.1042471266",
      "pub.1163202410",
      "pub.1164652827",
      "pub.1163045629",
      "pub.1106836591",
      "pub.1166872523",
      "pub.1156284911",
      "pub.1119942002",
      "pub.1163045258",
      "pub.1166872601",
      "pub.1173668048",
      "pub.1181300513",
      "pub.1095689025",
      "pub.1118248807",
      "pub.1133175312",
      "pub.1158239195",
      "pub.1171209008",
      "pub.1166872963",
      "pub.1129757334",
      "pub.1160816829",
      "pub.1167214836",
      "pub.1174225436",
      "pub.1166872813",
      "pub.1169524205",
      "pub.1086020012",
      "pub.1142776495",
      "pub.1162828780",
      "pub.1144759870",
      "pub.1159713539",
      "pub.1099151247",
      "pub.1168149665",
      "pub.1134089846",
      "pub.1166874040",
      "pub.1174224985",
      "pub.1168623653",
      "pub.1181529909",
      "pub.1165740721",
      "pub.1168164334",
      "pub.1153159015",
      "pub.1181138665",
      "pub.1138840268",
      "pub.1148390689",
      "pub.1160112177",
      "pub.1162746839",
      "pub.1167121017",
      "pub.1139947391",
      "pub.1146213159",
      "pub.1164602558",
      "pub.1151542260",
      "pub.1174344528",
      "pub.1094434189",
      "pub.1166873008",
      "pub.1148392045",
      "pub.1166873409",
      "pub.1118846385",
      "pub.1182811106",
      "pub.1166874514",
      "pub.1181182965",
      "pub.1100517312",
      "pub.1166873572",
      "pub.1146529147",
      "pub.1143968638",
      "pub.1163041822",
      "pub.1167120181",
      "pub.1163202465",
      "pub.1153160608",
      "pub.1117659479",
      "pub.1173426407",
      "pub.1146568087",
      "pub.1100516895",
      "pub.1157451981",
      "pub.1142230135",
      "pub.1152843639",
      "pub.1166874234",
      "pub.1166326084",
      "pub.1174225012",
      "pub.1174225358",
      "pub.1069992014",
      "pub.1122836184",
      "pub.1166874093",
      "pub.1169306136",
      "pub.1119019253",
      "pub.1163042387",
      "pub.1168185210",
      "pub.1144345294",
      "pub.1004486097",
      "pub.1152457948",
      "pub.1181783493",
      "pub.1117659409",
      "pub.1142776637",
      "pub.1104321164",
      "pub.1166072902",
      "pub.1144813060",
      "pub.1148390668",
      "pub.1158690222",
      "pub.1099221859",
      "pub.1186384457",
      "pub.1162714876",
      "pub.1129912534",
      "pub.1163749577",
      "pub.1119380936",
      "pub.1104321260",
      "pub.1133177007",
      "pub.1144294277",
      "pub.1176108429",
      "pub.1138840503",
      "pub.1103872751",
      "pub.1085197870",
      "pub.1170135934",
      "pub.1137490222",
      "pub.1135710434",
      "pub.1099106180",
      "pub.1156285111",
      "pub.1182671428",
      "pub.1164950133",
      "pub.1091867527",
      "pub.1165107256",
      "pub.1148122507",
      "pub.1168571955",
      "pub.1169200607",
      "pub.1174210971",
      "pub.1163044055",
      "pub.1168589819",
      "pub.1169759590",
      "pub.1148955603",
      "pub.1151381237",
      "pub.1148955808",
      "pub.1146216268",
      "pub.1147575362",
      "pub.1046331338",
      "pub.1106022887",
      "pub.1172768010",
      "pub.1093185199",
      "pub.1117658905",
      "pub.1164085450",
      "pub.1149741329",
      "pub.1160112082",
      "pub.1167961737",
      "pub.1157850927",
      "pub.1137255428",
      "pub.1147270439",
      "pub.1148491215",
      "pub.1164165159",
      "pub.1167352304",
      "pub.1169950705",
      "pub.1174224873",
      "pub.1163043571",
      "pub.1172502541",
      "pub.1133174396",
      "pub.1158341539",
      "pub.1170033790",
      "pub.1144245142",
      "pub.1107278872",
      "pub.1137805304",
      "pub.1149741578",
      "pub.1105386676",
      "pub.1132407464",
      "pub.1158645207",
      "pub.1137338045",
      "pub.1133177134",
      "pub.1166873181",
      "pub.1186384176",
      "pub.1166873914",
      "pub.1129757067",
      "pub.1157651417",
      "pub.1182672043",
      "pub.1149883714",
      "pub.1140364067",
      "pub.1160562348",
      "pub.1166166707",
      "pub.1186383975",
      "pub.1152455541",
      "pub.1035636783",
      "pub.1129757433",
      "pub.1121050330",
      "pub.1167748832",
      "pub.1001058137",
      "pub.1168833282",
      "pub.1182812080",
      "pub.1174211627",
      "pub.1105443367",
      "pub.1136998164",
      "pub.1079258573",
      "pub.1135720228",
      "pub.1159923650",
      "pub.1152818767",
      "pub.1155419910",
      "pub.1133177071",
      "pub.1155675189",
      "pub.1139284689",
      "pub.1169887899",
      "pub.1148391651",
      "pub.1120590150",
      "pub.1118547396",
      "pub.1166872814",
      "pub.1163043683",
      "pub.1119017753",
      "pub.1158079085",
      "pub.1163544078",
      "pub.1182813830",
      "pub.1156443066",
      "pub.1123821190",
      "pub.1158341232",
      "pub.1166873752",
      "pub.1169030983",
      "pub.1132949057",
      "pub.1148390813",
      "pub.1148391071",
      "pub.1139748253",
      "pub.1172421242",
      "pub.1061548895",
      "pub.1099106113",
      "pub.1100516773",
      "pub.1144244999",
      "pub.1182671453",
      "pub.1099110501",
      "pub.1160816154",
      "pub.1182277194",
      "pub.1117658962"
    ],
    "concepts_scores": [
      {
        "concept": "vision-language models",
        "relevance": 0.708
      },
      {
        "concept": "language model",
        "relevance": 0.679
      },
      {
        "concept": "artificial intelligence",
        "relevance": 0.628
      },
      {
        "concept": "adversarial attacks",
        "relevance": 0.567
      },
      {
        "concept": "robustness of models",
        "relevance": 0.563
      },
      {
        "concept": "objective metrics",
        "relevance": 0.548
      },
      {
        "concept": "models—are",
        "relevance": 0.445
      },
      {
        "concept": "language",
        "relevance": 0.423
      },
      {
        "concept": "prompt method",
        "relevance": 0.421
      },
      {
        "concept": "security",
        "relevance": 0.417
      },
      {
        "concept": "engineering",
        "relevance": 0.411
      },
      {
        "concept": "intelligence",
        "relevance": 0.409
      },
      {
        "concept": "robustness analysis",
        "relevance": 0.408
      },
      {
        "concept": "attacks",
        "relevance": 0.403
      },
      {
        "concept": "metrics",
        "relevance": 0.402
      },
      {
        "concept": "robustness",
        "relevance": 0.394
      },
      {
        "concept": "accuracy",
        "relevance": 0.379
      },
      {
        "concept": "model",
        "relevance": 0.378
      },
      {
        "concept": "technique",
        "relevance": 0.378
      },
      {
        "concept": "LLM",
        "relevance": 0.375
      },
      {
        "concept": "vision",
        "relevance": 0.375
      },
      {
        "concept": "method",
        "relevance": 0.372
      },
      {
        "concept": "input",
        "relevance": 0.37
      },
      {
        "concept": "capability",
        "relevance": 0.368
      },
      {
        "concept": "performance",
        "relevance": 0.365
      },
      {
        "concept": "applications",
        "relevance": 0.344
      },
      {
        "concept": "vulnerability",
        "relevance": 0.333
      },
      {
        "concept": "knowledge",
        "relevance": 0.319
      },
      {
        "concept": "utilization",
        "relevance": 0.3
      },
      {
        "concept": "research",
        "relevance": 0.296
      },
      {
        "concept": "process",
        "relevance": 0.288
      },
      {
        "concept": "perspective",
        "relevance": 0.273
      },
      {
        "concept": "self-consistently",
        "relevance": 0.248
      },
      {
        "concept": "chain",
        "relevance": 0.242
      },
      {
        "concept": "discussion",
        "relevance": 0.237
      },
      {
        "concept": "analysis",
        "relevance": 0.23
      },
      {
        "concept": "potential",
        "relevance": 0.2
      },
      {
        "concept": "review",
        "relevance": 0.184
      },
      {
        "concept": "risk",
        "relevance": 0.15
      },
      {
        "concept": "efficacy",
        "relevance": 0.149
      }
    ]
  },
  {
    "paperId": "pub.1173638910",
    "doi": "10.1109/tmi.2024.3424505",
    "title": "Attribute Prototype-Guided Iterative Scene Graph for Explainable Radiology Report Generation",
    "year": 2024,
    "citationCount": 7,
    "fieldCitationRatio": NaN,
    "abstract": "The potential of automated radiology report generation in alleviating the time-consuming tasks of radiologists is increasingly being recognized in medical practice. Existing report generation methods have evolved from using image-level features to the latest approach of utilizing anatomical regions, significantly enhancing interpretability. However, directly and simplistically using region features for report generation compromises the capability of relation reasoning and overlooks the common attributes potentially shared across regions. To address these limitations, we propose a novel region-based Attribute Prototype-guided Iterative Scene Graph generation framework (AP-ISG) for report generation, utilizing scene graph generation as an auxiliary task to further enhance interpretability and relational reasoning capability. The core components of AP-ISG are the Iterative Scene Graph Generation (ISGG) module and the Attribute Prototype-guided Learning (APL) module. Specifically, ISSG employs an autoregressive scheme for structural edge reasoning and a contextualization mechanism for relational reasoning. APL enhances intra-prototype matching and reduces inter-prototype semantic overlap in the visual space to fully model the potential attribute commonalities among regions. Extensive experiments on the MIMIC-CXR with Chest ImaGenome datasets demonstrate the superiority of AP-ISG across multiple metrics.",
    "reference_ids": [
      "pub.1099110523",
      "pub.1157784544",
      "pub.1110720745",
      "pub.1100060663",
      "pub.1138840605",
      "pub.1152230852",
      "pub.1099239594",
      "pub.1095842441",
      "pub.1151033096",
      "pub.1139948082",
      "pub.1123309938",
      "pub.1095453245",
      "pub.1163452669",
      "pub.1094921617",
      "pub.1144245054",
      "pub.1153032788",
      "pub.1163403532",
      "pub.1139947508",
      "pub.1156453907",
      "pub.1126983463",
      "pub.1167960611",
      "pub.1123988156",
      "pub.1129913493",
      "pub.1095795137",
      "pub.1033848499",
      "pub.1163452276",
      "pub.1107454655",
      "pub.1147579807",
      "pub.1111810652",
      "pub.1151381491",
      "pub.1133125928",
      "pub.1170137042",
      "pub.1152722100",
      "pub.1163453062",
      "pub.1118769417",
      "pub.1141326853",
      "pub.1151335089",
      "pub.1137708367",
      "pub.1155419410",
      "pub.1133176873",
      "pub.1163453847",
      "pub.1059743951",
      "pub.1127839727",
      "pub.1142365944"
    ],
    "concepts_scores": [
      {
        "concept": "scene graph generation",
        "relevance": 0.801
      },
      {
        "concept": "radiology report generation",
        "relevance": 0.799
      },
      {
        "concept": "report generation",
        "relevance": 0.748
      },
      {
        "concept": "graph generation",
        "relevance": 0.732
      },
      {
        "concept": "scene graph generation frameworks",
        "relevance": 0.71
      },
      {
        "concept": "image-level features",
        "relevance": 0.688
      },
      {
        "concept": "tasks of radiologists",
        "relevance": 0.678
      },
      {
        "concept": "time consuming task",
        "relevance": 0.66
      },
      {
        "concept": "relational reasoning capabilities",
        "relevance": 0.657
      },
      {
        "concept": "scene graph",
        "relevance": 0.639
      },
      {
        "concept": "reasoning capabilities",
        "relevance": 0.634
      },
      {
        "concept": "MIMIC-CXR",
        "relevance": 0.631
      },
      {
        "concept": "generation framework",
        "relevance": 0.613
      },
      {
        "concept": "generation method",
        "relevance": 0.596
      },
      {
        "concept": "multiple metrics",
        "relevance": 0.595
      },
      {
        "concept": "relational reasoning",
        "relevance": 0.57
      },
      {
        "concept": "semantic overlap",
        "relevance": 0.566
      },
      {
        "concept": "enhance interpretation",
        "relevance": 0.546
      },
      {
        "concept": "regional features",
        "relevance": 0.545
      },
      {
        "concept": "visual space",
        "relevance": 0.545
      },
      {
        "concept": "contextual mechanisms",
        "relevance": 0.495
      },
      {
        "concept": "explainability",
        "relevance": 0.483
      },
      {
        "concept": "core components",
        "relevance": 0.483
      },
      {
        "concept": "capability",
        "relevance": 0.481
      },
      {
        "concept": "scene",
        "relevance": 0.472
      },
      {
        "concept": "dataset",
        "relevance": 0.469
      },
      {
        "concept": "features",
        "relevance": 0.46
      },
      {
        "concept": "metrics",
        "relevance": 0.454
      },
      {
        "concept": "graph",
        "relevance": 0.452
      },
      {
        "concept": "scheme",
        "relevance": 0.449
      },
      {
        "concept": "iteration",
        "relevance": 0.448
      },
      {
        "concept": "modulation",
        "relevance": 0.448
      },
      {
        "concept": "autoregressive scheme",
        "relevance": 0.446
      },
      {
        "concept": "superiority",
        "relevance": 0.433
      },
      {
        "concept": "reasons",
        "relevance": 0.429
      },
      {
        "concept": "matching",
        "relevance": 0.42
      },
      {
        "concept": "framework",
        "relevance": 0.414
      },
      {
        "concept": "generation",
        "relevance": 0.401
      },
      {
        "concept": "attributes",
        "relevance": 0.399
      },
      {
        "concept": "space",
        "relevance": 0.364
      },
      {
        "concept": "method",
        "relevance": 0.363
      },
      {
        "concept": "aPL",
        "relevance": 0.344
      },
      {
        "concept": "experiments",
        "relevance": 0.344
      },
      {
        "concept": "contextual",
        "relevance": 0.343
      },
      {
        "concept": "commonalities",
        "relevance": 0.331
      },
      {
        "concept": "interpretation",
        "relevance": 0.325
      },
      {
        "concept": "medical practice",
        "relevance": 0.313
      },
      {
        "concept": "radiologists",
        "relevance": 0.307
      },
      {
        "concept": "core",
        "relevance": 0.302
      },
      {
        "concept": "limitations",
        "relevance": 0.295
      },
      {
        "concept": "overlap",
        "relevance": 0.276
      },
      {
        "concept": "anatomical regions",
        "relevance": 0.274
      },
      {
        "concept": "ISSG",
        "relevance": 0.274
      },
      {
        "concept": "practice",
        "relevance": 0.266
      },
      {
        "concept": "region",
        "relevance": 0.249
      },
      {
        "concept": "mechanism",
        "relevance": 0.24
      },
      {
        "concept": "potential",
        "relevance": 0.22
      },
      {
        "concept": "reports",
        "relevance": 0.217
      }
    ]
  }
]